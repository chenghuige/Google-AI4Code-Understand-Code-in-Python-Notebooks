{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gezi.common import *\n",
    "sys.path.append('..')\n",
    "from src.config import *\n",
    "from src.preprocess import *\n",
    "from src.eval import *\n",
    "gezi.init_flags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/goldenlock/ai4code-base?scriptVersionId=101148262\n",
    "# 9025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../working/offline/6/0'\n",
    "context_model_name = 'deberta-v3-small.flag-context2-aug.n_context-40.cls_loss_rate-0.1.eval.p13-4'\n",
    "pairwise_model_name = 'all-mpnet-base-v2.flag-pairwise13-4.pooling_mask-attention_mask.grad_acc-4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc = gezi.load(f'{root}/{context_model_name}/valid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = gezi.load(f'{root}/{pairwise_model_name}/valid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gezi.sort_dict_byid_(xc, 'cid')\n",
    "gezi.sort_dict_byid_(xp, 'cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = set(xc['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0002115f48f982</td>\n",
       "      <td>[9ec225f0, 18281c6c, e3b6b115, 4a044c54, 365fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00062ab8487156</td>\n",
       "      <td>[dcad687f, a2e1fc80, 7d977ee8, 45a82a59, cbbc3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>000efd285fb982</td>\n",
       "      <td>[74a30f80, ee2c8e08, 5523374e, ae8f8fe8, 2138e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0012865b766949</td>\n",
       "      <td>[f9cb50e9, 25f7db90, d804e819, 6593a545, fc5bb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>001308991e0c5e</td>\n",
       "      <td>[21147235, 6c01d0d2, 5bd28595, b8fd3a8c, a2501...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                         cell_order\n",
       "4   0002115f48f982  [9ec225f0, 18281c6c, e3b6b115, 4a044c54, 365fe...\n",
       "11  00062ab8487156  [dcad687f, a2e1fc80, 7d977ee8, 45a82a59, cbbc3...\n",
       "28  000efd285fb982  [74a30f80, ee2c8e08, 5523374e, ae8f8fe8, 2138e...\n",
       "39  0012865b766949  [f9cb50e9, 25f7db90, d804e819, 6593a545, fc5bb...\n",
       "42  001308991e0c5e  [21147235, 6c01d0d2, 5bd28595, b8fd3a8c, a2501..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gt = pd.read_csv(f'{FLAGS.root}/train_orders.csv')\n",
    "df_gt = df_gt[df_gt.id.isin(ids)]\n",
    "df_gt['cell_order'] = df_gt['cell_order'].apply(lambda x: x.split())\n",
    "df_gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9006251692558017"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_metric(xc, 'reg_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8992880214723898"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_metric(xc, 'pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896173129530509"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_metric(xc, 'cls_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8966581181771137"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_metric(xp, 'cls_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9044248355992179"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = xc.copy()\n",
    "x['pred'] = xc['reg_pred'] * 0.5 + xp['cls_pred'] * 0.5\n",
    "calc_metric(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9018247872358709"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = xc.copy()\n",
    "x['pred'] = xc['cls_pred'] * 0.5 + xp['cls_pred'] * 0.5\n",
    "calc_metric(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9036697563235938"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = xc.copy()\n",
    "x['pred'] = xc['reg_pred'] * 0.5 + xp['pred'] * 0.5\n",
    "calc_metric(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(x, y, prob):\n",
    "  # return y\n",
    "  # return x\n",
    "  if prob > 0.9:\n",
    "    return x * (1 - 0.0001) + y * 0.0001\n",
    "  elif abs(y - x) < 0.1:\n",
    "    return x * (1 - 0.0001) + y * 0.0001\n",
    "  elif abs(y - x) < 0.2:\n",
    "    return x * 0.95 * prob + y * (1 - 0.95 * prob)\n",
    "  elif abs(y - x) < 0.3:\n",
    "    return x * 0.85 * prob + y * (1 - 0.85 * prob)\n",
    "  elif abs(y - x) < 0.4:\n",
    "    return x * 0.5 * prob + y * (1 - 0.5 * prob)\n",
    "  else:\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.908585923202479"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['pred'] = [merge(x, y, prob) for x, y, prob in zip(xp['pred'], xc['pred'], xp['max_prob'])]\n",
    "calc_metric(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = pd.DataFrame(xp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.DataFrame(gezi.batch2list(xc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_c.merge(df_p[['cid', 'pred', 'cls_pred', 'max_prob', 'max_sim', 'probs', 'sims']], on='cid', suffixes=['_c', '_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_feather('../working/train.fea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train.id.isin(ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_train[['cid', 'ancestor_id', 'n_words', 'source']], on='cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gezi.set_fold(df, 5, 'ancestor_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1038b6bbf2b4f06958aea2b2d752408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "top:   0%|          | 0/424943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f552bb34c8f140258e3b6574a4b87d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ctop:   0%|          | 0/424943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e20f17983b4292b7b31ceb66ab4138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rule:   0%|          | 0/424943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['pred_diff0'] = abs(df['pred_c'] - df['pred_p'])\n",
    "df['pred_diff1'] = abs(df['reg_pred'] - df['pred_p'])\n",
    "df['pred_diff2'] = abs(df['cls_pred_c'] - df['pred_p'])\n",
    "df['pred_diff3'] = abs(df['cls2_pred'] - df['pred_p'])\n",
    "df['markdown_frac'] = df['n_markdown_cell'] / df['n_cell']\n",
    "df['span'] = 1 / (df['n_code_cell'] + 1)\n",
    "top2, top3, top4, top5 = [], [], [], []\n",
    "top2_prob, top3_prob, top4_prob, top5_prob = [], [], [], []\n",
    "top2_sim, top3_sim, top4_sim, top5_sim = [], [], [], []\n",
    "for i in tqdm(range(len(df)), desc='top'):\n",
    "  # cls_preds = df['cls_pred_ori'].values[i]\n",
    "  n_code = df['n_code_cell'].values[i]\n",
    "  probs = df['probs'].values[i]\n",
    "  sims = df['sims'].values[i]\n",
    "  idxes = (-probs).argsort()\n",
    "  if len(idxes) > 1:\n",
    "    top2.append((idxes[1] + 0.5) / (n_code + 1))\n",
    "    top2_prob.append(probs[idxes[1]])\n",
    "    top2_sim.append(sims[idxes[1]])\n",
    "  else:\n",
    "    top2.append(-1)\n",
    "    top2_prob.append(-1)\n",
    "    top2_sim.append(-1)\n",
    "  if len(idxes) > 2:\n",
    "    top3.append((idxes[2] + 0.5) / (n_code + 1))\n",
    "    top3_prob.append(probs[idxes[2]])\n",
    "    top3_sim.append(sims[idxes[2]])\n",
    "  else:\n",
    "    top3.append(-1)\n",
    "    top3_prob.append(-1)\n",
    "    top3_sim.append(-1)\n",
    "  if len(idxes) > 3:\n",
    "    top4.append((idxes[3] + 0.5) / (n_code + 1))\n",
    "    top4_prob.append(probs[idxes[3]])\n",
    "    top4_sim.append(sims[idxes[3]])\n",
    "  else:\n",
    "    top4.append(-1)\n",
    "    top4_prob.append(-1)\n",
    "    top4_sim.append(-1)\n",
    "  if len(idxes) > 4:\n",
    "    top5.append((idxes[4] + 0.5) / (n_code + 1))\n",
    "    top5_prob.append(probs[idxes[4]])\n",
    "    top5_sim.append(sims[idxes[4]])\n",
    "  else:\n",
    "    top5.append(-1)\n",
    "    top5_prob.append(-1)\n",
    "    top5_sim.append(-1)\n",
    "ctop_prob, ctop2, ctop3, ctop4, ctop2_prob, ctop3_prob, ctop4_prob = [], [], [], [], [], [], []\n",
    "for i in tqdm(range(len(df)), desc='ctop'):\n",
    "  preds = df['cls_pred_ori'].values[i]\n",
    "  probs = gezi.softmax(preds)\n",
    "  idxes = (-probs).argsort()\n",
    "  ctop_prob.append(probs[idxes[0]])\n",
    "  ctop2.append((idxes[1] + 0.5) / FLAGS.num_classes)\n",
    "  ctop2_prob.append(probs[idxes[1]])\n",
    "  ctop3.append((idxes[2] + 0.5) / FLAGS.num_classes)\n",
    "  ctop3_prob.append(probs[idxes[2]])\n",
    "  ctop4.append((idxes[3] + 0.5) / FLAGS.num_classes)\n",
    "  ctop4_prob.append(probs[idxes[3]])\n",
    "# for i in range(FLAGS.num_classes):\n",
    "#   df[f'cls_pred{i}'] = df['cls_pred_ori'].apply(lambda x: x[i])\n",
    "df['top2'] = top2\n",
    "df['top2_prob'] = top2_prob\n",
    "df['top2_sim'] = top2_sim\n",
    "df['top3'] = top3\n",
    "df['top3_prob'] = top3_prob\n",
    "df['top3_sim'] = top3_sim\n",
    "df['top4'] = top4\n",
    "df['top4_prob'] = top4_prob\n",
    "df['top4_sim'] = top4_sim\n",
    "df['top5'] = top5\n",
    "df['top5_prob'] = top5_prob\n",
    "df['top5_sim'] = top5_sim\n",
    "df['ctop_prob'] = ctop_prob\n",
    "df['ctop2'] = ctop2\n",
    "df['ctop2_prob'] = ctop2_prob\n",
    "df['ctop3'] = ctop3\n",
    "df['ctop3_prob'] = ctop3_prob\n",
    "df['ctop4'] = ctop4\n",
    "df['ctop4_prob'] = ctop4_prob\n",
    "df['pred_diff4'] = abs(df['pred_c'] - df['top2'])\n",
    "df['pred_diff5'] = abs(df['reg_pred'] - df['top2'])\n",
    "df['pred_diff6'] = abs(df['cls_pred_c'] - df['top2'])\n",
    "df['pred_diff7'] = abs(df['cls2_pred'] - df['top2'])\n",
    "df['pred_diff8'] = abs(df['pred_p'] - df['top2'])\n",
    "df['pred_diff9'] = abs(df['cls_pred_c'] - df['top3'])\n",
    "df['pred_diff10'] = abs(df['pred_p'] - df['top3'])\n",
    "df['rule_pred'] = [merge(x, y, prob) for x, y, prob in tqdm(zip(df.pred_p.values, df.pred_c.values, df.max_prob.values), total=len(df), desc='rule')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_cols =  [\n",
    "          'n_code_cell',\n",
    "          'n_markdown_cell',\n",
    "          'n_cell',\n",
    "          'cls_pred_c',\n",
    "          'pred_c',\n",
    "          'reg_pred',\n",
    "          'cls2_pred',\n",
    "          'pred_p',\n",
    "          'cls_pred_p',\n",
    "          'rule_pred',\n",
    "          'pred_diff0',\n",
    "          'pred_diff1',\n",
    "          'pred_diff2',\n",
    "          'pred_diff3',\n",
    "          'pred_diff4',\n",
    "          'pred_diff5',\n",
    "          'pred_diff6',\n",
    "          'pred_diff7',\n",
    "          'pred_diff8',\n",
    "          'pred_diff9',\n",
    "          'pred_diff10',\n",
    "          'max_sim',\n",
    "          'max_prob',\n",
    "          'markdown_frac',\n",
    "          'span',\n",
    "          'top2',\n",
    "          'top2_prob',\n",
    "          'top2_sim',\n",
    "          'top3',\n",
    "          'top3_prob',\n",
    "          'top3_sim',\n",
    "          'top4',\n",
    "          'top4_prob',\n",
    "          'top4_sim',\n",
    "          'top5',\n",
    "          'top5_prob',\n",
    "          'top5_sim',\n",
    "          'ctop_prob', \n",
    "          'ctop2', \n",
    "          'ctop2_prob', \n",
    "        ]\n",
    "\n",
    "cat_cols = [\n",
    "          \n",
    "            ]\n",
    "label_col = 'rel_rank'\n",
    "cols = reg_cols + cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, Pool\n",
    "xgb_params = {'learning_rate': 0.02,\n",
    "              'reg_lambda': 7.960622217848342e-07, \n",
    "              'subsample': 0.7422597612762745,\n",
    "              'max_depth': 10, \n",
    "              'early_stopping_rounds': 500,\n",
    "              'n_estimators': 10000,\n",
    "              'cat_features': [],\n",
    "              'loss_function': 'MAE',\n",
    "              }\n",
    "\n",
    "xgb_params2 = {'learning_rate': 0.09827605967564293,'tree_method':'gpu_hist', 'gpu_id':0,\n",
    "               'early_stopping_rounds': 50,\n",
    "               'n_estimators': 10000, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2495f4d7a5049fd998c69e21447523d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2544365\ttest: 0.2544365\ttest1: 0.2543514\tbest: 0.2543514 (0)\ttotal: 77.7ms\tremaining: 12m 56s\n",
      "500:\tlearn: 0.0632407\ttest: 0.0632407\ttest1: 0.0656280\tbest: 0.0656280 (500)\ttotal: 32.6s\tremaining: 10m 18s\n",
      "1000:\tlearn: 0.0610853\ttest: 0.0610853\ttest1: 0.0647097\tbest: 0.0647097 (1000)\ttotal: 1m 4s\tremaining: 9m 38s\n",
      "1500:\tlearn: 0.0595594\ttest: 0.0595594\ttest1: 0.0644209\tbest: 0.0644209 (1500)\ttotal: 1m 37s\tremaining: 9m 10s\n",
      "2000:\tlearn: 0.0583866\ttest: 0.0583866\ttest1: 0.0643415\tbest: 0.0643407 (1993)\ttotal: 2m 12s\tremaining: 8m 48s\n",
      "2500:\tlearn: 0.0573591\ttest: 0.0573591\ttest1: 0.0644437\tbest: 0.0643313 (2133)\ttotal: 2m 46s\tremaining: 8m 18s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.06433133434\n",
      "bestIteration = 2133\n",
      "\n",
      "Shrink model to first 2134 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 17:05:43] 4047567722.py:19 in <module>\n",
      "                    abs(x['pred'] - dvalid['rel_rank']).mean(): 0.06579407253591144\n",
      "[07/19/22 17:05:45] 4047567722.py:21 in <module>\n",
      "                    fold: 0\n",
      "                    merge_score: 0.9070703368237418\n",
      "                    score: 0.9104315790384504\n",
      "                    score - merge_score: 0.0033612422147085708\n",
      "[07/19/22 17:05:45] 4047567722.py:24 in <module>\n",
      "                    fold: 0\n",
      "                    np.asarray(merge_scores).mean(): 0.9070703368237418\n",
      "                    np.asarray(scores).mean(): 0.9104315790384504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2544434\ttest: 0.2544434\ttest1: 0.2543537\tbest: 0.2543537 (0)\ttotal: 64.3ms\tremaining: 10m 43s\n",
      "500:\tlearn: 0.0634916\ttest: 0.0634916\ttest1: 0.0644702\tbest: 0.0644702 (500)\ttotal: 31.2s\tremaining: 9m 51s\n",
      "1000:\tlearn: 0.0613120\ttest: 0.0613120\ttest1: 0.0635332\tbest: 0.0635332 (1000)\ttotal: 1m 2s\tremaining: 9m 23s\n",
      "1500:\tlearn: 0.0597885\ttest: 0.0597885\ttest1: 0.0632748\tbest: 0.0632740 (1497)\ttotal: 1m 35s\tremaining: 9m 1s\n",
      "2000:\tlearn: 0.0586173\ttest: 0.0586173\ttest1: 0.0631869\tbest: 0.0631860 (1984)\ttotal: 2m 14s\tremaining: 8m 56s\n",
      "2500:\tlearn: 0.0576180\ttest: 0.0576180\ttest1: 0.0631791\tbest: 0.0631777 (2403)\ttotal: 2m 49s\tremaining: 8m 26s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.0631777357\n",
      "bestIteration = 2403\n",
      "\n",
      "Shrink model to first 2404 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 17:09:09] 4047567722.py:19 in <module>\n",
      "                    abs(x['pred'] - dvalid['rel_rank']).mean(): 0.06494859335498927\n",
      "[07/19/22 17:09:10] 4047567722.py:21 in <module>\n",
      "                    fold: 1\n",
      "                    merge_score: 0.9082661676659034\n",
      "                    score: 0.9113040501897806\n",
      "                    score - merge_score: 0.0030378825238771556\n",
      "[07/19/22 17:09:10] 4047567722.py:24 in <module>\n",
      "                    fold: 1\n",
      "                    np.asarray(merge_scores).mean(): 0.9076682522448226\n",
      "                    np.asarray(scores).mean(): 0.9108678146141155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2543568\ttest: 0.2543568\ttest1: 0.2547335\tbest: 0.2547335 (0)\ttotal: 87.2ms\tremaining: 14m 31s\n",
      "500:\tlearn: 0.0633974\ttest: 0.0633974\ttest1: 0.0645867\tbest: 0.0645867 (500)\ttotal: 35.2s\tremaining: 11m 6s\n",
      "1000:\tlearn: 0.0611939\ttest: 0.0611939\ttest1: 0.0636154\tbest: 0.0636149 (997)\ttotal: 1m 10s\tremaining: 10m 34s\n",
      "1500:\tlearn: 0.0597349\ttest: 0.0597349\ttest1: 0.0633332\tbest: 0.0633332 (1500)\ttotal: 1m 45s\tremaining: 9m 57s\n",
      "2000:\tlearn: 0.0585400\ttest: 0.0585400\ttest1: 0.0632418\tbest: 0.0632418 (2000)\ttotal: 2m 21s\tremaining: 9m 27s\n",
      "2500:\tlearn: 0.0575181\ttest: 0.0575181\ttest1: 0.0632323\tbest: 0.0632187 (2350)\ttotal: 2m 57s\tremaining: 8m 51s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.06321870254\n",
      "bestIteration = 2350\n",
      "\n",
      "Shrink model to first 2351 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 17:12:35] 4047567722.py:19 in <module>\n",
      "                    abs(x['pred'] - dvalid['rel_rank']).mean(): 0.06479006687657934\n",
      "[07/19/22 17:12:37] 4047567722.py:21 in <module>\n",
      "                    fold: 2\n",
      "                    merge_score: 0.9108612410210817\n",
      "                    score: 0.913384589045658\n",
      "                    score - merge_score: 0.002523348024576322\n",
      "[07/19/22 17:12:37] 4047567722.py:24 in <module>\n",
      "                    fold: 2\n",
      "                    np.asarray(merge_scores).mean(): 0.908732581836909\n",
      "                    np.asarray(scores).mean(): 0.9117067394246297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2544802\ttest: 0.2544802\ttest1: 0.2542154\tbest: 0.2542154 (0)\ttotal: 69.5ms\tremaining: 11m 34s\n",
      "500:\tlearn: 0.0639086\ttest: 0.0639086\ttest1: 0.0630433\tbest: 0.0630433 (500)\ttotal: 34.3s\tremaining: 10m 49s\n",
      "1000:\tlearn: 0.0617233\ttest: 0.0617233\ttest1: 0.0620711\tbest: 0.0620711 (1000)\ttotal: 1m 9s\tremaining: 10m 25s\n",
      "1500:\tlearn: 0.0602526\ttest: 0.0602526\ttest1: 0.0617742\tbest: 0.0617736 (1499)\ttotal: 1m 43s\tremaining: 9m 43s\n",
      "2000:\tlearn: 0.0590934\ttest: 0.0590934\ttest1: 0.0616766\tbest: 0.0616766 (2000)\ttotal: 2m 17s\tremaining: 9m 9s\n",
      "2500:\tlearn: 0.0582094\ttest: 0.0582094\ttest1: 0.0616503\tbest: 0.0616483 (2491)\ttotal: 2m 50s\tremaining: 8m 32s\n",
      "3000:\tlearn: 0.0574687\ttest: 0.0574687\ttest1: 0.0616585\tbest: 0.0616402 (2877)\ttotal: 3m 26s\tremaining: 8m 2s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.06164022083\n",
      "bestIteration = 2877\n",
      "\n",
      "Shrink model to first 2878 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 17:16:34] 4047567722.py:19 in <module>\n",
      "                    abs(x['pred'] - dvalid['rel_rank']).mean(): 0.06352573785829235\n",
      "[07/19/22 17:16:36] 4047567722.py:21 in <module>\n",
      "                    fold: 3\n",
      "                    merge_score: 0.912103082718156\n",
      "                    score: 0.9153450754329285\n",
      "                    score - merge_score: 0.003241992714772546\n",
      "[07/19/22 17:16:36] 4047567722.py:24 in <module>\n",
      "                    fold: 3\n",
      "                    np.asarray(merge_scores).mean(): 0.9095752070572207\n",
      "                    np.asarray(scores).mean(): 0.9126163234267044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2544156\ttest: 0.2544156\ttest1: 0.2545067\tbest: 0.2545067 (0)\ttotal: 75ms\tremaining: 12m 29s\n",
      "500:\tlearn: 0.0631691\ttest: 0.0631691\ttest1: 0.0656771\tbest: 0.0656771 (500)\ttotal: 36.2s\tremaining: 11m 25s\n",
      "1000:\tlearn: 0.0610502\ttest: 0.0610502\ttest1: 0.0647680\tbest: 0.0647674 (999)\ttotal: 1m 13s\tremaining: 10m 57s\n",
      "1500:\tlearn: 0.0595070\ttest: 0.0595070\ttest1: 0.0644590\tbest: 0.0644590 (1500)\ttotal: 1m 50s\tremaining: 10m 27s\n",
      "2000:\tlearn: 0.0583593\ttest: 0.0583593\ttest1: 0.0643696\tbest: 0.0643680 (1964)\ttotal: 2m 28s\tremaining: 9m 55s\n",
      "2500:\tlearn: 0.0573699\ttest: 0.0573699\ttest1: 0.0643467\tbest: 0.0643405 (2462)\ttotal: 3m 6s\tremaining: 9m 18s\n",
      "3000:\tlearn: 0.0566059\ttest: 0.0566059\ttest1: 0.0643463\tbest: 0.0643402 (2567)\ttotal: 3m 42s\tremaining: 8m 40s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.06434017347\n",
      "bestIteration = 2567\n",
      "\n",
      "Shrink model to first 2568 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 17:20:27] 4047567722.py:19 in <module>\n",
      "                    abs(x['pred'] - dvalid['rel_rank']).mean(): 0.06573988537486983\n",
      "[07/19/22 17:20:29] 4047567722.py:21 in <module>\n",
      "                    fold: 4\n",
      "                    merge_score: 0.9039693073200067\n",
      "                    score: 0.9063462862332429\n",
      "                    score - merge_score: 0.002376978913236183\n",
      "[07/19/22 17:20:29] 4047567722.py:24 in <module>\n",
      "                    fold: 4\n",
      "                    np.asarray(merge_scores).mean(): 0.908454027109778\n",
      "                    np.asarray(scores).mean(): 0.911362315988012\n"
     ]
    }
   ],
   "source": [
    "merge_scores = []\n",
    "scores = []\n",
    "for fold in tqdm(range(FOLDS)):\n",
    "  dvalid = df[df.fold==fold]\n",
    "  dtrain = df[df.fold!=fold]\n",
    "  X_train = dtrain[cols]\n",
    "  y_train = dtrain[label_col]\n",
    "  X_valid = dvalid[cols]\n",
    "  y_valid = dvalid[label_col]\n",
    "  model = CatBoostRegressor(**xgb_params)\n",
    "  model.fit(X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                verbose=500,\n",
    "                )  \n",
    "  dvalid['cb_pred'] = model.predict(dvalid[cols])\n",
    "  x = {'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values}\n",
    "  x['pred'] = [merge(x, y, prob) for x, y, prob in zip(dvalid.pred_p.values, dvalid.pred_c.values, dvalid.max_prob.values)]\n",
    "  merge_score = calc_metric(x, 'pred', df_gt)\n",
    "  ic(abs(x['pred'] - dvalid['rel_rank']).mean())\n",
    "  score = calc_metric({'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values, 'pred': dvalid.cb_pred.values})\n",
    "  ic(fold, merge_score, score, score - merge_score)\n",
    "  merge_scores.append(merge_score)\n",
    "  scores.append(score)\n",
    "  ic(fold, np.asarray(merge_scores).mean(), np.asarray(scores).mean())\n",
    "  model.save_model(f'../working/cbt/{fold}.cbt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'CatBoostRegressor' has no attribute 'startswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29313/495679720.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgezi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/work/pikachu/utils/gezi/plot.py\u001b[0m in \u001b[0;36mfeature_importance\u001b[0;34m(model, topn)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfeature_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m   \u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'catboost'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m     \u001b[0mfeat_importances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lightgbm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'CatBoostRegressor' has no attribute 'startswith'"
     ]
    }
   ],
   "source": [
    "gezi.plot.feature_importance(model, topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1925003cfa3979ae366740114cfe890bf8d7ad5b88e4afe0ec571fe261ed45e3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
