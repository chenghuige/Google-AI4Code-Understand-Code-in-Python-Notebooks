{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../../../../utils')\n",
    "sys.path.append('../../../../third')\n",
    "from gezi.common import *\n",
    "from src.config import *\n",
    "from src.preprocess import *\n",
    "from src.eval import *\n",
    "gezi.init_flags()\n",
    "gezi.set_pandas()\n",
    "root = FLAGS.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('../working/train.fea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cid</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa</td>\n",
       "      <td>0</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t0</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Machine Learning Engineer Nanodegree\\n## Unsupervised Learning\\n## Project 3: Creating Customer Segments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa</td>\n",
       "      <td>1</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t1</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Welcome to the third project of the Machine Learning Engineer Nanodegree! In this notebook, some template code has already been provided for you, and it will be your job to implement the additional functionality necessary to successfully complete this project. Sections that begin with **'Implementation'** in the header indicate that the following block of code will require additional functionality which you must provide. Instructions will be provided for each section and the specifics of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa</td>\n",
       "      <td>2</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t2</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Getting Started\\n\\nIn this project, you will analyze a dataset containing data on various customers' annual spending amounts (reported in *monetary units*) of diverse product categories for internal structure. One goal of this project is to best describe the variation in the different types of customers that a wholesale distributor interacts with. Doing so would equip the distributor with insight into how to best structure their delivery service to meet the needs of each customer.\\n\\nThe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa</td>\n",
       "      <td>3</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t3</td>\n",
       "      <td>code</td>\n",
       "      <td># Import libraries necessary for this project\\nimport numpy as np\\nimport pandas as pd\\nimport renders as rs\\nimport sklearn as sk\\nfrom IPython.display import display # Allows the use of display() for DataFrames\\n\\n# Show matplotlib plots inline (nicely formatted in the notebook)\\n%matplotlib inline\\n\\n# Load the wholesale customers dataset\\ntry:\\n    data = pd.read_csv(\"customers.csv\")\\n    data.drop(['Region', 'Channel'], axis = 1, inplace = True)\\n    print \"Wholesale customers dataset h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa</td>\n",
       "      <td>4</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t4</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Data Exploration\\nIn this section, you will begin exploring the data through visualizations and code to understand how each feature is related to the others. You will observe a statistical description of the dataset, consider the relevance of each feature, and select a few sample data points from the dataset which you will track through the course of this project.\\n\\nRun the code block below to observe a statistical description of the dataset. Note that the dataset is composed of six impo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671640</th>\n",
       "      <td>30</td>\n",
       "      <td>4e3a6e88f5a8104a98b7dcd2583bf3c1208603e4</td>\n",
       "      <td>30</td>\n",
       "      <td>4e3a6e88f5a8104a98b7dcd2583bf3c1208603e4\\t30</td>\n",
       "      <td>code</td>\n",
       "      <td>plot.plot_train_test_accuracy(train_acc,test_acc)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671641</th>\n",
       "      <td>31</td>\n",
       "      <td>4e3a6e88f5a8104a98b7dcd2583bf3c1208603e4</td>\n",
       "      <td>31</td>\n",
       "      <td>4e3a6e88f5a8104a98b7dcd2583bf3c1208603e4\\t31</td>\n",
       "      <td>code</td>\n",
       "      <td>import shutil\\ndef save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\\n    torch.save(state, filename)\\n    if is_best:\\n        shutil.copyfile(filename, 'model_best.pth.tar')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671642</th>\n",
       "      <td>32</td>\n",
       "      <td>4e3a6e88f5a8104a98b7dcd2583bf3c1208603e4</td>\n",
       "      <td>32</td>\n",
       "      <td>4e3a6e88f5a8104a98b7dcd2583bf3c1208603e4\\t32</td>\n",
       "      <td>code</td>\n",
       "      <td>misclassified_images = evaluate.show_misclassified_images(model, device, testloader, classes)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671643</th>\n",
       "      <td>33</td>\n",
       "      <td>4e3a6e88f5a8104a98b7dcd2583bf3c1208603e4</td>\n",
       "      <td>33</td>\n",
       "      <td>4e3a6e88f5a8104a98b7dcd2583bf3c1208603e4\\t33</td>\n",
       "      <td>markdown</td>\n",
       "      <td>**GradCam View of misclassified images(for all 4 layers)**\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671644</th>\n",
       "      <td>34</td>\n",
       "      <td>4e3a6e88f5a8104a98b7dcd2583bf3c1208603e4</td>\n",
       "      <td>34</td>\n",
       "      <td>4e3a6e88f5a8104a98b7dcd2583bf3c1208603e4\\t34</td>\n",
       "      <td>code</td>\n",
       "      <td>layers = [model.layer1,model.layer2,model.layer3,model.layer4]\\nmiscalssified_images = evaluate.show_misclassified_images(model, device, testloader, classes)\\ngradcam.GradCamView(miscalssified_images,model,classes,layers)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1671645 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                        id  cell_id  \\\n",
       "0            0  ce5245bdd39f3c0cec310ba65aac2e244f040cfa        0   \n",
       "1            1  ce5245bdd39f3c0cec310ba65aac2e244f040cfa        1   \n",
       "2            2  ce5245bdd39f3c0cec310ba65aac2e244f040cfa        2   \n",
       "3            3  ce5245bdd39f3c0cec310ba65aac2e244f040cfa        3   \n",
       "4            4  ce5245bdd39f3c0cec310ba65aac2e244f040cfa        4   \n",
       "...        ...                                       ...      ...   \n",
       "1671640     30  4e3a6e88f5a8104a98b7dcd2583bf3c1208603e4       30   \n",
       "1671641     31  4e3a6e88f5a8104a98b7dcd2583bf3c1208603e4       31   \n",
       "1671642     32  4e3a6e88f5a8104a98b7dcd2583bf3c1208603e4       32   \n",
       "1671643     33  4e3a6e88f5a8104a98b7dcd2583bf3c1208603e4       33   \n",
       "1671644     34  4e3a6e88f5a8104a98b7dcd2583bf3c1208603e4       34   \n",
       "\n",
       "                                                  cid cell_type  \\\n",
       "0         ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t0  markdown   \n",
       "1         ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t1  markdown   \n",
       "2         ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t2  markdown   \n",
       "3         ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t3      code   \n",
       "4         ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t4  markdown   \n",
       "...                                               ...       ...   \n",
       "1671640  4e3a6e88f5a8104a98b7dcd2583bf3c1208603e4\\t30      code   \n",
       "1671641  4e3a6e88f5a8104a98b7dcd2583bf3c1208603e4\\t31      code   \n",
       "1671642  4e3a6e88f5a8104a98b7dcd2583bf3c1208603e4\\t32      code   \n",
       "1671643  4e3a6e88f5a8104a98b7dcd2583bf3c1208603e4\\t33  markdown   \n",
       "1671644  4e3a6e88f5a8104a98b7dcd2583bf3c1208603e4\\t34      code   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      source  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                 # Machine Learning Engineer Nanodegree\\n## Unsupervised Learning\\n## Project 3: Creating Customer Segments  \n",
       "1        Welcome to the third project of the Machine Learning Engineer Nanodegree! In this notebook, some template code has already been provided for you, and it will be your job to implement the additional functionality necessary to successfully complete this project. Sections that begin with **'Implementation'** in the header indicate that the following block of code will require additional functionality which you must provide. Instructions will be provided for each section and the specifics of the...  \n",
       "2        ## Getting Started\\n\\nIn this project, you will analyze a dataset containing data on various customers' annual spending amounts (reported in *monetary units*) of diverse product categories for internal structure. One goal of this project is to best describe the variation in the different types of customers that a wholesale distributor interacts with. Doing so would equip the distributor with insight into how to best structure their delivery service to meet the needs of each customer.\\n\\nThe ...  \n",
       "3        # Import libraries necessary for this project\\nimport numpy as np\\nimport pandas as pd\\nimport renders as rs\\nimport sklearn as sk\\nfrom IPython.display import display # Allows the use of display() for DataFrames\\n\\n# Show matplotlib plots inline (nicely formatted in the notebook)\\n%matplotlib inline\\n\\n# Load the wholesale customers dataset\\ntry:\\n    data = pd.read_csv(\"customers.csv\")\\n    data.drop(['Region', 'Channel'], axis = 1, inplace = True)\\n    print \"Wholesale customers dataset h...  \n",
       "4        ## Data Exploration\\nIn this section, you will begin exploring the data through visualizations and code to understand how each feature is related to the others. You will observe a statistical description of the dataset, consider the relevance of each feature, and select a few sample data points from the dataset which you will track through the course of this project.\\n\\nRun the code block below to observe a statistical description of the dataset. Note that the dataset is composed of six impo...  \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...  \n",
       "1671640                                                                                                                                                                                                                                                                                                                                                                                                                                                                    plot.plot_train_test_accuracy(train_acc,test_acc)  \n",
       "1671641                                                                                                                                                                                                                                                                                                                        import shutil\\ndef save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\\n    torch.save(state, filename)\\n    if is_best:\\n        shutil.copyfile(filename, 'model_best.pth.tar')  \n",
       "1671642                                                                                                                                                                                                                                                                                                                                                                                                                        misclassified_images = evaluate.show_misclassified_images(model, device, testloader, classes)  \n",
       "1671643                                                                                                                                                                                                                                                                                                                                                                                                                                                         **GradCam View of misclassified images(for all 4 layers)**\\n  \n",
       "1671644                                                                                                                                                                                                                                                                                        layers = [model.layer1,model.layer2,model.layer3,model.layer4]\\nmiscalssified_images = evaluate.show_misclassified_images(model, device, testloader, classes)\\ngradcam.GradCamView(miscalssified_images,model,classes,layers)  \n",
       "\n",
       "[1671645 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.read_feather(f'{root}/ext_100000_0.fea')\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47670"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d.id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc43bf79b9a4b5f935c21130cb7dc00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cid</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa</td>\n",
       "      <td>0</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t0</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Machine Learning Engineer Nanodegree\\n## Unsupervised Learning\\n## Project 3: Creating Customer Segments</td>\n",
       "      <td># Machine Learning Engineer Nanodegree\\n## Unsupervised Learning\\n## Project 3: Creating Customer Segments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa</td>\n",
       "      <td>1</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t1</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Welcome to the third project of the Machine Learning Engineer Nanodegree! In this notebook, some template code has already been provided for you, and it will be your job to implement the additional functionality necessary to successfully complete this project. Sections that begin with **'Implementation'** in the header indicate that the following block of code will require additional functionality which you must provide. Instructions will be provided for each section and the specifics of the...</td>\n",
       "      <td>Welcome to the third project of the Machine Learning Engineer Nanodegree! In this notebook, some template code has already been provided for you, and it will be your job to implement the additional functionality necessary to successfully complete this project. Sections that begin with **'Implementation'** in the header indicate that the following block of code will require additional functionality which you must provide. Instructions will be provided for each section and the specifics of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa</td>\n",
       "      <td>2</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t2</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Getting Started\\n\\nIn this project, you will analyze a dataset containing data on various customers' annual spending amounts (reported in *monetary units*) of diverse product categories for internal structure. One goal of this project is to best describe the variation in the different types of customers that a wholesale distributor interacts with. Doing so would equip the distributor with insight into how to best structure their delivery service to meet the needs of each customer.\\n\\nThe ...</td>\n",
       "      <td>## Getting Started\\n\\nIn this project, you will analyze a dataset containing data on various customers' annual spending amounts (reported in *monetary units*) of diverse product categories for internal structure. One goal of this project is to best describe the variation in the different types of customers that a wholesale distributor interacts with. Doing so would equip the distributor with insight into how to best structure their delivery service to meet the needs of each customer.\\n\\nThe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa</td>\n",
       "      <td>3</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t3</td>\n",
       "      <td>code</td>\n",
       "      <td># Import libraries necessary for this project\\nimport numpy as np\\nimport pandas as pd\\nimport renders as rs\\nimport sklearn as sk\\nfrom IPython.display import display # Allows the use of display() for DataFrames\\n\\n# Show matplotlib plots inline (nicely formatted in the notebook)\\n%matplotlib inline\\n\\n# Load the wholesale customers dataset\\ntry:\\n    data = pd.read_csv(\"customers.csv\")\\n    data.drop(['Region', 'Channel'], axis = 1, inplace = True)\\n    print \"Wholesale customers dataset h...</td>\n",
       "      <td># Import libraries necessary for this project\\nimport numpy as np\\nimport pandas as pd\\nimport renders as rs\\nimport sklearn as sk\\nfrom IPython.display import display # Allows the use of display() for DataFrames\\n\\n# Show matplotlib plots inline (nicely formatted in the notebook)\\n%matplotlib inline\\n\\n# Load the wholesale customers dataset\\ntry:\\n    data = pd.read_csv(\"customers.csv\")\\n    data.drop(['Region', 'Channel'], axis = 1, inplace = True)\\n    print \"Wholesale customers dataset h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0000</td>\n",
       "      <td>4</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa</td>\n",
       "      <td>4</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t4</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Data Exploration\\nIn this section, you will begin exploring the data through visualizations and code to understand how each feature is related to the others. You will observe a statistical description of the dataset, consider the relevance of each feature, and select a few sample data points from the dataset which you will track through the course of this project.\\n\\nRun the code block below to observe a statistical description of the dataset. Note that the dataset is composed of six impo...</td>\n",
       "      <td>## Data Exploration\\nIn this section, you will begin exploring the data through visualizations and code to understand how each feature is related to the others. You will observe a statistical description of the dataset, consider the relevance of each feature, and select a few sample data points from the dataset which you will track through the course of this project.\\n\\nRun the code block below to observe a statistical description of the dataset. Note that the dataset is composed of six impo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36735299</th>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>032f879c4ebf7168f0815105466fa7fe3c456097</td>\n",
       "      <td>16</td>\n",
       "      <td>032f879c4ebf7168f0815105466fa7fe3c456097\\t16</td>\n",
       "      <td>code</td>\n",
       "      <td>## Predict on each test data point (and time it!)\\nt_before = time.time()\\ntest_predictions = [NN_classifier(test_data[i,]) for i in range(len(test_labels))]\\nt_after = time.time()\\n\\n## Compute the error\\nerr_positions = np.not_equal(test_predictions, test_labels)\\nerror = float(np.sum(err_positions))/len(test_labels)\\n\\nprint(\"Error of nearest neighbor classifier: \", error)\\nprint(\"Classification time (seconds): \", t_after - t_before)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36735300</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>032f879c4ebf7168f0815105466fa7fe3c456097</td>\n",
       "      <td>17</td>\n",
       "      <td>032f879c4ebf7168f0815105466fa7fe3c456097\\t17</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## 7. Faster nearest neighbor methods\\n\\nPerforming nearest neighbor classification in the way we have presented requires a full pass through the training set in order to classify a single point. If there are $N$ training points in $\\mathbb{R}^d$, this takes $O(N d)$ time.\\n\\nFortunately, there are faster methods to perform nearest neighbor look up if we are willing to spend some time preprocessing the training set. `scikit-learn` has fast implementations of two useful nearest neighbor data ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36735301</th>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>032f879c4ebf7168f0815105466fa7fe3c456097</td>\n",
       "      <td>18</td>\n",
       "      <td>032f879c4ebf7168f0815105466fa7fe3c456097\\t18</td>\n",
       "      <td>code</td>\n",
       "      <td>from sklearn.neighbors import BallTree\\n\\n## Build nearest neighbor structure on training data\\nt_before = time.time()\\nball_tree = BallTree(train_data)\\nt_after = time.time()\\n\\n## Compute training time\\nt_training = t_after - t_before\\nprint(\"Time to build data structure (seconds): \", t_training)\\n\\n## Get nearest neighbor predictions on testing data\\nt_before = time.time()\\ntest_neighbors = np.squeeze(ball_tree.query(test_data, k=1, return_distance=False))\\nball_tree_predictions = train_l...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36735302</th>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>032f879c4ebf7168f0815105466fa7fe3c456097</td>\n",
       "      <td>19</td>\n",
       "      <td>032f879c4ebf7168f0815105466fa7fe3c456097\\t19</td>\n",
       "      <td>code</td>\n",
       "      <td>from sklearn.neighbors import KDTree\\n\\n## Build nearest neighbor structure on training data\\nt_before = time.time()\\nkd_tree = KDTree(train_data)\\nt_after = time.time()\\n\\n## Compute training time\\nt_training = t_after - t_before\\nprint(\"Time to build data structure (seconds): \", t_training)\\n\\n## Get nearest neighbor predictions on testing data\\nt_before = time.time()\\ntest_neighbors = np.squeeze(kd_tree.query(test_data, k=1, return_distance=False))\\nkd_tree_predictions = train_labels[test...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36735303</th>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>032f879c4ebf7168f0815105466fa7fe3c456097</td>\n",
       "      <td>20</td>\n",
       "      <td>032f879c4ebf7168f0815105466fa7fe3c456097\\t20</td>\n",
       "      <td>code</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73470655 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          level_0  index                                        id cell_id  \\\n",
       "0          0.0000      0  ce5245bdd39f3c0cec310ba65aac2e244f040cfa       0   \n",
       "1          1.0000      1  ce5245bdd39f3c0cec310ba65aac2e244f040cfa       1   \n",
       "2          2.0000      2  ce5245bdd39f3c0cec310ba65aac2e244f040cfa       2   \n",
       "3          3.0000      3  ce5245bdd39f3c0cec310ba65aac2e244f040cfa       3   \n",
       "4          4.0000      4  ce5245bdd39f3c0cec310ba65aac2e244f040cfa       4   \n",
       "...           ...    ...                                       ...     ...   \n",
       "36735299      NaN     16  032f879c4ebf7168f0815105466fa7fe3c456097      16   \n",
       "36735300      NaN     17  032f879c4ebf7168f0815105466fa7fe3c456097      17   \n",
       "36735301      NaN     18  032f879c4ebf7168f0815105466fa7fe3c456097      18   \n",
       "36735302      NaN     19  032f879c4ebf7168f0815105466fa7fe3c456097      19   \n",
       "36735303      NaN     20  032f879c4ebf7168f0815105466fa7fe3c456097      20   \n",
       "\n",
       "                                                   cid cell_type  \\\n",
       "0          ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t0  markdown   \n",
       "1          ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t1  markdown   \n",
       "2          ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t2  markdown   \n",
       "3          ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t3      code   \n",
       "4          ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t4  markdown   \n",
       "...                                                ...       ...   \n",
       "36735299  032f879c4ebf7168f0815105466fa7fe3c456097\\t16      code   \n",
       "36735300  032f879c4ebf7168f0815105466fa7fe3c456097\\t17  markdown   \n",
       "36735301  032f879c4ebf7168f0815105466fa7fe3c456097\\t18      code   \n",
       "36735302  032f879c4ebf7168f0815105466fa7fe3c456097\\t19      code   \n",
       "36735303  032f879c4ebf7168f0815105466fa7fe3c456097\\t20      code   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       source  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                  # Machine Learning Engineer Nanodegree\\n## Unsupervised Learning\\n## Project 3: Creating Customer Segments   \n",
       "1         Welcome to the third project of the Machine Learning Engineer Nanodegree! In this notebook, some template code has already been provided for you, and it will be your job to implement the additional functionality necessary to successfully complete this project. Sections that begin with **'Implementation'** in the header indicate that the following block of code will require additional functionality which you must provide. Instructions will be provided for each section and the specifics of the...   \n",
       "2         ## Getting Started\\n\\nIn this project, you will analyze a dataset containing data on various customers' annual spending amounts (reported in *monetary units*) of diverse product categories for internal structure. One goal of this project is to best describe the variation in the different types of customers that a wholesale distributor interacts with. Doing so would equip the distributor with insight into how to best structure their delivery service to meet the needs of each customer.\\n\\nThe ...   \n",
       "3         # Import libraries necessary for this project\\nimport numpy as np\\nimport pandas as pd\\nimport renders as rs\\nimport sklearn as sk\\nfrom IPython.display import display # Allows the use of display() for DataFrames\\n\\n# Show matplotlib plots inline (nicely formatted in the notebook)\\n%matplotlib inline\\n\\n# Load the wholesale customers dataset\\ntry:\\n    data = pd.read_csv(\"customers.csv\")\\n    data.drop(['Region', 'Channel'], axis = 1, inplace = True)\\n    print \"Wholesale customers dataset h...   \n",
       "4         ## Data Exploration\\nIn this section, you will begin exploring the data through visualizations and code to understand how each feature is related to the others. You will observe a statistical description of the dataset, consider the relevance of each feature, and select a few sample data points from the dataset which you will track through the course of this project.\\n\\nRun the code block below to observe a statistical description of the dataset. Note that the dataset is composed of six impo...   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ...   \n",
       "36735299                                                             ## Predict on each test data point (and time it!)\\nt_before = time.time()\\ntest_predictions = [NN_classifier(test_data[i,]) for i in range(len(test_labels))]\\nt_after = time.time()\\n\\n## Compute the error\\nerr_positions = np.not_equal(test_predictions, test_labels)\\nerror = float(np.sum(err_positions))/len(test_labels)\\n\\nprint(\"Error of nearest neighbor classifier: \", error)\\nprint(\"Classification time (seconds): \", t_after - t_before)   \n",
       "36735300  ## 7. Faster nearest neighbor methods\\n\\nPerforming nearest neighbor classification in the way we have presented requires a full pass through the training set in order to classify a single point. If there are $N$ training points in $\\mathbb{R}^d$, this takes $O(N d)$ time.\\n\\nFortunately, there are faster methods to perform nearest neighbor look up if we are willing to spend some time preprocessing the training set. `scikit-learn` has fast implementations of two useful nearest neighbor data ...   \n",
       "36735301  from sklearn.neighbors import BallTree\\n\\n## Build nearest neighbor structure on training data\\nt_before = time.time()\\nball_tree = BallTree(train_data)\\nt_after = time.time()\\n\\n## Compute training time\\nt_training = t_after - t_before\\nprint(\"Time to build data structure (seconds): \", t_training)\\n\\n## Get nearest neighbor predictions on testing data\\nt_before = time.time()\\ntest_neighbors = np.squeeze(ball_tree.query(test_data, k=1, return_distance=False))\\nball_tree_predictions = train_l...   \n",
       "36735302  from sklearn.neighbors import KDTree\\n\\n## Build nearest neighbor structure on training data\\nt_before = time.time()\\nkd_tree = KDTree(train_data)\\nt_after = time.time()\\n\\n## Compute training time\\nt_training = t_after - t_before\\nprint(\"Time to build data structure (seconds): \", t_training)\\n\\n## Get nearest neighbor predictions on testing data\\nt_before = time.time()\\ntest_neighbors = np.squeeze(kd_tree.query(test_data, k=1, return_distance=False))\\nkd_tree_predictions = train_labels[test...   \n",
       "36735303                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 None   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        score  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                  # Machine Learning Engineer Nanodegree\\n## Unsupervised Learning\\n## Project 3: Creating Customer Segments  \n",
       "1         Welcome to the third project of the Machine Learning Engineer Nanodegree! In this notebook, some template code has already been provided for you, and it will be your job to implement the additional functionality necessary to successfully complete this project. Sections that begin with **'Implementation'** in the header indicate that the following block of code will require additional functionality which you must provide. Instructions will be provided for each section and the specifics of the...  \n",
       "2         ## Getting Started\\n\\nIn this project, you will analyze a dataset containing data on various customers' annual spending amounts (reported in *monetary units*) of diverse product categories for internal structure. One goal of this project is to best describe the variation in the different types of customers that a wholesale distributor interacts with. Doing so would equip the distributor with insight into how to best structure their delivery service to meet the needs of each customer.\\n\\nThe ...  \n",
       "3         # Import libraries necessary for this project\\nimport numpy as np\\nimport pandas as pd\\nimport renders as rs\\nimport sklearn as sk\\nfrom IPython.display import display # Allows the use of display() for DataFrames\\n\\n# Show matplotlib plots inline (nicely formatted in the notebook)\\n%matplotlib inline\\n\\n# Load the wholesale customers dataset\\ntry:\\n    data = pd.read_csv(\"customers.csv\")\\n    data.drop(['Region', 'Channel'], axis = 1, inplace = True)\\n    print \"Wholesale customers dataset h...  \n",
       "4         ## Data Exploration\\nIn this section, you will begin exploring the data through visualizations and code to understand how each feature is related to the others. You will observe a statistical description of the dataset, consider the relevance of each feature, and select a few sample data points from the dataset which you will track through the course of this project.\\n\\nRun the code block below to observe a statistical description of the dataset. Note that the dataset is composed of six impo...  \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ...  \n",
       "36735299                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  NaN  \n",
       "36735300                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  NaN  \n",
       "36735301                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  NaN  \n",
       "36735302                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  NaN  \n",
       "36735303                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  NaN  \n",
       "\n",
       "[73470655 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = []\n",
    "for i in tqdm(range(2)):\n",
    "  ds.append(pd.read_feather(f'{root}/ext_1000000_{i}.fea'))\n",
    "d = pd.concat(ds)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['cell_id'] = d['cell_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['score'] = d['source'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.reset_index().to_feather(f'{root}/ext_1000000_0.fea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                                                                                                                                                                                                                                                                                                                   # Machine Learning Engineer Nanodegree\\n## Unsupervised Learning\\n## Project 3: Creating Customer Segments\n",
       "1          Welcome to the third project of the Machine Learning Engineer Nanodegree! In this notebook, some template code has already been provided for you, and it will be your job to implement the additional functionality necessary to successfully complete this project. Sections that begin with **'Implementation'** in the header indicate that the following block of code will require additional functionality which you must provide. Instructions will be provided for each section and the specifics of the...\n",
       "2          ## Getting Started\\n\\nIn this project, you will analyze a dataset containing data on various customers' annual spending amounts (reported in *monetary units*) of diverse product categories for internal structure. One goal of this project is to best describe the variation in the different types of customers that a wholesale distributor interacts with. Doing so would equip the distributor with insight into how to best structure their delivery service to meet the needs of each customer.\\n\\nThe ...\n",
       "3          # Import libraries necessary for this project\\nimport numpy as np\\nimport pandas as pd\\nimport renders as rs\\nimport sklearn as sk\\nfrom IPython.display import display # Allows the use of display() for DataFrames\\n\\n# Show matplotlib plots inline (nicely formatted in the notebook)\\n%matplotlib inline\\n\\n# Load the wholesale customers dataset\\ntry:\\n    data = pd.read_csv(\"customers.csv\")\\n    data.drop(['Region', 'Channel'], axis = 1, inplace = True)\\n    print \"Wholesale customers dataset h...\n",
       "4          ## Data Exploration\\nIn this section, you will begin exploring the data through visualizations and code to understand how each feature is related to the others. You will observe a statistical description of the dataset, consider the relevance of each feature, and select a few sample data points from the dataset which you will track through the course of this project.\\n\\nRun the code block below to observe a statistical description of the dataset. Note that the dataset is composed of six impo...\n",
       "                                                                                                                                                                                                                                                                  ...                                                                                                                                                                                                                                                         \n",
       "3682424                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          data_frame.U.plot(kind='kde')\n",
       "3682425                                                  ## 5. Create a new column from Y divided by X\\nThis new column will allow us to figure out the magnitude of the lineair relation between X and Y that we have seen in the scatter plot of the two variables. For the new column, calculate the mean, variance and standard deviation, so we can learn about the distribution of the noise in the lineair relation. Also, it may make sense to plot the distribution of the difference to further visualize the noise.\n",
       "3682426                                                                                                                                                                                                                                                                                                                                                                                                                                          # Create the new column\\ndata_frame['X_over_Y'] = data_frame.Y / data_frame.X\n",
       "3682427                                                                                                                                                                                                                                                                                        # Get the statistics for the new column\\n# This shows us that on aveerage Y = 1.8 * X\\n# However, there is some noise, so Y = 1.8 * X + noise\\ndata_frame.X_over_Y.mean(), data_frame.X_over_Y.var(), data_frame.X_over_Y.std()\n",
       "3682428                                                                                                                                                                                                                                                                                                                                                                                                    # Here we see that the distribution of the noise\\n# appears to be a normal distribution\\ndata_frame.X_over_Y.hist()\n",
       "Name: source, Length: 36735351, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_66926/3129101571.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_words'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/envs/pku/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         \"\"\"\n\u001b[0;32m-> 4357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[0;32m~/envs/pku/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/pku/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m                     \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m                 )\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/pku/lib/python3.7/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_66926/3129101571.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_words'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "d['n_words'] = d.source.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cid</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>8</td>\n",
       "      <td>4a1220c255be5705f6ef0ed39b29122f236c70a0</td>\n",
       "      <td>8</td>\n",
       "      <td>4a1220c255be5705f6ef0ed39b29122f236c70a0\\t8</td>\n",
       "      <td>code</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>10</td>\n",
       "      <td>4a1220c255be5705f6ef0ed39b29122f236c70a0</td>\n",
       "      <td>10</td>\n",
       "      <td>4a1220c255be5705f6ef0ed39b29122f236c70a0\\t10</td>\n",
       "      <td>code</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>12</td>\n",
       "      <td>4a1220c255be5705f6ef0ed39b29122f236c70a0</td>\n",
       "      <td>12</td>\n",
       "      <td>4a1220c255be5705f6ef0ed39b29122f236c70a0\\t12</td>\n",
       "      <td>code</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>14</td>\n",
       "      <td>4a1220c255be5705f6ef0ed39b29122f236c70a0</td>\n",
       "      <td>14</td>\n",
       "      <td>4a1220c255be5705f6ef0ed39b29122f236c70a0\\t14</td>\n",
       "      <td>code</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>16</td>\n",
       "      <td>4a1220c255be5705f6ef0ed39b29122f236c70a0</td>\n",
       "      <td>16</td>\n",
       "      <td>4a1220c255be5705f6ef0ed39b29122f236c70a0\\t16</td>\n",
       "      <td>code</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3682204</th>\n",
       "      <td>42</td>\n",
       "      <td>7d12a3a9e5bab2efd8e147ddd714e9b36f6d02e2</td>\n",
       "      <td>42</td>\n",
       "      <td>7d12a3a9e5bab2efd8e147ddd714e9b36f6d02e2\\t42</td>\n",
       "      <td>code</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3682315</th>\n",
       "      <td>6</td>\n",
       "      <td>a3a6e9efd2e7de89e349bf84a8e345131d0b836d</td>\n",
       "      <td>6</td>\n",
       "      <td>a3a6e9efd2e7de89e349bf84a8e345131d0b836d\\t6</td>\n",
       "      <td>code</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3682364</th>\n",
       "      <td>2</td>\n",
       "      <td>eb732c19e6a9deca682c4a1cc7b534597be7823d</td>\n",
       "      <td>2</td>\n",
       "      <td>eb732c19e6a9deca682c4a1cc7b534597be7823d\\t2</td>\n",
       "      <td>code</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3682395</th>\n",
       "      <td>33</td>\n",
       "      <td>eb732c19e6a9deca682c4a1cc7b534597be7823d</td>\n",
       "      <td>33</td>\n",
       "      <td>eb732c19e6a9deca682c4a1cc7b534597be7823d\\t33</td>\n",
       "      <td>code</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3682409</th>\n",
       "      <td>47</td>\n",
       "      <td>eb732c19e6a9deca682c4a1cc7b534597be7823d</td>\n",
       "      <td>47</td>\n",
       "      <td>eb732c19e6a9deca682c4a1cc7b534597be7823d\\t47</td>\n",
       "      <td>code</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1304512 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                        id cell_id  \\\n",
       "87           8  4a1220c255be5705f6ef0ed39b29122f236c70a0       8   \n",
       "89          10  4a1220c255be5705f6ef0ed39b29122f236c70a0      10   \n",
       "91          12  4a1220c255be5705f6ef0ed39b29122f236c70a0      12   \n",
       "93          14  4a1220c255be5705f6ef0ed39b29122f236c70a0      14   \n",
       "95          16  4a1220c255be5705f6ef0ed39b29122f236c70a0      16   \n",
       "...        ...                                       ...     ...   \n",
       "3682204     42  7d12a3a9e5bab2efd8e147ddd714e9b36f6d02e2      42   \n",
       "3682315      6  a3a6e9efd2e7de89e349bf84a8e345131d0b836d       6   \n",
       "3682364      2  eb732c19e6a9deca682c4a1cc7b534597be7823d       2   \n",
       "3682395     33  eb732c19e6a9deca682c4a1cc7b534597be7823d      33   \n",
       "3682409     47  eb732c19e6a9deca682c4a1cc7b534597be7823d      47   \n",
       "\n",
       "                                                  cid cell_type source score  \n",
       "87        4a1220c255be5705f6ef0ed39b29122f236c70a0\\t8      code   None  None  \n",
       "89       4a1220c255be5705f6ef0ed39b29122f236c70a0\\t10      code   None  None  \n",
       "91       4a1220c255be5705f6ef0ed39b29122f236c70a0\\t12      code   None  None  \n",
       "93       4a1220c255be5705f6ef0ed39b29122f236c70a0\\t14      code   None  None  \n",
       "95       4a1220c255be5705f6ef0ed39b29122f236c70a0\\t16      code   None  None  \n",
       "...                                               ...       ...    ...   ...  \n",
       "3682204  7d12a3a9e5bab2efd8e147ddd714e9b36f6d02e2\\t42      code   None  None  \n",
       "3682315   a3a6e9efd2e7de89e349bf84a8e345131d0b836d\\t6      code   None  None  \n",
       "3682364   eb732c19e6a9deca682c4a1cc7b534597be7823d\\t2      code   None  None  \n",
       "3682395  eb732c19e6a9deca682c4a1cc7b534597be7823d\\t33      code   None  None  \n",
       "3682409  eb732c19e6a9deca682c4a1cc7b534597be7823d\\t47      code   None  None  \n",
       "\n",
       "[1304512 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[d.source.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ids = set(d[d.source.isnull()].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cid</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa</td>\n",
       "      <td>0</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t0</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Machine Learning Engineer Nanodegree\\n## Unsupervised Learning\\n## Project 3: Creating Customer Segments</td>\n",
       "      <td># Machine Learning Engineer Nanodegree\\n## Unsupervised Learning\\n## Project 3: Creating Customer Segments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa</td>\n",
       "      <td>1</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t1</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Welcome to the third project of the Machine Learning Engineer Nanodegree! In this notebook, some template code has already been provided for you, and it will be your job to implement the additional functionality necessary to successfully complete this project. Sections that begin with **'Implementation'** in the header indicate that the following block of code will require additional functionality which you must provide. Instructions will be provided for each section and the specifics of the...</td>\n",
       "      <td>Welcome to the third project of the Machine Learning Engineer Nanodegree! In this notebook, some template code has already been provided for you, and it will be your job to implement the additional functionality necessary to successfully complete this project. Sections that begin with **'Implementation'** in the header indicate that the following block of code will require additional functionality which you must provide. Instructions will be provided for each section and the specifics of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa</td>\n",
       "      <td>2</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t2</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Getting Started\\n\\nIn this project, you will analyze a dataset containing data on various customers' annual spending amounts (reported in *monetary units*) of diverse product categories for internal structure. One goal of this project is to best describe the variation in the different types of customers that a wholesale distributor interacts with. Doing so would equip the distributor with insight into how to best structure their delivery service to meet the needs of each customer.\\n\\nThe ...</td>\n",
       "      <td>## Getting Started\\n\\nIn this project, you will analyze a dataset containing data on various customers' annual spending amounts (reported in *monetary units*) of diverse product categories for internal structure. One goal of this project is to best describe the variation in the different types of customers that a wholesale distributor interacts with. Doing so would equip the distributor with insight into how to best structure their delivery service to meet the needs of each customer.\\n\\nThe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa</td>\n",
       "      <td>3</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t3</td>\n",
       "      <td>code</td>\n",
       "      <td># Import libraries necessary for this project\\nimport numpy as np\\nimport pandas as pd\\nimport renders as rs\\nimport sklearn as sk\\nfrom IPython.display import display # Allows the use of display() for DataFrames\\n\\n# Show matplotlib plots inline (nicely formatted in the notebook)\\n%matplotlib inline\\n\\n# Load the wholesale customers dataset\\ntry:\\n    data = pd.read_csv(\"customers.csv\")\\n    data.drop(['Region', 'Channel'], axis = 1, inplace = True)\\n    print \"Wholesale customers dataset h...</td>\n",
       "      <td># Import libraries necessary for this project\\nimport numpy as np\\nimport pandas as pd\\nimport renders as rs\\nimport sklearn as sk\\nfrom IPython.display import display # Allows the use of display() for DataFrames\\n\\n# Show matplotlib plots inline (nicely formatted in the notebook)\\n%matplotlib inline\\n\\n# Load the wholesale customers dataset\\ntry:\\n    data = pd.read_csv(\"customers.csv\")\\n    data.drop(['Region', 'Channel'], axis = 1, inplace = True)\\n    print \"Wholesale customers dataset h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa</td>\n",
       "      <td>4</td>\n",
       "      <td>ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t4</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Data Exploration\\nIn this section, you will begin exploring the data through visualizations and code to understand how each feature is related to the others. You will observe a statistical description of the dataset, consider the relevance of each feature, and select a few sample data points from the dataset which you will track through the course of this project.\\n\\nRun the code block below to observe a statistical description of the dataset. Note that the dataset is composed of six impo...</td>\n",
       "      <td>## Data Exploration\\nIn this section, you will begin exploring the data through visualizations and code to understand how each feature is related to the others. You will observe a statistical description of the dataset, consider the relevance of each feature, and select a few sample data points from the dataset which you will track through the course of this project.\\n\\nRun the code block below to observe a statistical description of the dataset. Note that the dataset is composed of six impo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3682424</th>\n",
       "      <td>14</td>\n",
       "      <td>3abd245696a173c98ca08dabb7bdb0733d6714e7</td>\n",
       "      <td>14</td>\n",
       "      <td>3abd245696a173c98ca08dabb7bdb0733d6714e7\\t14</td>\n",
       "      <td>code</td>\n",
       "      <td>data_frame.U.plot(kind='kde')</td>\n",
       "      <td>data_frame.U.plot(kind='kde')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3682425</th>\n",
       "      <td>15</td>\n",
       "      <td>3abd245696a173c98ca08dabb7bdb0733d6714e7</td>\n",
       "      <td>15</td>\n",
       "      <td>3abd245696a173c98ca08dabb7bdb0733d6714e7\\t15</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## 5. Create a new column from Y divided by X\\nThis new column will allow us to figure out the magnitude of the lineair relation between X and Y that we have seen in the scatter plot of the two variables. For the new column, calculate the mean, variance and standard deviation, so we can learn about the distribution of the noise in the lineair relation. Also, it may make sense to plot the distribution of the difference to further visualize the noise.</td>\n",
       "      <td>## 5. Create a new column from Y divided by X\\nThis new column will allow us to figure out the magnitude of the lineair relation between X and Y that we have seen in the scatter plot of the two variables. For the new column, calculate the mean, variance and standard deviation, so we can learn about the distribution of the noise in the lineair relation. Also, it may make sense to plot the distribution of the difference to further visualize the noise.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3682426</th>\n",
       "      <td>16</td>\n",
       "      <td>3abd245696a173c98ca08dabb7bdb0733d6714e7</td>\n",
       "      <td>16</td>\n",
       "      <td>3abd245696a173c98ca08dabb7bdb0733d6714e7\\t16</td>\n",
       "      <td>code</td>\n",
       "      <td># Create the new column\\ndata_frame['X_over_Y'] = data_frame.Y / data_frame.X</td>\n",
       "      <td># Create the new column\\ndata_frame['X_over_Y'] = data_frame.Y / data_frame.X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3682427</th>\n",
       "      <td>17</td>\n",
       "      <td>3abd245696a173c98ca08dabb7bdb0733d6714e7</td>\n",
       "      <td>17</td>\n",
       "      <td>3abd245696a173c98ca08dabb7bdb0733d6714e7\\t17</td>\n",
       "      <td>code</td>\n",
       "      <td># Get the statistics for the new column\\n# This shows us that on aveerage Y = 1.8 * X\\n# However, there is some noise, so Y = 1.8 * X + noise\\ndata_frame.X_over_Y.mean(), data_frame.X_over_Y.var(), data_frame.X_over_Y.std()</td>\n",
       "      <td># Get the statistics for the new column\\n# This shows us that on aveerage Y = 1.8 * X\\n# However, there is some noise, so Y = 1.8 * X + noise\\ndata_frame.X_over_Y.mean(), data_frame.X_over_Y.var(), data_frame.X_over_Y.std()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3682428</th>\n",
       "      <td>18</td>\n",
       "      <td>3abd245696a173c98ca08dabb7bdb0733d6714e7</td>\n",
       "      <td>18</td>\n",
       "      <td>3abd245696a173c98ca08dabb7bdb0733d6714e7\\t18</td>\n",
       "      <td>code</td>\n",
       "      <td># Here we see that the distribution of the noise\\n# appears to be a normal distribution\\ndata_frame.X_over_Y.hist()</td>\n",
       "      <td># Here we see that the distribution of the noise\\n# appears to be a normal distribution\\ndata_frame.X_over_Y.hist()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16672245 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                        id cell_id  \\\n",
       "0            0  ce5245bdd39f3c0cec310ba65aac2e244f040cfa       0   \n",
       "1            1  ce5245bdd39f3c0cec310ba65aac2e244f040cfa       1   \n",
       "2            2  ce5245bdd39f3c0cec310ba65aac2e244f040cfa       2   \n",
       "3            3  ce5245bdd39f3c0cec310ba65aac2e244f040cfa       3   \n",
       "4            4  ce5245bdd39f3c0cec310ba65aac2e244f040cfa       4   \n",
       "...        ...                                       ...     ...   \n",
       "3682424     14  3abd245696a173c98ca08dabb7bdb0733d6714e7      14   \n",
       "3682425     15  3abd245696a173c98ca08dabb7bdb0733d6714e7      15   \n",
       "3682426     16  3abd245696a173c98ca08dabb7bdb0733d6714e7      16   \n",
       "3682427     17  3abd245696a173c98ca08dabb7bdb0733d6714e7      17   \n",
       "3682428     18  3abd245696a173c98ca08dabb7bdb0733d6714e7      18   \n",
       "\n",
       "                                                  cid cell_type  \\\n",
       "0         ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t0  markdown   \n",
       "1         ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t1  markdown   \n",
       "2         ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t2  markdown   \n",
       "3         ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t3      code   \n",
       "4         ce5245bdd39f3c0cec310ba65aac2e244f040cfa\\t4  markdown   \n",
       "...                                               ...       ...   \n",
       "3682424  3abd245696a173c98ca08dabb7bdb0733d6714e7\\t14      code   \n",
       "3682425  3abd245696a173c98ca08dabb7bdb0733d6714e7\\t15  markdown   \n",
       "3682426  3abd245696a173c98ca08dabb7bdb0733d6714e7\\t16      code   \n",
       "3682427  3abd245696a173c98ca08dabb7bdb0733d6714e7\\t17      code   \n",
       "3682428  3abd245696a173c98ca08dabb7bdb0733d6714e7\\t18      code   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      source  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                 # Machine Learning Engineer Nanodegree\\n## Unsupervised Learning\\n## Project 3: Creating Customer Segments   \n",
       "1        Welcome to the third project of the Machine Learning Engineer Nanodegree! In this notebook, some template code has already been provided for you, and it will be your job to implement the additional functionality necessary to successfully complete this project. Sections that begin with **'Implementation'** in the header indicate that the following block of code will require additional functionality which you must provide. Instructions will be provided for each section and the specifics of the...   \n",
       "2        ## Getting Started\\n\\nIn this project, you will analyze a dataset containing data on various customers' annual spending amounts (reported in *monetary units*) of diverse product categories for internal structure. One goal of this project is to best describe the variation in the different types of customers that a wholesale distributor interacts with. Doing so would equip the distributor with insight into how to best structure their delivery service to meet the needs of each customer.\\n\\nThe ...   \n",
       "3        # Import libraries necessary for this project\\nimport numpy as np\\nimport pandas as pd\\nimport renders as rs\\nimport sklearn as sk\\nfrom IPython.display import display # Allows the use of display() for DataFrames\\n\\n# Show matplotlib plots inline (nicely formatted in the notebook)\\n%matplotlib inline\\n\\n# Load the wholesale customers dataset\\ntry:\\n    data = pd.read_csv(\"customers.csv\")\\n    data.drop(['Region', 'Channel'], axis = 1, inplace = True)\\n    print \"Wholesale customers dataset h...   \n",
       "4        ## Data Exploration\\nIn this section, you will begin exploring the data through visualizations and code to understand how each feature is related to the others. You will observe a statistical description of the dataset, consider the relevance of each feature, and select a few sample data points from the dataset which you will track through the course of this project.\\n\\nRun the code block below to observe a statistical description of the dataset. Note that the dataset is composed of six impo...   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...   \n",
       "3682424                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        data_frame.U.plot(kind='kde')   \n",
       "3682425                                                ## 5. Create a new column from Y divided by X\\nThis new column will allow us to figure out the magnitude of the lineair relation between X and Y that we have seen in the scatter plot of the two variables. For the new column, calculate the mean, variance and standard deviation, so we can learn about the distribution of the noise in the lineair relation. Also, it may make sense to plot the distribution of the difference to further visualize the noise.   \n",
       "3682426                                                                                                                                                                                                                                                                                                                                                                                                                                        # Create the new column\\ndata_frame['X_over_Y'] = data_frame.Y / data_frame.X   \n",
       "3682427                                                                                                                                                                                                                                                                                      # Get the statistics for the new column\\n# This shows us that on aveerage Y = 1.8 * X\\n# However, there is some noise, so Y = 1.8 * X + noise\\ndata_frame.X_over_Y.mean(), data_frame.X_over_Y.var(), data_frame.X_over_Y.std()   \n",
       "3682428                                                                                                                                                                                                                                                                                                                                                                                                  # Here we see that the distribution of the noise\\n# appears to be a normal distribution\\ndata_frame.X_over_Y.hist()   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       score  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                 # Machine Learning Engineer Nanodegree\\n## Unsupervised Learning\\n## Project 3: Creating Customer Segments  \n",
       "1        Welcome to the third project of the Machine Learning Engineer Nanodegree! In this notebook, some template code has already been provided for you, and it will be your job to implement the additional functionality necessary to successfully complete this project. Sections that begin with **'Implementation'** in the header indicate that the following block of code will require additional functionality which you must provide. Instructions will be provided for each section and the specifics of the...  \n",
       "2        ## Getting Started\\n\\nIn this project, you will analyze a dataset containing data on various customers' annual spending amounts (reported in *monetary units*) of diverse product categories for internal structure. One goal of this project is to best describe the variation in the different types of customers that a wholesale distributor interacts with. Doing so would equip the distributor with insight into how to best structure their delivery service to meet the needs of each customer.\\n\\nThe ...  \n",
       "3        # Import libraries necessary for this project\\nimport numpy as np\\nimport pandas as pd\\nimport renders as rs\\nimport sklearn as sk\\nfrom IPython.display import display # Allows the use of display() for DataFrames\\n\\n# Show matplotlib plots inline (nicely formatted in the notebook)\\n%matplotlib inline\\n\\n# Load the wholesale customers dataset\\ntry:\\n    data = pd.read_csv(\"customers.csv\")\\n    data.drop(['Region', 'Channel'], axis = 1, inplace = True)\\n    print \"Wholesale customers dataset h...  \n",
       "4        ## Data Exploration\\nIn this section, you will begin exploring the data through visualizations and code to understand how each feature is related to the others. You will observe a statistical description of the dataset, consider the relevance of each feature, and select a few sample data points from the dataset which you will track through the course of this project.\\n\\nRun the code block below to observe a statistical description of the dataset. Note that the dataset is composed of six impo...  \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...  \n",
       "3682424                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        data_frame.U.plot(kind='kde')  \n",
       "3682425                                                ## 5. Create a new column from Y divided by X\\nThis new column will allow us to figure out the magnitude of the lineair relation between X and Y that we have seen in the scatter plot of the two variables. For the new column, calculate the mean, variance and standard deviation, so we can learn about the distribution of the noise in the lineair relation. Also, it may make sense to plot the distribution of the difference to further visualize the noise.  \n",
       "3682426                                                                                                                                                                                                                                                                                                                                                                                                                                        # Create the new column\\ndata_frame['X_over_Y'] = data_frame.Y / data_frame.X  \n",
       "3682427                                                                                                                                                                                                                                                                                      # Get the statistics for the new column\\n# This shows us that on aveerage Y = 1.8 * X\\n# However, there is some noise, so Y = 1.8 * X + noise\\ndata_frame.X_over_Y.mean(), data_frame.X_over_Y.var(), data_frame.X_over_Y.std()  \n",
       "3682428                                                                                                                                                                                                                                                                                                                                                                                                  # Here we see that the distribution of the noise\\n# appears to be a normal distribution\\ndata_frame.X_over_Y.hist()  \n",
       "\n",
       "[16672245 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = d[~d.id.isin(bad_ids)]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000001"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d.id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139256"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>n_words</th>\n",
       "      <th>cid</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>n_cell</th>\n",
       "      <th>n_code_cell</th>\n",
       "      <th>n_markdown_cell</th>\n",
       "      <th>markdown_frac</th>\n",
       "      <th>rank</th>\n",
       "      <th>code_rank</th>\n",
       "      <th>markdown_rank</th>\n",
       "      <th>rel_rank</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>fold</th>\n",
       "      <th>worker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1862f0a6</td>\n",
       "      <td>code</td>\n",
       "      <td># This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\\n# For example, here's several helpful packages to load\\n\\nimport numpy as np # linear algebra\\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\\n\\n# Input data files are available in the read-only \"../input/\" directory\\n# For example, running this (by clicking run or pressing Shift+Enter) will list...</td>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>140</td>\n",
       "      <td>00001756c60be8\\t1862f0a6</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>None</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>448eb224</td>\n",
       "      <td>markdown</td>\n",
       "      <td>**Импортируем необходимые для работы функции и классы**</td>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>7</td>\n",
       "      <td>00001756c60be8\\t448eb224</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>None</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2a9e43d6</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np\\nimport pandas as pd\\nimport random\\n\\nfrom sklearn.model_selection import train_test_split, cross_val_score\\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\\nfrom catboost import CatBoostRegressor\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.metrics import r2_score as r2\\nfrom sklearn.model_selection import KFold, GridSearchCV\\n\\nfrom datetime import datetime\\n\\nimport matplotlib\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n...</td>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>55</td>\n",
       "      <td>00001756c60be8\\t2a9e43d6</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>None</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0645</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7e2f170a</td>\n",
       "      <td>markdown</td>\n",
       "      <td>**Подключаем предупреждения**</td>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>2</td>\n",
       "      <td>00001756c60be8\\t7e2f170a</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>None</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>038b763d</td>\n",
       "      <td>code</td>\n",
       "      <td>import warnings\\nwarnings.filterwarnings('ignore')</td>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>3</td>\n",
       "      <td>00001756c60be8\\t038b763d</td>\n",
       "      <td>945aea18</td>\n",
       "      <td>None</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.0702</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370641</th>\n",
       "      <td>5369934b</td>\n",
       "      <td>markdown</td>\n",
       "      <td>* We have achieved 80.8% accuracy in predicting the prices of the homes in Banglore using LinearRegression Algorithm</td>\n",
       "      <td>fffe1d764579d5</td>\n",
       "      <td>18</td>\n",
       "      <td>fffe1d764579d5\\t5369934b</td>\n",
       "      <td>3c40bfa6</td>\n",
       "      <td>None</td>\n",
       "      <td>72</td>\n",
       "      <td>61</td>\n",
       "      <td>11</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>67</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.9597</td>\n",
       "      <td>0.9437</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370642</th>\n",
       "      <td>ac9db030</td>\n",
       "      <td>code</td>\n",
       "      <td>from sklearn.tree import DecisionTreeRegressor\\ndtr = DecisionTreeRegressor()\\ndtr.fit(x_train,y_train)\\nscore_dtr = 100*dtr.score(x_test,y_test)\\nprint(f'DTR Model score = {score_dtr:4.3f}%')</td>\n",
       "      <td>fffe1d764579d5</td>\n",
       "      <td>16</td>\n",
       "      <td>fffe1d764579d5\\tac9db030</td>\n",
       "      <td>3c40bfa6</td>\n",
       "      <td>None</td>\n",
       "      <td>72</td>\n",
       "      <td>61</td>\n",
       "      <td>11</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>68</td>\n",
       "      <td>59</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.9677</td>\n",
       "      <td>0.9577</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370643</th>\n",
       "      <td>a8ffc8b4</td>\n",
       "      <td>markdown</td>\n",
       "      <td>* We have achieved 75.2% accuracy in predicting the prices of the homes in Banglore using Decision Tree Regressor</td>\n",
       "      <td>fffe1d764579d5</td>\n",
       "      <td>19</td>\n",
       "      <td>fffe1d764579d5\\ta8ffc8b4</td>\n",
       "      <td>3c40bfa6</td>\n",
       "      <td>None</td>\n",
       "      <td>72</td>\n",
       "      <td>61</td>\n",
       "      <td>11</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>69</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.9718</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370644</th>\n",
       "      <td>70455170</td>\n",
       "      <td>code</td>\n",
       "      <td>from sklearn.ensemble import RandomForestRegressor\\nrfr = RandomForestRegressor()\\nrfr.fit(x_train,y_train)\\nscore_rfr = 100*rfr.score(x_test,y_test)\\nprint(f'RFR Model score = {score_rfr:4.3f}%')</td>\n",
       "      <td>fffe1d764579d5</td>\n",
       "      <td>16</td>\n",
       "      <td>fffe1d764579d5\\t70455170</td>\n",
       "      <td>3c40bfa6</td>\n",
       "      <td>None</td>\n",
       "      <td>72</td>\n",
       "      <td>61</td>\n",
       "      <td>11</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.9839</td>\n",
       "      <td>0.9859</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370645</th>\n",
       "      <td>380852e6</td>\n",
       "      <td>markdown</td>\n",
       "      <td>* We have achieved 85.5% accuracy in predicting the prices of homes in Banglore using Random Forest Regressor</td>\n",
       "      <td>fffe1d764579d5</td>\n",
       "      <td>18</td>\n",
       "      <td>fffe1d764579d5\\t380852e6</td>\n",
       "      <td>3c40bfa6</td>\n",
       "      <td>None</td>\n",
       "      <td>72</td>\n",
       "      <td>61</td>\n",
       "      <td>11</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>71</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9919</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6370646 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cell_id cell_type  \\\n",
       "0        1862f0a6      code   \n",
       "1        448eb224  markdown   \n",
       "2        2a9e43d6      code   \n",
       "3        7e2f170a  markdown   \n",
       "4        038b763d      code   \n",
       "...           ...       ...   \n",
       "6370641  5369934b  markdown   \n",
       "6370642  ac9db030      code   \n",
       "6370643  a8ffc8b4  markdown   \n",
       "6370644  70455170      code   \n",
       "6370645  380852e6  markdown   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      source  \\\n",
       "0        # This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\\n# For example, here's several helpful packages to load\\n\\nimport numpy as np # linear algebra\\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\\n\\n# Input data files are available in the read-only \"../input/\" directory\\n# For example, running this (by clicking run or pressing Shift+Enter) will list...   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                    **Импортируем необходимые для работы функции и классы**   \n",
       "2        import numpy as np\\nimport pandas as pd\\nimport random\\n\\nfrom sklearn.model_selection import train_test_split, cross_val_score\\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\\nfrom catboost import CatBoostRegressor\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.metrics import r2_score as r2\\nfrom sklearn.model_selection import KFold, GridSearchCV\\n\\nfrom datetime import datetime\\n\\nimport matplotlib\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n...   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              **Подключаем предупреждения**   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                         import warnings\\nwarnings.filterwarnings('ignore')   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...   \n",
       "6370641                                                                                                                                                                                                                                                                                                                                                                                                 * We have achieved 80.8% accuracy in predicting the prices of the homes in Banglore using LinearRegression Algorithm   \n",
       "6370642                                                                                                                                                                                                                                                                                                                     from sklearn.tree import DecisionTreeRegressor\\ndtr = DecisionTreeRegressor()\\ndtr.fit(x_train,y_train)\\nscore_dtr = 100*dtr.score(x_test,y_test)\\nprint(f'DTR Model score = {score_dtr:4.3f}%')   \n",
       "6370643                                                                                                                                                                                                                                                                                                                                                                                                   * We have achieved 75.2% accuracy in predicting the prices of the homes in Banglore using Decision Tree Regressor    \n",
       "6370644                                                                                                                                                                                                                                                                                                                 from sklearn.ensemble import RandomForestRegressor\\nrfr = RandomForestRegressor()\\nrfr.fit(x_train,y_train)\\nscore_rfr = 100*rfr.score(x_test,y_test)\\nprint(f'RFR Model score = {score_rfr:4.3f}%')   \n",
       "6370645                                                                                                                                                                                                                                                                                                                                                                                                       * We have achieved 85.5% accuracy in predicting the prices of homes in Banglore using Random Forest Regressor    \n",
       "\n",
       "                     id  n_words                       cid ancestor_id  \\\n",
       "0        00001756c60be8      140  00001756c60be8\\t1862f0a6    945aea18   \n",
       "1        00001756c60be8        7  00001756c60be8\\t448eb224    945aea18   \n",
       "2        00001756c60be8       55  00001756c60be8\\t2a9e43d6    945aea18   \n",
       "3        00001756c60be8        2  00001756c60be8\\t7e2f170a    945aea18   \n",
       "4        00001756c60be8        3  00001756c60be8\\t038b763d    945aea18   \n",
       "...                 ...      ...                       ...         ...   \n",
       "6370641  fffe1d764579d5       18  fffe1d764579d5\\t5369934b    3c40bfa6   \n",
       "6370642  fffe1d764579d5       16  fffe1d764579d5\\tac9db030    3c40bfa6   \n",
       "6370643  fffe1d764579d5       19  fffe1d764579d5\\ta8ffc8b4    3c40bfa6   \n",
       "6370644  fffe1d764579d5       16  fffe1d764579d5\\t70455170    3c40bfa6   \n",
       "6370645  fffe1d764579d5       18  fffe1d764579d5\\t380852e6    3c40bfa6   \n",
       "\n",
       "        parent_id  n_cell  n_code_cell  n_markdown_cell  markdown_frac  rank  \\\n",
       "0            None      58           30               28         0.4828     0   \n",
       "1            None      58           30               28         0.4828     1   \n",
       "2            None      58           30               28         0.4828     2   \n",
       "3            None      58           30               28         0.4828     3   \n",
       "4            None      58           30               28         0.4828     4   \n",
       "...           ...     ...          ...              ...            ...   ...   \n",
       "6370641      None      72           61               11         0.1528    67   \n",
       "6370642      None      72           61               11         0.1528    68   \n",
       "6370643      None      72           61               11         0.1528    69   \n",
       "6370644      None      72           61               11         0.1528    70   \n",
       "6370645      None      72           61               11         0.1528    71   \n",
       "\n",
       "         code_rank  markdown_rank  rel_rank  pct_rank  fold  worker  \n",
       "0                0             -1    0.0323    0.0000     2      42  \n",
       "1               -1              0    0.0484    0.0175     2      27  \n",
       "2                1             -1    0.0645    0.0351     2      72  \n",
       "3               -1              1    0.0806    0.0526     2      22  \n",
       "4                2             -1    0.0968    0.0702     2       7  \n",
       "...            ...            ...       ...       ...   ...     ...  \n",
       "6370641         -1              8    0.9597    0.9437     3      48  \n",
       "6370642         59             -1    0.9677    0.9577     3      28  \n",
       "6370643         -1              9    0.9758    0.9718     3      48  \n",
       "6370644         60             -1    0.9839    0.9859     3      58  \n",
       "6370645         -1             10    0.9919    1.0000     3      68  \n",
       "\n",
       "[6370646 rows x 19 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125372"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.ancestor_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ancestor_id'] = df.ancestor_id.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>n_words</th>\n",
       "      <th>cid</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>n_cell</th>\n",
       "      <th>n_code_cell</th>\n",
       "      <th>n_markdown_cell</th>\n",
       "      <th>markdown_frac</th>\n",
       "      <th>rank</th>\n",
       "      <th>code_rank</th>\n",
       "      <th>markdown_rank</th>\n",
       "      <th>rel_rank</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>fold</th>\n",
       "      <th>worker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [cell_id, cell_type, source, id, n_words, cid, ancestor_id, parent_id, n_cell, n_code_cell, n_markdown_cell, markdown_frac, rank, code_rank, markdown_rank, rel_rank, pct_rank, fold, worker]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.ancestor_id=='NaN'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>n_words</th>\n",
       "      <th>cid</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>n_cell</th>\n",
       "      <th>n_code_cell</th>\n",
       "      <th>n_markdown_cell</th>\n",
       "      <th>markdown_frac</th>\n",
       "      <th>rank</th>\n",
       "      <th>code_rank</th>\n",
       "      <th>markdown_rank</th>\n",
       "      <th>rel_rank</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>fold</th>\n",
       "      <th>worker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [cell_id, cell_type, source, id, n_words, cid, ancestor_id, parent_id, n_cell, n_code_cell, n_markdown_cell, markdown_frac, rank, code_rank, markdown_rank, rel_rank, pct_rank, fold, worker]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.source.str.contains('Welcome to the third project of the Machine Learning Engineer Nanodegree')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\t\t\t lm.all-mpnet-base-v2.fea\tsample_submission.csv\n",
      "ai4code-custom-data\t lm.all-mpnet-base-v2.lbl.fea\ttest\n",
      "ai4code-custom-data.zip  lm.all-mpnet-base-v2.lbld.fea\ttest2\n",
      "cache\t\t\t lm.deberta-v3-small.fea\ttrain\n",
      "dfs\t\t\t lm.deberta-v3-small.lbl.fea\ttrain.fea\n",
      "ext_100_0.fea\t\t lm.deberta-v3-small.lbld.fea\ttrain2.fea\n",
      "ext_100_0.feather\t ntbs\t\t\t\ttrain_ancestors.csv\n",
      "ext_200000_0.fea\t ntbs_list.json\t\t\ttrain_orders.csv\n",
      "ext_20000_0.fea\t\t pretrain\t\t\tw2v\n"
     ]
    }
   ],
   "source": [
    "!ls ../input/AI4Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld = pd.read_feather(f'{root}/lm.deberta-v3-small.lbld.fea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df[df.fold!=0].id) & set(ld[ld.fold==0].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_feather('../input/AI4Code/lm.ext_100000_0.deberta-v3-small.lbld.fea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[07/29/22 16:10:37] preprocess.py:43 in get_tokenizer()\n",
      "                    tokenizer.is_fast: True\n"
     ]
    }
   ],
   "source": [
    "tok = get_tokenizer('microsoft/deberta-v3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]|▁[|\\'|#|▁K|-|Mean|▁|觀|察|▁:|▁|使用|輪|[UNK]|分析|\\'|,|▁\\'|#|▁[|作|業|目|標|]|\\\\|n|-|▁|試|著|模|仿|範|例|寫|法|,|▁|利用|隨|機|生成|的|▁5|▁|群|高|斯|分|布|資|料|,|▁|以|輪|[UNK]|分析|來|觀|察|▁K|-|mean|▁|分|群|時|不|同|▁K|▁|值|的|比|較|\\'|,|▁\\'|#|▁[|作|業|重|點|]|\\\\|n|-|▁|使用|輪|[UNK]|分析|的|圖|表|,|▁|以及|實|際|的|分|群|散|佈|圖|,|▁|觀|察|▁K|-|Mean|▁|分|群|法|在|▁K|▁|有|所|不|同|時|,|▁|分|群|的|效|果|如|何|變|化|▁(|In|[|3|]|,|▁Out|[|3|]|)|\\'|,|▁\\'|#|▁|作|業|\\\\|n|*|▁|試|著|模|擬|出|▁5|▁|群|高|斯|分|布|的|資|料|,|▁|並|以|此|觀|察|▁K|-|mean|▁|與|輪|[UNK]|分析|的|結|果|▁\\'|,|▁\\'|#|▁|載|入|套|件|\\\\|n|import|▁num|py|▁as|▁np|\\\\|n|import|▁mat|plot|lib|\\\\|n|import|▁mat|plot|lib|.|py|plot|▁as|▁pl|t|\\\\|n|import|▁mat|plot|lib|.|cm|▁as|▁cm|\\\\|n|from|▁sk|learn|.|data|sets|▁import|▁make|_|blob|s|\\\\|n|from|▁sk|learn|.|cluster|▁import|▁KM|eans|\\\\|n|from|▁sk|learn|▁import|▁datasets|\\\\|n|from|▁sk|learn|.|metrics|▁import|▁silhouette|_|sample|s|,|▁silhouette|_|score|\\\\|n|\\\\|nn|p|.|random|.|seed|(|5|)|\\\\|n|\\\\|n|%|mat|plot|lib|▁inline|\\'|,|▁\\'|#|▁|生成|▁5|▁|群|資|料|\\\\|n|X|,|▁y|▁=|▁make|_|blob|s|(|n|_|sample|s|=|500|,|\\\\|n|▁n|_|features|=|2|,|\\\\|n|▁centers|=|5|,|\\\\|n|▁cluster|_|st|d|=|1|,|\\\\|n|▁center|_|box|=|(|-|10|.|0|,|▁10|.|0|)|,|\\\\|n|▁shuffle|=|True|,|\\\\|n|▁random|_|state|=|123|)|▁\\\\|n|\\\\|n|#|▁|設|定|需要|計|算|的|▁K|▁|值|集|合|\\\\|n|range|_|n|_|cluster|s|▁=|▁[|2|,|▁3|,|▁4|,|▁5|,|▁6|,|▁7|,|▁8|]|\\'|,|▁\\'|#|▁|計|算|並|繪|製|輪|[UNK]|分析|的|結|果|\\\\|n|#|▁|計|算|並|繪|製|輪|[UNK]|分析|的|結|果|\\\\|n|#|▁|因|下|列|為|[UNK]|圈|寫|法|,|▁|無|法|再|分|拆|為|更|小|執|行|區|塊|,|▁|請|見|[UNK]|\\\\|n|for|▁n|_|cluster|s|▁in|▁range|_|n|_|cluster|s|:|\\\\|n|▁#|▁|設|定|小|圖|排|版|為|▁1|▁row|▁2|▁columns|\\\\|n|▁fig|,|▁(|ax|1|,|▁a|x|2|)|▁=|▁pl|t|.|sub|plot|s|(|1|,|▁2|)|\\\\|n|▁fig|.|set|_|size|_|inches|(|18|,|▁7|)|\\\\|n|\\\\|n|▁#|▁|左|圖|為|輪|[UNK]|分析|(|Si|lh|ouette|▁analysis|)|,|▁|雖|然|輪|[UNK]|係|數|範|圍|在|(|-|1|,|1|)|區|間|,|▁|但|範|例|中|都|為|正|值|,|▁|因|此|我|們|把|顯|示|範|圍|定|在|(|-|0|.|1|,|1|)|之|間|\\\\|n|▁a|x|1|.|set|_|x|lim|(|[|-|0|.|1|,|▁1|]|)|\\\\|n|▁#|▁(|n|_|cluster|s|+|1|)|*|10|▁|這|部分|是|用|來|在|不|同|輪|[UNK]|圖|間|塞|入|空|白|,|▁|讓|圖|形|看|起|來|更|清|楚|\\\\|n|▁a|x|1|.|set|_|y|lim|(|[|0|,|▁len|(|X|)|▁+|▁(|n|_|cluster|s|▁+|▁1|)|▁*|▁10|]|)|\\\\|n|\\\\|n|▁#|▁|宣|告|▁K|Mean|▁|分|群|器|,|▁|對|▁X|▁|訓|練|並|預|測|\\\\|n|▁cluster|er|▁=|▁KM|eans|(|n|_|cluster|s|=|n|_|cluster|s|,|▁random|_|state|=|10|)|\\\\|n|▁cluster|_|label|s|▁=|▁cluster|er|.|fit|_|predict|(|X|)|\\\\|n|\\\\|n|▁#|▁|計|算|所|有|點|的|▁silhouette|_|score|▁|平|均|\\\\|n|▁silhouette|_|av|g|▁=|▁silhouette|_|score|(|X|,|▁cluster|_|label|s|)|\\\\|n|▁print|(|\"|For|▁n|_|cluster|s|▁=|\"|,|▁n|_|cluster|s|,|\\\\|n|▁\"|The|▁average|▁silhouette|_|score|▁is|▁:|\"|,|▁silhouette|_|av|g|)|\\\\|n|\\\\|n|▁#|▁|計|算|所|有|樣|本|的|▁The|▁silhouette|_|score|\\\\|n|▁sample|_|sil|h|ouette|_|values|▁=|▁silhouette|_|sample|s|(|X|,|▁cluster|_|label|s|)|\\\\|n|\\\\|n|▁y|_|lower|▁=|▁10|\\\\|n|▁for|▁i|▁in|▁range|(|n|_|cluster|s|)|:|\\\\|n|▁#|▁|收|集|集|群|▁i|▁|樣|本|的|輪|[UNK]|分|數|,|並|對|它|們|進|行|排|序|\\\\|n|▁it|h|_|cluster|_|sil|h|ouette|_|values|▁=|▁\\\\|\\\\|\\\\|n|▁sample|_|sil|h|ouette|_|values|[|cluster|_|label|s|▁=|=|▁i|]|\\\\|n|\\\\|n|▁it|h|_|cluster|_|sil|h|ouette|_|values|.|sort|(|)|\\\\|n|\\\\|n|▁size|_|cluster|_|i|▁=|▁it|h|_|cluster|_|sil|h|ouette|_|values|.|shape|[|0|]|\\\\|n|▁y|_|upper|▁=|▁y|_|lower|▁+|▁size|_|cluster|_|i|\\\\|n|\\\\|n|▁color|▁=|▁cm|.|nip|y|_|spectral|(|float|(|i|)|▁/|▁n|_|cluster|s|)|\\\\|n|▁a|x|1|.|fill|_|between|x|(|np|.|a|range|(|y|_|lower|,|▁y|_|upper|)|,|\\\\|n|▁0|,|▁it|h|_|cluster|_|sil|h|ouette|_|values|,|\\\\|n|▁face|color|=|color|,|▁edge|color|=|color|,|▁alpha|=|0|.|7|)|\\\\|n|\\\\|n|▁#|▁在|每|個|集|群|中|間|標|上|▁i|▁|的|數|值|\\\\|n|▁a|x|1|.|text|(|-|0|.|05|,|▁y|_|lower|▁+|▁0|.|5|▁*|▁size|_|cluster|_|i|,|▁str|(|i|)|)|\\\\|n|\\\\|n|▁#|▁|計|算|下|一|個|▁y|_|lower|▁|的|位置|\\\\|n|▁y|_|lower|▁=|▁y|_|upper|▁+|▁10|\\\\|n|\\\\|n|▁a|x|1|.|set|_|title|(|\"|The|▁silhouette|▁plot|▁for|▁the|▁various|▁clusters|.|\"|)|\\\\|n|▁a|x|1|.|set|_|x|label|(|\"|The|▁silhouette|▁coefficient|▁values|\"|)|\\\\|n|▁a|x|1|.|set|_|y|label|(|\"|Cluster|▁label|\"|)|\\\\|n|\\\\|n|▁#|▁|將|▁silhouette|_|score|▁|平|均|所|在|位置|,|▁|畫|上|一|條|垂|直|線|\\\\|n|▁a|x|1|.|ax|v|line|(|x|=|sil|h|ouette|_|av|g|,|▁color|=|\"|red|\"|,|▁line|style|=|\"|-|-|\"|)|\\\\|n|\\\\|n|▁a|x|1|.|set|_|y|tick|s|(|[|]|)|▁#|▁|清|空|▁y|▁|軸|的|格|線|\\\\|n|▁a|x|1|.|set|_|x|tick|s|(|[|-|0|.|1|,|▁0|,|▁0|.|2|,|▁0|.|4|,|▁0|.|6|,|▁0|.|8|,|▁1|]|)|\\\\|n|\\\\|n|▁#|▁|右|圖|我|們|用|來|畫|上|每|個|樣|本|點|的|分|群|狀|態|,|▁|從|另|一|個|角|度|觀|察|分|群|是|否|[UNK]|當|\\\\|n|▁colors|▁=|▁cm|.|nip|y|_|spectral|(|cluster|_|label|s|.|as|type|(|float|)|▁/|▁n|_|cluster|s|)|\\\\|n|▁a|x|2|.|scatter|(|X|[|:|,|▁0|]|,|▁X|[|:|,|▁1|]|,|▁marker|=|\\\\|\\'|.|\\\\|\\'|,|▁s|=|30|,|▁l|w|=|0|,|▁alpha|=|0|.|7|,|\\\\|n|▁c|=|color|s|,|▁edge|color|=|\\\\|\\'|k|\\\\|\\'|)|\\\\|n|\\\\|n|▁#|▁在|右|圖|每|一|群|的|中|心|處|,|▁|畫|上|一|個|圓|圈|並|標|註|對|應|的|編|號|\\\\|n|▁centers|▁=|▁cluster|er|.|cluster|_|center|s|_|\\\\|n|▁a|x|2|.|scatter|(|center|s|[|:|,|▁0|]|,|▁centers|[|:|,|▁1|]|,|▁marker|=|\\\\|\\'|o|\\\\|\\'|,|\\\\|n|▁c|=|\"|white|\"|,|▁alpha|=|1|,|▁s|=|200|,|▁edge|color|=|\\\\|\\'|k|\\\\|\\'|)|\\\\|n|\\\\|n|▁for|▁i|,|▁c|▁in|▁enumerate|(|center|s|)|:|\\\\|n|▁a|x|2|.|scatter|(|c|[|0|]|,|▁c|[|1|]|,|▁marker|=|\\\\|\\'|$|%|d|$|\\\\|\\'|▁%|▁i|,|▁alpha|=|1|,|\\\\|n|▁s|=|50|,|▁edge|color|=|\\\\|\\'|k|\\\\|\\'|)|\\\\|n|\\\\|n|▁a|x|2|.|set|_|title|(|\"|The|▁visualization|▁of|▁the|▁clustered|▁data|.|\"|)|\\\\|n|▁a|x|2|.|set|_|x|label|(|\"|Feature|▁space|▁for|▁the|▁1|st|▁feature|\"|)|\\\\|n|▁a|x|2|.|set|_|y|label|(|\"|Feature|▁space|▁for|▁the|▁2|nd|▁feature|\"|)|\\\\|n|\\\\|n|▁pl|t|.|s|up|title|(|(|\"|Si|lh|ouette|▁analysis|▁for|▁KM|eans|▁clustering|▁on|▁sample|▁data|▁\"|\\\\|n|▁\"|with|▁n|_|cluster|s|▁=|▁%|d|\"|▁%|▁n|_|cluster|s|)|,|\\\\|n|▁font|size|=|14|,|▁font|weight|=|\\\\|\\'|bold|\\\\|\\'|)|\\\\|n|\\\\|n|pl|t|.|show|(|)|\\'|,|▁None|]|[SEP]'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'|'.join(tok.convert_ids_to_tokens(d.input_ids.values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1925003cfa3979ae366740114cfe890bf8d7ad5b88e4afe0ec571fe261ed45e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
