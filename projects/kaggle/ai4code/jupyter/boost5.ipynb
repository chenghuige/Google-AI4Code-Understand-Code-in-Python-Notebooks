{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../../../../utils')\n",
    "sys.path.append('../../../../third')\n",
    "from gezi.common import *\n",
    "from src.config import *\n",
    "from src.preprocess import *\n",
    "from src.eval import *\n",
    "gezi.init_flags()\n",
    "gezi.set_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 7\n",
    "root = f'../working/offline/{V}/0'\n",
    "# pairwise two tower, recall model\n",
    "# pt_model = 'all-mpnet-base-v2.flag-pairwise14-2-pre_ext_emlm_mlm.ep1'\n",
    "# p2t_model = 'all-mpnet-base-v2.flag-pairwise14-2'\n",
    "pt_model = 'all-mpnet-base-v2.flag-pairwise14-2-pre_mlm3'\n",
    "# pt_model = 'all-mpnet-base-v2.flag-pairwise14-2'\n",
    "# pt_model2 = 'pmminilm.flag-pairwise14-2-pre_emlm_mlm-mmnilm'\n",
    "# pt_model2 = 'pmminilm.flag-pairwise14-2-pre_mlm3-pmminilm'\n",
    "# pt_model2 = 'pmminilm.flag-pairwise14-2'\n",
    "# pairwise concat, rank model\n",
    "# pc_model = 'deberta-v3-small.flag-pairwise14-4-cat-insert-extpred-ft.neg_rand_prob-0.neg_strategy-rand-sample'\n",
    "pc_model = 'deberta-v3-small.flag-pairwise14-4-cat-insert-oof-ft'\n",
    "\n",
    "# context model\n",
    "# c_model = 'deberta-v3-small.flag-context4-2-d'\n",
    "# c_model2 = 'lsg-mminilm.flag-context4-3-d-s-mminilm'\n",
    "# c_model = 'deberta-v3-small.flag-context4-2-d'\n",
    "# c_model = 'deberta-v3-small.flag-context4-2-d-oof-ft'\n",
    "# c_model = 'deberta-v3-small.flag-context4-2-d-oof-ft.list_train_ordered'\n",
    "c_model = 'deberta-v3-small.flag-context4-2-d-oof-ft.add_probs'\n",
    "c_model = 'deberta-v3-small.flag-context4-2-d-oof.add_probs'\n",
    "# c_model = 'deberta-v3-small.flag-context4-2-d-extpred-ft.0804'\n",
    "# c_model = 'deberta-v3-small.flag-context4-2-d-oof-ft.list_train_ordered'\n",
    "# c_model2 = 'lsg-mminilm.flag-context4-3-d-s-oof-ft-mminilm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_feather('../working/train.fea')\n",
    "df_train = df_train[df_train.fold==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = gezi.load(f'{root}/{pt_model}.eval/valid.pkl')\n",
    "xc = gezi.load(f'{root}/{c_model}.eval.160_30/valid.pkl')\n",
    "xpc = gezi.load(f'{root}/{pc_model}.eval/valid.pkl')\n",
    "gezi.sort_dict_byid_(xp, 'cid')\n",
    "gezi.sort_dict_byid_(xc, 'cid')\n",
    "gezi.sort_dict_byid_(xpc, 'cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = pd.DataFrame(gezi.batch2list(xc))\n",
    "# dg = d.groupby('pred_id')\n",
    "# max_preds = dg['pred'].max()\n",
    "# min_preds = dg['pred'].min()\n",
    "# max_cls_preds = dg['cls_pred'].max()\n",
    "# min_cls_preds = dg['cls_pred'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = gezi.load(f'{root}/{pt_model}.eval/valid.pkl')\n",
    "# xc = gezi.load(f'{root}/{c_model}.eval/valid.pkl')\n",
    "xc = gezi.load(f'{root}/{c_model}.eval.160_30/valid.pkl')\n",
    "xpc = gezi.load(f'{root}/{pc_model}.eval/valid.pkl')\n",
    "gezi.sort_dict_byid_(xp, 'cid')\n",
    "gezi.sort_dict_byid_(xc, 'cid')\n",
    "gezi.sort_dict_byid_(xpc, 'cid')\n",
    "\n",
    "ic(calc_metric(xp, 'cls_pred'))\n",
    "ic(calc_metric(xc, 'reg_pred'))\n",
    "ic(calc_metric(xc, 'cls_pred'))\n",
    "ic(calc_metric(xpc, 'cls_pred'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_preds = dict(zip(xpc['cid'], xpc['pred']))\n",
    "pc_cls_preds = dict(zip(xpc['cid'], xpc['cls_pred']))\n",
    "pc_probs = dict(zip(xpc['cid'], xpc['probs']))\n",
    "\n",
    "preds = []\n",
    "cls_preds = []\n",
    "probs = []\n",
    "marks = []\n",
    "for cid, pred, cls_pred, prob in zip(xp['cid'], xp['pred'], xp['cls_pred'], xp['probs']):\n",
    "  # if prob.max() < 10:\n",
    "  if prob.max() < 0.8:\n",
    "    marks.append(1)\n",
    "    preds.append(pc_preds.get(cid, pred))\n",
    "    probs.append(pc_probs.get(cid, prob))\n",
    "    cls_preds.append(pc_cls_preds.get(cid, cls_pred))\n",
    "  else:\n",
    "    marks.append(0)\n",
    "    preds.append(pred)\n",
    "    probs.append(prob)\n",
    "    cls_preds.append(cls_pred)\n",
    "    \n",
    "xpc = xp.copy()\n",
    "xpc['pred'] = np.asarray(preds)\n",
    "xpc['cls_pred'] = np.asarray(cls_preds)\n",
    "xpc['probs'] = np.asarray(probs)\n",
    "xpc['mark'] = np.asarray(marks)\n",
    "ic(xpc['mark'].mean())\n",
    "ic(calc_metric(xpc, 'cls_pred'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_COL = 'rel_rank'\n",
    "def diff_feats(x, l,r, name):\n",
    "  if isinstance(l, str):\n",
    "    x[f'{name}_diff'] = x[l] - x[r]\n",
    "  else:\n",
    "    x[f'{name}_diff'] = l - r\n",
    "  x[f'abs_{name}_diff'] = abs(x[f'{name}_diff'])\n",
    "\n",
    "def gen_pfeat(x_, topn=None):\n",
    "  x = {}\n",
    "  keys = ['pred', 'cls_pred']\n",
    "  x = {k: x_[k] for k in keys}\n",
    "  # x['rank_pred'] = x['pred'] * (1 + x_['n_code_cell']) - 0.5\n",
    "  # x['cls_rank_pred'] = x['cls_pred'] * (1 + x_['n_code_cell']) - 0.5\n",
    "  x['min_prob'] = x_['probs'].min()\n",
    "  x['var_prob'] = np.var(x_['probs'])\n",
    "  if 'sims' in x_:\n",
    "    x['min_sim'] = x_['sims'].min()\n",
    "    x['var_sim'] = np.var(x_['sims'])\n",
    "  \n",
    "  idxes = (-x_['probs']).argsort()\n",
    "  # topn = topn or len(idxes)\n",
    "  topn = topn or 10\n",
    "  for i in range(topn):\n",
    "    if i < len(idxes):\n",
    "      if i > 0:\n",
    "        x[f'top_pred_{i}'] = (idxes[i] + 0.5) / (x_['n_code_cell'] + 1)\n",
    "        # x[f'top_rank_{i}'] = idxes[i]\n",
    "      x[f'top_prob_{i}'] = x_['probs'][idxes[i]]\n",
    "      if 'sims' in x_:\n",
    "        x[f'top_sim_{i}'] = x_['sims'][idxes[i]]\n",
    "    else:\n",
    "      x[f'top_pred_{i}'] = -1\n",
    "      # x[f'top_rank_{i}'] = -1\n",
    "      x[f'top_prob_{i}'] = -1\n",
    "      if 'sims' in x_:\n",
    "        x[f'top_sim_{i}'] = -1\n",
    "  \n",
    "  diff_feats(x, 'cls_pred', 'pred', 'cls')\n",
    "  # diff_feats(x, 'cls_rank_pred', 'rank_pred', 'cls_rank')\n",
    "  return x\n",
    "\n",
    "def gen_cfeat(x_):\n",
    "  topn = min(10, len(x_['cls_pred_ori']))\n",
    "  x = {}\n",
    "  keys = [\n",
    "    # 'pred', \n",
    "    'cls_pred', \n",
    "    'reg_pred', \n",
    "    'cls2_pred', \n",
    "    'group_pos',\n",
    "    'group_rank',\n",
    "    ]\n",
    "  x = {k: x_[k] for k in keys}\n",
    "  # x['cls_rank_pred'] = x['cls_pred'] * FLAGS.num_classes - 0.5\n",
    "  # x['cls2_rank_pred'] = x['cls2_pred'] * FLAGS.num_classes - 0.5\n",
    "  # x['reg_rank_pred'] = x['reg_pred'] * FLAGS.num_classes - 0.5\n",
    "  preds = x_['cls_pred_ori']\n",
    "  probs = gezi.softmax(preds)\n",
    "  x['min_prob'] = probs.min()\n",
    "  x['var_prob'] = np.var(probs)\n",
    "  idxes = (-probs).argsort()\n",
    "\n",
    "  for i in range(topn):\n",
    "    if i < len(idxes):\n",
    "      if i > 0:\n",
    "        x[f'top_pred_{i}'] = (idxes[i] + 0.5) / FLAGS.num_classes\n",
    "        # x[f'tpop_rank_{i}']  = idxes[i] \n",
    "      x[f'top_prob_{i}'] = probs[idxes[i]]\n",
    "    else:\n",
    "      x[f'top_pred_{i}'] = -1\n",
    "      # x[f'top_rank_{i}'] = -1\n",
    "      x[f'top_prob_{i}'] = -1\n",
    "  diff_feats(x, 'cls_pred', 'reg_pred', 'cls_reg')\n",
    "  diff_feats(x, 'cls_pred', 'cls2_pred', 'cls_cls2')\n",
    "  diff_feats(x, 'cls2_pred', 'reg_pred', 'cls2_reg')\n",
    "  # diff_feats(x, 'cls_rank_pred', 'reg_rank_pred', 'cls_reg_rank')\n",
    "  # diff_feats(x, 'cls_rank_pred', 'cls2_rank_pred', 'cls_cls2_rank')\n",
    "  # diff_feats(x, 'cls2_rank_pred', 'reg_rank_pred', 'cls2_reg_rank')\n",
    "  # group_id = x_['pred_id']\n",
    "  # x['max_pred'] = max_preds[group_id]\n",
    "  # x['min_pred'] = min_preds[group_id]\n",
    "  # x['pred_ratio'] = (x['pred'] - x['min_pred']) / (x['max_pred'] - x['min_pred']) if (x['max_pred'] - x['min_pred']) else 1\n",
    "  # x['max_cls_pred'] = max_cls_preds[group_id]\n",
    "  # x['min_cls_pred'] = min_cls_preds[group_id]\n",
    "  # x['cls_pred_ratio'] = (x['cls_pred'] - x['min_cls_pred']) / (x['max_cls_pred'] - x['min_cls_pred']) if (x['max_cls_pred'] - x['min_cls_pred']) else 1\n",
    "  \n",
    "  return x\n",
    "\n",
    "def gen_feats():\n",
    "  xs = gezi.batch2list(xp)\n",
    "  p_feats = [gen_pfeat(x) for x in tqdm(xs, desc=f'gen_pfeats:xp')]\n",
    "  xs = gezi.batch2list(xc)\n",
    "  c_feats = [gen_cfeat(x) for x in tqdm(xs, desc=f'gen_cfeats:xc')]\n",
    "  xs = gezi.batch2list(xpc)\n",
    "  pc_feats = [gen_pfeat(x, topn=3) for x in tqdm(xs, desc=f'gen_pfeats:xpc')]\n",
    "\n",
    "  feats = []\n",
    "  for i in tqdm(range(len(p_feats)), desc='merge_feats'):\n",
    "    fe1 = p_feats[i]\n",
    "    fec = c_feats[i]\n",
    "    fepc = pc_feats[i]\n",
    "    fepc['mark'] = xpc['mark'][i]\n",
    "    \n",
    "    fe = {}\n",
    "    fe['code_ratio'] = xp['n_code_cell'][i] / xp['n_cell'][i]\n",
    "    diff_feats(fe, fe1['pred'], fec['reg_pred'], 'pc_reg')\n",
    "    diff_feats(fe, fe1['pred'], fec['cls_pred'], 'pc_cls')\n",
    "    diff_feats(fe, fe1['pred'], fec['cls2_pred'], 'pc_cls2')\n",
    "    diff_feats(fe, fe1['cls_pred'], fec['reg_pred'], 'pc_cls_reg')\n",
    "    diff_feats(fe, fe1['cls_pred'], fec['cls_pred'], 'pc_cls_cls')\n",
    "    diff_feats(fe, fe1['cls_pred'], fec['cls2_pred'], 'pc_cls_cls2')\n",
    "    \n",
    "    diff_feats(fe, fepc['pred'], fec['reg_pred'], 'pcc_reg')\n",
    "    diff_feats(fe, fepc['pred'], fec['cls_pred'], 'pcc_cls')\n",
    "    diff_feats(fe, fepc['pred'], fec['cls2_pred'], 'pcc_cls2')\n",
    "    diff_feats(fe, fepc['cls_pred'], fec['reg_pred'], 'pcc_cls_reg')\n",
    "    diff_feats(fe, fepc['cls_pred'], fec['cls_pred'], 'pcc_cls_cls')\n",
    "    diff_feats(fe, fepc['cls_pred'], fec['cls2_pred'], 'pcc_cls_cls2')\n",
    "    \n",
    "    # diff_feats(fe, fe1['rank_pred'], fec['reg_rank_pred'], 'pc_cls_rank')\n",
    "    # diff_feats(fe, fe1['cls_rank_pred'], fec['reg_rank_pred'], 'pc_cls_reg_rank')\n",
    "    # diff_feats(fe, fepc['rank_pred'], fec['reg_rank_pred'], 'pcc_cls_rank')\n",
    "    # diff_feats(fe, fepc['cls_rank_pred'], fec['reg_rank_pred'], 'pcc_cls_reg_rank')\n",
    "\n",
    "    fe1 = gezi.dict_prefix(fe1, 'xp_')\n",
    "    fe.update(fe1)\n",
    "    fec = gezi.dict_prefix(fec, 'xc_')\n",
    "    fe.update(fec)\n",
    "    fepc = gezi.dict_prefix(fepc, 'xpc_')\n",
    "    fe.update(fepc)\n",
    "\n",
    "    keys = [\n",
    "     'id', 'cell_id', 'cid',\n",
    "     'n_words', 'n_code_cell', 'n_cell'\n",
    "    ]\n",
    "    for key in keys:\n",
    "      fe[key] = xp[key][i]\n",
    "      \n",
    "    #  ic(feat)\n",
    "    feats.append(fe)\n",
    "  #  break\n",
    "  dfeats = pd.DataFrame(feats)\n",
    "  return dfeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfeats = gen_feats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfeats.merge(df_train[['cid', 'ancestor_id', LABEL_COL]], on='cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gezi.set_fold(df, 5, 'ancestor_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_cols = [x for x in dfeats.columns if x not in ['id', 'cell_id', 'cid', LABEL_COL]]\n",
    "cat_cols = []\n",
    "cols = reg_cols + cat_cols\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "dvalid = df[df.fold==fold]\n",
    "dtrain = df[df.fold!=fold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dtrain[cols]\n",
    "y_train = dtrain[LABEL_COL]\n",
    "X_valid = dvalid[cols]\n",
    "y_valid = dvalid[LABEL_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, CatBoostRanker, CatBoostClassifier\n",
    "cbt_params = {\n",
    "              # 'bootstrap_type': 'Poisson',\n",
    "              # 'learning_rate': 0.02,\n",
    "              'learning_rate': 0.03,\n",
    "              # 'reg_lambda': 7.960622217848342e-07, \n",
    "              'l2_leaf_reg': 3,\n",
    "              'subsample': 0.7422597612762745,\n",
    "              # 'bagging_temperature': 0.2,\n",
    "              # 'max_depth': 10, \n",
    "              # 'max_depth': 8,\n",
    "              'max_depth': 6,\n",
    "              # 'max_depth': 5,\n",
    "              'early_stopping_rounds': 500,\n",
    "              'n_estimators': 10000,\n",
    "              'cat_features': [],\n",
    "              'loss_function': 'MAE',\n",
    "              'min_child_samples': 100,\n",
    "              # 'task_type': 'GPU',\n",
    "              # 'devices': '0',\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbt_model = CatBoostRegressor(**cbt_params)\n",
    "cbt_model.fit(X_train, y_train,\n",
    "      eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "              verbose=100,\n",
    "              )  \n",
    "dvalid['cbt_pred'] = cbt_model.predict(dvalid[cols])\n",
    "cbt_score = calc_metric({'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values, 'pred': dvalid.cbt_pred.values})\n",
    "ic(cbt_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gezi.plot.feature_importance(cbt_model, topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "params = {\n",
    "          'boosting': 'gbdt',\n",
    "          'objective': 'regression_l1',\n",
    "          'metric': {'l1'},\n",
    "          # 'num_leaves': 32,\n",
    "          # 'num_leaves': 24,\n",
    "          'num_leaves': 12,\n",
    "          'min_data_in_leaf': 300,\n",
    "          # 'min_data_in_leaf': 500,\n",
    "          # 'max_depth': 5,\n",
    "          'learning_rate': 0.03,\n",
    "          # \"feature_fraction\": 0.8,\n",
    "          # \"bagging_fraction\": 0.75,\n",
    "          # \"feature_fraction\": 0.9,\n",
    "          # \"bagging_fraction\": 0.8,\n",
    "          'feature_fraction': 0.7,\n",
    "          'bagging_fraction': 0.7,\n",
    "          'min_data_in_bin':100,\n",
    "          \"lambda_l1\": 1e-7,\n",
    "          'lambda_l2': 1e-7,\n",
    "          \"random_state\": 1024,\n",
    "          \"num_threads\": 12,\n",
    "          }\n",
    "\n",
    "d_train = lgb.Dataset(X_train, y_train)\n",
    "d_valid = lgb.Dataset(X_valid, y_valid, reference=d_train)\n",
    "\n",
    "lgb_model = lgb.train(params,\n",
    "                d_train,\n",
    "                20000,\n",
    "                valid_sets=[d_train, d_valid],\n",
    "                verbose_eval=100,\n",
    "                early_stopping_rounds=200)\n",
    "dvalid['lgb_pred'] = lgb_model.predict(dvalid[cols])\n",
    "lgb_score = calc_metric({'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values, 'pred': dvalid.lgb_pred.values})\n",
    "ic(lgb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = lgb.LGBMRanker(\n",
    "#     objective=\"lambdarank\",\n",
    "#     metric=\"ndcg\",\n",
    "#     boosting_type=\"dart\",\n",
    "#     n_estimators=100,\n",
    "#     importance_type='gain',\n",
    "#     verbose=10,\n",
    "#     random_state = 17\n",
    "# )\n",
    "\n",
    "# qids_train = dtrain.groupby(['id'])['cell_id'].count().values\n",
    "# # y_train2 = [int(x * 1000) for x in y_train]\n",
    "\n",
    "# model.fit(\n",
    "#     X=X_train,\n",
    "#     y=y_train2,\n",
    "#     group=qids_train,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# params = {\n",
    "#       'reg_lambda': 7.960622217848342e-07, \n",
    "#                       'subsample': 0.7422597612762745,\n",
    "#                       # 'bagging_temperature': 0.2,\n",
    "#                       'max_depth': 10, \n",
    "#                       # 'early_stopping_rounds': 500,\n",
    "#                       # 'n_estimators': 10000,\n",
    "#                       # 'cat_features': [],\n",
    "#                       # 'loss_function': 'MAE',\n",
    "#                       'min_child_samples': 100,\n",
    "#                       # eval_metric='MAE',\n",
    "# }\n",
    "# model = xgb.XGBRanker(booster=\"gbtree\", \n",
    "#                       # objective=\"rank:ndcg\",\n",
    "#                       objective='rank:pairwise',\n",
    "#                       tree_method=\"gpu_hist\", \n",
    "#                       sampling_method=\"gradient_based\",\n",
    "#                       n_estimators=5000,\n",
    "#                       learning_rate=0.03,\n",
    "#                       **params\n",
    "#                       )\n",
    "# train_groups = dtrain.groupby('id').size().to_numpy()\n",
    "# eval_groups = dvalid.groupby('id').size().to_numpy()\n",
    "# model.fit(X_train, \n",
    "#           y_train, \n",
    "#           group=train_groups, \n",
    "#           eval_set=[(X_train, y_train),(X_valid, y_valid)],\n",
    "#           eval_group=[train_groups, eval_groups],\n",
    "#           verbose=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dvalid['xgb_pred'] = xgb_model.predict(dvalid[cols])\n",
    "# dvalid['xgb_pred'] = [gezi.sigmoid(x) for x in dvalid.xgb_pred.values]\n",
    "# xgb_score = calc_metric({'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values, 'pred': dvalid.xgb_pred.values})\n",
    "# ic(xgb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gezi.plot.feature_importance(lgb_model, topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 5\n",
    "cbt_scores, lgb_scores = [], []\n",
    "scores = []\n",
    "gezi.try_mkdir(f'../working/trees{v}')\n",
    "for fold in tqdm(range(FOLDS)):\n",
    "  dvalid = df[df.fold==fold]\n",
    "  dtrain = df[df.fold!=fold]\n",
    "  X_train = dtrain[cols]\n",
    "  y_train = dtrain[LABEL_COL]\n",
    "  X_valid = dvalid[cols]\n",
    "  y_valid = dvalid[LABEL_COL]\n",
    "  if fold > 0:\n",
    "    cbt_model = CatBoostRegressor(**cbt_params)\n",
    "    cbt_model.fit(X_train, y_train,\n",
    "          eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                  verbose=500,\n",
    "                  )  \n",
    "  cbt_model.save_model(f'../working/trees{v}/{fold}.cbt')\n",
    "  dvalid['cbt_pred'] = cbt_model.predict(dvalid[cols])\n",
    "  cbt_score = calc_metric({'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values, 'pred': dvalid.cbt_pred.values})\n",
    "  ic(cbt_score)\n",
    "  \n",
    "  d_train = lgb.Dataset(X_train, y_train)\n",
    "  d_valid = lgb.Dataset(X_valid, y_valid, reference=d_train)\n",
    "  if fold > 0:\n",
    "    lgb_model = lgb.train(params,\n",
    "                    d_train,\n",
    "                    20000,\n",
    "                    valid_sets=[d_train, d_valid],\n",
    "                    verbose_eval=500,\n",
    "                    early_stopping_rounds=200)\n",
    "  lgb_model.save_model(f'../working/trees{v}/{fold}.lgb')\n",
    "  dvalid['lgb_pred'] = lgb_model.predict(dvalid[cols])\n",
    "  \n",
    "  lgb_score = calc_metric({'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values, 'pred': dvalid.lgb_pred.values})\n",
    "  ic(lgb_score)\n",
    "  score = calc_metric({'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values, 'pred': (dvalid.cbt_pred.values * 0.3 + dvalid.lgb_pred.values * 0.7)})\n",
    "  ic(score)\n",
    "  \n",
    "  cbt_scores.append(cbt_score)\n",
    "  lgb_scores.append(lgb_score)\n",
    "  scores.append(score)\n",
    "  ic(fold, \n",
    "     np.asarray(cbt_scores).mean(), \n",
    "     np.asarray(lgb_scores).mean(),\n",
    "     np.asarray(scores).mean(),\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold: 0\n",
    "#                     np.asarray(cbt_scores).mean(): 0.9181025338378637\n",
    "#                     np.asarray(lgb_scores).mean(): 0.9193848140698876\n",
    "#                     np.asarray(scores).mean(): 0.9195238841373282\n",
    "\n",
    "#  fold: 4\n",
    "#                     np.asarray(cbt_scores).mean(): 0.9189608630607822\n",
    "#                     np.asarray(lgb_scores).mean(): 0.9196959050732708\n",
    "#                     np.asarray(scores).mean(): 0.9199400102856614"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "828c32aa8796f4caf0c9fde9f523bba8dbc7385abbb3ec2757d19a79cb47766b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
