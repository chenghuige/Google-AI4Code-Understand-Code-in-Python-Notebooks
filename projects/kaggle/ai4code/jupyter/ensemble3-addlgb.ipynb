{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gezi.common import *\n",
    "sys.path.append('..')\n",
    "from src.config import *\n",
    "from src.preprocess import *\n",
    "from src.eval import *\n",
    "gezi.init_flags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/goldenlock/ai4code-base?scriptVersionId=101148262\n",
    "# 9025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../working/offline/6/0'\n",
    "context_model_name = 'deberta-v3-small.flag-context2-aug.n_context-40.cls_loss_rate-0.1.eval.p13-4'\n",
    "pairwise_model_name = 'all-mpnet-base-v2.flag-pairwise13-4.pooling_mask-attention_mask.grad_acc-4'\n",
    "# pmodel2_name = 'deberta-v3-small.flag-pairwise14-2-cat.eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc = gezi.load(f'{root}/{context_model_name}/valid.pkl')\n",
    "xp = gezi.load(f'{root}/{pairwise_model_name}/valid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gezi.sort_dict_byid_(xc, 'cid')\n",
    "gezi.sort_dict_byid_(xp, 'cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = set(xc['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0002115f48f982</td>\n",
       "      <td>[9ec225f0, 18281c6c, e3b6b115, 4a044c54, 365fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00062ab8487156</td>\n",
       "      <td>[dcad687f, a2e1fc80, 7d977ee8, 45a82a59, cbbc3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>000efd285fb982</td>\n",
       "      <td>[74a30f80, ee2c8e08, 5523374e, ae8f8fe8, 2138e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0012865b766949</td>\n",
       "      <td>[f9cb50e9, 25f7db90, d804e819, 6593a545, fc5bb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>001308991e0c5e</td>\n",
       "      <td>[21147235, 6c01d0d2, 5bd28595, b8fd3a8c, a2501...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                         cell_order\n",
       "4   0002115f48f982  [9ec225f0, 18281c6c, e3b6b115, 4a044c54, 365fe...\n",
       "11  00062ab8487156  [dcad687f, a2e1fc80, 7d977ee8, 45a82a59, cbbc3...\n",
       "28  000efd285fb982  [74a30f80, ee2c8e08, 5523374e, ae8f8fe8, 2138e...\n",
       "39  0012865b766949  [f9cb50e9, 25f7db90, d804e819, 6593a545, fc5bb...\n",
       "42  001308991e0c5e  [21147235, 6c01d0d2, 5bd28595, b8fd3a8c, a2501..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gt = pd.read_csv(f'{FLAGS.root}/train_orders.csv')\n",
    "df_gt = df_gt[df_gt.id.isin(ids)]\n",
    "df_gt['cell_order'] = df_gt['cell_order'].apply(lambda x: x.split())\n",
    "df_gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9006251692558017"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_metric(xc, 'reg_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8992880214723898"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_metric(xc, 'pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896173129530509"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_metric(xc, 'cls_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8966581181771137"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_metric(xp, 'cls_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9044248355992179"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = xc.copy()\n",
    "x['pred'] = xc['reg_pred'] * 0.5 + xp['cls_pred'] * 0.5\n",
    "calc_metric(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9018247872358709"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = xc.copy()\n",
    "x['pred'] = xc['cls_pred'] * 0.5 + xp['cls_pred'] * 0.5\n",
    "calc_metric(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9036697563235938"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = xc.copy()\n",
    "x['pred'] = xc['reg_pred'] * 0.5 + xp['pred'] * 0.5\n",
    "calc_metric(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(x, y, prob):\n",
    "  # return y\n",
    "  # return x\n",
    "  if prob > 0.9:\n",
    "    return x * (1 - 0.0001) + y * 0.0001\n",
    "  elif abs(y - x) < 0.1:\n",
    "    return x * (1 - 0.0001) + y * 0.0001\n",
    "  elif abs(y - x) < 0.2:\n",
    "    return x * 0.95 * prob + y * (1 - 0.95 * prob)\n",
    "  elif abs(y - x) < 0.3:\n",
    "    return x * 0.85 * prob + y * (1 - 0.85 * prob)\n",
    "  elif abs(y - x) < 0.4:\n",
    "    return x * 0.5 * prob + y * (1 - 0.5 * prob)\n",
    "  else:\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.908585923202479"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['pred'] = [merge(x, y, prob) for x, y, prob in zip(xp['pred'], xc['pred'], xp['max_prob'])]\n",
    "calc_metric(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = pd.DataFrame(xp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.DataFrame(gezi.batch2list(xc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_c.merge(df_p[['cid', 'pred', 'cls_pred', 'max_prob', 'max_sim', 'probs', 'sims']], on='cid', suffixes=['_c', '_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_feather('../working/train.fea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train.id.isin(ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_train[['cid', 'ancestor_id', 'n_words', 'source']], on='cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gezi.set_fold(df, 5, 'ancestor_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7fa8be958f4fdabbe5672a4d27a26b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "top:   0%|          | 0/424943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976763c71b15442988037b59054db4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ctop:   0%|          | 0/424943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d892dc854f84c4b9f197c4e88f428ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rule:   0%|          | 0/424943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['pred_diff0'] = abs(df['pred_c'] - df['pred_p'])\n",
    "df['pred_diff1'] = abs(df['reg_pred'] - df['pred_p'])\n",
    "df['pred_diff2'] = abs(df['cls_pred_c'] - df['pred_p'])\n",
    "df['pred_diff3'] = abs(df['cls2_pred'] - df['pred_p'])\n",
    "df['markdown_frac'] = df['n_markdown_cell'] / df['n_cell']\n",
    "df['span'] = 1 / (df['n_code_cell'] + 1)\n",
    "top2, top3, top4, top5 = [], [], [], []\n",
    "top2_prob, top3_prob, top4_prob, top5_prob = [], [], [], []\n",
    "top2_sim, top3_sim, top4_sim, top5_sim = [], [], [], []\n",
    "for i in tqdm(range(len(df)), desc='top'):\n",
    "  # cls_preds = df['cls_pred_ori'].values[i]\n",
    "  n_code = df['n_code_cell'].values[i]\n",
    "  probs = df['probs'].values[i]\n",
    "  sims = df['sims'].values[i]\n",
    "  idxes = (-probs).argsort()\n",
    "  if len(idxes) > 1:\n",
    "    top2.append((idxes[1] + 0.5) / (n_code + 1))\n",
    "    top2_prob.append(probs[idxes[1]])\n",
    "    top2_sim.append(sims[idxes[1]])\n",
    "  else:\n",
    "    top2.append(-1)\n",
    "    top2_prob.append(-1)\n",
    "    top2_sim.append(-1)\n",
    "  if len(idxes) > 2:\n",
    "    top3.append((idxes[2] + 0.5) / (n_code + 1))\n",
    "    top3_prob.append(probs[idxes[2]])\n",
    "    top3_sim.append(sims[idxes[2]])\n",
    "  else:\n",
    "    top3.append(-1)\n",
    "    top3_prob.append(-1)\n",
    "    top3_sim.append(-1)\n",
    "  if len(idxes) > 3:\n",
    "    top4.append((idxes[3] + 0.5) / (n_code + 1))\n",
    "    top4_prob.append(probs[idxes[3]])\n",
    "    top4_sim.append(sims[idxes[3]])\n",
    "  else:\n",
    "    top4.append(-1)\n",
    "    top4_prob.append(-1)\n",
    "    top4_sim.append(-1)\n",
    "  if len(idxes) > 4:\n",
    "    top5.append((idxes[4] + 0.5) / (n_code + 1))\n",
    "    top5_prob.append(probs[idxes[4]])\n",
    "    top5_sim.append(sims[idxes[4]])\n",
    "  else:\n",
    "    top5.append(-1)\n",
    "    top5_prob.append(-1)\n",
    "    top5_sim.append(-1)\n",
    "ctop_prob, ctop2, ctop3, ctop4, ctop2_prob, ctop3_prob, ctop4_prob = [], [], [], [], [], [], []\n",
    "for i in tqdm(range(len(df)), desc='ctop'):\n",
    "  preds = df['cls_pred_ori'].values[i]\n",
    "  probs = gezi.softmax(preds)\n",
    "  idxes = (-probs).argsort()\n",
    "  ctop_prob.append(probs[idxes[0]])\n",
    "  ctop2.append((idxes[1] + 0.5) / FLAGS.num_classes)\n",
    "  ctop2_prob.append(probs[idxes[1]])\n",
    "  ctop3.append((idxes[2] + 0.5) / FLAGS.num_classes)\n",
    "  ctop3_prob.append(probs[idxes[2]])\n",
    "  ctop4.append((idxes[3] + 0.5) / FLAGS.num_classes)\n",
    "  ctop4_prob.append(probs[idxes[3]])\n",
    "# for i in range(FLAGS.num_classes):\n",
    "#   df[f'cls_pred{i}'] = df['cls_pred_ori'].apply(lambda x: x[i])\n",
    "df['top2'] = top2\n",
    "df['top2_prob'] = top2_prob\n",
    "df['top2_sim'] = top2_sim\n",
    "df['top3'] = top3\n",
    "df['top3_prob'] = top3_prob\n",
    "df['top3_sim'] = top3_sim\n",
    "df['top4'] = top4\n",
    "df['top4_prob'] = top4_prob\n",
    "df['top4_sim'] = top4_sim\n",
    "df['top5'] = top5\n",
    "df['top5_prob'] = top5_prob\n",
    "df['top5_sim'] = top5_sim\n",
    "df['ctop_prob'] = ctop_prob\n",
    "df['ctop2'] = ctop2\n",
    "df['ctop2_prob'] = ctop2_prob\n",
    "df['ctop3'] = ctop3\n",
    "df['ctop3_prob'] = ctop3_prob\n",
    "df['ctop4'] = ctop4\n",
    "df['ctop4_prob'] = ctop4_prob\n",
    "df['pred_diff4'] = abs(df['pred_c'] - df['top2'])\n",
    "df['pred_diff5'] = abs(df['reg_pred'] - df['top2'])\n",
    "df['pred_diff6'] = abs(df['cls_pred_c'] - df['top2'])\n",
    "df['pred_diff7'] = abs(df['cls2_pred'] - df['top2'])\n",
    "df['pred_diff8'] = abs(df['pred_p'] - df['top2'])\n",
    "df['pred_diff9'] = abs(df['cls_pred_c'] - df['top3'])\n",
    "df['pred_diff10'] = abs(df['pred_p'] - df['top3'])\n",
    "df['rule_pred'] = [merge(x, y, prob) for x, y, prob in tqdm(zip(df.pred_p.values, df.pred_c.values, df.max_prob.values), total=len(df), desc='rule')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_cols =  [\n",
    "          'n_code_cell',\n",
    "          'n_markdown_cell',\n",
    "          'n_cell',\n",
    "          'cls_pred_c',\n",
    "          'pred_c',\n",
    "          'reg_pred',\n",
    "          'cls2_pred',\n",
    "          'pred_p',\n",
    "          'cls_pred_p',\n",
    "          'rule_pred',\n",
    "          'pred_diff0',\n",
    "          'pred_diff1',\n",
    "          'pred_diff2',\n",
    "          'pred_diff3',\n",
    "          'pred_diff4',\n",
    "          'pred_diff5',\n",
    "          'pred_diff6',\n",
    "          'pred_diff7',\n",
    "          'pred_diff8',\n",
    "          'pred_diff9',\n",
    "          'pred_diff10',\n",
    "          'max_sim',\n",
    "          'max_prob',\n",
    "          'markdown_frac',\n",
    "          'span',\n",
    "          'top2',\n",
    "          'top2_prob',\n",
    "          'top2_sim',\n",
    "          'top3',\n",
    "          'top3_prob',\n",
    "          'top3_sim',\n",
    "          'top4',\n",
    "          'top4_prob',\n",
    "          'top4_sim',\n",
    "          'top5',\n",
    "          'top5_prob',\n",
    "          'top5_sim',\n",
    "          'ctop_prob', \n",
    "          'ctop2', \n",
    "          'ctop2_prob', \n",
    "        ]\n",
    "\n",
    "cat_cols = [\n",
    "          \n",
    "            ]\n",
    "label_col = 'rel_rank'\n",
    "cols = reg_cols + cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "import lightgbm as lgb\n",
    "xgb_params = {'learning_rate': 0.02,\n",
    "              'reg_lambda': 7.960622217848342e-07, \n",
    "              'subsample': 0.7422597612762745,\n",
    "              'max_depth': 10, \n",
    "              'early_stopping_rounds': 500,\n",
    "              'n_estimators': 10000,\n",
    "              'cat_features': [],\n",
    "              'loss_function': 'MAE',\n",
    "              }\n",
    "\n",
    "xgb_params2 = {'learning_rate': 0.09827605967564293,'tree_method':'gpu_hist', 'gpu_id':0,\n",
    "               'early_stopping_rounds': 50,\n",
    "               'n_estimators': 10000, }\n",
    "\n",
    "params = {\n",
    "          'boosting': 'gbdt',\n",
    "          'objective': 'regression_l1',\n",
    "          'metric': {'l1'},\n",
    "          'num_leaves': 32,\n",
    "          'min_data_in_leaf': 300,\n",
    "          # 'max_depth': 10,\n",
    "          'learning_rate': 0.02,\n",
    "          \"feature_fraction\": 0.8,\n",
    "          \"bagging_fraction\": 0.75,\n",
    "          'min_data_in_bin':100,\n",
    "          \"lambda_l1\": 1e-7,\n",
    "          'lambda_l2': 1e-7,\n",
    "          \"random_state\": 1024,\n",
    "          \"num_threads\": 12,\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3484245a874f4791a12230489a751f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2544365\ttest: 0.2544365\ttest1: 0.2543514\tbest: 0.2543514 (0)\ttotal: 304ms\tremaining: 50m 36s\n",
      "500:\tlearn: 0.0632407\ttest: 0.0632407\ttest1: 0.0656280\tbest: 0.0656280 (500)\ttotal: 2m 24s\tremaining: 45m 37s\n",
      "1000:\tlearn: 0.0610853\ttest: 0.0610853\ttest1: 0.0647097\tbest: 0.0647097 (1000)\ttotal: 4m 36s\tremaining: 41m 24s\n",
      "1500:\tlearn: 0.0595594\ttest: 0.0595594\ttest1: 0.0644209\tbest: 0.0644209 (1500)\ttotal: 6m 59s\tremaining: 39m 34s\n",
      "2000:\tlearn: 0.0583866\ttest: 0.0583866\ttest1: 0.0643415\tbest: 0.0643407 (1993)\ttotal: 8m 44s\tremaining: 34m 57s\n",
      "2500:\tlearn: 0.0573591\ttest: 0.0573591\ttest1: 0.0644437\tbest: 0.0643313 (2133)\ttotal: 10m 49s\tremaining: 32m 26s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.06433133434\n",
      "bestIteration = 2133\n",
      "\n",
      "Shrink model to first 2134 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 18:48:01] 3574203340.py:22 in <module>\n",
      "                    abs(x['pred'] - dvalid['rel_rank']).mean(): 0.06579407253591144\n",
      "                    merge_score: 0.9070703368237418\n",
      "[07/19/22 18:48:03] 3574203340.py:24 in <module>\n",
      "                    cbt_score: 0.9104315790384504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.090401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9620\n",
      "[LightGBM] [Info] Number of data points in the train set: 342411, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 0.455056\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.0647922\tvalid_1's l1: 0.0661354\n",
      "[1000]\ttraining's l1: 0.0635188\tvalid_1's l1: 0.0651149\n",
      "[1500]\ttraining's l1: 0.0629869\tvalid_1's l1: 0.0648134\n",
      "[2000]\ttraining's l1: 0.0625055\tvalid_1's l1: 0.0645739\n",
      "[2500]\ttraining's l1: 0.0622016\tvalid_1's l1: 0.064447\n",
      "[3000]\ttraining's l1: 0.0619868\tvalid_1's l1: 0.0643525\n",
      "[3500]\ttraining's l1: 0.0617939\tvalid_1's l1: 0.0642797\n",
      "[4000]\ttraining's l1: 0.0616054\tvalid_1's l1: 0.0642211\n",
      "[4500]\ttraining's l1: 0.0614102\tvalid_1's l1: 0.0641626\n",
      "[5000]\ttraining's l1: 0.0612468\tvalid_1's l1: 0.0641157\n",
      "[5500]\ttraining's l1: 0.0611164\tvalid_1's l1: 0.0640904\n",
      "[6000]\ttraining's l1: 0.0609961\tvalid_1's l1: 0.0640588\n",
      "[6500]\ttraining's l1: 0.0608363\tvalid_1's l1: 0.0640315\n",
      "[7000]\ttraining's l1: 0.0607076\tvalid_1's l1: 0.0640063\n",
      "[7500]\ttraining's l1: 0.0605915\tvalid_1's l1: 0.0639842\n",
      "[8000]\ttraining's l1: 0.0604984\tvalid_1's l1: 0.0639646\n",
      "[8500]\ttraining's l1: 0.0604275\tvalid_1's l1: 0.0639541\n",
      "[9000]\ttraining's l1: 0.0603307\tvalid_1's l1: 0.063937\n",
      "[9500]\ttraining's l1: 0.0602403\tvalid_1's l1: 0.0639216\n",
      "[10000]\ttraining's l1: 0.0601566\tvalid_1's l1: 0.0639162\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0601566\tvalid_1's l1: 0.0639162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 19:06:13] 3574203340.py:38 in <module>\n",
      "                    lgb_score: 0.9105593900599513\n",
      "[07/19/22 19:06:15] 3574203340.py:40 in <module>\n",
      "                    score: 0.9108104250842369\n",
      "[07/19/22 19:06:15] 3574203340.py:46 in <module>\n",
      "                    fold: 0\n",
      "                    np.asarray(merge_scores).mean(): 0.9070703368237418\n",
      "                    np.asarray(cbt_scores).mean(): 0.9104315790384504\n",
      "                    np.asarray(lgb_scores).mean(): 0.9105593900599513\n",
      "                    np.asarray(scores).mean(): 0.9108104250842369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2544434\ttest: 0.2544434\ttest1: 0.2543537\tbest: 0.2543537 (0)\ttotal: 297ms\tremaining: 49m 33s\n",
      "500:\tlearn: 0.0634916\ttest: 0.0634916\ttest1: 0.0644702\tbest: 0.0644702 (500)\ttotal: 1m 54s\tremaining: 36m 13s\n",
      "1000:\tlearn: 0.0613120\ttest: 0.0613120\ttest1: 0.0635332\tbest: 0.0635332 (1000)\ttotal: 3m 58s\tremaining: 35m 40s\n",
      "1500:\tlearn: 0.0597885\ttest: 0.0597885\ttest1: 0.0632748\tbest: 0.0632740 (1497)\ttotal: 5m 44s\tremaining: 32m 29s\n",
      "2000:\tlearn: 0.0586173\ttest: 0.0586173\ttest1: 0.0631869\tbest: 0.0631860 (1984)\ttotal: 7m 19s\tremaining: 29m 18s\n",
      "2500:\tlearn: 0.0576180\ttest: 0.0576180\ttest1: 0.0631791\tbest: 0.0631777 (2403)\ttotal: 8m 31s\tremaining: 25m 33s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.0631777357\n",
      "bestIteration = 2403\n",
      "\n",
      "Shrink model to first 2404 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 19:15:58] 3574203340.py:22 in <module>\n",
      "                    abs(x['pred'] - dvalid['rel_rank']).mean(): 0.06494859335498927\n",
      "                    merge_score: 0.9082661676659034\n",
      "[07/19/22 19:16:00] 3574203340.py:24 in <module>\n",
      "                    cbt_score: 0.9113040501897806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9620\n",
      "[LightGBM] [Info] Number of data points in the train set: 339696, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 0.455882\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.0650076\tvalid_1's l1: 0.0653554\n",
      "[1000]\ttraining's l1: 0.063744\tvalid_1's l1: 0.0643512\n",
      "[1500]\ttraining's l1: 0.0632422\tvalid_1's l1: 0.0640458\n",
      "[2000]\ttraining's l1: 0.0628426\tvalid_1's l1: 0.0638371\n",
      "[2500]\ttraining's l1: 0.0625767\tvalid_1's l1: 0.0637031\n",
      "[3000]\ttraining's l1: 0.0623132\tvalid_1's l1: 0.0635855\n",
      "[3500]\ttraining's l1: 0.0620879\tvalid_1's l1: 0.0634816\n",
      "[4000]\ttraining's l1: 0.0618203\tvalid_1's l1: 0.0633663\n",
      "[4500]\ttraining's l1: 0.0616646\tvalid_1's l1: 0.063309\n",
      "[5000]\ttraining's l1: 0.0615008\tvalid_1's l1: 0.0632538\n",
      "[5500]\ttraining's l1: 0.061358\tvalid_1's l1: 0.0632157\n",
      "[6000]\ttraining's l1: 0.0611679\tvalid_1's l1: 0.0631493\n",
      "[6500]\ttraining's l1: 0.0610654\tvalid_1's l1: 0.0631246\n",
      "[7000]\ttraining's l1: 0.0609463\tvalid_1's l1: 0.0630961\n",
      "[7500]\ttraining's l1: 0.0608344\tvalid_1's l1: 0.0630732\n",
      "[8000]\ttraining's l1: 0.0606611\tvalid_1's l1: 0.0630297\n",
      "[8500]\ttraining's l1: 0.0605369\tvalid_1's l1: 0.0630053\n",
      "[9000]\ttraining's l1: 0.060443\tvalid_1's l1: 0.062983\n",
      "[9500]\ttraining's l1: 0.0603714\tvalid_1's l1: 0.0629813\n",
      "[10000]\ttraining's l1: 0.0602825\tvalid_1's l1: 0.062962\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0602825\tvalid_1's l1: 0.062962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 19:35:05] 3574203340.py:38 in <module>\n",
      "                    lgb_score: 0.9116758935987295\n",
      "[07/19/22 19:35:07] 3574203340.py:40 in <module>\n",
      "                    score: 0.911906263365432\n",
      "[07/19/22 19:35:07] 3574203340.py:46 in <module>\n",
      "                    fold: 1\n",
      "                    np.asarray(merge_scores).mean(): 0.9076682522448226\n",
      "                    np.asarray(cbt_scores).mean(): 0.9108678146141155\n",
      "                    np.asarray(lgb_scores).mean(): 0.9111176418293404\n",
      "                    np.asarray(scores).mean(): 0.9113583442248345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2543568\ttest: 0.2543568\ttest1: 0.2547335\tbest: 0.2547335 (0)\ttotal: 222ms\tremaining: 36m 58s\n",
      "500:\tlearn: 0.0633974\ttest: 0.0633974\ttest1: 0.0645867\tbest: 0.0645867 (500)\ttotal: 1m 41s\tremaining: 31m 55s\n",
      "1000:\tlearn: 0.0611939\ttest: 0.0611939\ttest1: 0.0636154\tbest: 0.0636149 (997)\ttotal: 3m 27s\tremaining: 31m 5s\n",
      "1500:\tlearn: 0.0597349\ttest: 0.0597349\ttest1: 0.0633332\tbest: 0.0633332 (1500)\ttotal: 5m 18s\tremaining: 30m 4s\n",
      "2000:\tlearn: 0.0585400\ttest: 0.0585400\ttest1: 0.0632418\tbest: 0.0632418 (2000)\ttotal: 7m 15s\tremaining: 29m 2s\n",
      "2500:\tlearn: 0.0575181\ttest: 0.0575181\ttest1: 0.0632323\tbest: 0.0632187 (2350)\ttotal: 9m 14s\tremaining: 27m 41s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.06321870254\n",
      "bestIteration = 2350\n",
      "\n",
      "Shrink model to first 2351 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 19:45:47] 3574203340.py:22 in <module>\n",
      "                    abs(x['pred'] - dvalid['rel_rank']).mean(): 0.06479006687657934\n",
      "                    merge_score: 0.9108612410210817\n",
      "[07/19/22 19:45:49] 3574203340.py:24 in <module>\n",
      "                    cbt_score: 0.913384589045658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9615\n",
      "[LightGBM] [Info] Number of data points in the train set: 337766, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 0.456522\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.0649914\tvalid_1's l1: 0.0652922\n",
      "[1000]\ttraining's l1: 0.0638173\tvalid_1's l1: 0.0643126\n",
      "[1500]\ttraining's l1: 0.0632963\tvalid_1's l1: 0.0639719\n",
      "[2000]\ttraining's l1: 0.0629197\tvalid_1's l1: 0.0637599\n",
      "[2500]\ttraining's l1: 0.0626347\tvalid_1's l1: 0.0636082\n",
      "[3000]\ttraining's l1: 0.0623596\tvalid_1's l1: 0.0634822\n",
      "[3500]\ttraining's l1: 0.0621284\tvalid_1's l1: 0.06338\n",
      "[4000]\ttraining's l1: 0.0619203\tvalid_1's l1: 0.0632876\n",
      "[4500]\ttraining's l1: 0.061725\tvalid_1's l1: 0.0632072\n",
      "[5000]\ttraining's l1: 0.0615643\tvalid_1's l1: 0.0631521\n",
      "[5500]\ttraining's l1: 0.0614303\tvalid_1's l1: 0.0631073\n",
      "[6000]\ttraining's l1: 0.0612565\tvalid_1's l1: 0.063041\n",
      "[6500]\ttraining's l1: 0.0611367\tvalid_1's l1: 0.0630035\n",
      "[7000]\ttraining's l1: 0.0610355\tvalid_1's l1: 0.0629793\n",
      "[7500]\ttraining's l1: 0.0608968\tvalid_1's l1: 0.0629338\n",
      "[8000]\ttraining's l1: 0.0607839\tvalid_1's l1: 0.0629103\n",
      "[8500]\ttraining's l1: 0.0606964\tvalid_1's l1: 0.0628887\n",
      "[9000]\ttraining's l1: 0.0606119\tvalid_1's l1: 0.0628641\n",
      "[9500]\ttraining's l1: 0.0605404\tvalid_1's l1: 0.0628463\n",
      "[10000]\ttraining's l1: 0.0604696\tvalid_1's l1: 0.0628296\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0604696\tvalid_1's l1: 0.0628296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 19:57:58] 3574203340.py:38 in <module>\n",
      "                    lgb_score: 0.913843828123805\n",
      "[07/19/22 19:58:00] 3574203340.py:40 in <module>\n",
      "                    score: 0.9140259844061986\n",
      "[07/19/22 19:58:00] 3574203340.py:46 in <module>\n",
      "                    fold: 2\n",
      "                    np.asarray(merge_scores).mean(): 0.908732581836909\n",
      "                    np.asarray(cbt_scores).mean(): 0.9117067394246297\n",
      "                    np.asarray(lgb_scores).mean(): 0.9120263705941619\n",
      "                    np.asarray(scores).mean(): 0.9122475576186225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2544802\ttest: 0.2544802\ttest1: 0.2542154\tbest: 0.2542154 (0)\ttotal: 108ms\tremaining: 17m 59s\n",
      "500:\tlearn: 0.0639086\ttest: 0.0639086\ttest1: 0.0630433\tbest: 0.0630433 (500)\ttotal: 29.7s\tremaining: 9m 22s\n",
      "1000:\tlearn: 0.0617233\ttest: 0.0617233\ttest1: 0.0620711\tbest: 0.0620711 (1000)\ttotal: 1m 6s\tremaining: 10m\n",
      "1500:\tlearn: 0.0602526\ttest: 0.0602526\ttest1: 0.0617742\tbest: 0.0617736 (1499)\ttotal: 1m 53s\tremaining: 10m 44s\n",
      "2000:\tlearn: 0.0590934\ttest: 0.0590934\ttest1: 0.0616766\tbest: 0.0616766 (2000)\ttotal: 2m 57s\tremaining: 11m 49s\n",
      "2500:\tlearn: 0.0582094\ttest: 0.0582094\ttest1: 0.0616503\tbest: 0.0616483 (2491)\ttotal: 3m 56s\tremaining: 11m 50s\n",
      "3000:\tlearn: 0.0574687\ttest: 0.0574687\ttest1: 0.0616585\tbest: 0.0616402 (2877)\ttotal: 5m 14s\tremaining: 12m 13s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.06164022083\n",
      "bestIteration = 2877\n",
      "\n",
      "Shrink model to first 2878 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 20:04:13] 3574203340.py:22 in <module>\n",
      "                    abs(x['pred'] - dvalid['rel_rank']).mean(): 0.06352573785829235\n",
      "                    merge_score: 0.912103082718156\n",
      "[07/19/22 20:04:14] 3574203340.py:24 in <module>\n",
      "                    cbt_score: 0.9153450754329285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9618\n",
      "[LightGBM] [Info] Number of data points in the train set: 337964, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 0.455939\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.06544\tvalid_1's l1: 0.0637464\n",
      "[1000]\ttraining's l1: 0.0641727\tvalid_1's l1: 0.0627004\n",
      "[1500]\ttraining's l1: 0.0636562\tvalid_1's l1: 0.0623658\n",
      "[2000]\ttraining's l1: 0.0633189\tvalid_1's l1: 0.0621868\n",
      "[2500]\ttraining's l1: 0.0630115\tvalid_1's l1: 0.0620483\n",
      "[3000]\ttraining's l1: 0.0627619\tvalid_1's l1: 0.0619395\n",
      "[3500]\ttraining's l1: 0.0625693\tvalid_1's l1: 0.061875\n",
      "[4000]\ttraining's l1: 0.0623764\tvalid_1's l1: 0.0617949\n",
      "[4500]\ttraining's l1: 0.0621323\tvalid_1's l1: 0.0617022\n",
      "[5000]\ttraining's l1: 0.0619575\tvalid_1's l1: 0.0616612\n",
      "[5500]\ttraining's l1: 0.061791\tvalid_1's l1: 0.0616023\n",
      "[6000]\ttraining's l1: 0.0616641\tvalid_1's l1: 0.0615681\n",
      "[6500]\ttraining's l1: 0.0614959\tvalid_1's l1: 0.0615169\n",
      "[7000]\ttraining's l1: 0.0613359\tvalid_1's l1: 0.0614732\n",
      "[7500]\ttraining's l1: 0.0612223\tvalid_1's l1: 0.0614481\n",
      "[8000]\ttraining's l1: 0.0611172\tvalid_1's l1: 0.0614275\n",
      "[8500]\ttraining's l1: 0.0610072\tvalid_1's l1: 0.061404\n",
      "[9000]\ttraining's l1: 0.0609028\tvalid_1's l1: 0.0613767\n",
      "[9500]\ttraining's l1: 0.0608359\tvalid_1's l1: 0.0613659\n",
      "[10000]\ttraining's l1: 0.0607649\tvalid_1's l1: 0.0613556\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0607649\tvalid_1's l1: 0.0613556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 20:14:04] 3574203340.py:38 in <module>\n",
      "                    lgb_score: 0.9155733956431529\n",
      "[07/19/22 20:14:05] 3574203340.py:40 in <module>\n",
      "                    score: 0.9158815507917495\n",
      "[07/19/22 20:14:05] 3574203340.py:46 in <module>\n",
      "                    fold: 3\n",
      "                    np.asarray(merge_scores).mean(): 0.9095752070572207\n",
      "                    np.asarray(cbt_scores).mean(): 0.9126163234267044\n",
      "                    np.asarray(lgb_scores).mean(): 0.9129131268564097\n",
      "                    np.asarray(scores).mean(): 0.9131560559119043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2544156\ttest: 0.2544156\ttest1: 0.2545067\tbest: 0.2545067 (0)\ttotal: 159ms\tremaining: 26m 31s\n",
      "500:\tlearn: 0.0631691\ttest: 0.0631691\ttest1: 0.0656771\tbest: 0.0656771 (500)\ttotal: 50.3s\tremaining: 15m 54s\n",
      "1000:\tlearn: 0.0610502\ttest: 0.0610502\ttest1: 0.0647680\tbest: 0.0647674 (999)\ttotal: 1m 43s\tremaining: 15m 28s\n",
      "1500:\tlearn: 0.0595070\ttest: 0.0595070\ttest1: 0.0644590\tbest: 0.0644590 (1500)\ttotal: 2m 35s\tremaining: 14m 38s\n",
      "2000:\tlearn: 0.0583593\ttest: 0.0583593\ttest1: 0.0643696\tbest: 0.0643680 (1964)\ttotal: 3m 31s\tremaining: 14m 6s\n",
      "2500:\tlearn: 0.0573699\ttest: 0.0573699\ttest1: 0.0643467\tbest: 0.0643405 (2462)\ttotal: 4m 25s\tremaining: 13m 16s\n",
      "3000:\tlearn: 0.0566059\ttest: 0.0566059\ttest1: 0.0643463\tbest: 0.0643402 (2567)\ttotal: 5m 19s\tremaining: 12m 25s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.06434017347\n",
      "bestIteration = 2567\n",
      "\n",
      "Shrink model to first 2568 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 20:19:38] 3574203340.py:22 in <module>\n",
      "                    abs(x['pred'] - dvalid['rel_rank']).mean(): 0.06573988537486983\n",
      "                    merge_score: 0.9039693073200067\n",
      "[07/19/22 20:19:40] 3574203340.py:24 in <module>\n",
      "                    cbt_score: 0.9063462862332429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9618\n",
      "[LightGBM] [Info] Number of data points in the train set: 341935, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 0.456522\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.0646559\tvalid_1's l1: 0.0661909\n",
      "[1000]\ttraining's l1: 0.0634453\tvalid_1's l1: 0.0652767\n",
      "[1500]\ttraining's l1: 0.0629304\tvalid_1's l1: 0.0649668\n",
      "[2000]\ttraining's l1: 0.0625989\tvalid_1's l1: 0.0647895\n",
      "[2500]\ttraining's l1: 0.062325\tvalid_1's l1: 0.0646627\n",
      "[3000]\ttraining's l1: 0.0620582\tvalid_1's l1: 0.0645413\n",
      "[3500]\ttraining's l1: 0.0618253\tvalid_1's l1: 0.0644568\n",
      "[4000]\ttraining's l1: 0.0616556\tvalid_1's l1: 0.064407\n",
      "[4500]\ttraining's l1: 0.0614767\tvalid_1's l1: 0.0643504\n",
      "[5000]\ttraining's l1: 0.0613315\tvalid_1's l1: 0.0643022\n",
      "[5500]\ttraining's l1: 0.0611098\tvalid_1's l1: 0.0642258\n",
      "[6000]\ttraining's l1: 0.0609852\tvalid_1's l1: 0.0641908\n",
      "[6500]\ttraining's l1: 0.0608538\tvalid_1's l1: 0.064157\n",
      "[7000]\ttraining's l1: 0.0607102\tvalid_1's l1: 0.0641163\n",
      "[7500]\ttraining's l1: 0.0605774\tvalid_1's l1: 0.0640817\n",
      "[8000]\ttraining's l1: 0.0604688\tvalid_1's l1: 0.0640672\n",
      "[8500]\ttraining's l1: 0.0603766\tvalid_1's l1: 0.0640518\n",
      "[9000]\ttraining's l1: 0.0602932\tvalid_1's l1: 0.0640324\n",
      "[9500]\ttraining's l1: 0.0601913\tvalid_1's l1: 0.0640163\n",
      "[10000]\ttraining's l1: 0.0600871\tvalid_1's l1: 0.0640009\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0600871\tvalid_1's l1: 0.0640009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 20:23:13] 3574203340.py:38 in <module>\n",
      "                    lgb_score: 0.9067770507000141\n",
      "[07/19/22 20:23:15] 3574203340.py:40 in <module>\n",
      "                    score: 0.9069607880602689\n",
      "[07/19/22 20:23:15] 3574203340.py:46 in <module>\n",
      "                    fold: 4\n",
      "                    np.asarray(merge_scores).mean(): 0.908454027109778\n",
      "                    np.asarray(cbt_scores).mean(): 0.911362315988012\n",
      "                    np.asarray(lgb_scores).mean(): 0.9116859116251306\n",
      "                    np.asarray(scores).mean(): 0.9119170023415772\n"
     ]
    }
   ],
   "source": [
    "merge_scores = []\n",
    "cbt_scores, lgb_scores = [], []\n",
    "scores = []\n",
    "for fold in tqdm(range(FOLDS)):\n",
    "  dvalid = df[df.fold==fold]\n",
    "  dtrain = df[df.fold!=fold]\n",
    "  X_train = dtrain[cols]\n",
    "  y_train = dtrain[label_col]\n",
    "  X_valid = dvalid[cols]\n",
    "  y_valid = dvalid[label_col]\n",
    "  cbt_model = CatBoostRegressor(**xgb_params)\n",
    "  cbt_model.fit(X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                verbose=500,\n",
    "                )  \n",
    "  # cbt_model.save_model(f'../working/trees/{fold}.cbt')\n",
    "  dvalid['cb_pred'] = cbt_model.predict(dvalid[cols])\n",
    "  \n",
    "  x = {'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values}\n",
    "  x['pred'] = [merge(x, y, prob) for x, y, prob in zip(dvalid.pred_p.values, dvalid.pred_c.values, dvalid.max_prob.values)]\n",
    "  merge_score = calc_metric(x, 'pred', df_gt)\n",
    "  ic(abs(x['pred'] - dvalid['rel_rank']).mean(), merge_score)\n",
    "  cbt_score = calc_metric({'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values, 'pred': dvalid.cb_pred.values})\n",
    "  ic(cbt_score)\n",
    "  \n",
    "  d_train = lgb.Dataset(X_train, y_train)\n",
    "  d_valid = lgb.Dataset(X_valid, y_valid, reference=d_train)\n",
    "  lgb_model = lgb.train(params,\n",
    "                  d_train,\n",
    "                  10000,\n",
    "                  valid_sets=[d_train, d_valid],\n",
    "                  verbose_eval=500,\n",
    "                  early_stopping_rounds=500)\n",
    "  # lgb_model.save_model(f'../working/trees/{fold}.lgb')\n",
    "  dvalid['lgb_pred'] = lgb_model.predict(dvalid[cols])\n",
    "  \n",
    "  lgb_score = calc_metric({'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values, 'pred': dvalid.lgb_pred.values})\n",
    "  ic(lgb_score)\n",
    "  score = calc_metric({'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values, 'pred': (dvalid.cb_pred.values * 0.3 + dvalid.lgb_pred.values * 0.7)})\n",
    "  ic(score)\n",
    "  \n",
    "  merge_scores.append(merge_score)\n",
    "  cbt_scores.append(cbt_score)\n",
    "  lgb_scores.append(lgb_score)\n",
    "  scores.append(score)\n",
    "  ic(fold, \n",
    "     np.asarray(merge_scores).mean(), \n",
    "     np.asarray(cbt_scores).mean(), \n",
    "     np.asarray(lgb_scores).mean(),\n",
    "     np.asarray(scores).mean(),\n",
    "     )\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'feat_importances' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_52780/4086542548.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgezi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbt_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/work/pikachu/utils/gezi/plot.py\u001b[0m in \u001b[0;36mfeature_importance\u001b[0;34m(model, topn)\u001b[0m\n\u001b[1;32m    823\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lightgbm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0mfeat_importances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m   \u001b[0msorted_idxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_importances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtopn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0msorted_idxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_idxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtopn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'feat_importances' referenced before assignment"
     ]
    }
   ],
   "source": [
    "gezi.plot.feature_importance(cbt_model, topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gezi.plot.feature_importance(lgb_model, topn=20)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1925003cfa3979ae366740114cfe890bf8d7ad5b88e4afe0ec571fe261ed45e3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
