{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../../../../utils')\n",
    "sys.path.append('../../../../third')\n",
    "from gezi.common import *\n",
    "from src.config import *\n",
    "from src.preprocess import *\n",
    "from src.eval import *\n",
    "gezi.init_flags()\n",
    "gezi.set_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 7\n",
    "root = f'../working/offline/{V}/0'\n",
    "# pairwise two tower, recall model\n",
    "# pt_model = 'all-mpnet-base-v2.flag-pairwise14-2-pre_ext_emlm_mlm.ep1'\n",
    "# p2t_model = 'all-mpnet-base-v2.flag-pairwise14-2'\n",
    "pt_model = 'all-mpnet-base-v2.flag-pairwise14-2-pre_mlm3'\n",
    "# pt_model = 'all-mpnet-base-v2.flag-pairwise14-2'\n",
    "# pt_model2 = 'pmminilm.flag-pairwise14-2-pre_emlm_mlm-mmnilm'\n",
    "# pt_model2 = 'pmminilm.flag-pairwise14-2-pre_mlm3-pmminilm'\n",
    "pt_model2 = 'pmminilm.flag-pairwise14-2'\n",
    "# pairwise concat, rank model\n",
    "# pc_model = 'deberta-v3-small.flag-pairwise14-4-cat-insert-extpred-ft.neg_rand_prob-0.neg_strategy-rand-sample'\n",
    "pc_model = 'deberta-v3-small.flag-pairwise14-4-cat-insert-oof-ft'\n",
    "\n",
    "# context model\n",
    "# c_model = 'deberta-v3-small.flag-context4-2-d'\n",
    "# c_model2 = 'lsg-mminilm.flag-context4-3-d-s-mminilm'\n",
    "# c_model = 'deberta-v3-small.flag-context4-2-d'\n",
    "# c_model = 'deberta-v3-small.flag-context4-2-d-oof-ft'\n",
    "c_model = 'deberta-v3-small.flag-context4-2-d-oof-ft.list_train_ordered'\n",
    "# c_model = 'deberta-v3-small.flag-context4-2-d-extpred-ft.0804'\n",
    "# c_model = 'deberta-v3-small.flag-context4-2-d-oof-ft.list_train_ordered'\n",
    "c_model2 = 'lsg-mminilm.flag-context4-3-d-s-oof-ft-mminilm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_feather('../working/train.fea')\n",
    "df_train = df_train[df_train.fold==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = gezi.load(f'{root}/{pt_model}.eval/valid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'cell_id', 'cid', 'pred', 'max_prob', 'max_sim', 'cls_pred', 'n_words', 'match_rank', 'match_code', 'n_code_cell', 'n_cell', 'probs', 'sims'])"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xp.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp2 = gezi.load(f'{root}/{pt_model2}.eval/valid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc = gezi.load(f'{root}/{c_model}.eval/valid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpc = gezi.load(f'{root}/{pc_model}.eval/valid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xc2 = gezi.load(f'{root}/{c_model2}.eval/valid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27590"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(xp['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "gezi.save(xp, '../working/xs/xp.pkl')\n",
    "gezi.save(xp2, '../working/xs/xp2.pkl')\n",
    "gezi.save(xc, '../working/xs/xc.pkl')\n",
    "gezi.save(xpc, '../working/xs/xpc.pkl')\n",
    "# gezi.save(xc2, '../working/xs/xc2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'cell_id', 'cid', 'cell_type', 'rank', 'rel_rank', 'match_code', 'n_code_cell', 'n_markdown_cell', 'n_cell', 'code_idxes', 'n_words', 'pred', 'cls_pred_ori', 'cls_pred', 'probs', 'match_rank'])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xpc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc_metric(xc, 'reg_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pred', 'cls_pred', 'cid', 'group_pos', 'group_rank', 'pred_id', 'id', 'cell_id', 'cell_type', 'rank', 'rel_rank', 'n_code_cell', 'n_markdown_cell', 'n_cell', 'n_words', 'reg_pred', 'cls_pred_ori', 'cls2_pred'])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = pd.DataFrame(gezi.batch2list(xc))\n",
    "# dg = d.groupby('pred_id')\n",
    "# max_preds = dg['pred'].max()\n",
    "# min_preds = dg['pred'].min()\n",
    "# max_cls_preds = dg['cls_pred'].max()\n",
    "# min_cls_preds = dg['cls_pred'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "gezi.sort_dict_byid_(xp, 'cid')\n",
    "gezi.sort_dict_byid_(xp2, 'cid')\n",
    "gezi.sort_dict_byid_(xc, 'cid')\n",
    "gezi.sort_dict_byid_(xpc, 'cid')\n",
    "# gezi.sort_dict_byid_(xc2, 'cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/06/22 21:57:55] 238809541.py:25 in <module>\n",
      "                    xpc['mark'].mean(): 0.13489809221472057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13489809221472057"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_negs = xpc['cls_pred_ori'].shape[1] \n",
    "pc_preds = dict(zip(xpc['cid'], xpc['pred']))\n",
    "pc_cls_preds = dict(zip(xpc['cid'], xpc['cls_pred']))\n",
    "pc_probs = dict(zip(xpc['cid'], xpc['probs']))\n",
    "\n",
    "preds = []\n",
    "cls_preds = []\n",
    "probs = []\n",
    "marks = []\n",
    "for cid, pred, cls_pred, prob in zip(xp['cid'], xp['pred'], xp['cls_pred'], xp['probs']):\n",
    "  preds.append(pc_preds.get(cid, pred))\n",
    "  cls_preds.append(pc_cls_preds.get(cid, cls_pred))\n",
    "  if prob.max() < 0.4:\n",
    "    marks.append(1)\n",
    "    probs.append(pc_probs.get(cid, prob))\n",
    "  else:\n",
    "    probs.append(prob)\n",
    "    marks.append(0)\n",
    "\n",
    "xpc = xp.copy()\n",
    "xpc['pred'] = np.asarray(preds)\n",
    "xpc['cls_pred'] = np.asarray(cls_preds)\n",
    "xpc['probs'] = np.asarray(probs)\n",
    "xpc['mark'] = np.asarray(marks)\n",
    "ic(xpc['mark'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_COL = 'rel_rank'\n",
    "def diff_feats(x, l,r, name):\n",
    "  if isinstance(l, str):\n",
    "    x[f'{name}_diff'] = x[l] - x[r]\n",
    "  else:\n",
    "    x[f'{name}_diff'] = l - r\n",
    "  x[f'abs_{name}_diff'] = abs(x[f'{name}_diff'])\n",
    "\n",
    "def gen_pfeat(x_, topn=10):\n",
    "  x = {}\n",
    "  keys = ['pred', 'cls_pred']\n",
    "  x = {k: x_[k] for k in keys}\n",
    "  x['rank_pred'] = x['pred'] * (1 + x_['n_code_cell']) - 0.5\n",
    "  x['cls_rank_pred'] = x['cls_pred'] * (1 + x_['n_code_cell']) - 0.5\n",
    "  x['min_prob'] = x_['probs'].min()\n",
    "  x['var_prob'] = np.var(x_['probs'])\n",
    "  if 'sims' in x_:\n",
    "    x['min_sim'] = x_['sims'].min()\n",
    "    x['var_sim'] = np.var(x_['sims'])\n",
    "  \n",
    "  idxes = (-x_['probs']).argsort()\n",
    "  for i in range(topn):\n",
    "    if i < len(idxes):\n",
    "      if i > 0:\n",
    "        x[f'top_pred_{i}'] = (idxes[i] + 0.5) / (x_['n_code_cell'] + 1)\n",
    "      x[f'top_prob_{i}'] = x_['probs'][idxes[i]]\n",
    "      if 'sims' in x_:\n",
    "        x[f'top_sim_{i}'] = x_['sims'][idxes[i]]\n",
    "    else:\n",
    "      x[f'top_pred_{i}'] = -1\n",
    "      x[f'top_prob_{i}'] = -1\n",
    "      if 'sims' in x_:\n",
    "        x[f'top_sim_{i}'] = -1\n",
    "  \n",
    "  diff_feats(x, 'cls_pred', 'pred', 'cls')\n",
    "  return x\n",
    "\n",
    "def gen_cfeat(x_):\n",
    "  topn = 4\n",
    "  x = {}\n",
    "  keys = [\n",
    "    'pred', \n",
    "    'cls_pred', \n",
    "    'reg_pred', \n",
    "    'cls2_pred', \n",
    "    'group_pos',\n",
    "    'group_rank',\n",
    "    ]\n",
    "  x = {k: x_[k] for k in keys}\n",
    "  x['rank_pred'] = x['pred'] * FLAGS.num_classes - 0.5\n",
    "  x['cls_rank_pred'] = x['cls_pred'] * FLAGS.num_classes - 0.5\n",
    "  x['cls2_rank_pred'] = x['cls2_pred'] * FLAGS.num_classes - 0.5\n",
    "  x['reg_rank_pred'] = x['cls_pred'] * FLAGS.num_classes - 0.5\n",
    "  preds = x_['cls_pred_ori']\n",
    "  probs = gezi.softmax(preds)\n",
    "  x['min_prob'] = probs.min()\n",
    "  x['var_prob'] = np.var(probs)\n",
    "  idxes = (-probs).argsort()\n",
    "\n",
    "  for i in range(topn):\n",
    "    if i < len(idxes):\n",
    "      if i > 0:\n",
    "        x[f'top_pred_{i}'] = (idxes[i] + 0.5) / FLAGS.num_classes\n",
    "      x[f'top_prob_{i}'] = probs[idxes[i]]\n",
    "    else:\n",
    "      x[f'top_pred_{i}'] = -1\n",
    "      x[f'top_prob_{i}'] = -1\n",
    "  diff_feats(x, 'cls_pred', 'reg_pred', 'cls_reg')\n",
    "  diff_feats(x, 'cls_pred', 'cls2_pred', 'cls_cls2')\n",
    "  diff_feats(x, 'cls2_pred', 'reg_pred', 'cls2_reg')\n",
    "  \n",
    "  # group_id = x_['pred_id']\n",
    "  # x['max_pred'] = max_preds[group_id]\n",
    "  # x['min_pred'] = min_preds[group_id]\n",
    "  # x['pred_ratio'] = (x['pred'] - x['min_pred']) / (x['max_pred'] - x['min_pred']) if (x['max_pred'] - x['min_pred']) else 1\n",
    "  # x['max_cls_pred'] = max_cls_preds[group_id]\n",
    "  # x['min_cls_pred'] = min_cls_preds[group_id]\n",
    "  # x['cls_pred_ratio'] = (x['cls_pred'] - x['min_cls_pred']) / (x['max_cls_pred'] - x['min_cls_pred']) if (x['max_cls_pred'] - x['min_cls_pred']) else 1\n",
    "  \n",
    "  return x\n",
    "\n",
    "def gen_feats():\n",
    "  xs = gezi.batch2list(xp)\n",
    "  p_feats = [gen_pfeat(x) for x in tqdm(xs, desc=f'gen_pfeats:xp')]\n",
    "  xs = gezi.batch2list(xp2)\n",
    "  p2_feats = [gen_pfeat(x) for x in tqdm(xs, desc=f'gen_pfeats:xp2')]\n",
    "  xs = gezi.batch2list(xc)\n",
    "  c_feats = [gen_cfeat(x) for x in tqdm(xs, desc=f'gen_cfeats:xc')]\n",
    "  xs = gezi.batch2list(xpc)\n",
    "  pc_feats = [gen_pfeat(x, topn=5) for x in tqdm(xs, desc=f'gen_pfeats:xpc')]\n",
    "  # xs = gezi.batch2list(xc2)\n",
    "  # c2_feats = [gen_cfeat(x) for x in tqdm(xs, desc=f'gen_cfeats:xc2')]\n",
    "  feats = []\n",
    "  for i in tqdm(range(len(xs)), desc='merge_feats'):\n",
    "    fe1 = p_feats[i]\n",
    "    fe2= p2_feats[i]\n",
    "    fec = c_feats[i]\n",
    "    fepc = pc_feats[i]\n",
    "    fepc['mark'] = xpc['mark'][i]\n",
    "    # fec2 = c2_feats[i]\n",
    "    \n",
    "    fe = {}\n",
    "    fe['code_ratio'] = xp['n_code_cell'][i] / xp['n_cell'][i]\n",
    "    diff_feats(fe, fe1['pred'], fe2['pred'], 'ps')\n",
    "    diff_feats(fe, fe1['cls_pred'], fe2['cls_pred'], 'ps_cls')\n",
    "    diff_feats(fe, fe1['pred'], fec['reg_pred'], 'pc_reg')\n",
    "    diff_feats(fe, fe2['pred'], fec['reg_pred'], 'p2c_reg')\n",
    "    diff_feats(fe, fe1['pred'], fec['cls_pred'], 'pc_cls')\n",
    "    diff_feats(fe, fe2['pred'], fec['cls_pred'], 'p2c_cls')\n",
    "    diff_feats(fe, fe1['pred'], fec['cls2_pred'], 'pc_cls2')\n",
    "    diff_feats(fe, fe2['pred'], fec['cls2_pred'], 'p2c_cls2')\n",
    "    diff_feats(fe, fe1['cls_pred'], fec['reg_pred'], 'pc_cls_reg')\n",
    "    diff_feats(fe, fe2['cls_pred'], fec['reg_pred'], 'p2c_cls_reg')\n",
    "    diff_feats(fe, fe1['cls_pred'], fec['cls_pred'], 'pc_cls_cls')\n",
    "    diff_feats(fe, fe2['cls_pred'], fec['cls_pred'], 'p2c_cls_cls')\n",
    "    diff_feats(fe, fe1['cls_pred'], fec['cls2_pred'], 'pc_cls_cls2')\n",
    "    diff_feats(fe, fe2['cls_pred'], fec['cls2_pred'], 'p2c_cls_cls2')\n",
    "    \n",
    "    diff_feats(fe, fepc['pred'], fec['reg_pred'], 'pcc_reg')\n",
    "    diff_feats(fe, fepc['pred'], fec['cls_pred'], 'pcc_cls')\n",
    "    diff_feats(fe, fepc['pred'], fec['cls2_pred'], 'pcc_cls2')\n",
    "    diff_feats(fe, fepc['cls_pred'], fec['reg_pred'], 'pcc_cls_reg')\n",
    "    diff_feats(fe, fepc['cls_pred'], fec['cls_pred'], 'pcc_cls_cls')\n",
    "    diff_feats(fe, fepc['cls_pred'], fec['cls2_pred'], 'pcc_cls_cls2')\n",
    "\n",
    "    fe1 = gezi.dict_prefix(fe1, 'xp_')\n",
    "    fe.update(fe1)\n",
    "    fe2 = gezi.dict_prefix(fe2, 'xp2_')\n",
    "    fe.update(fe2)\n",
    "    fec = gezi.dict_prefix(fec, 'xc_')\n",
    "    fe.update(fec)\n",
    "    fepc = gezi.dict_prefix(fepc, 'xpc_')\n",
    "    fe.update(fepc)\n",
    "    # fec2 = gezi.dict_prefix(fec, 'xc2_')\n",
    "    # fe.update(fec2)\n",
    "    \n",
    "    keys = [\n",
    "     'id', 'cell_id', 'cid',\n",
    "     'n_words', 'n_code_cell', 'n_cell'\n",
    "    ]\n",
    "    for key in keys:\n",
    "      fe[key] = xp[key][i]\n",
    "      \n",
    "    #  ic(feat)\n",
    "    feats.append(fe)\n",
    "  #  break\n",
    "  dfeats = pd.DataFrame(feats)\n",
    "  return dfeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12540fac791549019e2ffd4fcaaefdad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gen_pfeats:xp:   0%|          | 0/424943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa224d19b2b0457e9759e056d8197125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gen_pfeats:xp2:   0%|          | 0/424943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350db93541704b83b99032f236125867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gen_cfeats:xc:   0%|          | 0/424943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c8c5353aac4e82bfc60e645263cbbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gen_pfeats:xpc:   0%|          | 0/424943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23cb5dfff21b4542aa7efb66aef6ac66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merge_feats:   0%|          | 0/424943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfeats = gen_feats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfeats.merge(df_train[['cid', 'ancestor_id', LABEL_COL]], on='cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "gezi.set_fold(df, 5, 'ancestor_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_cols = [x for x in dfeats.columns if x not in ['id', 'cell_id', 'cid', LABEL_COL]]\n",
    "cat_cols = []\n",
    "cols = reg_cols + cat_cols\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "dvalid = df[df.fold==fold]\n",
    "dtrain = df[df.fold!=fold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dtrain[cols]\n",
    "y_train = dtrain[LABEL_COL]\n",
    "X_valid = dvalid[cols]\n",
    "y_valid = dvalid[LABEL_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, CatBoostRanker\n",
    "cbt_params = {\n",
    "              # 'bootstrap_type': 'Poisson',\n",
    "              # 'learning_rate': 0.02,\n",
    "              'learning_rate': 0.03,\n",
    "              'reg_lambda': 7.960622217848342e-07, \n",
    "              'subsample': 0.7422597612762745,\n",
    "              # 'bagging_temperature': 0.2,\n",
    "              'max_depth': 10, \n",
    "              'early_stopping_rounds': 500,\n",
    "              'n_estimators': 10000,\n",
    "              'cat_features': [],\n",
    "              'loss_function': 'MAE',\n",
    "              'min_child_samples': 100,\n",
    "              # 'task_type': 'GPU',\n",
    "              # 'devices': '0',\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2521270\ttest: 0.2521270\ttest1: 0.2520677\tbest: 0.2520677 (0)\ttotal: 117ms\tremaining: 19m 30s\n",
      "100:\tlearn: 0.0658651\ttest: 0.0658651\ttest1: 0.0677811\tbest: 0.0677811 (100)\ttotal: 10.9s\tremaining: 17m 51s\n",
      "200:\tlearn: 0.0588522\ttest: 0.0588522\ttest1: 0.0612441\tbest: 0.0612441 (200)\ttotal: 20.9s\tremaining: 17m\n",
      "300:\tlearn: 0.0572635\ttest: 0.0572635\ttest1: 0.0600526\tbest: 0.0600526 (300)\ttotal: 29s\tremaining: 15m 35s\n",
      "400:\tlearn: 0.0562642\ttest: 0.0562642\ttest1: 0.0594592\tbest: 0.0594592 (400)\ttotal: 38.1s\tremaining: 15m 10s\n",
      "500:\tlearn: 0.0555671\ttest: 0.0555671\ttest1: 0.0591370\tbest: 0.0591370 (500)\ttotal: 48.8s\tremaining: 15m 25s\n",
      "600:\tlearn: 0.0550424\ttest: 0.0550424\ttest1: 0.0589438\tbest: 0.0589422 (599)\ttotal: 1m\tremaining: 15m 44s\n",
      "700:\tlearn: 0.0545422\ttest: 0.0545422\ttest1: 0.0588120\tbest: 0.0588120 (700)\ttotal: 1m 13s\tremaining: 16m 18s\n",
      "800:\tlearn: 0.0541464\ttest: 0.0541464\ttest1: 0.0587282\tbest: 0.0587281 (799)\ttotal: 1m 30s\tremaining: 17m 14s\n",
      "900:\tlearn: 0.0537275\ttest: 0.0537275\ttest1: 0.0586473\tbest: 0.0586473 (900)\ttotal: 1m 42s\tremaining: 17m 14s\n",
      "1000:\tlearn: 0.0533306\ttest: 0.0533306\ttest1: 0.0585982\tbest: 0.0585953 (999)\ttotal: 1m 53s\tremaining: 16m 59s\n",
      "1100:\tlearn: 0.0529535\ttest: 0.0529535\ttest1: 0.0585798\tbest: 0.0585798 (1100)\ttotal: 2m 11s\tremaining: 17m 38s\n",
      "1200:\tlearn: 0.0526050\ttest: 0.0526050\ttest1: 0.0585689\tbest: 0.0585671 (1195)\ttotal: 2m 23s\tremaining: 17m 32s\n",
      "1300:\tlearn: 0.0522535\ttest: 0.0522535\ttest1: 0.0585753\tbest: 0.0585647 (1251)\ttotal: 2m 37s\tremaining: 17m 30s\n",
      "1400:\tlearn: 0.0519258\ttest: 0.0519258\ttest1: 0.0585552\tbest: 0.0585545 (1397)\ttotal: 2m 50s\tremaining: 17m 23s\n",
      "1500:\tlearn: 0.0515857\ttest: 0.0515857\ttest1: 0.0585562\tbest: 0.0585538 (1405)\ttotal: 3m 3s\tremaining: 17m 20s\n",
      "1600:\tlearn: 0.0512616\ttest: 0.0512616\ttest1: 0.0585404\tbest: 0.0585383 (1593)\ttotal: 3m 16s\tremaining: 17m 12s\n",
      "1700:\tlearn: 0.0509393\ttest: 0.0509393\ttest1: 0.0585379\tbest: 0.0585354 (1673)\ttotal: 3m 29s\tremaining: 17m 4s\n",
      "1800:\tlearn: 0.0505499\ttest: 0.0505499\ttest1: 0.0585387\tbest: 0.0585354 (1673)\ttotal: 3m 43s\tremaining: 16m 55s\n",
      "1900:\tlearn: 0.0502168\ttest: 0.0502168\ttest1: 0.0585494\tbest: 0.0585339 (1821)\ttotal: 3m 56s\tremaining: 16m 46s\n",
      "2000:\tlearn: 0.0499113\ttest: 0.0499113\ttest1: 0.0585792\tbest: 0.0585339 (1821)\ttotal: 4m 9s\tremaining: 16m 38s\n",
      "2100:\tlearn: 0.0495620\ttest: 0.0495620\ttest1: 0.0585848\tbest: 0.0585339 (1821)\ttotal: 4m 22s\tremaining: 16m 27s\n",
      "2200:\tlearn: 0.0492225\ttest: 0.0492225\ttest1: 0.0586196\tbest: 0.0585339 (1821)\ttotal: 4m 35s\tremaining: 16m 15s\n",
      "2300:\tlearn: 0.0488895\ttest: 0.0488895\ttest1: 0.0586380\tbest: 0.0585339 (1821)\ttotal: 4m 48s\tremaining: 16m 4s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.05853389455\n",
      "bestIteration = 1821\n",
      "\n",
      "Shrink model to first 1822 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/06/22 22:08:09] 3249242939.py:8 in <module>\n",
      "                    cbt_score: 0.9180987808225505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9180987808225505"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbt_model = CatBoostRegressor(**cbt_params)\n",
    "cbt_model.fit(X_train, y_train,\n",
    "      eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "              verbose=100,\n",
    "              )  \n",
    "dvalid['cb_pred'] = cbt_model.predict(dvalid[cols])\n",
    "cbt_score = calc_metric({'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values, 'pred': dvalid.cb_pred.values})\n",
    "ic(cbt_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "importance=%{x}<br>feat_name=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "h",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          1.0268210414353016,
          1.0849774222957522,
          1.2889745387328975,
          1.2948876930920177,
          1.339791647514763,
          1.4402574706947278,
          1.6348087811595173,
          1.641003034208947,
          2.0058465078949395,
          2.1918526128094027,
          2.1918900591603037,
          2.253019449958029,
          2.342717549391975,
          2.5110909157792576,
          3.4294832568241977,
          4.183848158968111,
          4.3232186848988725,
          5.747144279234261,
          6.808999036522421,
          10.19669915186645
         ],
         "xaxis": "x",
         "y": [
          "xpc_top_pred_2",
          "abs_pcc_cls_diff",
          "xc_top_pred_2",
          "xp2_top_pred_1",
          "xpc_cls_diff",
          "xc_reg_rank_pred",
          "xc_cls_pred",
          "xc_top_pred_3",
          "xp2_cls_pred",
          "xc_cls2_rank_pred",
          "xc_cls_rank_pred",
          "xp2_pred",
          "xc_pred",
          "xpc_abs_cls_diff",
          "xc_rank_pred",
          "xc_reg_pred",
          "xp_pred",
          "xp_cls_pred",
          "xpc_pred",
          "xpc_cls_pred"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "importance"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "feat_name"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"f6d4775d-72e7-4725-9547-c8d62826ddcc\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f6d4775d-72e7-4725-9547-c8d62826ddcc\")) {                    Plotly.newPlot(                        \"f6d4775d-72e7-4725-9547-c8d62826ddcc\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"importance=%{x}<br>feat_name=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"h\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[1.0268210414353016,1.0849774222957522,1.2889745387328975,1.2948876930920177,1.339791647514763,1.4402574706947278,1.6348087811595173,1.641003034208947,2.0058465078949395,2.1918526128094027,2.1918900591603037,2.253019449958029,2.342717549391975,2.5110909157792576,3.4294832568241977,4.183848158968111,4.3232186848988725,5.747144279234261,6.808999036522421,10.19669915186645],\"xaxis\":\"x\",\"y\":[\"xpc_top_pred_2\",\"abs_pcc_cls_diff\",\"xc_top_pred_2\",\"xp2_top_pred_1\",\"xpc_cls_diff\",\"xc_reg_rank_pred\",\"xc_cls_pred\",\"xc_top_pred_3\",\"xp2_cls_pred\",\"xc_cls2_rank_pred\",\"xc_cls_rank_pred\",\"xp2_pred\",\"xc_pred\",\"xpc_abs_cls_diff\",\"xc_rank_pred\",\"xc_reg_pred\",\"xp_pred\",\"xp_cls_pred\",\"xpc_pred\",\"xpc_cls_pred\"],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"importance\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"feat_name\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('f6d4775d-72e7-4725-9547-c8d62826ddcc');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gezi.plot.feature_importance(cbt_model, topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gezi.plot.feature_importance_df(cbt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_name</th>\n",
       "      <th>importanace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xpc_cls_pred</td>\n",
       "      <td>10.1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xpc_pred</td>\n",
       "      <td>6.8090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xp_cls_pred</td>\n",
       "      <td>5.7471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xp_pred</td>\n",
       "      <td>4.3232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xc_reg_pred</td>\n",
       "      <td>4.1838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feat_name  importanace\n",
       "0  xpc_cls_pred      10.1967\n",
       "1      xpc_pred       6.8090\n",
       "2   xp_cls_pred       5.7471\n",
       "3       xp_pred       4.3232\n",
       "4   xc_reg_pred       4.1838"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_name</th>\n",
       "      <th>importanace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [feat_name, importanace]\n",
       "Index: []"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[f.feat_name=='c_cls_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_name</th>\n",
       "      <th>importanace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [feat_name, importanace]\n",
       "Index: []"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[f.feat_name=='c_reg_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_name</th>\n",
       "      <th>importanace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [feat_name, importanace]\n",
       "Index: []"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[f.feat_name=='c_pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_name</th>\n",
       "      <th>importanace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [feat_name, importanace]\n",
       "Index: []"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[f.feat_name=='c_max_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 42239\n",
      "[LightGBM] [Info] Number of data points in the train set: 342411, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score 0.455056\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.0679607\tvalid_1's l1: 0.0693578\n",
      "[200]\ttraining's l1: 0.0601533\tvalid_1's l1: 0.0616897\n",
      "[300]\ttraining's l1: 0.0586329\tvalid_1's l1: 0.060265\n",
      "[400]\ttraining's l1: 0.0575984\tvalid_1's l1: 0.059332\n",
      "[500]\ttraining's l1: 0.0571358\tvalid_1's l1: 0.0589539\n",
      "[600]\ttraining's l1: 0.0568726\tvalid_1's l1: 0.0587605\n",
      "[700]\ttraining's l1: 0.0567056\tvalid_1's l1: 0.0586502\n",
      "[800]\ttraining's l1: 0.056569\tvalid_1's l1: 0.0585723\n",
      "[900]\ttraining's l1: 0.0564228\tvalid_1's l1: 0.0584939\n",
      "[1000]\ttraining's l1: 0.056297\tvalid_1's l1: 0.0584283\n",
      "[1100]\ttraining's l1: 0.056199\tvalid_1's l1: 0.0583855\n",
      "[1200]\ttraining's l1: 0.0561269\tvalid_1's l1: 0.0583564\n",
      "[1300]\ttraining's l1: 0.0560263\tvalid_1's l1: 0.0583076\n",
      "[1400]\ttraining's l1: 0.0559345\tvalid_1's l1: 0.0582749\n",
      "[1500]\ttraining's l1: 0.0558661\tvalid_1's l1: 0.0582523\n",
      "[1600]\ttraining's l1: 0.0558011\tvalid_1's l1: 0.0582244\n",
      "[1700]\ttraining's l1: 0.0557446\tvalid_1's l1: 0.0582084\n",
      "[1800]\ttraining's l1: 0.0556797\tvalid_1's l1: 0.0581876\n",
      "[1900]\ttraining's l1: 0.05562\tvalid_1's l1: 0.0581703\n",
      "[2000]\ttraining's l1: 0.0555644\tvalid_1's l1: 0.0581582\n",
      "[2100]\ttraining's l1: 0.0555052\tvalid_1's l1: 0.0581398\n",
      "[2200]\ttraining's l1: 0.0554486\tvalid_1's l1: 0.0581204\n",
      "[2300]\ttraining's l1: 0.0554007\tvalid_1's l1: 0.0581073\n",
      "[2400]\ttraining's l1: 0.0553499\tvalid_1's l1: 0.0580974\n",
      "[2500]\ttraining's l1: 0.055294\tvalid_1's l1: 0.0580834\n",
      "[2600]\ttraining's l1: 0.0552251\tvalid_1's l1: 0.0580639\n",
      "[2700]\ttraining's l1: 0.0551662\tvalid_1's l1: 0.0580489\n",
      "[2800]\ttraining's l1: 0.0551177\tvalid_1's l1: 0.058037\n",
      "[2900]\ttraining's l1: 0.0550771\tvalid_1's l1: 0.0580292\n",
      "[3000]\ttraining's l1: 0.0550234\tvalid_1's l1: 0.0580175\n",
      "[3100]\ttraining's l1: 0.0549627\tvalid_1's l1: 0.058008\n",
      "[3200]\ttraining's l1: 0.0548982\tvalid_1's l1: 0.0579885\n",
      "[3300]\ttraining's l1: 0.0548514\tvalid_1's l1: 0.0579794\n",
      "[3400]\ttraining's l1: 0.0547589\tvalid_1's l1: 0.0579641\n",
      "[3500]\ttraining's l1: 0.0546898\tvalid_1's l1: 0.0579552\n",
      "[3600]\ttraining's l1: 0.0546297\tvalid_1's l1: 0.0579385\n",
      "[3700]\ttraining's l1: 0.0545266\tvalid_1's l1: 0.0579254\n",
      "[3800]\ttraining's l1: 0.0544803\tvalid_1's l1: 0.0579161\n",
      "[3900]\ttraining's l1: 0.0543642\tvalid_1's l1: 0.0579035\n",
      "[4000]\ttraining's l1: 0.0542316\tvalid_1's l1: 0.0578937\n",
      "[4100]\ttraining's l1: 0.0541367\tvalid_1's l1: 0.0578807\n",
      "[4200]\ttraining's l1: 0.0541176\tvalid_1's l1: 0.0578771\n",
      "[4300]\ttraining's l1: 0.0540837\tvalid_1's l1: 0.0578672\n",
      "[4400]\ttraining's l1: 0.0540439\tvalid_1's l1: 0.05786\n",
      "[4500]\ttraining's l1: 0.0539868\tvalid_1's l1: 0.0578506\n",
      "[4600]\ttraining's l1: 0.053959\tvalid_1's l1: 0.0578439\n",
      "[4700]\ttraining's l1: 0.0539352\tvalid_1's l1: 0.05784\n",
      "[4800]\ttraining's l1: 0.0539067\tvalid_1's l1: 0.0578344\n",
      "[4900]\ttraining's l1: 0.0538709\tvalid_1's l1: 0.0578292\n",
      "[5000]\ttraining's l1: 0.0538391\tvalid_1's l1: 0.0578248\n",
      "[5100]\ttraining's l1: 0.0537987\tvalid_1's l1: 0.0578188\n",
      "[5200]\ttraining's l1: 0.053754\tvalid_1's l1: 0.0578111\n",
      "[5300]\ttraining's l1: 0.0537164\tvalid_1's l1: 0.0578074\n",
      "[5400]\ttraining's l1: 0.0536908\tvalid_1's l1: 0.0578039\n",
      "[5500]\ttraining's l1: 0.0536489\tvalid_1's l1: 0.0577989\n",
      "[5600]\ttraining's l1: 0.0536198\tvalid_1's l1: 0.0577986\n",
      "Early stopping, best iteration is:\n",
      "[5518]\ttraining's l1: 0.0536423\tvalid_1's l1: 0.0577979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/06/22 22:10:19] 4120804186.py:36 in <module>\n",
      "                    lgb_score: 0.9189092236293597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9189092236293597"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "params = {\n",
    "          'boosting': 'gbdt',\n",
    "          'objective': 'regression_l1',\n",
    "          'metric': {'l1'},\n",
    "          'num_leaves': 32,\n",
    "          # 'num_leaves': 16,\n",
    "          'min_data_in_leaf': 300,\n",
    "          # 'min_data_in_leaf': 500,\n",
    "          # 'max_depth': 5,\n",
    "          'learning_rate': 0.03,\n",
    "          # \"feature_fraction\": 0.8,\n",
    "          # \"bagging_fraction\": 0.75,\n",
    "          # \"feature_fraction\": 0.9,\n",
    "          # \"bagging_fraction\": 0.8,\n",
    "          'feature_fraction': 0.7,\n",
    "          'bagging_fraction': 0.7,\n",
    "          'min_data_in_bin':100,\n",
    "          \"lambda_l1\": 1e-7,\n",
    "          'lambda_l2': 1e-7,\n",
    "          \"random_state\": 1024,\n",
    "          \"num_threads\": 12,\n",
    "          }\n",
    "\n",
    "d_train = lgb.Dataset(X_train, y_train)\n",
    "d_valid = lgb.Dataset(X_valid, y_valid, reference=d_train)\n",
    "\n",
    "lgb_model = lgb.train(params,\n",
    "                d_train,\n",
    "                10000,\n",
    "                valid_sets=[d_train, d_valid],\n",
    "                verbose_eval=100,\n",
    "                early_stopping_rounds=100)\n",
    "dvalid['lgb_pred'] = lgb_model.predict(dvalid[cols])\n",
    "lgb_score = calc_metric({'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values, 'pred': dvalid.lgb_pred.values})\n",
    "ic(lgb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "importance=%{x}<br>feat_name=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "h",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          1617,
          1627,
          1647,
          1653,
          1683,
          1731,
          1757,
          1769,
          1809,
          1857,
          1979,
          1980,
          2027,
          2055,
          2269,
          2332,
          2581,
          2757,
          3197,
          4915
         ],
         "xaxis": "x",
         "y": [
          "xc_cls_cls2_diff",
          "pcc_cls2_diff",
          "xc_cls_pred",
          "xc_abs_cls2_reg_diff",
          "xp2_cls_pred",
          "xc_reg_pred",
          "pcc_cls_diff",
          "abs_pcc_cls_diff",
          "xc_rank_pred",
          "xc_top_prob_2",
          "xc_abs_cls_cls2_diff",
          "xc_pred",
          "code_ratio",
          "xp_pred",
          "xc_top_prob_1",
          "xpc_pred",
          "xp_cls_pred",
          "xpc_cls_diff",
          "xpc_abs_cls_diff",
          "xpc_cls_pred"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "importance"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "feat_name"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"2455fd33-2811-49bd-90b0-4b69a9fd32b7\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2455fd33-2811-49bd-90b0-4b69a9fd32b7\")) {                    Plotly.newPlot(                        \"2455fd33-2811-49bd-90b0-4b69a9fd32b7\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"importance=%{x}<br>feat_name=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"h\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[1617,1627,1647,1653,1683,1731,1757,1769,1809,1857,1979,1980,2027,2055,2269,2332,2581,2757,3197,4915],\"xaxis\":\"x\",\"y\":[\"xc_cls_cls2_diff\",\"pcc_cls2_diff\",\"xc_cls_pred\",\"xc_abs_cls2_reg_diff\",\"xp2_cls_pred\",\"xc_reg_pred\",\"pcc_cls_diff\",\"abs_pcc_cls_diff\",\"xc_rank_pred\",\"xc_top_prob_2\",\"xc_abs_cls_cls2_diff\",\"xc_pred\",\"code_ratio\",\"xp_pred\",\"xc_top_prob_1\",\"xpc_pred\",\"xp_cls_pred\",\"xpc_cls_diff\",\"xpc_abs_cls_diff\",\"xpc_cls_pred\"],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"importance\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"feat_name\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('2455fd33-2811-49bd-90b0-4b69a9fd32b7');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gezi.plot.feature_importance(lgb_model, topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               xpc_cls_pred\n",
       "1                   xpc_pred\n",
       "2                xp_cls_pred\n",
       "3                    xp_pred\n",
       "4                xc_reg_pred\n",
       "5               xc_rank_pred\n",
       "6           xpc_abs_cls_diff\n",
       "7                    xc_pred\n",
       "8                   xp2_pred\n",
       "9           xc_cls_rank_pred\n",
       "10         xc_cls2_rank_pred\n",
       "11              xp2_cls_pred\n",
       "12             xc_top_pred_3\n",
       "13               xc_cls_pred\n",
       "14          xc_reg_rank_pred\n",
       "15              xpc_cls_diff\n",
       "16            xp2_top_pred_1\n",
       "17             xc_top_pred_2\n",
       "18          abs_pcc_cls_diff\n",
       "19            xpc_top_pred_2\n",
       "20             xc_top_pred_1\n",
       "21             xp_top_pred_1\n",
       "22          abs_pcc_reg_diff\n",
       "23         xp2_cls_rank_pred\n",
       "24               xpc_min_sim\n",
       "25              xc_cls2_pred\n",
       "26              xp_top_sim_4\n",
       "27              xp_top_sim_3\n",
       "28             xp2_rank_pred\n",
       "29         abs_pcc_cls2_diff\n",
       "30            xpc_top_pred_1\n",
       "31      abs_pcc_cls_reg_diff\n",
       "32           abs_pc_cls_diff\n",
       "33      xc_abs_cls_cls2_diff\n",
       "34           xp_abs_cls_diff\n",
       "35             xp_top_pred_2\n",
       "36               xp_cls_diff\n",
       "37          xc_cls_cls2_diff\n",
       "38              xp_top_sim_7\n",
       "39              pcc_cls_diff\n",
       "40           abs_ps_cls_diff\n",
       "41                xp_min_sim\n",
       "42           xc_cls_reg_diff\n",
       "43          pcc_cls_cls_diff\n",
       "44            xpc_top_pred_4\n",
       "45             xpc_top_sim_4\n",
       "46             xpc_top_sim_0\n",
       "47              xp_top_sim_8\n",
       "48          abs_p2c_cls_diff\n",
       "49              pcc_reg_diff\n",
       "50                code_ratio\n",
       "51              xp_top_sim_5\n",
       "52              xp_top_sim_6\n",
       "53         pcc_cls_cls2_diff\n",
       "54      xc_abs_cls2_reg_diff\n",
       "55         xpc_cls_rank_pred\n",
       "56     abs_pcc_cls_cls2_diff\n",
       "57             xp_top_prob_0\n",
       "58           abs_pc_reg_diff\n",
       "59            xpc_top_prob_0\n",
       "60            xp2_top_prob_2\n",
       "61         p2c_cls_cls2_diff\n",
       "62          pcc_cls_reg_diff\n",
       "63             pcc_cls2_diff\n",
       "64              xp_top_sim_1\n",
       "65               n_code_cell\n",
       "66            xp2_top_pred_7\n",
       "67            xp2_top_prob_5\n",
       "68          abs_pc_cls2_diff\n",
       "69               xp_var_prob\n",
       "70             xp_top_pred_4\n",
       "71      abs_pcc_cls_cls_diff\n",
       "72             xpc_top_sim_3\n",
       "73               pc_cls_diff\n",
       "74           pc_cls_reg_diff\n",
       "75              xc_group_pos\n",
       "76              xp2_var_prob\n",
       "77      abs_pc_cls_cls2_diff\n",
       "78               ps_cls_diff\n",
       "79             xp_top_prob_2\n",
       "80          pc_cls_cls2_diff\n",
       "81           pc_cls_cls_diff\n",
       "82             xpc_top_sim_1\n",
       "83               xc_min_prob\n",
       "84               xc_var_prob\n",
       "85          xp_cls_rank_pred\n",
       "86              xp_rank_pred\n",
       "87       abs_pc_cls_reg_diff\n",
       "88              p2c_reg_diff\n",
       "89              xp_top_sim_0\n",
       "90               pc_reg_diff\n",
       "91       xc_abs_cls_reg_diff\n",
       "92               xp2_var_sim\n",
       "93          abs_p2c_reg_diff\n",
       "94          p2c_cls_reg_diff\n",
       "95            xp2_top_pred_6\n",
       "96            xp2_top_prob_3\n",
       "97             xc_group_rank\n",
       "98                    n_cell\n",
       "99       abs_pc_cls_cls_diff\n",
       "100            xp_top_prob_1\n",
       "101            xp2_top_sim_6\n",
       "102           xpc_top_prob_3\n",
       "103             pc_cls2_diff\n",
       "104           xp2_top_prob_0\n",
       "105            xp2_top_sim_9\n",
       "106           xpc_top_prob_1\n",
       "107        abs_p2c_cls2_diff\n",
       "108           xp2_top_pred_2\n",
       "109            xc_top_prob_3\n",
       "110           xp2_top_prob_7\n",
       "111                  ps_diff\n",
       "112            xp_top_prob_3\n",
       "113           xpc_top_prob_2\n",
       "114              xp2_min_sim\n",
       "115         p2c_cls_cls_diff\n",
       "116            xp_top_prob_4\n",
       "117           xp2_top_prob_1\n",
       "118             xpc_var_prob\n",
       "119           xp2_top_prob_4\n",
       "120               xp_var_sim\n",
       "121            xc_top_prob_0\n",
       "122            p2c_cls2_diff\n",
       "123             xp2_cls_diff\n",
       "124     abs_p2c_cls_reg_diff\n",
       "125            xc_top_prob_1\n",
       "126           xpc_top_prob_4\n",
       "127         xp2_abs_cls_diff\n",
       "128            xpc_rank_pred\n",
       "129           xp2_top_pred_3\n",
       "130                  n_words\n",
       "131             xp_top_sim_9\n",
       "132            xp_top_pred_3\n",
       "133           xpc_top_pred_3\n",
       "134         xc_cls2_reg_diff\n",
       "135              abs_ps_diff\n",
       "136            xp2_top_sim_1\n",
       "137             xp_top_sim_2\n",
       "138            xp_top_pred_9\n",
       "139            xpc_top_sim_2\n",
       "140            xp2_top_sim_0\n",
       "141    abs_p2c_cls_cls2_diff\n",
       "142           xp2_top_pred_5\n",
       "143           xp2_top_prob_8\n",
       "144           xp2_top_pred_8\n",
       "145             p2c_cls_diff\n",
       "146            xp_top_pred_5\n",
       "147     abs_p2c_cls_cls_diff\n",
       "148            xc_top_prob_2\n",
       "149            xp_top_pred_8\n",
       "150            xp_top_prob_5\n",
       "151              xpc_var_sim\n",
       "152           xp2_top_prob_9\n",
       "153            xp_top_pred_6\n",
       "154             xp2_min_prob\n",
       "155            xp_top_prob_6\n",
       "156            xp2_top_sim_2\n",
       "157            xp_top_prob_9\n",
       "158            xp_top_prob_7\n",
       "159            xp_top_prob_8\n",
       "160            xp_top_pred_7\n",
       "161           xp2_top_pred_4\n",
       "162           xp2_top_prob_6\n",
       "163            xp2_top_sim_3\n",
       "164              xp_min_prob\n",
       "165            xp2_top_sim_4\n",
       "166            xp2_top_sim_8\n",
       "167             xpc_min_prob\n",
       "168           xp2_top_pred_9\n",
       "169            xp2_top_sim_5\n",
       "170            xp2_top_sim_7\n",
       "171                 xpc_mark\n",
       "Name: feat_name, dtype: object"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.feat_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61cc3ea32dcf4b64b2a1d2359c597184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/06/22 22:10:30] 1460528775.py:21 in <module>\n",
      "                    cbt_score: 0.9180987808225505\n",
      "[08/06/22 22:10:36] 1460528775.py:36 in <module>\n",
      "                    lgb_score: 0.9189092236293597\n",
      "[08/06/22 22:10:38] 1460528775.py:38 in <module>\n",
      "                    score: 0.9191193924869012\n",
      "[08/06/22 22:10:38] 1460528775.py:43 in <module>\n",
      "                    fold: 0\n",
      "                    np.asarray(cbt_scores).mean(): 0.9180987808225505\n",
      "                    np.asarray(lgb_scores).mean(): 0.9189092236293597\n",
      "                    np.asarray(scores).mean(): 0.9191193924869012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2521482\ttest: 0.2521482\ttest1: 0.2520588\tbest: 0.2520588 (0)\ttotal: 130ms\tremaining: 21m 42s\n",
      "500:\tlearn: 0.0560802\ttest: 0.0560802\ttest1: 0.0571944\tbest: 0.0571944 (500)\ttotal: 1m 4s\tremaining: 20m 28s\n",
      "1000:\tlearn: 0.0538933\ttest: 0.0538933\ttest1: 0.0567411\tbest: 0.0567406 (996)\ttotal: 2m 10s\tremaining: 19m 34s\n",
      "1500:\tlearn: 0.0520550\ttest: 0.0520550\ttest1: 0.0566893\tbest: 0.0566829 (1353)\ttotal: 3m 19s\tremaining: 18m 46s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.05668289978\n",
      "bestIteration = 1353\n",
      "\n",
      "Shrink model to first 1354 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/06/22 22:14:50] 1460528775.py:21 in <module>\n",
      "                    cbt_score: 0.9206339201638898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072868 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 42242\n",
      "[LightGBM] [Info] Number of data points in the train set: 339696, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score 0.455882\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.0575369\tvalid_1's l1: 0.0570709\n",
      "[1000]\ttraining's l1: 0.0566904\tvalid_1's l1: 0.0565963\n",
      "[1500]\ttraining's l1: 0.0562107\tvalid_1's l1: 0.0564033\n",
      "[2000]\ttraining's l1: 0.0558452\tvalid_1's l1: 0.056307\n",
      "[2500]\ttraining's l1: 0.055542\tvalid_1's l1: 0.0562538\n",
      "[3000]\ttraining's l1: 0.0552829\tvalid_1's l1: 0.0562031\n",
      "[3500]\ttraining's l1: 0.0550554\tvalid_1's l1: 0.0561654\n",
      "[4000]\ttraining's l1: 0.0548109\tvalid_1's l1: 0.0561224\n",
      "[4500]\ttraining's l1: 0.0545924\tvalid_1's l1: 0.0560891\n",
      "[5000]\ttraining's l1: 0.0543943\tvalid_1's l1: 0.0560635\n",
      "[5500]\ttraining's l1: 0.0540037\tvalid_1's l1: 0.056036\n",
      "[6000]\ttraining's l1: 0.053797\tvalid_1's l1: 0.0560096\n",
      "[6500]\ttraining's l1: 0.0536682\tvalid_1's l1: 0.0559968\n",
      "[7000]\ttraining's l1: 0.0535586\tvalid_1's l1: 0.0559822\n",
      "[7500]\ttraining's l1: 0.0534468\tvalid_1's l1: 0.055972\n",
      "Early stopping, best iteration is:\n",
      "[7542]\ttraining's l1: 0.053441\tvalid_1's l1: 0.0559711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/06/22 22:17:23] 1460528775.py:36 in <module>\n",
      "                    lgb_score: 0.9214827620173677\n",
      "[08/06/22 22:17:25] 1460528775.py:38 in <module>\n",
      "                    score: 0.9217103867731014\n",
      "[08/06/22 22:17:25] 1460528775.py:43 in <module>\n",
      "                    fold: 1\n",
      "                    np.asarray(cbt_scores).mean(): 0.9193663504932201\n",
      "                    np.asarray(lgb_scores).mean(): 0.9201959928233636\n",
      "                    np.asarray(scores).mean(): 0.9204148896300013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2520452\ttest: 0.2520452\ttest1: 0.2524351\tbest: 0.2524351 (0)\ttotal: 137ms\tremaining: 22m 52s\n",
      "500:\tlearn: 0.0558184\ttest: 0.0558184\ttest1: 0.0581517\tbest: 0.0581517 (500)\ttotal: 1m 6s\tremaining: 21m 8s\n",
      "1000:\tlearn: 0.0534504\ttest: 0.0534504\ttest1: 0.0576135\tbest: 0.0576135 (1000)\ttotal: 2m 14s\tremaining: 20m 9s\n",
      "1500:\tlearn: 0.0515893\ttest: 0.0515893\ttest1: 0.0575369\tbest: 0.0575238 (1445)\ttotal: 3m 17s\tremaining: 18m 39s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.0575237541\n",
      "bestIteration = 1445\n",
      "\n",
      "Shrink model to first 1446 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/06/22 22:21:35] 1460528775.py:21 in <module>\n",
      "                    cbt_score: 0.9206408427737685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 42235\n",
      "[LightGBM] [Info] Number of data points in the train set: 337766, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score 0.456522\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.0574115\tvalid_1's l1: 0.0582293\n",
      "[1000]\ttraining's l1: 0.0565746\tvalid_1's l1: 0.0576932\n",
      "[1500]\ttraining's l1: 0.0560955\tvalid_1's l1: 0.0574699\n",
      "[2000]\ttraining's l1: 0.0557441\tvalid_1's l1: 0.0573471\n",
      "[2500]\ttraining's l1: 0.0554411\tvalid_1's l1: 0.0572534\n",
      "[3000]\ttraining's l1: 0.0551335\tvalid_1's l1: 0.057191\n",
      "[3500]\ttraining's l1: 0.0548977\tvalid_1's l1: 0.0571507\n",
      "[4000]\ttraining's l1: 0.0546588\tvalid_1's l1: 0.0571055\n",
      "[4500]\ttraining's l1: 0.0544703\tvalid_1's l1: 0.057074\n",
      "[5000]\ttraining's l1: 0.0541938\tvalid_1's l1: 0.0570358\n",
      "[5500]\ttraining's l1: 0.0539283\tvalid_1's l1: 0.0570046\n",
      "[6000]\ttraining's l1: 0.0537827\tvalid_1's l1: 0.0569843\n",
      "[6500]\ttraining's l1: 0.0534217\tvalid_1's l1: 0.0569575\n",
      "Early stopping, best iteration is:\n",
      "[6400]\ttraining's l1: 0.0534449\tvalid_1's l1: 0.0569562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/06/22 22:24:05] 1460528775.py:36 in <module>\n",
      "                    lgb_score: 0.9210763995616803\n",
      "[08/06/22 22:24:07] 1460528775.py:38 in <module>\n",
      "                    score: 0.9214030178145094\n",
      "[08/06/22 22:24:08] 1460528775.py:43 in <module>\n",
      "                    fold: 2\n",
      "                    np.asarray(cbt_scores).mean(): 0.9197911812534029\n",
      "                    np.asarray(lgb_scores).mean(): 0.9204894617361359\n",
      "                    np.asarray(scores).mean(): 0.920744265691504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2521714\ttest: 0.2521714\ttest1: 0.2519077\tbest: 0.2519077 (0)\ttotal: 202ms\tremaining: 33m 37s\n",
      "500:\tlearn: 0.0563460\ttest: 0.0563460\ttest1: 0.0563055\tbest: 0.0563055 (500)\ttotal: 1m 15s\tremaining: 23m 46s\n",
      "1000:\tlearn: 0.0541437\ttest: 0.0541437\ttest1: 0.0557924\tbest: 0.0557913 (997)\ttotal: 2m 18s\tremaining: 20m 43s\n",
      "1500:\tlearn: 0.0522651\ttest: 0.0522651\ttest1: 0.0557055\tbest: 0.0557047 (1499)\ttotal: 3m 11s\tremaining: 18m 2s\n",
      "2000:\tlearn: 0.0504285\ttest: 0.0504285\ttest1: 0.0557778\tbest: 0.0556993 (1525)\ttotal: 4m 2s\tremaining: 16m 8s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.05569929522\n",
      "bestIteration = 1525\n",
      "\n",
      "Shrink model to first 1526 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/06/22 22:28:19] 1460528775.py:21 in <module>\n",
      "                    cbt_score: 0.9232255937699436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.073891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 42238\n",
      "[LightGBM] [Info] Number of data points in the train set: 337964, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score 0.455939\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.0578385\tvalid_1's l1: 0.0563202\n",
      "[1000]\ttraining's l1: 0.0569348\tvalid_1's l1: 0.0557633\n",
      "[1500]\ttraining's l1: 0.0564344\tvalid_1's l1: 0.0555894\n",
      "[2000]\ttraining's l1: 0.0560693\tvalid_1's l1: 0.0554782\n",
      "[2500]\ttraining's l1: 0.0557627\tvalid_1's l1: 0.0554116\n",
      "[3000]\ttraining's l1: 0.0554979\tvalid_1's l1: 0.0553583\n",
      "[3500]\ttraining's l1: 0.0553018\tvalid_1's l1: 0.0553187\n",
      "[4000]\ttraining's l1: 0.0550736\tvalid_1's l1: 0.0552734\n",
      "[4500]\ttraining's l1: 0.0548836\tvalid_1's l1: 0.0552472\n",
      "[5000]\ttraining's l1: 0.054721\tvalid_1's l1: 0.05523\n",
      "[5500]\ttraining's l1: 0.0545208\tvalid_1's l1: 0.0552013\n",
      "[6000]\ttraining's l1: 0.0541354\tvalid_1's l1: 0.0551555\n",
      "[6500]\ttraining's l1: 0.0539912\tvalid_1's l1: 0.0551377\n",
      "[7000]\ttraining's l1: 0.0538651\tvalid_1's l1: 0.0551221\n",
      "[7500]\ttraining's l1: 0.0537096\tvalid_1's l1: 0.0551085\n",
      "Early stopping, best iteration is:\n",
      "[7772]\ttraining's l1: 0.0536347\tvalid_1's l1: 0.0550972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/06/22 22:30:42] 1460528775.py:36 in <module>\n",
      "                    lgb_score: 0.9239120971047396\n",
      "[08/06/22 22:30:43] 1460528775.py:38 in <module>\n",
      "                    score: 0.9241708857213959\n",
      "[08/06/22 22:30:44] 1460528775.py:43 in <module>\n",
      "                    fold: 3\n",
      "                    np.asarray(cbt_scores).mean(): 0.9206497843825381\n",
      "                    np.asarray(lgb_scores).mean(): 0.9213451205782868\n",
      "                    np.asarray(scores).mean(): 0.921600920698977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2521184\ttest: 0.2521184\ttest1: 0.2522320\tbest: 0.2522320 (0)\ttotal: 98.5ms\tremaining: 16m 24s\n",
      "500:\tlearn: 0.0556479\ttest: 0.0556479\ttest1: 0.0594704\tbest: 0.0594704 (500)\ttotal: 39.9s\tremaining: 12m 36s\n",
      "1000:\tlearn: 0.0535107\ttest: 0.0535107\ttest1: 0.0589242\tbest: 0.0589190 (997)\ttotal: 1m 20s\tremaining: 11m 59s\n",
      "1500:\tlearn: 0.0516401\ttest: 0.0516401\ttest1: 0.0588782\tbest: 0.0588679 (1427)\ttotal: 2m\tremaining: 11m 19s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.05886792073\n",
      "bestIteration = 1427\n",
      "\n",
      "Shrink model to first 1428 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/06/22 22:33:24] 1460528775.py:21 in <module>\n",
      "                    cbt_score: 0.9125464914102784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 42239\n",
      "[LightGBM] [Info] Number of data points in the train set: 341935, number of used features: 172\n",
      "[LightGBM] [Info] Start training from score 0.456522\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.0570207\tvalid_1's l1: 0.059339\n",
      "[1000]\ttraining's l1: 0.0562284\tvalid_1's l1: 0.0588261\n",
      "[1500]\ttraining's l1: 0.0558005\tvalid_1's l1: 0.0586305\n",
      "[2000]\ttraining's l1: 0.0554935\tvalid_1's l1: 0.0585239\n",
      "[2500]\ttraining's l1: 0.0551335\tvalid_1's l1: 0.0584192\n",
      "[3000]\ttraining's l1: 0.0548529\tvalid_1's l1: 0.0583538\n",
      "[3500]\ttraining's l1: 0.0546552\tvalid_1's l1: 0.0583118\n",
      "[4000]\ttraining's l1: 0.0543752\tvalid_1's l1: 0.0582777\n",
      "Early stopping, best iteration is:\n",
      "[4122]\ttraining's l1: 0.0543249\tvalid_1's l1: 0.0582714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/06/22 22:34:42] 1460528775.py:36 in <module>\n",
      "                    lgb_score: 0.9129216309789512\n",
      "[08/06/22 22:34:44] 1460528775.py:38 in <module>\n",
      "                    score: 0.9132761849554141\n",
      "[08/06/22 22:34:44] 1460528775.py:43 in <module>\n",
      "                    fold: 4\n",
      "                    np.asarray(cbt_scores).mean(): 0.9190291257880862\n",
      "                    np.asarray(lgb_scores).mean(): 0.9196604226584195\n",
      "                    np.asarray(scores).mean(): 0.9199359735502645\n"
     ]
    }
   ],
   "source": [
    "FOLDS = 5\n",
    "cbt_scores, lgb_scores = [], []\n",
    "scores = []\n",
    "gezi.try_mkdir('../working/trees')\n",
    "for fold in tqdm(range(FOLDS)):\n",
    "  dvalid = df[df.fold==fold]\n",
    "  dtrain = df[df.fold!=fold]\n",
    "  X_train = dtrain[cols]\n",
    "  y_train = dtrain[LABEL_COL]\n",
    "  X_valid = dvalid[cols]\n",
    "  y_valid = dvalid[LABEL_COL]\n",
    "  if fold > 0:\n",
    "    cbt_model = CatBoostRegressor(**cbt_params)\n",
    "    cbt_model.fit(X_train, y_train,\n",
    "          eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                  verbose=500,\n",
    "                  )  \n",
    "  cbt_model.save_model(f'../working/trees/{fold}.cbt')\n",
    "  dvalid['cb_pred'] = cbt_model.predict(dvalid[cols])\n",
    "  cbt_score = calc_metric({'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values, 'pred': dvalid.cb_pred.values})\n",
    "  ic(cbt_score)\n",
    "  \n",
    "  d_train = lgb.Dataset(X_train, y_train)\n",
    "  d_valid = lgb.Dataset(X_valid, y_valid, reference=d_train)\n",
    "  if fold > 0:\n",
    "    lgb_model = lgb.train(params,\n",
    "                    d_train,\n",
    "                    10000,\n",
    "                    valid_sets=[d_train, d_valid],\n",
    "                    verbose_eval=500,\n",
    "                    early_stopping_rounds=100)\n",
    "  lgb_model.save_model(f'../working/trees/{fold}.lgb')\n",
    "  dvalid['lgb_pred'] = lgb_model.predict(dvalid[cols])\n",
    "  \n",
    "  lgb_score = calc_metric({'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values, 'pred': dvalid.lgb_pred.values})\n",
    "  ic(lgb_score)\n",
    "  score = calc_metric({'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values, 'pred': (dvalid.cb_pred.values * 0.3 + dvalid.lgb_pred.values * 0.7)})\n",
    "  ic(score)\n",
    "  \n",
    "  cbt_scores.append(cbt_score)\n",
    "  lgb_scores.append(lgb_score)\n",
    "  scores.append(score)\n",
    "  ic(fold, \n",
    "     np.asarray(cbt_scores).mean(), \n",
    "     np.asarray(lgb_scores).mean(),\n",
    "     np.asarray(scores).mean(),\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold: 0\n",
    "#                     np.asarray(cbt_scores).mean(): 0.9181025338378637\n",
    "#                     np.asarray(lgb_scores).mean(): 0.9193848140698876\n",
    "#                     np.asarray(scores).mean(): 0.9195238841373282\n",
    "\n",
    "#  fold: 4\n",
    "#                     np.asarray(cbt_scores).mean(): 0.9189608630607822\n",
    "#                     np.asarray(lgb_scores).mean(): 0.9196959050732708\n",
    "#                     np.asarray(scores).mean(): 0.9199400102856614"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_ratio</th>\n",
       "      <th>ps_diff</th>\n",
       "      <th>abs_ps_diff</th>\n",
       "      <th>ps_cls_diff</th>\n",
       "      <th>abs_ps_cls_diff</th>\n",
       "      <th>pc_reg_diff</th>\n",
       "      <th>abs_pc_reg_diff</th>\n",
       "      <th>p2c_reg_diff</th>\n",
       "      <th>abs_p2c_reg_diff</th>\n",
       "      <th>pc_cls_diff</th>\n",
       "      <th>abs_pc_cls_diff</th>\n",
       "      <th>p2c_cls_diff</th>\n",
       "      <th>abs_p2c_cls_diff</th>\n",
       "      <th>pc_cls2_diff</th>\n",
       "      <th>abs_pc_cls2_diff</th>\n",
       "      <th>p2c_cls2_diff</th>\n",
       "      <th>abs_p2c_cls2_diff</th>\n",
       "      <th>pc_cls_reg_diff</th>\n",
       "      <th>abs_pc_cls_reg_diff</th>\n",
       "      <th>p2c_cls_reg_diff</th>\n",
       "      <th>abs_p2c_cls_reg_diff</th>\n",
       "      <th>pc_cls_cls_diff</th>\n",
       "      <th>abs_pc_cls_cls_diff</th>\n",
       "      <th>p2c_cls_cls_diff</th>\n",
       "      <th>abs_p2c_cls_cls_diff</th>\n",
       "      <th>pc_cls_cls2_diff</th>\n",
       "      <th>abs_pc_cls_cls2_diff</th>\n",
       "      <th>p2c_cls_cls2_diff</th>\n",
       "      <th>abs_p2c_cls_cls2_diff</th>\n",
       "      <th>pcc_reg_diff</th>\n",
       "      <th>abs_pcc_reg_diff</th>\n",
       "      <th>pcc_cls_diff</th>\n",
       "      <th>abs_pcc_cls_diff</th>\n",
       "      <th>pcc_cls2_diff</th>\n",
       "      <th>abs_pcc_cls2_diff</th>\n",
       "      <th>pcc_cls_reg_diff</th>\n",
       "      <th>abs_pcc_cls_reg_diff</th>\n",
       "      <th>pcc_cls_cls_diff</th>\n",
       "      <th>abs_pcc_cls_cls_diff</th>\n",
       "      <th>pcc_cls_cls2_diff</th>\n",
       "      <th>abs_pcc_cls_cls2_diff</th>\n",
       "      <th>xp_pred</th>\n",
       "      <th>xp_cls_pred</th>\n",
       "      <th>xp_rank_pred</th>\n",
       "      <th>xp_cls_rank_pred</th>\n",
       "      <th>xp_min_prob</th>\n",
       "      <th>xp_var_prob</th>\n",
       "      <th>xp_min_sim</th>\n",
       "      <th>xp_var_sim</th>\n",
       "      <th>xp_top_prob_0</th>\n",
       "      <th>xp_top_sim_0</th>\n",
       "      <th>xp_top_pred_1</th>\n",
       "      <th>xp_top_prob_1</th>\n",
       "      <th>xp_top_sim_1</th>\n",
       "      <th>xp_top_pred_2</th>\n",
       "      <th>xp_top_prob_2</th>\n",
       "      <th>xp_top_sim_2</th>\n",
       "      <th>xp_top_pred_3</th>\n",
       "      <th>xp_top_prob_3</th>\n",
       "      <th>xp_top_sim_3</th>\n",
       "      <th>xp_top_pred_4</th>\n",
       "      <th>xp_top_prob_4</th>\n",
       "      <th>xp_top_sim_4</th>\n",
       "      <th>xp_top_pred_5</th>\n",
       "      <th>xp_top_prob_5</th>\n",
       "      <th>xp_top_sim_5</th>\n",
       "      <th>xp_top_pred_6</th>\n",
       "      <th>xp_top_prob_6</th>\n",
       "      <th>xp_top_sim_6</th>\n",
       "      <th>xp_top_pred_7</th>\n",
       "      <th>xp_top_prob_7</th>\n",
       "      <th>xp_top_sim_7</th>\n",
       "      <th>xp_top_pred_8</th>\n",
       "      <th>xp_top_prob_8</th>\n",
       "      <th>xp_top_sim_8</th>\n",
       "      <th>xp_top_pred_9</th>\n",
       "      <th>xp_top_prob_9</th>\n",
       "      <th>xp_top_sim_9</th>\n",
       "      <th>xp_cls_diff</th>\n",
       "      <th>xp_abs_cls_diff</th>\n",
       "      <th>xp2_pred</th>\n",
       "      <th>xp2_cls_pred</th>\n",
       "      <th>xp2_rank_pred</th>\n",
       "      <th>xp2_cls_rank_pred</th>\n",
       "      <th>xp2_min_prob</th>\n",
       "      <th>xp2_var_prob</th>\n",
       "      <th>xp2_min_sim</th>\n",
       "      <th>xp2_var_sim</th>\n",
       "      <th>xp2_top_prob_0</th>\n",
       "      <th>xp2_top_sim_0</th>\n",
       "      <th>xp2_top_pred_1</th>\n",
       "      <th>xp2_top_prob_1</th>\n",
       "      <th>xp2_top_sim_1</th>\n",
       "      <th>xp2_top_pred_2</th>\n",
       "      <th>xp2_top_prob_2</th>\n",
       "      <th>xp2_top_sim_2</th>\n",
       "      <th>xp2_top_pred_3</th>\n",
       "      <th>xp2_top_prob_3</th>\n",
       "      <th>xp2_top_sim_3</th>\n",
       "      <th>xp2_top_pred_4</th>\n",
       "      <th>xp2_top_prob_4</th>\n",
       "      <th>xp2_top_sim_4</th>\n",
       "      <th>xp2_top_pred_5</th>\n",
       "      <th>xp2_top_prob_5</th>\n",
       "      <th>xp2_top_sim_5</th>\n",
       "      <th>xp2_top_pred_6</th>\n",
       "      <th>xp2_top_prob_6</th>\n",
       "      <th>xp2_top_sim_6</th>\n",
       "      <th>xp2_top_pred_7</th>\n",
       "      <th>xp2_top_prob_7</th>\n",
       "      <th>xp2_top_sim_7</th>\n",
       "      <th>xp2_top_pred_8</th>\n",
       "      <th>xp2_top_prob_8</th>\n",
       "      <th>xp2_top_sim_8</th>\n",
       "      <th>xp2_top_pred_9</th>\n",
       "      <th>xp2_top_prob_9</th>\n",
       "      <th>xp2_top_sim_9</th>\n",
       "      <th>xp2_cls_diff</th>\n",
       "      <th>xp2_abs_cls_diff</th>\n",
       "      <th>xc_pred</th>\n",
       "      <th>xc_cls_pred</th>\n",
       "      <th>xc_reg_pred</th>\n",
       "      <th>xc_cls2_pred</th>\n",
       "      <th>xc_group_pos</th>\n",
       "      <th>xc_group_rank</th>\n",
       "      <th>xc_rank_pred</th>\n",
       "      <th>xc_cls_rank_pred</th>\n",
       "      <th>xc_cls2_rank_pred</th>\n",
       "      <th>xc_reg_rank_pred</th>\n",
       "      <th>xc_min_prob</th>\n",
       "      <th>xc_var_prob</th>\n",
       "      <th>xc_top_prob_0</th>\n",
       "      <th>xc_top_pred_1</th>\n",
       "      <th>xc_top_prob_1</th>\n",
       "      <th>xc_top_pred_2</th>\n",
       "      <th>xc_top_prob_2</th>\n",
       "      <th>xc_top_pred_3</th>\n",
       "      <th>xc_top_prob_3</th>\n",
       "      <th>xc_cls_reg_diff</th>\n",
       "      <th>xc_abs_cls_reg_diff</th>\n",
       "      <th>xc_cls_cls2_diff</th>\n",
       "      <th>xc_abs_cls_cls2_diff</th>\n",
       "      <th>xc_cls2_reg_diff</th>\n",
       "      <th>xc_abs_cls2_reg_diff</th>\n",
       "      <th>xpc_pred</th>\n",
       "      <th>xpc_cls_pred</th>\n",
       "      <th>xpc_rank_pred</th>\n",
       "      <th>xpc_cls_rank_pred</th>\n",
       "      <th>xpc_min_prob</th>\n",
       "      <th>xpc_var_prob</th>\n",
       "      <th>xpc_min_sim</th>\n",
       "      <th>xpc_var_sim</th>\n",
       "      <th>xpc_top_prob_0</th>\n",
       "      <th>xpc_top_sim_0</th>\n",
       "      <th>xpc_top_pred_1</th>\n",
       "      <th>xpc_top_prob_1</th>\n",
       "      <th>xpc_top_sim_1</th>\n",
       "      <th>xpc_top_pred_2</th>\n",
       "      <th>xpc_top_prob_2</th>\n",
       "      <th>xpc_top_sim_2</th>\n",
       "      <th>xpc_top_pred_3</th>\n",
       "      <th>xpc_top_prob_3</th>\n",
       "      <th>xpc_top_sim_3</th>\n",
       "      <th>xpc_top_pred_4</th>\n",
       "      <th>xpc_top_prob_4</th>\n",
       "      <th>xpc_top_sim_4</th>\n",
       "      <th>xpc_cls_diff</th>\n",
       "      <th>xpc_abs_cls_diff</th>\n",
       "      <th>xpc_mark</th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cid</th>\n",
       "      <th>n_words</th>\n",
       "      <th>n_code_cell</th>\n",
       "      <th>n_cell</th>\n",
       "      <th>ancestor_id</th>\n",
       "      <th>rel_rank</th>\n",
       "      <th>fold</th>\n",
       "      <th>cb_pred</th>\n",
       "      <th>lgb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5692</td>\n",
       "      <td>-0.0263</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>-0.0042</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>-0.0026</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0237</td>\n",
       "      <td>0.0237</td>\n",
       "      <td>-0.0034</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>-0.0041</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>-0.0217</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>-0.0026</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0201</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>-0.0034</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>-0.0210</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>-0.0042</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>-0.0026</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0034</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>-0.0076</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>-0.0060</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>-0.0068</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.8816</td>\n",
       "      <td>0.8816</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>33.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.7477</td>\n",
       "      <td>0.9079</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.5951</td>\n",
       "      <td>0.8289</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5295</td>\n",
       "      <td>0.6184</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5057</td>\n",
       "      <td>0.9342</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4822</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4765</td>\n",
       "      <td>0.6711</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4511</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4507</td>\n",
       "      <td>0.4342</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4434</td>\n",
       "      <td>0.5395</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4349</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9079</td>\n",
       "      <td>0.8640</td>\n",
       "      <td>34.0000</td>\n",
       "      <td>32.3327</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.7285</td>\n",
       "      <td>0.5429</td>\n",
       "      <td>0.6184</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>0.4922</td>\n",
       "      <td>0.8816</td>\n",
       "      <td>0.0592</td>\n",
       "      <td>0.4741</td>\n",
       "      <td>0.9342</td>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.4680</td>\n",
       "      <td>0.6711</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.4421</td>\n",
       "      <td>0.6974</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.4186</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.4135</td>\n",
       "      <td>0.8289</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.4103</td>\n",
       "      <td>0.6447</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.3978</td>\n",
       "      <td>0.7763</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>-0.0439</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>0.8842</td>\n",
       "      <td>0.8857</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>87.9951</td>\n",
       "      <td>87.9160</td>\n",
       "      <td>88.0000</td>\n",
       "      <td>87.9160</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.9844</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.8550</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>-0.0016</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.8816</td>\n",
       "      <td>0.8782</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>32.8708</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.7477</td>\n",
       "      <td>0.9079</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.5951</td>\n",
       "      <td>0.8289</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5295</td>\n",
       "      <td>0.6184</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5057</td>\n",
       "      <td>0.9342</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4822</td>\n",
       "      <td>-0.0034</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0</td>\n",
       "      <td>000efd285fb982</td>\n",
       "      <td>14f36391</td>\n",
       "      <td>000efd285fb982\\t14f36391</td>\n",
       "      <td>102</td>\n",
       "      <td>37</td>\n",
       "      <td>65</td>\n",
       "      <td>389f14ff</td>\n",
       "      <td>0.8816</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8821</td>\n",
       "      <td>0.8834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5692</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0095</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>-0.0028</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>-0.0028</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>-0.0130</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>-0.0035</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>-0.0174</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>-0.0079</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>-0.0162</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>-0.0067</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>-0.0028</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>-0.0065</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>-0.0109</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>-0.0097</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.3289</td>\n",
       "      <td>0.3188</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>11.6137</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.2815</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.7837</td>\n",
       "      <td>0.7111</td>\n",
       "      <td>0.2763</td>\n",
       "      <td>0.2041</td>\n",
       "      <td>0.6816</td>\n",
       "      <td>0.3553</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.6139</td>\n",
       "      <td>0.4868</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.5691</td>\n",
       "      <td>0.4605</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.5367</td>\n",
       "      <td>0.5658</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.5361</td>\n",
       "      <td>0.5132</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.5337</td>\n",
       "      <td>0.4342</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.5296</td>\n",
       "      <td>0.3026</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.1711</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.5178</td>\n",
       "      <td>-0.0102</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.3289</td>\n",
       "      <td>0.3283</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>11.9761</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>0.5162</td>\n",
       "      <td>0.2763</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.4008</td>\n",
       "      <td>0.3553</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.3769</td>\n",
       "      <td>0.1711</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>0.3816</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.3052</td>\n",
       "      <td>0.4605</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.2975</td>\n",
       "      <td>0.4342</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.2781</td>\n",
       "      <td>0.4868</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.2765</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.2745</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.2728</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.3340</td>\n",
       "      <td>0.3362</td>\n",
       "      <td>0.3318</td>\n",
       "      <td>0.3350</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>32.8991</td>\n",
       "      <td>33.1195</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>33.1195</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.8291</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.1423</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.3050</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.3289</td>\n",
       "      <td>0.3253</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>11.8622</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.2815</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.7837</td>\n",
       "      <td>0.7111</td>\n",
       "      <td>0.2763</td>\n",
       "      <td>0.2041</td>\n",
       "      <td>0.6816</td>\n",
       "      <td>0.3553</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.6139</td>\n",
       "      <td>0.4868</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.5691</td>\n",
       "      <td>0.4605</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.5367</td>\n",
       "      <td>-0.0036</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0</td>\n",
       "      <td>000efd285fb982</td>\n",
       "      <td>1f3749ad</td>\n",
       "      <td>000efd285fb982\\t1f3749ad</td>\n",
       "      <td>102</td>\n",
       "      <td>37</td>\n",
       "      <td>65</td>\n",
       "      <td>389f14ff</td>\n",
       "      <td>0.3355</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3323</td>\n",
       "      <td>0.3306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5692</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>-0.0039</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>-0.0039</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>-0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>-0.0059</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>-0.0068</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>-0.0039</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>-0.0068</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>-0.0110</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.1711</td>\n",
       "      <td>0.1691</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>5.9257</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.2701</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>0.6585</td>\n",
       "      <td>0.0658</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.5712</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.5360</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.5256</td>\n",
       "      <td>0.2237</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.5173</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.5088</td>\n",
       "      <td>0.4342</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.4891</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.4865</td>\n",
       "      <td>0.6184</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.4806</td>\n",
       "      <td>0.2763</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.4798</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.1711</td>\n",
       "      <td>0.1682</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>5.8929</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.9607</td>\n",
       "      <td>0.4999</td>\n",
       "      <td>0.0658</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.3846</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.3394</td>\n",
       "      <td>0.1184</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.3238</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.3234</td>\n",
       "      <td>0.4868</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.3156</td>\n",
       "      <td>0.1447</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.3083</td>\n",
       "      <td>0.2237</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.3069</td>\n",
       "      <td>-0.0028</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.1673</td>\n",
       "      <td>0.1708</td>\n",
       "      <td>0.1638</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.2290</td>\n",
       "      <td>16.5761</td>\n",
       "      <td>17.0000</td>\n",
       "      <td>16.5761</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.8486</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.0652</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.0373</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>-0.0042</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.1711</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>5.7324</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.2701</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>0.6585</td>\n",
       "      <td>0.0658</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.5712</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.5360</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.5256</td>\n",
       "      <td>0.2237</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.5173</td>\n",
       "      <td>-0.0070</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0</td>\n",
       "      <td>000efd285fb982</td>\n",
       "      <td>24cfe6eb</td>\n",
       "      <td>000efd285fb982\\t24cfe6eb</td>\n",
       "      <td>102</td>\n",
       "      <td>37</td>\n",
       "      <td>65</td>\n",
       "      <td>389f14ff</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1688</td>\n",
       "      <td>0.1696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5692</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0234</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.0929</td>\n",
       "      <td>0.0929</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.1132</td>\n",
       "      <td>0.1132</td>\n",
       "      <td>-0.0099</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>-0.0169</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2048</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>7.2822</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.1225</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.6456</td>\n",
       "      <td>0.5698</td>\n",
       "      <td>0.1184</td>\n",
       "      <td>0.3406</td>\n",
       "      <td>0.5558</td>\n",
       "      <td>0.2237</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.4733</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.4492</td>\n",
       "      <td>0.4342</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.4278</td>\n",
       "      <td>0.1447</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.4229</td>\n",
       "      <td>0.2763</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.4050</td>\n",
       "      <td>0.1711</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.4011</td>\n",
       "      <td>0.5395</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>0.4605</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.3895</td>\n",
       "      <td>-0.0452</td>\n",
       "      <td>0.0452</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>8.1700</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.0977</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.8111</td>\n",
       "      <td>0.5544</td>\n",
       "      <td>0.1184</td>\n",
       "      <td>0.1139</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.1447</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.4809</td>\n",
       "      <td>0.1711</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.4337</td>\n",
       "      <td>0.2763</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.4163</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.3909</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.3866</td>\n",
       "      <td>0.2237</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3186</td>\n",
       "      <td>0.4342</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.2949</td>\n",
       "      <td>0.3289</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.2941</td>\n",
       "      <td>-0.0218</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.1318</td>\n",
       "      <td>0.1353</td>\n",
       "      <td>0.1283</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.6790</td>\n",
       "      <td>13.0283</td>\n",
       "      <td>11.0000</td>\n",
       "      <td>13.0283</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.4233</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.2888</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>-0.0133</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.1184</td>\n",
       "      <td>0.1434</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>4.9498</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.1225</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.6456</td>\n",
       "      <td>0.5698</td>\n",
       "      <td>0.1184</td>\n",
       "      <td>0.3406</td>\n",
       "      <td>0.5558</td>\n",
       "      <td>0.2237</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.4733</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.4492</td>\n",
       "      <td>0.4342</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.4278</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0</td>\n",
       "      <td>000efd285fb982</td>\n",
       "      <td>2863864b</td>\n",
       "      <td>000efd285fb982\\t2863864b</td>\n",
       "      <td>102</td>\n",
       "      <td>37</td>\n",
       "      <td>65</td>\n",
       "      <td>389f14ff</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.1264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5692</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1788</td>\n",
       "      <td>0.1788</td>\n",
       "      <td>0.2056</td>\n",
       "      <td>0.2056</td>\n",
       "      <td>0.2056</td>\n",
       "      <td>0.2056</td>\n",
       "      <td>0.2983</td>\n",
       "      <td>0.2983</td>\n",
       "      <td>0.2983</td>\n",
       "      <td>0.2983</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.1609</td>\n",
       "      <td>0.1609</td>\n",
       "      <td>-0.0179</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.2536</td>\n",
       "      <td>0.2536</td>\n",
       "      <td>0.0748</td>\n",
       "      <td>0.0748</td>\n",
       "      <td>-0.0429</td>\n",
       "      <td>0.0429</td>\n",
       "      <td>-0.2217</td>\n",
       "      <td>0.2217</td>\n",
       "      <td>0.2056</td>\n",
       "      <td>0.2056</td>\n",
       "      <td>0.2983</td>\n",
       "      <td>0.2983</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.1195</td>\n",
       "      <td>0.1195</td>\n",
       "      <td>0.2122</td>\n",
       "      <td>0.2122</td>\n",
       "      <td>-0.0843</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.9421</td>\n",
       "      <td>37.0000</td>\n",
       "      <td>35.3012</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.4058</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.7177</td>\n",
       "      <td>0.7718</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.7342</td>\n",
       "      <td>0.8816</td>\n",
       "      <td>0.0569</td>\n",
       "      <td>0.7161</td>\n",
       "      <td>0.6184</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.7015</td>\n",
       "      <td>0.5132</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.6785</td>\n",
       "      <td>0.5395</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.6776</td>\n",
       "      <td>0.8289</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.6758</td>\n",
       "      <td>0.4868</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.6752</td>\n",
       "      <td>0.6711</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.6749</td>\n",
       "      <td>0.5658</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.6678</td>\n",
       "      <td>-0.0447</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.7633</td>\n",
       "      <td>37.0000</td>\n",
       "      <td>28.5071</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.2367</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.3107</td>\n",
       "      <td>0.5565</td>\n",
       "      <td>0.6184</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>0.5479</td>\n",
       "      <td>0.4868</td>\n",
       "      <td>0.1318</td>\n",
       "      <td>0.5330</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.0984</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.8816</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.5181</td>\n",
       "      <td>0.5132</td>\n",
       "      <td>0.0414</td>\n",
       "      <td>0.5013</td>\n",
       "      <td>0.6447</td>\n",
       "      <td>0.0283</td>\n",
       "      <td>0.4908</td>\n",
       "      <td>0.4342</td>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.4845</td>\n",
       "      <td>0.9079</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.4653</td>\n",
       "      <td>0.6711</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.4632</td>\n",
       "      <td>-0.2235</td>\n",
       "      <td>0.2235</td>\n",
       "      <td>0.7349</td>\n",
       "      <td>0.6885</td>\n",
       "      <td>0.7812</td>\n",
       "      <td>0.9850</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>72.9885</td>\n",
       "      <td>68.3520</td>\n",
       "      <td>98.0000</td>\n",
       "      <td>68.3520</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.2932</td>\n",
       "      <td>0.5350</td>\n",
       "      <td>0.1879</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.1646</td>\n",
       "      <td>0.4850</td>\n",
       "      <td>0.1545</td>\n",
       "      <td>-0.0927</td>\n",
       "      <td>0.0927</td>\n",
       "      <td>-0.2965</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>0.2037</td>\n",
       "      <td>0.2037</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.9007</td>\n",
       "      <td>37.0000</td>\n",
       "      <td>33.7281</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.4058</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.7177</td>\n",
       "      <td>0.7718</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.7342</td>\n",
       "      <td>0.8816</td>\n",
       "      <td>0.0569</td>\n",
       "      <td>0.7161</td>\n",
       "      <td>0.6184</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.7015</td>\n",
       "      <td>0.5132</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.6785</td>\n",
       "      <td>-0.0861</td>\n",
       "      <td>0.0861</td>\n",
       "      <td>0</td>\n",
       "      <td>000efd285fb982</td>\n",
       "      <td>35213836</td>\n",
       "      <td>000efd285fb982\\t35213836</td>\n",
       "      <td>102</td>\n",
       "      <td>37</td>\n",
       "      <td>65</td>\n",
       "      <td>389f14ff</td>\n",
       "      <td>0.9561</td>\n",
       "      <td>4</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.9340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424936</th>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>-0.0036</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>-0.0036</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>-0.0042</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>-0.0042</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>-0.0145</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>-0.0353</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>-0.0191</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>-0.0360</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>-0.0036</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>-0.0042</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>-0.0612</td>\n",
       "      <td>0.0612</td>\n",
       "      <td>-0.0449</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>-0.0618</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.7199</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>8.8590</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>0.2543</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.9151</td>\n",
       "      <td>0.4658</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.0624</td>\n",
       "      <td>0.4069</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.3659</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.3477</td>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.3394</td>\n",
       "      <td>0.9615</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.3294</td>\n",
       "      <td>0.4231</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.3279</td>\n",
       "      <td>0.2692</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.3073</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.3044</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.3043</td>\n",
       "      <td>-0.0108</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.6990</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>8.5874</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.7569</td>\n",
       "      <td>0.3949</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.1874</td>\n",
       "      <td>0.3567</td>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.2959</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.2893</td>\n",
       "      <td>0.2692</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.2611</td>\n",
       "      <td>0.4231</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.2335</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.2287</td>\n",
       "      <td>0.9615</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.2176</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.2089</td>\n",
       "      <td>-0.0317</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.7263</td>\n",
       "      <td>0.7181</td>\n",
       "      <td>0.7344</td>\n",
       "      <td>0.7350</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>72.1257</td>\n",
       "      <td>71.3138</td>\n",
       "      <td>73.0000</td>\n",
       "      <td>71.3138</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.9175</td>\n",
       "      <td>0.6550</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.8050</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>-0.0162</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>-0.0169</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.6732</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>8.2519</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>0.2543</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.9151</td>\n",
       "      <td>0.4658</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.0624</td>\n",
       "      <td>0.4069</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.3659</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.3477</td>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.3394</td>\n",
       "      <td>-0.0575</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>0</td>\n",
       "      <td>fff4714a37cf49</td>\n",
       "      <td>4425d40b</td>\n",
       "      <td>fff4714a37cf49\\t4425d40b</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>f81c5d18</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7310</td>\n",
       "      <td>0.7229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424937</th>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.1672</td>\n",
       "      <td>0.1672</td>\n",
       "      <td>-0.1546</td>\n",
       "      <td>0.1546</td>\n",
       "      <td>-0.1546</td>\n",
       "      <td>0.1546</td>\n",
       "      <td>-0.0889</td>\n",
       "      <td>0.0889</td>\n",
       "      <td>-0.0889</td>\n",
       "      <td>0.0889</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>-0.1382</td>\n",
       "      <td>0.1382</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>-0.0725</td>\n",
       "      <td>0.0725</td>\n",
       "      <td>0.0947</td>\n",
       "      <td>0.0947</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.1839</td>\n",
       "      <td>0.1839</td>\n",
       "      <td>-0.1546</td>\n",
       "      <td>0.1546</td>\n",
       "      <td>-0.0889</td>\n",
       "      <td>0.0889</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>-0.0799</td>\n",
       "      <td>0.0799</td>\n",
       "      <td>-0.0142</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0751</td>\n",
       "      <td>0.0751</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.1318</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.2131</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0.4106</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.9440</td>\n",
       "      <td>0.7422</td>\n",
       "      <td>0.4231</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.6774</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.6228</td>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.5875</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.5869</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.5731</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.5527</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.5526</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5010</td>\n",
       "      <td>0.2692</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4712</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.2989</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.3862</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.2520</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.5698</td>\n",
       "      <td>0.4884</td>\n",
       "      <td>0.4231</td>\n",
       "      <td>0.1239</td>\n",
       "      <td>0.4466</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.4399</td>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.0860</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.4232</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.4053</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.3926</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.3888</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.3659</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.3429</td>\n",
       "      <td>0.1836</td>\n",
       "      <td>0.1836</td>\n",
       "      <td>0.2371</td>\n",
       "      <td>0.2043</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.2138</td>\n",
       "      <td>19.9256</td>\n",
       "      <td>11.0000</td>\n",
       "      <td>19.9256</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.6982</td>\n",
       "      <td>0.4250</td>\n",
       "      <td>0.1545</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.0573</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.0331</td>\n",
       "      <td>-0.0658</td>\n",
       "      <td>0.0658</td>\n",
       "      <td>0.0893</td>\n",
       "      <td>0.0893</td>\n",
       "      <td>-0.1550</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.1901</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.9713</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0.4106</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.9440</td>\n",
       "      <td>0.7422</td>\n",
       "      <td>0.4231</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.6774</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.6228</td>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.5875</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.5869</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0</td>\n",
       "      <td>fff4714a37cf49</td>\n",
       "      <td>5edf1d2a</td>\n",
       "      <td>fff4714a37cf49\\t5edf1d2a</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>f81c5d18</td>\n",
       "      <td>0.4231</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>0.1306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424938</th>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0762</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>-0.0028</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>-0.0797</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>-0.0050</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>-0.0819</td>\n",
       "      <td>0.0819</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>-0.0079</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>-0.0114</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>-0.0053</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>-0.0136</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0028</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>-0.0050</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>-0.0247</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>-0.0282</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>-0.0304</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4997</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>5.9962</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0706</td>\n",
       "      <td>0.4513</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.7599</td>\n",
       "      <td>0.4231</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.5940</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.5915</td>\n",
       "      <td>0.2692</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.5898</td>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.5865</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.5783</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.5677</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.5647</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5188</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.4231</td>\n",
       "      <td>0.4914</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>5.8877</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.2508</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>0.4387</td>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.2190</td>\n",
       "      <td>0.4219</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1848</td>\n",
       "      <td>0.4172</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.0956</td>\n",
       "      <td>0.3992</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.3721</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.3617</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.3468</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.3411</td>\n",
       "      <td>0.2692</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.3185</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.2967</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>0.5010</td>\n",
       "      <td>0.5028</td>\n",
       "      <td>0.4993</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.6017</td>\n",
       "      <td>49.7767</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>49.7767</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.9468</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.4250</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.4350</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>-0.0022</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4746</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>5.6697</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0706</td>\n",
       "      <td>0.4513</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.7599</td>\n",
       "      <td>0.4231</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.5940</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.5915</td>\n",
       "      <td>0.2692</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.5898</td>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.5865</td>\n",
       "      <td>-0.0254</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>0</td>\n",
       "      <td>fff4714a37cf49</td>\n",
       "      <td>9527a079</td>\n",
       "      <td>fff4714a37cf49\\t9527a079</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>f81c5d18</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4996</td>\n",
       "      <td>0.5012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424939</th>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0467</td>\n",
       "      <td>0.0467</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0474</td>\n",
       "      <td>0.0474</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0405</td>\n",
       "      <td>0.0405</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>0.0424</td>\n",
       "      <td>0.0424</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>0.3924</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>4.6017</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0434</td>\n",
       "      <td>0.3853</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.7758</td>\n",
       "      <td>0.6852</td>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.1965</td>\n",
       "      <td>0.6551</td>\n",
       "      <td>0.2692</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.6051</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.5693</td>\n",
       "      <td>0.4231</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.5636</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.4985</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.4974</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.4776</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4542</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>0.3457</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>3.9940</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.2516</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.6573</td>\n",
       "      <td>0.2692</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.5239</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.4465</td>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.4414</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.4207</td>\n",
       "      <td>0.4231</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3938</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3351</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3343</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3161</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3091</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.3424</td>\n",
       "      <td>0.3379</td>\n",
       "      <td>0.3469</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33.7412</td>\n",
       "      <td>33.2899</td>\n",
       "      <td>34.0000</td>\n",
       "      <td>33.2899</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.9175</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>-0.0090</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>-0.0071</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>0.3874</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>4.5360</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0434</td>\n",
       "      <td>0.3853</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.7758</td>\n",
       "      <td>0.6852</td>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.1965</td>\n",
       "      <td>0.6551</td>\n",
       "      <td>0.2692</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.6051</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.5693</td>\n",
       "      <td>0.4231</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.5636</td>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.0412</td>\n",
       "      <td>0</td>\n",
       "      <td>fff4714a37cf49</td>\n",
       "      <td>effc5f17</td>\n",
       "      <td>fff4714a37cf49\\teffc5f17</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>f81c5d18</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3456</td>\n",
       "      <td>0.3425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424940</th>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>-0.0207</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0040</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>-0.0167</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>-0.0161</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>-0.0287</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>-0.0291</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>-0.0245</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>0.7889</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>9.7556</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.3902</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.6348</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.5373</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.5142</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.4878</td>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.4613</td>\n",
       "      <td>0.4231</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.4423</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.4356</td>\n",
       "      <td>0.9615</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4033</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4031</td>\n",
       "      <td>-0.0188</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>0.7763</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>9.5916</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0491</td>\n",
       "      <td>0.3364</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.8402</td>\n",
       "      <td>0.6223</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.5622</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.5128</td>\n",
       "      <td>0.4231</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.5098</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.5066</td>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.5018</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.4901</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.4873</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3548</td>\n",
       "      <td>-0.0314</td>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.8013</td>\n",
       "      <td>0.7929</td>\n",
       "      <td>0.8096</td>\n",
       "      <td>0.8050</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>79.6257</td>\n",
       "      <td>78.7944</td>\n",
       "      <td>80.0000</td>\n",
       "      <td>78.7944</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>-0.0121</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>-0.0046</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>0.7805</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>9.6464</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.3902</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.6348</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.5373</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.5142</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.4878</td>\n",
       "      <td>-0.0272</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0</td>\n",
       "      <td>fff4714a37cf49</td>\n",
       "      <td>f8744de1</td>\n",
       "      <td>fff4714a37cf49\\tf8744de1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>f81c5d18</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8138</td>\n",
       "      <td>0.8064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83008 rows × 180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        code_ratio  ps_diff  abs_ps_diff  ps_cls_diff  abs_ps_cls_diff  \\\n",
       "3           0.5692  -0.0263       0.0263       0.0176           0.0176   \n",
       "4           0.5692   0.0000       0.0000      -0.0095           0.0095   \n",
       "5           0.5692   0.0000       0.0000       0.0009           0.0009   \n",
       "6           0.5692   0.0000       0.0000      -0.0234           0.0234   \n",
       "7           0.5692   0.0000       0.0000       0.1788           0.1788   \n",
       "...            ...      ...          ...          ...              ...   \n",
       "424936      0.5714   0.0000       0.0000       0.0209           0.0209   \n",
       "424937      0.5714   0.0000       0.0000      -0.1672           0.1672   \n",
       "424938      0.5714   0.0769       0.0769       0.0083           0.0083   \n",
       "424939      0.5714   0.0000       0.0000       0.0467           0.0467   \n",
       "424940      0.5714   0.0000       0.0000       0.0126           0.0126   \n",
       "\n",
       "        pc_reg_diff  abs_pc_reg_diff  p2c_reg_diff  abs_p2c_reg_diff  \\\n",
       "3           -0.0042           0.0042        0.0222            0.0222   \n",
       "4           -0.0028           0.0028       -0.0028            0.0028   \n",
       "5            0.0072           0.0072        0.0072            0.0072   \n",
       "6            0.1217           0.1217        0.1217            0.1217   \n",
       "7            0.2056           0.2056        0.2056            0.2056   \n",
       "...             ...              ...           ...               ...   \n",
       "424936      -0.0036           0.0036       -0.0036            0.0036   \n",
       "424937      -0.1546           0.1546       -0.1546            0.1546   \n",
       "424938       0.0007           0.0007       -0.0762            0.0762   \n",
       "424939      -0.0008           0.0008       -0.0008            0.0008   \n",
       "424940      -0.0019           0.0019       -0.0019            0.0019   \n",
       "\n",
       "        pc_cls_diff  abs_pc_cls_diff  p2c_cls_diff  abs_p2c_cls_diff  \\\n",
       "3           -0.0026           0.0026        0.0237            0.0237   \n",
       "4           -0.0072           0.0072       -0.0072            0.0072   \n",
       "5            0.0003           0.0003        0.0003            0.0003   \n",
       "6            0.1147           0.1147        0.1147            0.1147   \n",
       "7            0.2983           0.2983        0.2983            0.2983   \n",
       "...             ...              ...           ...               ...   \n",
       "424936       0.0126           0.0126        0.0126            0.0126   \n",
       "424937      -0.0889           0.0889       -0.0889            0.0889   \n",
       "424938      -0.0028           0.0028       -0.0797            0.0797   \n",
       "424939       0.0083           0.0083        0.0083            0.0083   \n",
       "424940       0.0147           0.0147        0.0147            0.0147   \n",
       "\n",
       "        pc_cls2_diff  abs_pc_cls2_diff  p2c_cls2_diff  abs_p2c_cls2_diff  \\\n",
       "3            -0.0034            0.0034         0.0229             0.0229   \n",
       "4            -0.0061            0.0061        -0.0061             0.0061   \n",
       "5            -0.0039            0.0039        -0.0039             0.0039   \n",
       "6             0.1350            0.1350         0.1350             0.1350   \n",
       "7             0.0018            0.0018         0.0018             0.0018   \n",
       "...              ...               ...            ...                ...   \n",
       "424936       -0.0042            0.0042        -0.0042             0.0042   \n",
       "424937        0.0004            0.0004         0.0004             0.0004   \n",
       "424938       -0.0050            0.0050        -0.0819             0.0819   \n",
       "424939        0.0012            0.0012         0.0012             0.0012   \n",
       "424940        0.0027            0.0027         0.0027             0.0027   \n",
       "\n",
       "        pc_cls_reg_diff  abs_pc_cls_reg_diff  p2c_cls_reg_diff  \\\n",
       "3               -0.0041               0.0041           -0.0217   \n",
       "4               -0.0130               0.0130           -0.0035   \n",
       "5                0.0053               0.0053            0.0044   \n",
       "6                0.0765               0.0765            0.0999   \n",
       "7                0.1609               0.1609           -0.0179   \n",
       "...                 ...                  ...               ...   \n",
       "424936          -0.0145               0.0145           -0.0353   \n",
       "424937          -0.1382               0.1382            0.0289   \n",
       "424938           0.0004               0.0004           -0.0079   \n",
       "424939           0.0455               0.0455           -0.0012   \n",
       "424940          -0.0207               0.0207           -0.0333   \n",
       "\n",
       "        abs_p2c_cls_reg_diff  pc_cls_cls_diff  abs_pc_cls_cls_diff  \\\n",
       "3                     0.0217          -0.0026               0.0026   \n",
       "4                     0.0035          -0.0174               0.0174   \n",
       "5                     0.0044          -0.0017               0.0017   \n",
       "6                     0.0999           0.0695               0.0695   \n",
       "7                     0.0179           0.2536               0.2536   \n",
       "...                      ...              ...                  ...   \n",
       "424936                0.0353           0.0018               0.0018   \n",
       "424937                0.0289          -0.0725               0.0725   \n",
       "424938                0.0079          -0.0031               0.0031   \n",
       "424939                0.0012           0.0545               0.0545   \n",
       "424940                0.0333          -0.0040               0.0040   \n",
       "\n",
       "        p2c_cls_cls_diff  abs_p2c_cls_cls_diff  pc_cls_cls2_diff  \\\n",
       "3                -0.0201                0.0201           -0.0034   \n",
       "4                -0.0079                0.0079           -0.0162   \n",
       "5                -0.0025                0.0025           -0.0059   \n",
       "6                 0.0929                0.0929            0.0898   \n",
       "7                 0.0748                0.0748           -0.0429   \n",
       "...                  ...                   ...               ...   \n",
       "424936           -0.0191                0.0191           -0.0151   \n",
       "424937            0.0947                0.0947            0.0168   \n",
       "424938           -0.0114                0.0114           -0.0053   \n",
       "424939            0.0078                0.0078            0.0474   \n",
       "424940           -0.0167                0.0167           -0.0161   \n",
       "\n",
       "        abs_pc_cls_cls2_diff  p2c_cls_cls2_diff  abs_p2c_cls_cls2_diff  \\\n",
       "3                     0.0034            -0.0210                 0.0210   \n",
       "4                     0.0162            -0.0067                 0.0067   \n",
       "5                     0.0059            -0.0068                 0.0068   \n",
       "6                     0.0898             0.1132                 0.1132   \n",
       "7                     0.0429            -0.2217                 0.2217   \n",
       "...                      ...                ...                    ...   \n",
       "424936                0.0151            -0.0360                 0.0360   \n",
       "424937                0.0168             0.1839                 0.1839   \n",
       "424938                0.0053            -0.0136                 0.0136   \n",
       "424939                0.0474             0.0007                 0.0007   \n",
       "424940                0.0161            -0.0287                 0.0287   \n",
       "\n",
       "        pcc_reg_diff  abs_pcc_reg_diff  pcc_cls_diff  abs_pcc_cls_diff  \\\n",
       "3            -0.0042            0.0042       -0.0026            0.0026   \n",
       "4            -0.0028            0.0028       -0.0072            0.0072   \n",
       "5             0.0072            0.0072        0.0003            0.0003   \n",
       "6            -0.0099            0.0099       -0.0169            0.0169   \n",
       "7             0.2056            0.2056        0.2983            0.2983   \n",
       "...              ...               ...           ...               ...   \n",
       "424936       -0.0036            0.0036        0.0126            0.0126   \n",
       "424937       -0.1546            0.1546       -0.0889            0.0889   \n",
       "424938        0.0007            0.0007       -0.0028            0.0028   \n",
       "424939       -0.0008            0.0008        0.0083            0.0083   \n",
       "424940       -0.0019            0.0019        0.0147            0.0147   \n",
       "\n",
       "        pcc_cls2_diff  abs_pcc_cls2_diff  pcc_cls_reg_diff  \\\n",
       "3             -0.0034             0.0034           -0.0076   \n",
       "4             -0.0061             0.0061           -0.0065   \n",
       "5             -0.0039             0.0039            0.0002   \n",
       "6              0.0034             0.0034            0.0151   \n",
       "7              0.0018             0.0018            0.1195   \n",
       "...               ...                ...               ...   \n",
       "424936        -0.0042             0.0042           -0.0612   \n",
       "424937         0.0004             0.0004           -0.0799   \n",
       "424938        -0.0050             0.0050           -0.0247   \n",
       "424939         0.0012             0.0012            0.0405   \n",
       "424940         0.0027             0.0027           -0.0291   \n",
       "\n",
       "        abs_pcc_cls_reg_diff  pcc_cls_cls_diff  abs_pcc_cls_cls_diff  \\\n",
       "3                     0.0076           -0.0060                0.0060   \n",
       "4                     0.0065           -0.0109                0.0109   \n",
       "5                     0.0002           -0.0068                0.0068   \n",
       "6                     0.0151            0.0081                0.0081   \n",
       "7                     0.1195            0.2122                0.2122   \n",
       "...                      ...               ...                   ...   \n",
       "424936                0.0612           -0.0449                0.0449   \n",
       "424937                0.0799           -0.0142                0.0142   \n",
       "424938                0.0247           -0.0282                0.0282   \n",
       "424939                0.0405            0.0495                0.0495   \n",
       "424940                0.0291           -0.0125                0.0125   \n",
       "\n",
       "        pcc_cls_cls2_diff  abs_pcc_cls_cls2_diff  xp_pred  xp_cls_pred  \\\n",
       "3                 -0.0068                 0.0068   0.8816       0.8816   \n",
       "4                 -0.0097                 0.0097   0.3289       0.3188   \n",
       "5                 -0.0110                 0.0110   0.1711       0.1691   \n",
       "6                  0.0284                 0.0284   0.2500       0.2048   \n",
       "7                 -0.0843                 0.0843   0.9868       0.9421   \n",
       "...                   ...                    ...      ...          ...   \n",
       "424936            -0.0618                 0.0618   0.7308       0.7199   \n",
       "424937             0.0751                 0.0751   0.1154       0.1318   \n",
       "424938            -0.0304                 0.0304   0.5000       0.4997   \n",
       "424939             0.0424                 0.0424   0.3462       0.3924   \n",
       "424940            -0.0245                 0.0245   0.8077       0.7889   \n",
       "\n",
       "        xp_rank_pred  xp_cls_rank_pred  xp_min_prob  xp_var_prob  xp_min_sim  \\\n",
       "3            33.0000           33.0007       0.0000       0.0256      0.1710   \n",
       "4            12.0000           11.6137       0.0000       0.0166      0.2815   \n",
       "5             6.0000            5.9257       0.0000       0.0241      0.2701   \n",
       "6             9.0000            7.2822       0.0000       0.0133      0.1225   \n",
       "7            37.0000           35.3012       0.0000       0.0134      0.4058   \n",
       "...              ...               ...          ...          ...         ...   \n",
       "424936        9.0000            8.8590       0.0001       0.0588      0.2543   \n",
       "424937        1.0000            1.2131       0.0000       0.0628      0.4106   \n",
       "424938        6.0000            5.9962       0.0000       0.0706      0.4513   \n",
       "424939        4.0000            4.6017       0.0000       0.0434      0.3853   \n",
       "424940       10.0000            9.7556       0.0000       0.0641      0.3902   \n",
       "\n",
       "        xp_var_sim  xp_top_prob_0  xp_top_sim_0  xp_top_pred_1  xp_top_prob_1  \\\n",
       "3           0.0139         0.9990        0.7477         0.9079         0.0010   \n",
       "4           0.0101         0.7837        0.7111         0.2763         0.2041   \n",
       "5           0.0078         0.9705        0.6585         0.0658         0.0182   \n",
       "6           0.0122         0.6456        0.5698         0.1184         0.3406   \n",
       "7           0.0074         0.7177        0.7718         0.9605         0.1291   \n",
       "...            ...            ...           ...            ...            ...   \n",
       "424936      0.0031         0.9151        0.4658         0.6538         0.0624   \n",
       "424937      0.0086         0.9440        0.7422         0.4231         0.0494   \n",
       "424938      0.0053         0.9976        0.7599         0.4231         0.0005   \n",
       "424939      0.0075         0.7758        0.6852         0.5769         0.1965   \n",
       "424940      0.0054         0.9537        0.6348         0.5000         0.0293   \n",
       "\n",
       "        xp_top_sim_1  xp_top_pred_2  xp_top_prob_2  xp_top_sim_2  \\\n",
       "3             0.5951         0.8289         0.0000        0.5295   \n",
       "4             0.6816         0.3553         0.0094        0.6139   \n",
       "5             0.5712         0.0921         0.0037        0.5360   \n",
       "6             0.5558         0.2237         0.0080        0.4733   \n",
       "7             0.7342         0.8816         0.0569        0.7161   \n",
       "...              ...            ...            ...           ...   \n",
       "424936        0.4069         0.5000         0.0096        0.3659   \n",
       "424937        0.6774         0.1923         0.0041        0.6228   \n",
       "424938        0.5940         0.1154         0.0005        0.5915   \n",
       "424939        0.6551         0.2692         0.0201        0.6051   \n",
       "424940        0.5584         0.1923         0.0112        0.5373   \n",
       "\n",
       "        xp_top_pred_3  xp_top_prob_3  xp_top_sim_3  xp_top_pred_4  \\\n",
       "3              0.6184         0.0000        0.5057         0.9342   \n",
       "4              0.4868         0.0012        0.5691         0.4605   \n",
       "5              0.0132         0.0023        0.5256         0.2237   \n",
       "6              0.0921         0.0027        0.4492         0.4342   \n",
       "7              0.6184         0.0292        0.7015         0.5132   \n",
       "...               ...            ...           ...            ...   \n",
       "424936         0.1154         0.0042        0.3477         0.5769   \n",
       "424937         0.5769         0.0008        0.5875         0.5000   \n",
       "424938         0.2692         0.0004        0.5898         0.5769   \n",
       "424939         0.8846         0.0039        0.5693         0.4231   \n",
       "424940         0.1154         0.0039        0.5142         0.8846   \n",
       "\n",
       "        xp_top_prob_4  xp_top_sim_4  xp_top_pred_5  xp_top_prob_5  \\\n",
       "3              0.0000        0.4822         0.7500         0.0000   \n",
       "4              0.0003        0.5367         0.5658         0.0003   \n",
       "5              0.0016        0.5173         0.1974         0.0011   \n",
       "6              0.0010        0.4278         0.1447         0.0008   \n",
       "7              0.0102        0.6785         0.5395         0.0098   \n",
       "...               ...           ...            ...            ...   \n",
       "424936         0.0029        0.3394         0.9615         0.0018   \n",
       "424937         0.0008        0.5869         0.0385         0.0004   \n",
       "424938         0.0004        0.5865         0.1923         0.0003   \n",
       "424939         0.0030        0.5636         0.8077         0.0002   \n",
       "424940         0.0012        0.4878         0.5769         0.0004   \n",
       "\n",
       "        xp_top_sim_5  xp_top_pred_6  xp_top_prob_6  xp_top_sim_6  \\\n",
       "3             0.4765         0.6711         0.0000        0.4511   \n",
       "4             0.5361         0.5132         0.0002        0.5337   \n",
       "5             0.5088         0.4342         0.0004        0.4891   \n",
       "6             0.4229         0.2763         0.0004        0.4050   \n",
       "7             0.6776         0.8289         0.0091        0.6758   \n",
       "...              ...            ...            ...           ...   \n",
       "424936        0.3294         0.4231         0.0017        0.3279   \n",
       "424937        0.5731         0.7308         0.0002        0.5527   \n",
       "424938        0.5783         0.7308         0.0002        0.5677   \n",
       "424939        0.5019         0.1923         0.0002        0.4985   \n",
       "424940        0.4613         0.4231         0.0001        0.4423   \n",
       "\n",
       "        xp_top_pred_7  xp_top_prob_7  xp_top_sim_7  xp_top_pred_8  \\\n",
       "3              0.9605         0.0000        0.4507         0.4342   \n",
       "4              0.4342         0.0002        0.5296         0.3026   \n",
       "5              0.0395         0.0004        0.4865         0.6184   \n",
       "6              0.1711         0.0003        0.4011         0.5395   \n",
       "7              0.4868         0.0088        0.6752         0.6711   \n",
       "...               ...            ...           ...            ...   \n",
       "424936         0.2692         0.0007        0.3073         0.8077   \n",
       "424937         0.6538         0.0002        0.5526         0.8077   \n",
       "424938         0.8077         0.0001        0.5647         0.6538   \n",
       "424939         0.6538         0.0001        0.4974         0.5000   \n",
       "424940         0.0385         0.0001        0.4356         0.9615   \n",
       "\n",
       "        xp_top_prob_8  xp_top_sim_8  xp_top_pred_9  xp_top_prob_9  \\\n",
       "3              0.0000        0.4434         0.5395         0.0000   \n",
       "4              0.0002        0.5255         0.1711         0.0001   \n",
       "5              0.0003        0.4806         0.2763         0.0003   \n",
       "6              0.0002        0.3960         0.4605         0.0002   \n",
       "7              0.0087        0.6749         0.5658         0.0063   \n",
       "...               ...           ...            ...            ...   \n",
       "424936         0.0006        0.3044         0.0385         0.0006   \n",
       "424937         0.0000        0.5010         0.2692         0.0000   \n",
       "424938         0.0000        0.5300         0.3462         0.0000   \n",
       "424939         0.0001        0.4776         0.7308         0.0000   \n",
       "424940         0.0000        0.4033         0.3462         0.0000   \n",
       "\n",
       "        xp_top_sim_9  xp_cls_diff  xp_abs_cls_diff  xp2_pred  xp2_cls_pred  \\\n",
       "3             0.4349       0.0000           0.0000    0.9079        0.8640   \n",
       "4             0.5178      -0.0102           0.0102    0.3289        0.3283   \n",
       "5             0.4798      -0.0020           0.0020    0.1711        0.1682   \n",
       "6             0.3895      -0.0452           0.0452    0.2500        0.2282   \n",
       "7             0.6678      -0.0447           0.0447    0.9868        0.7633   \n",
       "...              ...          ...              ...       ...           ...   \n",
       "424936        0.3043      -0.0108           0.0108    0.7308        0.6990   \n",
       "424937        0.4712       0.0164           0.0164    0.1154        0.2989   \n",
       "424938        0.5188      -0.0003           0.0003    0.4231        0.4914   \n",
       "424939        0.4542       0.0463           0.0463    0.3462        0.3457   \n",
       "424940        0.4031      -0.0188           0.0188    0.8077        0.7763   \n",
       "\n",
       "        xp2_rank_pred  xp2_cls_rank_pred  xp2_min_prob  xp2_var_prob  \\\n",
       "3             34.0000            32.3327        0.0000        0.0138   \n",
       "4             12.0000            11.9761        0.0000        0.0244   \n",
       "5              6.0000             5.8929        0.0000        0.0236   \n",
       "6              9.0000             8.1700        0.0000        0.0170   \n",
       "7             37.0000            28.5071        0.0000        0.0042   \n",
       "...               ...                ...           ...           ...   \n",
       "424936         9.0000             8.5874        0.0002        0.0409   \n",
       "424937         1.0000             3.3862        0.0001        0.0218   \n",
       "424938         5.0000             5.8877        0.0004        0.0139   \n",
       "424939         4.0000             3.9940        0.0000        0.0697   \n",
       "424940        10.0000             9.5916        0.0000        0.0491   \n",
       "\n",
       "        xp2_min_sim  xp2_var_sim  xp2_top_prob_0  xp2_top_sim_0  \\\n",
       "3            0.0410       0.0184          0.7285         0.5429   \n",
       "4            0.0527       0.0094          0.9772         0.5162   \n",
       "5            0.0806       0.0098          0.9607         0.4999   \n",
       "6            0.0977       0.0140          0.8111         0.5544   \n",
       "7            0.2367       0.0078          0.3107         0.5565   \n",
       "...             ...          ...             ...            ...   \n",
       "424936       0.1750       0.0037          0.7569         0.3949   \n",
       "424937       0.2520       0.0041          0.5698         0.4884   \n",
       "424938       0.2508       0.0037          0.4054         0.4387   \n",
       "424939       0.2516       0.0119          0.9913         0.6573   \n",
       "424940       0.3364       0.0079          0.8402         0.6223   \n",
       "\n",
       "        xp2_top_pred_1  xp2_top_prob_1  xp2_top_sim_1  xp2_top_pred_2  \\\n",
       "3               0.6184          0.1146         0.4922          0.8816   \n",
       "4               0.2763          0.0145         0.4008          0.3553   \n",
       "5               0.0658          0.0142         0.3846          0.0132   \n",
       "6               0.1184          0.1139         0.5006          0.1447   \n",
       "7               0.6184          0.2273         0.5479          0.4868   \n",
       "...                ...             ...            ...             ...   \n",
       "424936          0.6538          0.1874         0.3567          0.5769   \n",
       "424937          0.4231          0.1239         0.4466          0.7308   \n",
       "424938          0.5769          0.2190         0.4219          0.5000   \n",
       "424939          0.2692          0.0076         0.5239          0.1923   \n",
       "424940          0.7308          0.0938         0.5622          0.6538   \n",
       "\n",
       "        xp2_top_prob_2  xp2_top_sim_2  xp2_top_pred_3  xp2_top_prob_3  \\\n",
       "3               0.0592         0.4741          0.9342          0.0473   \n",
       "4               0.0061         0.3769          0.1711          0.0005   \n",
       "5               0.0117         0.3791          0.0921          0.0027   \n",
       "6               0.0556         0.4809          0.1711          0.0099   \n",
       "7               0.1318         0.5330          0.9605          0.0984   \n",
       "...                ...            ...             ...             ...   \n",
       "424936          0.0204         0.2959          0.1154          0.0160   \n",
       "424937          0.0968         0.4399          0.5769          0.0860   \n",
       "424938          0.1848         0.4172          0.6538          0.0956   \n",
       "424939          0.0005         0.4465          0.5769          0.0004   \n",
       "424940          0.0155         0.5128          0.4231          0.0139   \n",
       "\n",
       "        xp2_top_sim_3  xp2_top_pred_4  xp2_top_prob_4  xp2_top_sim_4  \\\n",
       "3              0.4680          0.6711          0.0184         0.4421   \n",
       "4              0.3080          0.3816          0.0004         0.3052   \n",
       "5              0.3394          0.1184          0.0018         0.3285   \n",
       "6              0.4337          0.2763          0.0052         0.4163   \n",
       "7              0.5250          0.8816          0.0765         0.5181   \n",
       "...               ...             ...             ...            ...   \n",
       "424936         0.2893          0.2692          0.0060         0.2625   \n",
       "424937         0.4366          0.6538          0.0527         0.4232   \n",
       "424938         0.3992          0.1154          0.0356         0.3721   \n",
       "424939         0.4414          0.8846          0.0002         0.4207   \n",
       "424940         0.5098          0.1923          0.0123         0.5066   \n",
       "\n",
       "        xp2_top_pred_5  xp2_top_prob_5  xp2_top_sim_5  xp2_top_pred_6  \\\n",
       "3               0.6974          0.0078         0.4186          0.7500   \n",
       "4               0.4605          0.0003         0.2975          0.4342   \n",
       "5               0.1974          0.0016         0.3238          0.0395   \n",
       "6               0.1974          0.0021         0.3909          0.0921   \n",
       "7               0.5132          0.0414         0.5013          0.6447   \n",
       "...                ...             ...            ...             ...   \n",
       "424936          0.8077          0.0057         0.2611          0.4231   \n",
       "424937          0.5000          0.0274         0.4053          0.0385   \n",
       "424938          0.7308          0.0244         0.3617          0.8077   \n",
       "424939          0.4231          0.0001         0.3938          0.1154   \n",
       "424940          0.5769          0.0104         0.5018          0.1154   \n",
       "\n",
       "        xp2_top_prob_6  xp2_top_sim_6  xp2_top_pred_7  xp2_top_prob_7  \\\n",
       "3               0.0065         0.4135          0.8289          0.0057   \n",
       "4               0.0002         0.2781          0.4868          0.0002   \n",
       "5               0.0015         0.3234          0.4868          0.0011   \n",
       "6               0.0018         0.3866          0.2237          0.0001   \n",
       "7               0.0283         0.4908          0.4342          0.0224   \n",
       "...                ...            ...             ...             ...   \n",
       "424936          0.0021         0.2335          0.1923          0.0018   \n",
       "424937          0.0172         0.3926          0.1923          0.0150   \n",
       "424938          0.0141         0.3468          0.1923          0.0115   \n",
       "424939          0.0000         0.3351          0.6538          0.0000   \n",
       "424940          0.0067         0.4901          0.5000          0.0061   \n",
       "\n",
       "        xp2_top_sim_7  xp2_top_pred_8  xp2_top_prob_8  xp2_top_sim_8  \\\n",
       "3              0.4103          0.6447          0.0036         0.3978   \n",
       "4              0.2765          0.1974          0.0001         0.2745   \n",
       "5              0.3156          0.1447          0.0009         0.3083   \n",
       "6              0.3186          0.4342          0.0001         0.2949   \n",
       "7              0.4845          0.9079          0.0112         0.4653   \n",
       "...               ...             ...             ...            ...   \n",
       "424936         0.2287          0.9615          0.0012         0.2176   \n",
       "424937         0.3888          0.8077          0.0065         0.3659   \n",
       "424938         0.3411          0.2692          0.0050         0.3185   \n",
       "424939         0.3343          0.8077          0.0000         0.3161   \n",
       "424940         0.4873          0.8846          0.0010         0.4375   \n",
       "\n",
       "        xp2_top_pred_9  xp2_top_prob_9  xp2_top_sim_9  xp2_cls_diff  \\\n",
       "3               0.7763          0.0017         0.3773       -0.0439   \n",
       "4               0.2500          0.0001         0.2728       -0.0006   \n",
       "5               0.2237          0.0008         0.3069       -0.0028   \n",
       "6               0.3289          0.0001         0.2941       -0.0218   \n",
       "7               0.6711          0.0103         0.4632       -0.2235   \n",
       "...                ...             ...            ...           ...   \n",
       "424936          0.8846          0.0009         0.2089       -0.0317   \n",
       "424937          0.8846          0.0028         0.3429        0.1836   \n",
       "424938          0.3462          0.0023         0.2967        0.0683   \n",
       "424939          0.5000          0.0000         0.3091       -0.0005   \n",
       "424940          0.3462          0.0000         0.3548       -0.0314   \n",
       "\n",
       "        xp2_abs_cls_diff  xc_pred  xc_cls_pred  xc_reg_pred  xc_cls2_pred  \\\n",
       "3                 0.0439   0.8850       0.8842       0.8857        0.8850   \n",
       "4                 0.0006   0.3340       0.3362       0.3318        0.3350   \n",
       "5                 0.0028   0.1673       0.1708       0.1638        0.1750   \n",
       "6                 0.0218   0.1318       0.1353       0.1283        0.1150   \n",
       "7                 0.2235   0.7349       0.6885       0.7812        0.9850   \n",
       "...                  ...      ...          ...          ...           ...   \n",
       "424936            0.0317   0.7263       0.7181       0.7344        0.7350   \n",
       "424937            0.1836   0.2371       0.2043       0.2700        0.1150   \n",
       "424938            0.0683   0.5010       0.5028       0.4993        0.5050   \n",
       "424939            0.0005   0.3424       0.3379       0.3469        0.3450   \n",
       "424940            0.0314   0.8013       0.7929       0.8096        0.8050   \n",
       "\n",
       "        xc_group_pos  xc_group_rank  xc_rank_pred  xc_cls_rank_pred  \\\n",
       "3                  2              1       87.9951           87.9160   \n",
       "4                  2              1       32.8991           33.1195   \n",
       "5                  1              1       16.2290           16.5761   \n",
       "6                  0              0       12.6790           13.0283   \n",
       "7                  1              2       72.9885           68.3520   \n",
       "...              ...            ...           ...               ...   \n",
       "424936             2              1       72.1257           71.3138   \n",
       "424937             0              0       23.2138           19.9256   \n",
       "424938             0              0       49.6017           49.7767   \n",
       "424939             1              1       33.7412           33.2899   \n",
       "424940             1              2       79.6257           78.7944   \n",
       "\n",
       "        xc_cls2_rank_pred  xc_reg_rank_pred  xc_min_prob  xc_var_prob  \\\n",
       "3                 88.0000           87.9160       0.0000       0.0096   \n",
       "4                 33.0000           33.1195       0.0000       0.0070   \n",
       "5                 17.0000           16.5761       0.0000       0.0072   \n",
       "6                 11.0000           13.0283       0.0000       0.0027   \n",
       "7                 98.0000           68.3520       0.0000       0.0017   \n",
       "...                   ...               ...          ...          ...   \n",
       "424936            73.0000           71.3138       0.0000       0.0083   \n",
       "424937            11.0000           19.9256       0.0000       0.0051   \n",
       "424938            50.0000           49.7767       0.0000       0.0089   \n",
       "424939            34.0000           33.2899       0.0000       0.0083   \n",
       "424940            80.0000           78.7944       0.0000       0.0090   \n",
       "\n",
       "        xc_top_prob_0  xc_top_pred_1  xc_top_prob_1  xc_top_pred_2  \\\n",
       "3              0.9844         0.8750         0.0104         0.8550   \n",
       "4              0.8291         0.3250         0.1423         0.3450   \n",
       "5              0.8486         0.1450         0.0652         0.1650   \n",
       "6              0.4233         0.1250         0.2888         0.1450   \n",
       "7              0.2932         0.5350         0.1879         0.5050   \n",
       "...               ...            ...            ...            ...   \n",
       "424936         0.9175         0.6550         0.0243         0.8050   \n",
       "424937         0.6982         0.4250         0.1545         0.5050   \n",
       "424938         0.9468         0.5150         0.0321         0.4250   \n",
       "424939         0.9175         0.2650         0.0316         0.1950   \n",
       "424940         0.9541         0.8850         0.0097         0.8250   \n",
       "\n",
       "        xc_top_prob_2  xc_top_pred_3  xc_top_prob_3  xc_cls_reg_diff  \\\n",
       "3              0.0022         0.9050         0.0015          -0.0016   \n",
       "4              0.0046         0.3050         0.0037           0.0044   \n",
       "5              0.0373         0.0650         0.0123           0.0069   \n",
       "6              0.1100         0.1750         0.0488           0.0070   \n",
       "7              0.1646         0.4850         0.1545          -0.0927   \n",
       "...               ...            ...            ...              ...   \n",
       "424936         0.0128         0.3450         0.0125          -0.0162   \n",
       "424937         0.0573         0.2650         0.0331          -0.0658   \n",
       "424938         0.0097         0.4350         0.0042           0.0035   \n",
       "424939         0.0295         0.1150         0.0138          -0.0090   \n",
       "424940         0.0089         0.1150         0.0066          -0.0166   \n",
       "\n",
       "        xc_abs_cls_reg_diff  xc_cls_cls2_diff  xc_abs_cls_cls2_diff  \\\n",
       "3                    0.0016           -0.0008                0.0008   \n",
       "4                    0.0044            0.0012                0.0012   \n",
       "5                    0.0069           -0.0042                0.0042   \n",
       "6                    0.0070            0.0203                0.0203   \n",
       "7                    0.0927           -0.2965                0.2965   \n",
       "...                     ...               ...                   ...   \n",
       "424936               0.0162           -0.0169                0.0169   \n",
       "424937               0.0658            0.0893                0.0893   \n",
       "424938               0.0035           -0.0022                0.0022   \n",
       "424939               0.0090           -0.0071                0.0071   \n",
       "424940               0.0166           -0.0121                0.0121   \n",
       "\n",
       "        xc_cls2_reg_diff  xc_abs_cls2_reg_diff  xpc_pred  xpc_cls_pred  \\\n",
       "3                -0.0007                0.0007    0.8816        0.8782   \n",
       "4                 0.0032                0.0032    0.3289        0.3253   \n",
       "5                 0.0112                0.0112    0.1711        0.1640   \n",
       "6                -0.0133                0.0133    0.1184        0.1434   \n",
       "7                 0.2037                0.2037    0.9868        0.9007   \n",
       "...                  ...                   ...       ...           ...   \n",
       "424936            0.0006                0.0006    0.7308        0.6732   \n",
       "424937           -0.1550                0.1550    0.1154        0.1901   \n",
       "424938            0.0057                0.0057    0.5000        0.4746   \n",
       "424939           -0.0019                0.0019    0.3462        0.3874   \n",
       "424940           -0.0046                0.0046    0.8077        0.7805   \n",
       "\n",
       "        xpc_rank_pred  xpc_cls_rank_pred  xpc_min_prob  xpc_var_prob  \\\n",
       "3             33.0000            32.8708        0.0000        0.0256   \n",
       "4             12.0000            11.8622        0.0000        0.0166   \n",
       "5              6.0000             5.7324        0.0000        0.0241   \n",
       "6              4.0000             4.9498        0.0000        0.0133   \n",
       "7             37.0000            33.7281        0.0000        0.0134   \n",
       "...               ...                ...           ...           ...   \n",
       "424936         9.0000             8.2519        0.0001        0.0588   \n",
       "424937         1.0000             1.9713        0.0000        0.0628   \n",
       "424938         6.0000             5.6697        0.0000        0.0706   \n",
       "424939         4.0000             4.5360        0.0000        0.0434   \n",
       "424940        10.0000             9.6464        0.0000        0.0641   \n",
       "\n",
       "        xpc_min_sim  xpc_var_sim  xpc_top_prob_0  xpc_top_sim_0  \\\n",
       "3            0.1710       0.0139          0.9990         0.7477   \n",
       "4            0.2815       0.0101          0.7837         0.7111   \n",
       "5            0.2701       0.0078          0.9705         0.6585   \n",
       "6            0.1225       0.0122          0.6456         0.5698   \n",
       "7            0.4058       0.0074          0.7177         0.7718   \n",
       "...             ...          ...             ...            ...   \n",
       "424936       0.2543       0.0031          0.9151         0.4658   \n",
       "424937       0.4106       0.0086          0.9440         0.7422   \n",
       "424938       0.4513       0.0053          0.9976         0.7599   \n",
       "424939       0.3853       0.0075          0.7758         0.6852   \n",
       "424940       0.3902       0.0054          0.9537         0.6348   \n",
       "\n",
       "        xpc_top_pred_1  xpc_top_prob_1  xpc_top_sim_1  xpc_top_pred_2  \\\n",
       "3               0.9079          0.0010         0.5951          0.8289   \n",
       "4               0.2763          0.2041         0.6816          0.3553   \n",
       "5               0.0658          0.0182         0.5712          0.0921   \n",
       "6               0.1184          0.3406         0.5558          0.2237   \n",
       "7               0.9605          0.1291         0.7342          0.8816   \n",
       "...                ...             ...            ...             ...   \n",
       "424936          0.6538          0.0624         0.4069          0.5000   \n",
       "424937          0.4231          0.0494         0.6774          0.1923   \n",
       "424938          0.4231          0.0005         0.5940          0.1154   \n",
       "424939          0.5769          0.1965         0.6551          0.2692   \n",
       "424940          0.5000          0.0293         0.5584          0.1923   \n",
       "\n",
       "        xpc_top_prob_2  xpc_top_sim_2  xpc_top_pred_3  xpc_top_prob_3  \\\n",
       "3               0.0000         0.5295          0.6184          0.0000   \n",
       "4               0.0094         0.6139          0.4868          0.0012   \n",
       "5               0.0037         0.5360          0.0132          0.0023   \n",
       "6               0.0080         0.4733          0.0921          0.0027   \n",
       "7               0.0569         0.7161          0.6184          0.0292   \n",
       "...                ...            ...             ...             ...   \n",
       "424936          0.0096         0.3659          0.1154          0.0042   \n",
       "424937          0.0041         0.6228          0.5769          0.0008   \n",
       "424938          0.0005         0.5915          0.2692          0.0004   \n",
       "424939          0.0201         0.6051          0.8846          0.0039   \n",
       "424940          0.0112         0.5373          0.1154          0.0039   \n",
       "\n",
       "        xpc_top_sim_3  xpc_top_pred_4  xpc_top_prob_4  xpc_top_sim_4  \\\n",
       "3              0.5057          0.9342          0.0000         0.4822   \n",
       "4              0.5691          0.4605          0.0003         0.5367   \n",
       "5              0.5256          0.2237          0.0016         0.5173   \n",
       "6              0.4492          0.4342          0.0010         0.4278   \n",
       "7              0.7015          0.5132          0.0102         0.6785   \n",
       "...               ...             ...             ...            ...   \n",
       "424936         0.3477          0.5769          0.0029         0.3394   \n",
       "424937         0.5875          0.5000          0.0008         0.5869   \n",
       "424938         0.5898          0.5769          0.0004         0.5865   \n",
       "424939         0.5693          0.4231          0.0030         0.5636   \n",
       "424940         0.5142          0.8846          0.0012         0.4878   \n",
       "\n",
       "        xpc_cls_diff  xpc_abs_cls_diff  xpc_mark              id   cell_id  \\\n",
       "3            -0.0034            0.0034         0  000efd285fb982  14f36391   \n",
       "4            -0.0036            0.0036         0  000efd285fb982  1f3749ad   \n",
       "5            -0.0070            0.0070         0  000efd285fb982  24cfe6eb   \n",
       "6             0.0250            0.0250         0  000efd285fb982  2863864b   \n",
       "7            -0.0861            0.0861         0  000efd285fb982  35213836   \n",
       "...              ...               ...       ...             ...       ...   \n",
       "424936       -0.0575            0.0575         0  fff4714a37cf49  4425d40b   \n",
       "424937        0.0747            0.0747         0  fff4714a37cf49  5edf1d2a   \n",
       "424938       -0.0254            0.0254         0  fff4714a37cf49  9527a079   \n",
       "424939        0.0412            0.0412         0  fff4714a37cf49  effc5f17   \n",
       "424940       -0.0272            0.0272         0  fff4714a37cf49  f8744de1   \n",
       "\n",
       "                             cid  n_words  n_code_cell  n_cell ancestor_id  \\\n",
       "3       000efd285fb982\\t14f36391      102           37      65    389f14ff   \n",
       "4       000efd285fb982\\t1f3749ad      102           37      65    389f14ff   \n",
       "5       000efd285fb982\\t24cfe6eb      102           37      65    389f14ff   \n",
       "6       000efd285fb982\\t2863864b      102           37      65    389f14ff   \n",
       "7       000efd285fb982\\t35213836      102           37      65    389f14ff   \n",
       "...                          ...      ...          ...     ...         ...   \n",
       "424936  fff4714a37cf49\\t4425d40b        4           12      21    f81c5d18   \n",
       "424937  fff4714a37cf49\\t5edf1d2a        4           12      21    f81c5d18   \n",
       "424938  fff4714a37cf49\\t9527a079        4           12      21    f81c5d18   \n",
       "424939  fff4714a37cf49\\teffc5f17        4           12      21    f81c5d18   \n",
       "424940  fff4714a37cf49\\tf8744de1        4           12      21    f81c5d18   \n",
       "\n",
       "        rel_rank  fold  cb_pred  lgb_pred  \n",
       "3         0.8816     4   0.8821    0.8834  \n",
       "4         0.3355     4   0.3323    0.3306  \n",
       "5         0.1776     4   0.1688    0.1696  \n",
       "6         0.2500     4   0.1183    0.1264  \n",
       "7         0.9561     4   0.9050    0.9340  \n",
       "...          ...   ...      ...       ...  \n",
       "424936    0.7308     4   0.7310    0.7229  \n",
       "424937    0.4231     4   0.1302    0.1306  \n",
       "424938    0.5000     4   0.4996    0.5012  \n",
       "424939    0.3462     4   0.3456    0.3425  \n",
       "424940    0.8077     4   0.8138    0.8064  \n",
       "\n",
       "[83008 rows x 180 columns]"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "828c32aa8796f4caf0c9fde9f523bba8dbc7385abbb3ec2757d19a79cb47766b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
