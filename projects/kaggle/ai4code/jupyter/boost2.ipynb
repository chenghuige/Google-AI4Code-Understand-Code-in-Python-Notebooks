{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../../../../utils')\n",
    "sys.path.append('../../../../third')\n",
    "from gezi.common import *\n",
    "from src.config import *\n",
    "from src.preprocess import *\n",
    "from src.eval import *\n",
    "gezi.init_flags()\n",
    "gezi.set_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 7\n",
    "root = f'../working/offline/{V}/0'\n",
    "# pairwise two tower, recall model\n",
    "# pt_model = 'all-mpnet-base-v2.flag-pairwise14-2-pre_ext_emlm_mlm.ep1'\n",
    "# p2t_model = 'all-mpnet-base-v2.flag-pairwise14-2'\n",
    "pt_model = 'all-mpnet-base-v2.flag-pairwise14-2-pre_mlm3'\n",
    "# pt_model = 'all-mpnet-base-v2.flag-pairwise14-2'\n",
    "# pt_model2 = 'pmminilm.flag-pairwise14-2-pre_emlm_mlm-mmnilm'\n",
    "# pt_model2 = 'pmminilm.flag-pairwise14-2-pre_mlm3-pmminilm'\n",
    "pt_model2 = 'pmminilm.flag-pairwise14-2'\n",
    "# pairwise concat, rank model\n",
    "\n",
    "# context model\n",
    "# c_model = 'deberta-v3-small.flag-context4-2-d'\n",
    "# c_model2 = 'lsg-mminilm.flag-context4-3-d-s-mminilm'\n",
    "# c_model = 'deberta-v3-small.flag-context4-2-d'\n",
    "# c_model = 'deberta-v3-small.flag-context4-2-d-oof-ft'\n",
    "c_model = 'deberta-v3-small.flag-context4-2-d-oof-ft.list_train_ordered'\n",
    "# c_model = 'deberta-v3-small.flag-context4-2-d-extpred-ft.0804'\n",
    "\n",
    "pc_model = 'deberta-v3-small.flag-pairwise14-4-cat-insert-extpred-ft.neg_rand_prob-0.neg_strategy-rand-sample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_feather('../working/train.fea')\n",
    "df_train = df_train[df_train.fold==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = gezi.load(f'{root}/{pt_model}.eval/valid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'cell_id', 'cid', 'pred', 'max_prob', 'max_sim', 'cls_pred', 'n_words', 'match_rank', 'match_code', 'n_code_cell', 'n_cell', 'probs', 'sims'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xp.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp2 = gezi.load(f'{root}/{pt_model2}.eval/valid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc = gezi.load(f'{root}/{c_model}.eval/valid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc_metric(xc, 'reg_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pred', 'cls_pred', 'cid', 'pos', 'pred_id', 'id', 'cell_id', 'cell_type', 'rank', 'rel_rank', 'n_code_cell', 'n_markdown_cell', 'n_cell', 'n_words', 'reg_pred', 'cls_pred_ori', 'cls2_pred'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(gezi.batch2list(xc))\n",
    "dg = d.groupby('pred_id')\n",
    "max_preds = dg['pred'].max()\n",
    "min_preds = dg['pred'].min()\n",
    "max_cls_preds = dg['cls_pred'].max()\n",
    "min_cls_preds = dg['cls_pred'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gezi.sort_dict_byid_(xp, 'cid')\n",
    "gezi.sort_dict_byid_(xp2, 'cid')\n",
    "gezi.sort_dict_byid_(xc, 'cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_COL = 'rel_rank'\n",
    "def diff_feats(x, l,r, name):\n",
    "  if isinstance(l, str):\n",
    "    x[f'{name}_diff'] = x[l] - x[r]\n",
    "  else:\n",
    "    x[f'{name}_diff'] = l - r\n",
    "  x[f'abs_{name}_diff'] = abs(x[f'{name}_diff'])\n",
    "\n",
    "def gen_pfeat(x_):\n",
    "  topn = 10\n",
    "  x = {}\n",
    "  keys = ['pred', 'cls_pred']\n",
    "  x = {k: x_[k] for k in keys}\n",
    "  x['rank_pred'] = x['pred'] * (1 + x_['n_code_cell']) - 0.5\n",
    "  x['cls_rank_pred'] = x['cls_pred'] * (1 + x_['n_code_cell']) - 0.5\n",
    "  x['min_prob'] = x_['probs'].min()\n",
    "  x['min_sim'] = x_['sims'].min()\n",
    "  x['var_prob'] = np.var(x_['probs'])\n",
    "  x['var_sim'] = np.var(x_['sims'])\n",
    "  idxes = (-x_['probs']).argsort()\n",
    "  for i in range(topn):\n",
    "    if i < len(idxes):\n",
    "      if i > 0:\n",
    "        x[f'top_pred_{i}'] = (idxes[i] + 0.5) / (x_['n_code_cell'] + 1)\n",
    "      x[f'top_prob_{i}'] = x_['probs'][idxes[i]]\n",
    "      x[f'top_sim_{i}'] = x_['sims'][idxes[i]]\n",
    "    else:\n",
    "      x[f'top_pred_{i}'] = -1\n",
    "      x[f'top_prob_{i}'] = -1\n",
    "      x[f'top_sim_{i}'] = -1\n",
    "  \n",
    "  diff_feats(x, 'cls_pred', 'pred', 'cls')\n",
    "  return x\n",
    "\n",
    "def gen_cfeat(x_):\n",
    "  topn = 4\n",
    "  x = {}\n",
    "  keys = [\n",
    "    'pred', \n",
    "    'cls_pred', \n",
    "    'reg_pred', \n",
    "    'cls2_pred', \n",
    "    # 'pos'\n",
    "    ]\n",
    "  x = {k: x_[k] for k in keys}\n",
    "  x['rank_pred'] = x['pred'] * FLAGS.num_classes - 0.5\n",
    "  x['cls_rank_pred'] = x['cls_pred'] * FLAGS.num_classes - 0.5\n",
    "  x['cls2_rank_pred'] = x['cls2_pred'] * FLAGS.num_classes - 0.5\n",
    "  x['reg_rank_pred'] = x['cls_pred'] * FLAGS.num_classes - 0.5\n",
    "  preds = x_['cls_pred_ori']\n",
    "  probs = gezi.softmax(preds)\n",
    "  x['min_prob'] = probs.min()\n",
    "  x['var_prob'] = np.var(probs)\n",
    "  idxes = (-probs).argsort()\n",
    "\n",
    "  for i in range(topn):\n",
    "    if i < len(idxes):\n",
    "      if i > 0:\n",
    "        x[f'top_pred_{i}'] = (idxes[i] + 0.5) / FLAGS.num_classes\n",
    "      x[f'top_prob_{i}'] = probs[idxes[i]]\n",
    "    else:\n",
    "      x[f'top_pred_{i}'] = -1\n",
    "      x[f'top_prob_{i}'] = -1\n",
    "  diff_feats(x, 'cls_pred', 'reg_pred', 'cls_reg')\n",
    "  diff_feats(x, 'cls_pred', 'cls2_pred', 'cls_cls2')\n",
    "  diff_feats(x, 'cls2_pred', 'reg_pred', 'cls2_reg')\n",
    "  \n",
    "  # group_id = x_['pred_id']\n",
    "  # x['max_pred'] = max_preds[group_id]\n",
    "  # x['min_pred'] = min_preds[group_id]\n",
    "  # x['pred_ratio'] = (x['pred'] - x['min_pred']) / (x['max_pred'] - x['min_pred']) if (x['max_pred'] - x['min_pred']) else 1\n",
    "  # x['max_cls_pred'] = max_cls_preds[group_id]\n",
    "  # x['min_cls_pred'] = min_cls_preds[group_id]\n",
    "  # x['cls_pred_ratio'] = (x['cls_pred'] - x['min_cls_pred']) / (x['max_cls_pred'] - x['min_cls_pred']) if (x['max_cls_pred'] - x['min_cls_pred']) else 1\n",
    "  \n",
    "  return x\n",
    "\n",
    "def gen_feats():\n",
    "  xs = gezi.batch2list(xp)\n",
    "  p_feats = [gen_pfeat(x) for x in tqdm(xs, desc=f'gen_pfeats:xp')]\n",
    "  xs = gezi.batch2list(xp2)\n",
    "  p2_feats = [gen_pfeat(x) for x in tqdm(xs, desc=f'gen_pfeats:xp2')]\n",
    "  xs = gezi.batch2list(xc)\n",
    "  c_feats = [gen_cfeat(x) for x in tqdm(xs, desc=f'gen_cfeats:xc')]\n",
    "  feats = []\n",
    "  for i in tqdm(range(len(xs)), desc='merge_feats'):\n",
    "    fe1 = p_feats[i]\n",
    "    fe2= p2_feats[i]\n",
    "    fec = c_feats[i]\n",
    "    \n",
    "    fe = {}\n",
    "    fe['code_ratio'] = xp['n_code_cell'][i] / xp['n_cell'][i]\n",
    "    diff_feats(fe, fe1['pred'], fe2['pred'], 'ps')\n",
    "    diff_feats(fe, fe1['cls_pred'], fe2['cls_pred'], 'ps_cls')\n",
    "    diff_feats(fe, fe1['pred'], fec['reg_pred'], 'pc_reg')\n",
    "    diff_feats(fe, fe2['pred'], fec['reg_pred'], 'p2c_reg')\n",
    "    diff_feats(fe, fe1['pred'], fec['cls_pred'], 'pc_cls')\n",
    "    diff_feats(fe, fe2['pred'], fec['cls_pred'], 'p2c_cls')\n",
    "    diff_feats(fe, fe1['pred'], fec['cls2_pred'], 'pc_cls2')\n",
    "    diff_feats(fe, fe2['pred'], fec['cls2_pred'], 'p2c_cls2')\n",
    "    diff_feats(fe, fe1['cls_pred'], fec['reg_pred'], 'pc_cls_reg')\n",
    "    diff_feats(fe, fe2['cls_pred'], fec['reg_pred'], 'p2c_cls_reg')\n",
    "    diff_feats(fe, fe1['cls_pred'], fec['cls_pred'], 'pc_cls_cls')\n",
    "    diff_feats(fe, fe2['cls_pred'], fec['cls_pred'], 'p2c_cls_cls')\n",
    "\n",
    "    fe1 = gezi.dict_prefix(fe1, 'p_')\n",
    "    fe.update(fe1)\n",
    "    fe2 = gezi.dict_prefix(fe2, 'p2_')\n",
    "    fe.update(fe2)\n",
    "    fec = gezi.dict_prefix(fec, 'c_')\n",
    "    fe.update(fec)\n",
    "    \n",
    "    keys = [\n",
    "     'id', 'cell_id', 'cid',\n",
    "     'n_words', 'n_code_cell', 'n_cell'\n",
    "    ]\n",
    "    for key in keys:\n",
    "      fe[key] = xp[key][i]\n",
    "      \n",
    "    #  ic(feat)\n",
    "    feats.append(fe)\n",
    "  #  break\n",
    "  dfeats = pd.DataFrame(feats)\n",
    "  return dfeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a25921a42e4a53a10d56498973605a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gen_pfeats:xp:   0%|          | 0/424943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1232963b4741769314531ea0a53e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gen_pfeats:xp2:   0%|          | 0/424943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25142f503a848648a7df1bfa79172b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gen_cfeats:xc:   0%|          | 0/424943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b90494cadc44d89747edadbb7282f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merge_feats:   0%|          | 0/424943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfeats = gen_feats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_ratio</th>\n",
       "      <th>ps_diff</th>\n",
       "      <th>abs_ps_diff</th>\n",
       "      <th>ps_cls_diff</th>\n",
       "      <th>abs_ps_cls_diff</th>\n",
       "      <th>pc_reg_diff</th>\n",
       "      <th>abs_pc_reg_diff</th>\n",
       "      <th>p2c_reg_diff</th>\n",
       "      <th>abs_p2c_reg_diff</th>\n",
       "      <th>pc_cls_diff</th>\n",
       "      <th>abs_pc_cls_diff</th>\n",
       "      <th>p2c_cls_diff</th>\n",
       "      <th>abs_p2c_cls_diff</th>\n",
       "      <th>pc_cls2_diff</th>\n",
       "      <th>abs_pc_cls2_diff</th>\n",
       "      <th>p2c_cls2_diff</th>\n",
       "      <th>abs_p2c_cls2_diff</th>\n",
       "      <th>pc_cls_reg_diff</th>\n",
       "      <th>abs_pc_cls_reg_diff</th>\n",
       "      <th>p2c_cls_reg_diff</th>\n",
       "      <th>abs_p2c_cls_reg_diff</th>\n",
       "      <th>pc_cls_cls_diff</th>\n",
       "      <th>abs_pc_cls_cls_diff</th>\n",
       "      <th>p2c_cls_cls_diff</th>\n",
       "      <th>abs_p2c_cls_cls_diff</th>\n",
       "      <th>p_pred</th>\n",
       "      <th>p_cls_pred</th>\n",
       "      <th>p_rank_pred</th>\n",
       "      <th>p_cls_rank_pred</th>\n",
       "      <th>p_min_prob</th>\n",
       "      <th>p_min_sim</th>\n",
       "      <th>p_var_prob</th>\n",
       "      <th>p_var_sim</th>\n",
       "      <th>p_top_prob_0</th>\n",
       "      <th>p_top_sim_0</th>\n",
       "      <th>p_top_pred_1</th>\n",
       "      <th>p_top_prob_1</th>\n",
       "      <th>p_top_sim_1</th>\n",
       "      <th>p_top_pred_2</th>\n",
       "      <th>p_top_prob_2</th>\n",
       "      <th>p_top_sim_2</th>\n",
       "      <th>p_top_pred_3</th>\n",
       "      <th>p_top_prob_3</th>\n",
       "      <th>p_top_sim_3</th>\n",
       "      <th>p_top_pred_4</th>\n",
       "      <th>p_top_prob_4</th>\n",
       "      <th>p_top_sim_4</th>\n",
       "      <th>p_top_pred_5</th>\n",
       "      <th>p_top_prob_5</th>\n",
       "      <th>p_top_sim_5</th>\n",
       "      <th>p_top_pred_6</th>\n",
       "      <th>p_top_prob_6</th>\n",
       "      <th>p_top_sim_6</th>\n",
       "      <th>p_top_pred_7</th>\n",
       "      <th>p_top_prob_7</th>\n",
       "      <th>p_top_sim_7</th>\n",
       "      <th>p_top_pred_8</th>\n",
       "      <th>p_top_prob_8</th>\n",
       "      <th>p_top_sim_8</th>\n",
       "      <th>p_top_pred_9</th>\n",
       "      <th>p_top_prob_9</th>\n",
       "      <th>p_top_sim_9</th>\n",
       "      <th>p_cls_diff</th>\n",
       "      <th>p_abs_cls_diff</th>\n",
       "      <th>p2_pred</th>\n",
       "      <th>p2_cls_pred</th>\n",
       "      <th>p2_rank_pred</th>\n",
       "      <th>p2_cls_rank_pred</th>\n",
       "      <th>p2_min_prob</th>\n",
       "      <th>p2_min_sim</th>\n",
       "      <th>p2_var_prob</th>\n",
       "      <th>p2_var_sim</th>\n",
       "      <th>p2_top_prob_0</th>\n",
       "      <th>p2_top_sim_0</th>\n",
       "      <th>p2_top_pred_1</th>\n",
       "      <th>p2_top_prob_1</th>\n",
       "      <th>p2_top_sim_1</th>\n",
       "      <th>p2_top_pred_2</th>\n",
       "      <th>p2_top_prob_2</th>\n",
       "      <th>p2_top_sim_2</th>\n",
       "      <th>p2_top_pred_3</th>\n",
       "      <th>p2_top_prob_3</th>\n",
       "      <th>p2_top_sim_3</th>\n",
       "      <th>p2_top_pred_4</th>\n",
       "      <th>p2_top_prob_4</th>\n",
       "      <th>p2_top_sim_4</th>\n",
       "      <th>p2_top_pred_5</th>\n",
       "      <th>p2_top_prob_5</th>\n",
       "      <th>p2_top_sim_5</th>\n",
       "      <th>p2_top_pred_6</th>\n",
       "      <th>p2_top_prob_6</th>\n",
       "      <th>p2_top_sim_6</th>\n",
       "      <th>p2_top_pred_7</th>\n",
       "      <th>p2_top_prob_7</th>\n",
       "      <th>p2_top_sim_7</th>\n",
       "      <th>p2_top_pred_8</th>\n",
       "      <th>p2_top_prob_8</th>\n",
       "      <th>p2_top_sim_8</th>\n",
       "      <th>p2_top_pred_9</th>\n",
       "      <th>p2_top_prob_9</th>\n",
       "      <th>p2_top_sim_9</th>\n",
       "      <th>p2_cls_diff</th>\n",
       "      <th>p2_abs_cls_diff</th>\n",
       "      <th>c_pred</th>\n",
       "      <th>c_cls_pred</th>\n",
       "      <th>c_reg_pred</th>\n",
       "      <th>c_cls2_pred</th>\n",
       "      <th>c_rank_pred</th>\n",
       "      <th>c_cls_rank_pred</th>\n",
       "      <th>c_cls2_rank_pred</th>\n",
       "      <th>c_reg_rank_pred</th>\n",
       "      <th>c_min_prob</th>\n",
       "      <th>c_var_prob</th>\n",
       "      <th>c_top_prob_0</th>\n",
       "      <th>c_top_pred_1</th>\n",
       "      <th>c_top_prob_1</th>\n",
       "      <th>c_top_pred_2</th>\n",
       "      <th>c_top_prob_2</th>\n",
       "      <th>c_top_pred_3</th>\n",
       "      <th>c_top_prob_3</th>\n",
       "      <th>c_cls_reg_diff</th>\n",
       "      <th>c_abs_cls_reg_diff</th>\n",
       "      <th>c_cls_cls2_diff</th>\n",
       "      <th>c_abs_cls_cls2_diff</th>\n",
       "      <th>c_cls2_reg_diff</th>\n",
       "      <th>c_abs_cls2_reg_diff</th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cid</th>\n",
       "      <th>n_words</th>\n",
       "      <th>n_code_cell</th>\n",
       "      <th>n_cell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8889</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0237</td>\n",
       "      <td>0.0237</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>-0.0023</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>-0.0023</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.0645</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5031</td>\n",
       "      <td>0.0867</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.9432</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0456</td>\n",
       "      <td>0.6840</td>\n",
       "      <td>0.3889</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.6498</td>\n",
       "      <td>0.6111</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.5963</td>\n",
       "      <td>0.2778</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.5899</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.5559</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5262</td>\n",
       "      <td>0.7222</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5204</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5031</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.0882</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2937</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2628</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.7826</td>\n",
       "      <td>0.5662</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1731</td>\n",
       "      <td>0.5248</td>\n",
       "      <td>0.3889</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.4660</td>\n",
       "      <td>0.2778</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.4658</td>\n",
       "      <td>0.6111</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.3866</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.3546</td>\n",
       "      <td>0.7222</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2721</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2628</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.0548</td>\n",
       "      <td>0.0578</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>4.9806</td>\n",
       "      <td>5.2824</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>5.2824</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.9844</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.9450</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0002115f48f982</td>\n",
       "      <td>9ec225f0</td>\n",
       "      <td>0002115f48f982\\t9ec225f0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>-0.0035</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>-0.0035</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>-0.0212</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>-0.0078</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>0.9456</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>9.9017</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5679</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.9215</td>\n",
       "      <td>0.8047</td>\n",
       "      <td>0.8636</td>\n",
       "      <td>0.0752</td>\n",
       "      <td>0.7497</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.6594</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.6548</td>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.6450</td>\n",
       "      <td>0.6818</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.6200</td>\n",
       "      <td>0.4091</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.5992</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.5896</td>\n",
       "      <td>0.5909</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5820</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5739</td>\n",
       "      <td>-0.0089</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>0.9368</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>9.8051</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>0.0672</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.9087</td>\n",
       "      <td>0.4671</td>\n",
       "      <td>0.8636</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.3937</td>\n",
       "      <td>0.6818</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.3535</td>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.3202</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.3155</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.3071</td>\n",
       "      <td>0.5909</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.2982</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.2824</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.2561</td>\n",
       "      <td>-0.0177</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.9557</td>\n",
       "      <td>0.9534</td>\n",
       "      <td>0.9580</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>95.0712</td>\n",
       "      <td>94.8416</td>\n",
       "      <td>95.0000</td>\n",
       "      <td>94.8416</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.9922</td>\n",
       "      <td>0.9650</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.8650</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>-0.0046</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>-0.0016</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>-0.0030</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>00062ab8487156</td>\n",
       "      <td>96c8449c</td>\n",
       "      <td>00062ab8487156\\t96c8449c</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>0.2323</td>\n",
       "      <td>0.2323</td>\n",
       "      <td>-0.0811</td>\n",
       "      <td>0.0811</td>\n",
       "      <td>-0.5356</td>\n",
       "      <td>0.5356</td>\n",
       "      <td>-0.0824</td>\n",
       "      <td>0.0824</td>\n",
       "      <td>-0.5369</td>\n",
       "      <td>0.5369</td>\n",
       "      <td>-0.0950</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>-0.5495</td>\n",
       "      <td>0.5495</td>\n",
       "      <td>-0.1452</td>\n",
       "      <td>0.1452</td>\n",
       "      <td>-0.3776</td>\n",
       "      <td>0.3776</td>\n",
       "      <td>-0.1466</td>\n",
       "      <td>0.1466</td>\n",
       "      <td>-0.3789</td>\n",
       "      <td>0.3789</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4358</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>4.2939</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>0.6508</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>0.2409</td>\n",
       "      <td>0.6341</td>\n",
       "      <td>0.4091</td>\n",
       "      <td>0.0963</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>0.5909</td>\n",
       "      <td>0.0622</td>\n",
       "      <td>0.6044</td>\n",
       "      <td>0.6818</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.6006</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.5830</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.5409</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.5374</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.5322</td>\n",
       "      <td>0.8636</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.5029</td>\n",
       "      <td>-0.0642</td>\n",
       "      <td>0.0642</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.2035</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.7382</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.4471</td>\n",
       "      <td>0.4111</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.2928</td>\n",
       "      <td>0.3995</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1636</td>\n",
       "      <td>0.3836</td>\n",
       "      <td>0.6818</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.3508</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.3259</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.3230</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.2829</td>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.2577</td>\n",
       "      <td>0.4091</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.2552</td>\n",
       "      <td>0.5909</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.2457</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>0.5824</td>\n",
       "      <td>0.5811</td>\n",
       "      <td>0.5950</td>\n",
       "      <td>57.6727</td>\n",
       "      <td>57.7400</td>\n",
       "      <td>59.0000</td>\n",
       "      <td>57.7400</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.3826</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.1671</td>\n",
       "      <td>0.4050</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.6850</td>\n",
       "      <td>0.0971</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>-0.0126</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>00062ab8487156</td>\n",
       "      <td>aa354742</td>\n",
       "      <td>00062ab8487156\\taa354742</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5692</td>\n",
       "      <td>-0.0263</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>-0.0042</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>-0.0026</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0237</td>\n",
       "      <td>0.0237</td>\n",
       "      <td>-0.0034</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>-0.0041</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>-0.0217</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>-0.0026</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>-0.0201</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.8816</td>\n",
       "      <td>0.8816</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>33.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.7477</td>\n",
       "      <td>0.9079</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.5951</td>\n",
       "      <td>0.8289</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5295</td>\n",
       "      <td>0.6184</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5057</td>\n",
       "      <td>0.9342</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4822</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4765</td>\n",
       "      <td>0.6711</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4511</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4507</td>\n",
       "      <td>0.4342</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4434</td>\n",
       "      <td>0.5395</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4349</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9079</td>\n",
       "      <td>0.8640</td>\n",
       "      <td>34.0000</td>\n",
       "      <td>32.3327</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.7285</td>\n",
       "      <td>0.5429</td>\n",
       "      <td>0.6184</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>0.4922</td>\n",
       "      <td>0.8816</td>\n",
       "      <td>0.0592</td>\n",
       "      <td>0.4741</td>\n",
       "      <td>0.9342</td>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.4680</td>\n",
       "      <td>0.6711</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.4421</td>\n",
       "      <td>0.6974</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.4186</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.4135</td>\n",
       "      <td>0.8289</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.4103</td>\n",
       "      <td>0.6447</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.3978</td>\n",
       "      <td>0.7763</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>-0.0439</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>0.8842</td>\n",
       "      <td>0.8857</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>87.9951</td>\n",
       "      <td>87.9160</td>\n",
       "      <td>88.0000</td>\n",
       "      <td>87.9160</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.9844</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.8550</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>-0.0016</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>000efd285fb982</td>\n",
       "      <td>14f36391</td>\n",
       "      <td>000efd285fb982\\t14f36391</td>\n",
       "      <td>102</td>\n",
       "      <td>37</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5692</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0095</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>-0.0028</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>-0.0028</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>-0.0130</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>-0.0035</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>-0.0174</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>-0.0079</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.3289</td>\n",
       "      <td>0.3188</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>11.6137</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2815</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.7837</td>\n",
       "      <td>0.7111</td>\n",
       "      <td>0.2763</td>\n",
       "      <td>0.2041</td>\n",
       "      <td>0.6816</td>\n",
       "      <td>0.3553</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.6139</td>\n",
       "      <td>0.4868</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.5691</td>\n",
       "      <td>0.4605</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.5367</td>\n",
       "      <td>0.5658</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.5361</td>\n",
       "      <td>0.5132</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.5337</td>\n",
       "      <td>0.4342</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.5296</td>\n",
       "      <td>0.3026</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.1711</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.5178</td>\n",
       "      <td>-0.0102</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.3289</td>\n",
       "      <td>0.3283</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>11.9761</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>0.5162</td>\n",
       "      <td>0.2763</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.4008</td>\n",
       "      <td>0.3553</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.3769</td>\n",
       "      <td>0.1711</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>0.3816</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.3052</td>\n",
       "      <td>0.4605</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.2975</td>\n",
       "      <td>0.4342</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.2781</td>\n",
       "      <td>0.4868</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.2765</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.2745</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.2728</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.3340</td>\n",
       "      <td>0.3362</td>\n",
       "      <td>0.3318</td>\n",
       "      <td>0.3350</td>\n",
       "      <td>32.8991</td>\n",
       "      <td>33.1195</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>33.1195</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.8291</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.1423</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.3050</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>000efd285fb982</td>\n",
       "      <td>1f3749ad</td>\n",
       "      <td>000efd285fb982\\t1f3749ad</td>\n",
       "      <td>102</td>\n",
       "      <td>37</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424938</th>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>-0.0762</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>-0.0028</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>-0.0797</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>-0.0050</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>-0.0819</td>\n",
       "      <td>0.0819</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>-0.0079</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>-0.0114</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4997</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>5.9962</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4513</td>\n",
       "      <td>0.0706</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.7599</td>\n",
       "      <td>0.4231</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.5940</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.5915</td>\n",
       "      <td>0.2692</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.5898</td>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.5865</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.5783</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.5677</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.5647</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5188</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.4231</td>\n",
       "      <td>0.4914</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>5.8877</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.2508</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>0.4387</td>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.2190</td>\n",
       "      <td>0.4219</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.1848</td>\n",
       "      <td>0.4172</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.0956</td>\n",
       "      <td>0.3992</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.3721</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.3617</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.3468</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.3411</td>\n",
       "      <td>0.2692</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.3185</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.2967</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>0.5010</td>\n",
       "      <td>0.5028</td>\n",
       "      <td>0.4993</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>49.6017</td>\n",
       "      <td>49.7767</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>49.7767</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.9468</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.4250</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.4350</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>-0.0022</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>fff4714a37cf49</td>\n",
       "      <td>9527a079</td>\n",
       "      <td>fff4714a37cf49\\t9527a079</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424939</th>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0467</td>\n",
       "      <td>0.0467</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>0.3924</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>4.6017</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3853</td>\n",
       "      <td>0.0434</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.7758</td>\n",
       "      <td>0.6852</td>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.1965</td>\n",
       "      <td>0.6551</td>\n",
       "      <td>0.2692</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.6051</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.5693</td>\n",
       "      <td>0.4231</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.5636</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.4985</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.4974</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.4776</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4542</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>0.3457</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>3.9940</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2516</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.6573</td>\n",
       "      <td>0.2692</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.5239</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.4465</td>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.4414</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.4207</td>\n",
       "      <td>0.4231</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.3938</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3351</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3343</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3161</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3091</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.3424</td>\n",
       "      <td>0.3379</td>\n",
       "      <td>0.3469</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>33.7412</td>\n",
       "      <td>33.2899</td>\n",
       "      <td>34.0000</td>\n",
       "      <td>33.2899</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.9175</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>-0.0090</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>-0.0071</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>fff4714a37cf49</td>\n",
       "      <td>effc5f17</td>\n",
       "      <td>fff4714a37cf49\\teffc5f17</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424940</th>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>-0.0207</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>-0.0333</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-0.0040</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>-0.0167</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>0.7889</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>9.7556</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3902</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.6348</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.5373</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.5142</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.4878</td>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.4613</td>\n",
       "      <td>0.4231</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.4423</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.4356</td>\n",
       "      <td>0.9615</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4033</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4031</td>\n",
       "      <td>-0.0188</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>0.7763</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>9.5916</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3364</td>\n",
       "      <td>0.0491</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.8402</td>\n",
       "      <td>0.6223</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.5622</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.5128</td>\n",
       "      <td>0.4231</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.5098</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.5066</td>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.5018</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.4901</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.4873</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3548</td>\n",
       "      <td>-0.0314</td>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.8013</td>\n",
       "      <td>0.7929</td>\n",
       "      <td>0.8096</td>\n",
       "      <td>0.8050</td>\n",
       "      <td>79.6257</td>\n",
       "      <td>78.7944</td>\n",
       "      <td>80.0000</td>\n",
       "      <td>78.7944</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>-0.0121</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>-0.0046</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>fff4714a37cf49</td>\n",
       "      <td>f8744de1</td>\n",
       "      <td>fff4714a37cf49\\tf8744de1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424941</th>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0811</td>\n",
       "      <td>0.0811</td>\n",
       "      <td>-0.3574</td>\n",
       "      <td>0.3574</td>\n",
       "      <td>-0.3574</td>\n",
       "      <td>0.3574</td>\n",
       "      <td>-0.3048</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>-0.3048</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>-0.3824</td>\n",
       "      <td>0.3824</td>\n",
       "      <td>-0.3824</td>\n",
       "      <td>0.3824</td>\n",
       "      <td>-0.2635</td>\n",
       "      <td>0.2635</td>\n",
       "      <td>-0.3446</td>\n",
       "      <td>0.3446</td>\n",
       "      <td>-0.2109</td>\n",
       "      <td>0.2109</td>\n",
       "      <td>-0.2920</td>\n",
       "      <td>0.2920</td>\n",
       "      <td>0.6026</td>\n",
       "      <td>0.6965</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>26.6632</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3870</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.3993</td>\n",
       "      <td>0.6375</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>0.2073</td>\n",
       "      <td>0.6231</td>\n",
       "      <td>0.9103</td>\n",
       "      <td>0.0680</td>\n",
       "      <td>0.5987</td>\n",
       "      <td>0.4744</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>0.5931</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.0503</td>\n",
       "      <td>0.5920</td>\n",
       "      <td>0.6795</td>\n",
       "      <td>0.0402</td>\n",
       "      <td>0.5871</td>\n",
       "      <td>0.7051</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.5846</td>\n",
       "      <td>0.7821</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.5845</td>\n",
       "      <td>0.7564</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.5781</td>\n",
       "      <td>0.6282</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.5713</td>\n",
       "      <td>0.0939</td>\n",
       "      <td>0.0939</td>\n",
       "      <td>0.6026</td>\n",
       "      <td>0.6154</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>23.5002</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.1629</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.1595</td>\n",
       "      <td>0.3343</td>\n",
       "      <td>0.6795</td>\n",
       "      <td>0.1304</td>\n",
       "      <td>0.3288</td>\n",
       "      <td>0.6282</td>\n",
       "      <td>0.1089</td>\n",
       "      <td>0.3239</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.0901</td>\n",
       "      <td>0.3187</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.0720</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.3082</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>0.0540</td>\n",
       "      <td>0.3046</td>\n",
       "      <td>0.9359</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.3036</td>\n",
       "      <td>0.9103</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.2950</td>\n",
       "      <td>0.2692</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.2901</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.9337</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.9850</td>\n",
       "      <td>92.8663</td>\n",
       "      <td>90.2365</td>\n",
       "      <td>98.0000</td>\n",
       "      <td>90.2365</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.3994</td>\n",
       "      <td>0.8350</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.9150</td>\n",
       "      <td>0.1022</td>\n",
       "      <td>0.9350</td>\n",
       "      <td>0.0759</td>\n",
       "      <td>-0.0526</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>-0.0776</td>\n",
       "      <td>0.0776</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>fffc1b4f08e81c</td>\n",
       "      <td>143cccfb</td>\n",
       "      <td>fffc1b4f08e81c\\t143cccfb</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424942</th>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>0.3866</td>\n",
       "      <td>0.3866</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.3447</td>\n",
       "      <td>0.3447</td>\n",
       "      <td>-0.0142</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>-0.3568</td>\n",
       "      <td>0.3568</td>\n",
       "      <td>0.1304</td>\n",
       "      <td>0.1304</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0885</td>\n",
       "      <td>0.0885</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.9872</td>\n",
       "      <td>0.7310</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>28.0072</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5061</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.3005</td>\n",
       "      <td>0.7126</td>\n",
       "      <td>0.6026</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.6988</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>0.1163</td>\n",
       "      <td>0.6917</td>\n",
       "      <td>0.6795</td>\n",
       "      <td>0.0578</td>\n",
       "      <td>0.6764</td>\n",
       "      <td>0.9103</td>\n",
       "      <td>0.0536</td>\n",
       "      <td>0.6747</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.6679</td>\n",
       "      <td>0.2692</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.6612</td>\n",
       "      <td>0.7051</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.6591</td>\n",
       "      <td>0.4744</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.6586</td>\n",
       "      <td>0.6282</td>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.6582</td>\n",
       "      <td>-0.2562</td>\n",
       "      <td>0.2562</td>\n",
       "      <td>0.6282</td>\n",
       "      <td>0.6459</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>24.6908</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.1499</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.2192</td>\n",
       "      <td>0.3271</td>\n",
       "      <td>0.9872</td>\n",
       "      <td>0.1303</td>\n",
       "      <td>0.3129</td>\n",
       "      <td>0.6026</td>\n",
       "      <td>0.1253</td>\n",
       "      <td>0.3118</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>0.1208</td>\n",
       "      <td>0.3108</td>\n",
       "      <td>0.6795</td>\n",
       "      <td>0.0981</td>\n",
       "      <td>0.3051</td>\n",
       "      <td>0.4231</td>\n",
       "      <td>0.0467</td>\n",
       "      <td>0.2848</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>0.2803</td>\n",
       "      <td>0.2692</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.2721</td>\n",
       "      <td>0.6538</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.2618</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.2617</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.6215</td>\n",
       "      <td>0.6424</td>\n",
       "      <td>0.6006</td>\n",
       "      <td>0.9850</td>\n",
       "      <td>61.6509</td>\n",
       "      <td>63.7433</td>\n",
       "      <td>98.0000</td>\n",
       "      <td>63.7433</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.7050</td>\n",
       "      <td>0.1079</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>0.0975</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.0716</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>-0.3426</td>\n",
       "      <td>0.3426</td>\n",
       "      <td>0.3844</td>\n",
       "      <td>0.3844</td>\n",
       "      <td>fffc1b4f08e81c</td>\n",
       "      <td>ffc27279</td>\n",
       "      <td>fffc1b4f08e81c\\tffc27279</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>424943 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        code_ratio  ps_diff  abs_ps_diff  ps_cls_diff  abs_ps_cls_diff  \\\n",
       "0           0.8889   0.0000       0.0000      -0.0237           0.0237   \n",
       "1           0.8333   0.0000       0.0000       0.0088           0.0088   \n",
       "2           0.8333   0.4545       0.4545       0.2323           0.2323   \n",
       "3           0.5692  -0.0263       0.0263       0.0176           0.0176   \n",
       "4           0.5692   0.0000       0.0000      -0.0095           0.0095   \n",
       "...            ...      ...          ...          ...              ...   \n",
       "424938      0.5714   0.0769       0.0769       0.0083           0.0083   \n",
       "424939      0.5714   0.0000       0.0000       0.0467           0.0467   \n",
       "424940      0.5714   0.0000       0.0000       0.0126           0.0126   \n",
       "424941      0.9500   0.0000       0.0000       0.0811           0.0811   \n",
       "424942      0.9500   0.3590       0.3590       0.0850           0.0850   \n",
       "\n",
       "        pc_reg_diff  abs_pc_reg_diff  p2c_reg_diff  abs_p2c_reg_diff  \\\n",
       "0            0.0038           0.0038        0.0038            0.0038   \n",
       "1           -0.0035           0.0035       -0.0035            0.0035   \n",
       "2           -0.0811           0.0811       -0.5356            0.5356   \n",
       "3           -0.0042           0.0042        0.0222            0.0222   \n",
       "4           -0.0028           0.0028       -0.0028            0.0028   \n",
       "...             ...              ...           ...               ...   \n",
       "424938       0.0007           0.0007       -0.0762            0.0762   \n",
       "424939      -0.0008           0.0008       -0.0008            0.0008   \n",
       "424940      -0.0019           0.0019       -0.0019            0.0019   \n",
       "424941      -0.3574           0.3574       -0.3574            0.3574   \n",
       "424942       0.3866           0.3866        0.0276            0.0276   \n",
       "\n",
       "        pc_cls_diff  abs_pc_cls_diff  p2c_cls_diff  abs_p2c_cls_diff  \\\n",
       "0           -0.0023           0.0023       -0.0023            0.0023   \n",
       "1            0.0011           0.0011        0.0011            0.0011   \n",
       "2           -0.0824           0.0824       -0.5369            0.5369   \n",
       "3           -0.0026           0.0026        0.0237            0.0237   \n",
       "4           -0.0072           0.0072       -0.0072            0.0072   \n",
       "...             ...              ...           ...               ...   \n",
       "424938      -0.0028           0.0028       -0.0797            0.0797   \n",
       "424939       0.0083           0.0083        0.0083            0.0083   \n",
       "424940       0.0147           0.0147        0.0147            0.0147   \n",
       "424941      -0.3048           0.3048       -0.3048            0.3048   \n",
       "424942       0.3447           0.3447       -0.0142            0.0142   \n",
       "\n",
       "        pc_cls2_diff  abs_pc_cls2_diff  p2c_cls2_diff  abs_p2c_cls2_diff  \\\n",
       "0             0.0006            0.0006         0.0006             0.0006   \n",
       "1            -0.0005            0.0005        -0.0005             0.0005   \n",
       "2            -0.0950            0.0950        -0.5495             0.5495   \n",
       "3            -0.0034            0.0034         0.0229             0.0229   \n",
       "4            -0.0061            0.0061        -0.0061             0.0061   \n",
       "...              ...               ...            ...                ...   \n",
       "424938       -0.0050            0.0050        -0.0819             0.0819   \n",
       "424939        0.0012            0.0012         0.0012             0.0012   \n",
       "424940        0.0027            0.0027         0.0027             0.0027   \n",
       "424941       -0.3824            0.3824        -0.3824             0.3824   \n",
       "424942        0.0022            0.0022        -0.3568             0.3568   \n",
       "\n",
       "        pc_cls_reg_diff  abs_pc_cls_reg_diff  p2c_cls_reg_diff  \\\n",
       "0                0.0127               0.0127            0.0364   \n",
       "1               -0.0124               0.0124           -0.0212   \n",
       "2               -0.1452               0.1452           -0.3776   \n",
       "3               -0.0041               0.0041           -0.0217   \n",
       "4               -0.0130               0.0130           -0.0035   \n",
       "...                 ...                  ...               ...   \n",
       "424938           0.0004               0.0004           -0.0079   \n",
       "424939           0.0455               0.0455           -0.0012   \n",
       "424940          -0.0207               0.0207           -0.0333   \n",
       "424941          -0.2635               0.2635           -0.3446   \n",
       "424942           0.1304               0.1304            0.0453   \n",
       "\n",
       "        abs_p2c_cls_reg_diff  pc_cls_cls_diff  abs_pc_cls_cls_diff  \\\n",
       "0                     0.0364           0.0067               0.0067   \n",
       "1                     0.0212          -0.0078               0.0078   \n",
       "2                     0.3776          -0.1466               0.1466   \n",
       "3                     0.0217          -0.0026               0.0026   \n",
       "4                     0.0035          -0.0174               0.0174   \n",
       "...                      ...              ...                  ...   \n",
       "424938                0.0079          -0.0031               0.0031   \n",
       "424939                0.0012           0.0545               0.0545   \n",
       "424940                0.0333          -0.0040               0.0040   \n",
       "424941                0.3446          -0.2109               0.2109   \n",
       "424942                0.0453           0.0885               0.0885   \n",
       "\n",
       "        p2c_cls_cls_diff  abs_p2c_cls_cls_diff  p_pred  p_cls_pred  \\\n",
       "0                 0.0304                0.0304  0.0556      0.0645   \n",
       "1                -0.0166                0.0166  0.9545      0.9456   \n",
       "2                -0.3789                0.3789  0.5000      0.4358   \n",
       "3                -0.0201                0.0201  0.8816      0.8816   \n",
       "4                -0.0079                0.0079  0.3289      0.3188   \n",
       "...                  ...                   ...     ...         ...   \n",
       "424938           -0.0114                0.0114  0.5000      0.4997   \n",
       "424939            0.0078                0.0078  0.3462      0.3924   \n",
       "424940           -0.0167                0.0167  0.8077      0.7889   \n",
       "424941           -0.2920                0.2920  0.6026      0.6965   \n",
       "424942            0.0035                0.0035  0.9872      0.7310   \n",
       "\n",
       "        p_rank_pred  p_cls_rank_pred  p_min_prob  p_min_sim  p_var_prob  \\\n",
       "0            0.0000           0.0808      0.0000     0.5031      0.0867   \n",
       "1           10.0000           9.9017      0.0000     0.5679      0.0695   \n",
       "2            5.0000           4.2939      0.0004     0.4950      0.0226   \n",
       "3           33.0000          33.0007      0.0000     0.1710      0.0256   \n",
       "4           12.0000          11.6137      0.0000     0.2815      0.0166   \n",
       "...             ...              ...         ...        ...         ...   \n",
       "424938       6.0000           5.9962      0.0000     0.4513      0.0706   \n",
       "424939       4.0000           4.6017      0.0000     0.3853      0.0434   \n",
       "424940      10.0000           9.7556      0.0000     0.3902      0.0641   \n",
       "424941      23.0000          26.6632      0.0000     0.3870      0.0049   \n",
       "424942      38.0000          28.0072      0.0000     0.5061      0.0030   \n",
       "\n",
       "        p_var_sim  p_top_prob_0  p_top_sim_0  p_top_pred_1  p_top_prob_1  \\\n",
       "0          0.0062        0.9432       0.7505        0.1667        0.0456   \n",
       "1          0.0052        0.9215       0.8047        0.8636        0.0752   \n",
       "2          0.0026        0.5150       0.6508        0.2273        0.2409   \n",
       "3          0.0139        0.9990       0.7477        0.9079        0.0010   \n",
       "4          0.0101        0.7837       0.7111        0.2763        0.2041   \n",
       "...           ...           ...          ...           ...           ...   \n",
       "424938     0.0053        0.9976       0.7599        0.4231        0.0005   \n",
       "424939     0.0075        0.7758       0.6852        0.5769        0.1965   \n",
       "424940     0.0054        0.9537       0.6348        0.5000        0.0293   \n",
       "424941     0.0044        0.3993       0.6375        0.8846        0.2073   \n",
       "424942     0.0021        0.3005       0.7126        0.6026        0.1603   \n",
       "\n",
       "        p_top_sim_1  p_top_pred_2  p_top_prob_2  p_top_sim_2  p_top_pred_3  \\\n",
       "0            0.6840        0.3889        0.0096       0.6498        0.6111   \n",
       "1            0.7497        0.2273        0.0012       0.6594        0.0455   \n",
       "2            0.6341        0.4091        0.0963       0.6140        0.5909   \n",
       "3            0.5951        0.8289        0.0000       0.5295        0.6184   \n",
       "4            0.6816        0.3553        0.0094       0.6139        0.4868   \n",
       "...             ...           ...           ...          ...           ...   \n",
       "424938       0.5940        0.1154        0.0005       0.5915        0.2692   \n",
       "424939       0.6551        0.2692        0.0201       0.6051        0.8846   \n",
       "424940       0.5584        0.1923        0.0112       0.5373        0.1154   \n",
       "424941       0.6231        0.9103        0.0680       0.5987        0.4744   \n",
       "424942       0.6988        0.8846        0.1163       0.6917        0.6795   \n",
       "\n",
       "        p_top_prob_3  p_top_sim_3  p_top_pred_4  p_top_prob_4  p_top_sim_4  \\\n",
       "0             0.0008       0.5963        0.2778        0.0006       0.5899   \n",
       "1             0.0010       0.6548        0.7727        0.0006       0.6450   \n",
       "2             0.0622       0.6044        0.6818        0.0523       0.6006   \n",
       "3             0.0000       0.5057        0.9342        0.0000       0.4822   \n",
       "4             0.0012       0.5691        0.4605        0.0003       0.5367   \n",
       "...              ...          ...           ...           ...          ...   \n",
       "424938        0.0004       0.5898        0.5769        0.0004       0.5865   \n",
       "424939        0.0039       0.5693        0.4231        0.0030       0.5636   \n",
       "424940        0.0039       0.5142        0.8846        0.0012       0.4878   \n",
       "424941        0.0528       0.5931        0.7308        0.0503       0.5920   \n",
       "424942        0.0578       0.6764        0.9103        0.0536       0.6747   \n",
       "\n",
       "        p_top_pred_5  p_top_prob_5  p_top_sim_5  p_top_pred_6  p_top_prob_6  \\\n",
       "0             0.5000        0.0001       0.5559        0.9444        0.0000   \n",
       "1             0.6818        0.0002       0.6200        0.4091        0.0001   \n",
       "2             0.3182        0.0235       0.5830        0.1364        0.0035   \n",
       "3             0.7500        0.0000       0.4765        0.6711        0.0000   \n",
       "4             0.5658        0.0003       0.5361        0.5132        0.0002   \n",
       "...              ...           ...          ...           ...           ...   \n",
       "424938        0.1923        0.0003       0.5783        0.7308        0.0002   \n",
       "424939        0.8077        0.0002       0.5019        0.1923        0.0002   \n",
       "424940        0.5769        0.0004       0.4613        0.4231        0.0001   \n",
       "424941        0.6795        0.0402       0.5871        0.7051        0.0359   \n",
       "424942        0.7308        0.0394       0.6679        0.2692        0.0289   \n",
       "\n",
       "        p_top_sim_6  p_top_pred_7  p_top_prob_7  p_top_sim_7  p_top_pred_8  \\\n",
       "0            0.5262        0.7222        0.0000       0.5204        0.8333   \n",
       "1            0.5992        0.1364        0.0001       0.5896        0.5909   \n",
       "2            0.5409        0.9545        0.0029       0.5374        0.0455   \n",
       "3            0.4511        0.9605        0.0000       0.4507        0.4342   \n",
       "4            0.5337        0.4342        0.0002       0.5296        0.3026   \n",
       "...             ...           ...           ...          ...           ...   \n",
       "424938       0.5677        0.8077        0.0001       0.5647        0.6538   \n",
       "424939       0.4985        0.6538        0.0001       0.4974        0.5000   \n",
       "424940       0.4423        0.0385        0.0001       0.4356        0.9615   \n",
       "424941       0.5846        0.7821        0.0356       0.5845        0.7564   \n",
       "424942       0.6612        0.7051        0.0263       0.6591        0.4744   \n",
       "\n",
       "        p_top_prob_8  p_top_sim_8  p_top_pred_9  p_top_prob_9  p_top_sim_9  \\\n",
       "0             0.0000       0.5031       -1.0000       -1.0000      -1.0000   \n",
       "1             0.0000       0.5820        0.5000        0.0000       0.5739   \n",
       "2             0.0023       0.5322        0.8636        0.0006       0.5029   \n",
       "3             0.0000       0.4434        0.5395        0.0000       0.4349   \n",
       "4             0.0002       0.5255        0.1711        0.0001       0.5178   \n",
       "...              ...          ...           ...           ...          ...   \n",
       "424938        0.0000       0.5300        0.3462        0.0000       0.5188   \n",
       "424939        0.0001       0.4776        0.7308        0.0000       0.4542   \n",
       "424940        0.0000       0.4033        0.3462        0.0000       0.4031   \n",
       "424941        0.0267       0.5781        0.6282        0.0195       0.5713   \n",
       "424942        0.0258       0.6586        0.6282        0.0253       0.6582   \n",
       "\n",
       "        p_cls_diff  p_abs_cls_diff  p2_pred  p2_cls_pred  p2_rank_pred  \\\n",
       "0           0.0090          0.0090   0.0556       0.0882        0.0000   \n",
       "1          -0.0089          0.0089   0.9545       0.9368       10.0000   \n",
       "2          -0.0642          0.0642   0.0455       0.2035        0.0000   \n",
       "3           0.0000          0.0000   0.9079       0.8640       34.0000   \n",
       "4          -0.0102          0.0102   0.3289       0.3283       12.0000   \n",
       "...            ...             ...      ...          ...           ...   \n",
       "424938     -0.0003          0.0003   0.4231       0.4914        5.0000   \n",
       "424939      0.0463          0.0463   0.3462       0.3457        4.0000   \n",
       "424940     -0.0188          0.0188   0.8077       0.7763       10.0000   \n",
       "424941      0.0939          0.0939   0.6026       0.6154       23.0000   \n",
       "424942     -0.2562          0.2562   0.6282       0.6459       24.0000   \n",
       "\n",
       "        p2_cls_rank_pred  p2_min_prob  p2_min_sim  p2_var_prob  p2_var_sim  \\\n",
       "0                 0.2937       0.0000      0.2628       0.0591      0.0098   \n",
       "1                 9.8051       0.0001      0.2140       0.0672      0.0044   \n",
       "2                 1.7382       0.0010      0.2431       0.0204      0.0037   \n",
       "3                32.3327       0.0000      0.0410       0.0138      0.0184   \n",
       "4                11.9761       0.0000      0.0527       0.0244      0.0094   \n",
       "...                  ...          ...         ...          ...         ...   \n",
       "424938            5.8877       0.0004      0.2508       0.0139      0.0037   \n",
       "424939            3.9940       0.0000      0.2516       0.0697      0.0119   \n",
       "424940            9.5916       0.0000      0.3364       0.0491      0.0079   \n",
       "424941           23.5002       0.0003      0.1629       0.0015      0.0029   \n",
       "424942           24.6908       0.0003      0.1499       0.0022      0.0023   \n",
       "\n",
       "        p2_top_prob_0  p2_top_sim_0  p2_top_pred_1  p2_top_prob_1  \\\n",
       "0              0.7826        0.5662         0.1667         0.1731   \n",
       "1              0.9087        0.4671         0.8636         0.0623   \n",
       "2              0.4471        0.4111         0.1364         0.2928   \n",
       "3              0.7285        0.5429         0.6184         0.1146   \n",
       "4              0.9772        0.5162         0.2763         0.0145   \n",
       "...               ...           ...            ...            ...   \n",
       "424938         0.4054        0.4387         0.5769         0.2190   \n",
       "424939         0.9913        0.6573         0.2692         0.0076   \n",
       "424940         0.8402        0.6223         0.7308         0.0938   \n",
       "424941         0.1595        0.3343         0.6795         0.1304   \n",
       "424942         0.2192        0.3271         0.9872         0.1303   \n",
       "\n",
       "        p2_top_sim_1  p2_top_pred_2  p2_top_prob_2  p2_top_sim_2  \\\n",
       "0             0.5248         0.3889         0.0202        0.4660   \n",
       "1             0.3937         0.6818         0.0144        0.3535   \n",
       "2             0.3995         0.5000         0.1636        0.3836   \n",
       "3             0.4922         0.8816         0.0592        0.4741   \n",
       "4             0.4008         0.3553         0.0061        0.3769   \n",
       "...              ...            ...            ...           ...   \n",
       "424938        0.4219         0.5000         0.1848        0.4172   \n",
       "424939        0.5239         0.1923         0.0005        0.4465   \n",
       "424940        0.5622         0.6538         0.0155        0.5128   \n",
       "424941        0.3288         0.6282         0.1089        0.3239   \n",
       "424942        0.3129         0.6026         0.1253        0.3118   \n",
       "\n",
       "        p2_top_pred_3  p2_top_prob_3  p2_top_sim_3  p2_top_pred_4  \\\n",
       "0              0.2778         0.0201        0.4658         0.6111   \n",
       "1              0.7727         0.0043        0.3202         0.0455   \n",
       "2              0.6818         0.0494        0.3508         0.9545   \n",
       "3              0.9342         0.0473        0.4680         0.6711   \n",
       "4              0.1711         0.0005        0.3080         0.3816   \n",
       "...               ...            ...           ...            ...   \n",
       "424938         0.6538         0.0956        0.3992         0.1154   \n",
       "424939         0.5769         0.0004        0.4414         0.8846   \n",
       "424940         0.4231         0.0139        0.5098         0.1923   \n",
       "424941         0.7308         0.0901        0.3187         0.6538   \n",
       "424942         0.8846         0.1208        0.3108         0.6795   \n",
       "\n",
       "        p2_top_prob_4  p2_top_sim_4  p2_top_pred_5  p2_top_prob_5  \\\n",
       "0              0.0025        0.4087         0.5000         0.0011   \n",
       "1              0.0036        0.3155         0.2273         0.0026   \n",
       "2              0.0199        0.3259         0.2273         0.0179   \n",
       "3              0.0184        0.4421         0.6974         0.0078   \n",
       "4              0.0004        0.3052         0.4605         0.0003   \n",
       "...               ...           ...            ...            ...   \n",
       "424938         0.0356        0.3721         0.7308         0.0244   \n",
       "424939         0.0002        0.4207         0.4231         0.0001   \n",
       "424940         0.0123        0.5066         0.5769         0.0104   \n",
       "424941         0.0720        0.3125         0.0897         0.0614   \n",
       "424942         0.0981        0.3051         0.4231         0.0467   \n",
       "\n",
       "        p2_top_sim_5  p2_top_pred_6  p2_top_prob_6  p2_top_sim_6  \\\n",
       "0             0.3866         0.9444         0.0003        0.3546   \n",
       "1             0.3071         0.5909         0.0019        0.2982   \n",
       "2             0.3230         0.3182         0.0041        0.2829   \n",
       "3             0.4186         0.7500         0.0065        0.4135   \n",
       "4             0.2975         0.4342         0.0002        0.2781   \n",
       "...              ...            ...            ...           ...   \n",
       "424938        0.3617         0.8077         0.0141        0.3468   \n",
       "424939        0.3938         0.1154         0.0000        0.3351   \n",
       "424940        0.5018         0.1154         0.0067        0.4901   \n",
       "424941        0.3082         0.8846         0.0540        0.3046   \n",
       "424942        0.2848         0.7308         0.0397        0.2803   \n",
       "\n",
       "        p2_top_pred_7  p2_top_prob_7  p2_top_sim_7  p2_top_pred_8  \\\n",
       "0              0.7222         0.0000        0.2721         0.8333   \n",
       "1              0.1364         0.0011        0.2824         0.5000   \n",
       "2              0.7727         0.0017        0.2577         0.4091   \n",
       "3              0.8289         0.0057        0.4103         0.6447   \n",
       "4              0.4868         0.0002        0.2765         0.1974   \n",
       "...               ...            ...           ...            ...   \n",
       "424938         0.1923         0.0115        0.3411         0.2692   \n",
       "424939         0.6538         0.0000        0.3343         0.8077   \n",
       "424940         0.5000         0.0061        0.4873         0.8846   \n",
       "424941         0.9359         0.0519        0.3036         0.9103   \n",
       "424942         0.2692         0.0294        0.2721         0.6538   \n",
       "\n",
       "        p2_top_prob_8  p2_top_sim_8  p2_top_pred_9  p2_top_prob_9  \\\n",
       "0              0.0000        0.2628        -1.0000        -1.0000   \n",
       "1              0.0007        0.2700         0.3182         0.0004   \n",
       "2              0.0015        0.2552         0.5909         0.0011   \n",
       "3              0.0036        0.3978         0.7763         0.0017   \n",
       "4              0.0001        0.2745         0.2500         0.0001   \n",
       "...               ...           ...            ...            ...   \n",
       "424938         0.0050        0.3185         0.3462         0.0023   \n",
       "424939         0.0000        0.3161         0.5000         0.0000   \n",
       "424940         0.0010        0.4375         0.3462         0.0000   \n",
       "424941         0.0380        0.2950         0.2692         0.0317   \n",
       "424942         0.0202        0.2618         0.0641         0.0201   \n",
       "\n",
       "        p2_top_sim_9  p2_cls_diff  p2_abs_cls_diff  c_pred  c_cls_pred  \\\n",
       "0            -1.0000       0.0326           0.0326  0.0548      0.0578   \n",
       "1             0.2561      -0.0177           0.0177  0.9557      0.9534   \n",
       "2             0.2457       0.1580           0.1580  0.5817      0.5824   \n",
       "3             0.3773      -0.0439           0.0439  0.8850      0.8842   \n",
       "4             0.2728      -0.0006           0.0006  0.3340      0.3362   \n",
       "...              ...          ...              ...     ...         ...   \n",
       "424938        0.2967       0.0683           0.0683  0.5010      0.5028   \n",
       "424939        0.3091      -0.0005           0.0005  0.3424      0.3379   \n",
       "424940        0.3548      -0.0314           0.0314  0.8013      0.7929   \n",
       "424941        0.2901       0.0128           0.0128  0.9337      0.9074   \n",
       "424942        0.2617       0.0177           0.0177  0.6215      0.6424   \n",
       "\n",
       "        c_reg_pred  c_cls2_pred  c_rank_pred  c_cls_rank_pred  \\\n",
       "0           0.0518       0.0550       4.9806           5.2824   \n",
       "1           0.9580       0.9550      95.0712          94.8416   \n",
       "2           0.5811       0.5950      57.6727          57.7400   \n",
       "3           0.8857       0.8850      87.9951          87.9160   \n",
       "4           0.3318       0.3350      32.8991          33.1195   \n",
       "...            ...          ...          ...              ...   \n",
       "424938      0.4993       0.5050      49.6017          49.7767   \n",
       "424939      0.3469       0.3450      33.7412          33.2899   \n",
       "424940      0.8096       0.8050      79.6257          78.7944   \n",
       "424941      0.9600       0.9850      92.8663          90.2365   \n",
       "424942      0.6006       0.9850      61.6509          63.7433   \n",
       "\n",
       "        c_cls2_rank_pred  c_reg_rank_pred  c_min_prob  c_var_prob  \\\n",
       "0                 5.0000           5.2824      0.0000      0.0096   \n",
       "1                95.0000          94.8416      0.0000      0.0098   \n",
       "2                59.0000          57.7400      0.0000      0.0020   \n",
       "3                88.0000          87.9160      0.0000      0.0096   \n",
       "4                33.0000          33.1195      0.0000      0.0070   \n",
       "...                  ...              ...         ...         ...   \n",
       "424938           50.0000          49.7767      0.0000      0.0089   \n",
       "424939           34.0000          33.2899      0.0000      0.0083   \n",
       "424940           80.0000          78.7944      0.0000      0.0090   \n",
       "424941           98.0000          90.2365      0.0000      0.0019   \n",
       "424942           98.0000          63.7433      0.0000      0.0008   \n",
       "\n",
       "        c_top_prob_0  c_top_pred_1  c_top_prob_1  c_top_pred_2  c_top_prob_2  \\\n",
       "0             0.9844        0.1650        0.0203        0.0350        0.0009   \n",
       "1             0.9922        0.9650        0.0041        0.8650        0.0016   \n",
       "2             0.3826        0.5050        0.1671        0.4050        0.1282   \n",
       "3             0.9844        0.8750        0.0104        0.8550        0.0022   \n",
       "4             0.8291        0.3250        0.1423        0.3450        0.0046   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "424938        0.9468        0.5150        0.0321        0.4250        0.0097   \n",
       "424939        0.9175        0.2650        0.0316        0.1950        0.0295   \n",
       "424940        0.9541        0.8850        0.0097        0.8250        0.0089   \n",
       "424941        0.3994        0.8350        0.1312        0.9150        0.1022   \n",
       "424942        0.2240        0.7050        0.1079        0.6750        0.0975   \n",
       "\n",
       "        c_top_pred_3  c_top_prob_3  c_cls_reg_diff  c_abs_cls_reg_diff  \\\n",
       "0             0.9450        0.0002          0.0060              0.0060   \n",
       "1             0.0450        0.0009         -0.0046              0.0046   \n",
       "2             0.6850        0.0971          0.0013              0.0013   \n",
       "3             0.9050        0.0015         -0.0016              0.0016   \n",
       "4             0.3050        0.0037          0.0044              0.0044   \n",
       "...              ...           ...             ...                 ...   \n",
       "424938        0.4350        0.0042          0.0035              0.0035   \n",
       "424939        0.1150        0.0138         -0.0090              0.0090   \n",
       "424940        0.1150        0.0066         -0.0166              0.0166   \n",
       "424941        0.9350        0.0759         -0.0526              0.0526   \n",
       "424942        0.4750        0.0716          0.0418              0.0418   \n",
       "\n",
       "        c_cls_cls2_diff  c_abs_cls_cls2_diff  c_cls2_reg_diff  \\\n",
       "0                0.0028               0.0028           0.0032   \n",
       "1               -0.0016               0.0016          -0.0030   \n",
       "2               -0.0126               0.0126           0.0139   \n",
       "3               -0.0008               0.0008          -0.0007   \n",
       "4                0.0012               0.0012           0.0032   \n",
       "...                 ...                  ...              ...   \n",
       "424938          -0.0022               0.0022           0.0057   \n",
       "424939          -0.0071               0.0071          -0.0019   \n",
       "424940          -0.0121               0.0121          -0.0046   \n",
       "424941          -0.0776               0.0776           0.0250   \n",
       "424942          -0.3426               0.3426           0.3844   \n",
       "\n",
       "        c_abs_cls2_reg_diff              id   cell_id  \\\n",
       "0                    0.0032  0002115f48f982  9ec225f0   \n",
       "1                    0.0030  00062ab8487156  96c8449c   \n",
       "2                    0.0139  00062ab8487156  aa354742   \n",
       "3                    0.0007  000efd285fb982  14f36391   \n",
       "4                    0.0032  000efd285fb982  1f3749ad   \n",
       "...                     ...             ...       ...   \n",
       "424938               0.0057  fff4714a37cf49  9527a079   \n",
       "424939               0.0019  fff4714a37cf49  effc5f17   \n",
       "424940               0.0046  fff4714a37cf49  f8744de1   \n",
       "424941               0.0250  fffc1b4f08e81c  143cccfb   \n",
       "424942               0.3844  fffc1b4f08e81c  ffc27279   \n",
       "\n",
       "                             cid  n_words  n_code_cell  n_cell  \n",
       "0       0002115f48f982\\t9ec225f0        2            8       9  \n",
       "1       00062ab8487156\\t96c8449c        6           10      12  \n",
       "2       00062ab8487156\\taa354742        6           10      12  \n",
       "3       000efd285fb982\\t14f36391      102           37      65  \n",
       "4       000efd285fb982\\t1f3749ad      102           37      65  \n",
       "...                          ...      ...          ...     ...  \n",
       "424938  fff4714a37cf49\\t9527a079        4           12      21  \n",
       "424939  fff4714a37cf49\\teffc5f17        4           12      21  \n",
       "424940  fff4714a37cf49\\tf8744de1        4           12      21  \n",
       "424941  fffc1b4f08e81c\\t143cccfb        9           38      40  \n",
       "424942  fffc1b4f08e81c\\tffc27279        9           38      40  \n",
       "\n",
       "[424943 rows x 132 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfeats.merge(df_train[['cid', 'ancestor_id', LABEL_COL]], on='cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gezi.set_fold(df, 5, 'ancestor_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_cols = [x for x in dfeats.columns if x not in ['id', 'cell_id', 'cid', LABEL_COL]]\n",
    "cat_cols = []\n",
    "cols = reg_cols + cat_cols\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "dvalid = df[df.fold==fold]\n",
    "dtrain = df[df.fold!=fold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dtrain[cols]\n",
    "y_train = dtrain[LABEL_COL]\n",
    "X_valid = dvalid[cols]\n",
    "y_valid = dvalid[LABEL_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, CatBoostRanker\n",
    "cbt_params = {\n",
    "              # 'bootstrap_type': 'Poisson',\n",
    "              # 'learning_rate': 0.02,\n",
    "              'learning_rate': 0.03,\n",
    "              'reg_lambda': 7.960622217848342e-07, \n",
    "              'subsample': 0.7422597612762745,\n",
    "              # 'bagging_temperature': 0.2,\n",
    "              'max_depth': 10, \n",
    "              'early_stopping_rounds': 500,\n",
    "              'n_estimators': 10000,\n",
    "              'cat_features': [],\n",
    "              'loss_function': 'MAE',\n",
    "              'min_child_samples': 100,\n",
    "              # 'task_type': 'GPU',\n",
    "              # 'devices': '0',\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2522445\ttest: 0.2522445\ttest1: 0.2522014\tbest: 0.2522014 (0)\ttotal: 80.7ms\tremaining: 13m 26s\n",
      "100:\tlearn: 0.0667309\ttest: 0.0667309\ttest1: 0.0684230\tbest: 0.0684230 (100)\ttotal: 6.99s\tremaining: 11m 24s\n",
      "200:\tlearn: 0.0601964\ttest: 0.0601964\ttest1: 0.0622242\tbest: 0.0622242 (200)\ttotal: 13.6s\tremaining: 11m 3s\n",
      "300:\tlearn: 0.0590556\ttest: 0.0590556\ttest1: 0.0614556\tbest: 0.0614556 (300)\ttotal: 20.5s\tremaining: 10m 59s\n",
      "400:\tlearn: 0.0583226\ttest: 0.0583226\ttest1: 0.0610615\tbest: 0.0610615 (400)\ttotal: 27.4s\tremaining: 10m 56s\n",
      "500:\tlearn: 0.0577011\ttest: 0.0577011\ttest1: 0.0607874\tbest: 0.0607874 (500)\ttotal: 34.2s\tremaining: 10m 49s\n",
      "600:\tlearn: 0.0571735\ttest: 0.0571735\ttest1: 0.0606203\tbest: 0.0606203 (600)\ttotal: 41.2s\tremaining: 10m 44s\n",
      "700:\tlearn: 0.0567438\ttest: 0.0567438\ttest1: 0.0605238\tbest: 0.0605238 (700)\ttotal: 48.1s\tremaining: 10m 37s\n",
      "800:\tlearn: 0.0563123\ttest: 0.0563123\ttest1: 0.0604505\tbest: 0.0604505 (800)\ttotal: 55.1s\tremaining: 10m 32s\n",
      "900:\tlearn: 0.0558635\ttest: 0.0558635\ttest1: 0.0604040\tbest: 0.0604029 (898)\ttotal: 1m 2s\tremaining: 10m 26s\n",
      "1000:\tlearn: 0.0554715\ttest: 0.0554715\ttest1: 0.0603776\tbest: 0.0603776 (1000)\ttotal: 1m 8s\tremaining: 10m 19s\n",
      "1100:\tlearn: 0.0551222\ttest: 0.0551222\ttest1: 0.0603547\tbest: 0.0603540 (1091)\ttotal: 1m 15s\tremaining: 10m 13s\n",
      "1200:\tlearn: 0.0546946\ttest: 0.0546946\ttest1: 0.0603422\tbest: 0.0603345 (1188)\ttotal: 1m 22s\tremaining: 10m 7s\n",
      "1300:\tlearn: 0.0542866\ttest: 0.0542866\ttest1: 0.0603290\tbest: 0.0603258 (1296)\ttotal: 1m 29s\tremaining: 10m\n",
      "1400:\tlearn: 0.0539004\ttest: 0.0539004\ttest1: 0.0603238\tbest: 0.0603232 (1361)\ttotal: 1m 36s\tremaining: 9m 53s\n",
      "1500:\tlearn: 0.0534726\ttest: 0.0534726\ttest1: 0.0603444\tbest: 0.0603199 (1414)\ttotal: 1m 43s\tremaining: 9m 46s\n",
      "1600:\tlearn: 0.0530863\ttest: 0.0530863\ttest1: 0.0603861\tbest: 0.0603199 (1414)\ttotal: 1m 50s\tremaining: 9m 39s\n",
      "1700:\tlearn: 0.0527245\ttest: 0.0527245\ttest1: 0.0604125\tbest: 0.0603199 (1414)\ttotal: 1m 57s\tremaining: 9m 32s\n",
      "1800:\tlearn: 0.0524048\ttest: 0.0524048\ttest1: 0.0604256\tbest: 0.0603199 (1414)\ttotal: 2m 4s\tremaining: 9m 25s\n",
      "1900:\tlearn: 0.0521252\ttest: 0.0521252\ttest1: 0.0604576\tbest: 0.0603199 (1414)\ttotal: 2m 10s\tremaining: 9m 17s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.06031987481\n",
      "bestIteration = 1414\n",
      "\n",
      "Shrink model to first 1415 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/05/22 19:42:16] 147506464.py:7 in <module>\n",
      "                    calc_metric({'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values, 'pred': dvalid.cb_pred.values}): 0.9155755035269483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9155755035269483"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbt_model = CatBoostRegressor(**cbt_params)\n",
    "cbt_model.fit(X_train, y_train,\n",
    "      eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "              verbose=100,\n",
    "              )  \n",
    "dvalid['cb_pred'] = cbt_model.predict(dvalid[cols])\n",
    "ic(calc_metric({'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values, 'pred': dvalid.cb_pred.values}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "importance=%{x}<br>feat_name=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "h",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          1.161964455954475,
          1.405848480356758,
          1.551081588051987,
          1.6794242108202613,
          1.6992905370470397,
          1.7604183161005786,
          1.8776819804585734,
          2.1830753687915823,
          2.2185813802924126,
          2.614084642232465,
          2.6916305917878764,
          3.261491270398657,
          3.3229678073852367,
          3.4881117646827837,
          3.764272466950143,
          4.1334207985874825,
          4.524757316691922,
          4.833289105890265,
          7.205445928923272,
          13.04469146460591
         ],
         "xaxis": "x",
         "y": [
          "c_top_prob_3",
          "c_cls2_rank_pred",
          "c_cls2_pred",
          "c_abs_cls_cls2_diff",
          "p_top_pred_2",
          "p_cls_diff",
          "p2_pred",
          "c_top_pred_2",
          "p2_top_pred_1",
          "c_reg_rank_pred",
          "p_abs_cls_diff",
          "c_rank_pred",
          "c_top_pred_1",
          "p2_cls_pred",
          "c_cls_pred",
          "p_pred",
          "c_cls_rank_pred",
          "c_pred",
          "c_reg_pred",
          "p_cls_pred"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "importance"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "feat_name"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"32f52570-e584-44b4-9ebe-1f0be426a319\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"32f52570-e584-44b4-9ebe-1f0be426a319\")) {                    Plotly.newPlot(                        \"32f52570-e584-44b4-9ebe-1f0be426a319\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"importance=%{x}<br>feat_name=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"h\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[1.161964455954475,1.405848480356758,1.551081588051987,1.6794242108202613,1.6992905370470397,1.7604183161005786,1.8776819804585734,2.1830753687915823,2.2185813802924126,2.614084642232465,2.6916305917878764,3.261491270398657,3.3229678073852367,3.4881117646827837,3.764272466950143,4.1334207985874825,4.524757316691922,4.833289105890265,7.205445928923272,13.04469146460591],\"xaxis\":\"x\",\"y\":[\"c_top_prob_3\",\"c_cls2_rank_pred\",\"c_cls2_pred\",\"c_abs_cls_cls2_diff\",\"p_top_pred_2\",\"p_cls_diff\",\"p2_pred\",\"c_top_pred_2\",\"p2_top_pred_1\",\"c_reg_rank_pred\",\"p_abs_cls_diff\",\"c_rank_pred\",\"c_top_pred_1\",\"p2_cls_pred\",\"c_cls_pred\",\"p_pred\",\"c_cls_rank_pred\",\"c_pred\",\"c_reg_pred\",\"p_cls_pred\"],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"importance\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"feat_name\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('32f52570-e584-44b4-9ebe-1f0be426a319');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gezi.plot.feature_importance(cbt_model, topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = gezi.plot.feature_importance_df(cbt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_name</th>\n",
       "      <th>importanace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p_cls_pred</td>\n",
       "      <td>13.0447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c_reg_pred</td>\n",
       "      <td>7.2054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c_pred</td>\n",
       "      <td>4.8333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c_cls_rank_pred</td>\n",
       "      <td>4.5248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p_pred</td>\n",
       "      <td>4.1334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feat_name  importanace\n",
       "0       p_cls_pred      13.0447\n",
       "1       c_reg_pred       7.2054\n",
       "2           c_pred       4.8333\n",
       "3  c_cls_rank_pred       4.5248\n",
       "4           p_pred       4.1334"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_name</th>\n",
       "      <th>importanace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c_cls_pred</td>\n",
       "      <td>3.7643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feat_name  importanace\n",
       "5  c_cls_pred       3.7643"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[f.feat_name=='c_cls_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_name</th>\n",
       "      <th>importanace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c_reg_pred</td>\n",
       "      <td>7.2054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feat_name  importanace\n",
       "1  c_reg_pred       7.2054"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[f.feat_name=='c_reg_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_name</th>\n",
       "      <th>importanace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [feat_name, importanace]\n",
       "Index: []"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[f.feat_name=='c_pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_name</th>\n",
       "      <th>importanace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [feat_name, importanace]\n",
       "Index: []"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[f.feat_name=='c_max_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32031\n",
      "[LightGBM] [Info] Number of data points in the train set: 342411, number of used features: 129\n",
      "[LightGBM] [Info] Start training from score 0.455056\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.0591138\tvalid_1's l1: 0.0606629\n",
      "[1000]\ttraining's l1: 0.05834\tvalid_1's l1: 0.0601804\n",
      "[1500]\ttraining's l1: 0.0578747\tvalid_1's l1: 0.0599995\n",
      "[2000]\ttraining's l1: 0.057544\tvalid_1's l1: 0.0599034\n",
      "[2500]\ttraining's l1: 0.0572907\tvalid_1's l1: 0.0598324\n",
      "[3000]\ttraining's l1: 0.057037\tvalid_1's l1: 0.0597697\n",
      "[3500]\ttraining's l1: 0.0568802\tvalid_1's l1: 0.0597449\n",
      "[4000]\ttraining's l1: 0.0567262\tvalid_1's l1: 0.0597228\n",
      "[4500]\ttraining's l1: 0.0565447\tvalid_1's l1: 0.0596965\n",
      "[5000]\ttraining's l1: 0.0563927\tvalid_1's l1: 0.0596735\n",
      "[5500]\ttraining's l1: 0.0562475\tvalid_1's l1: 0.0596624\n",
      "[6000]\ttraining's l1: 0.0561002\tvalid_1's l1: 0.0596453\n",
      "[6500]\ttraining's l1: 0.0559791\tvalid_1's l1: 0.0596328\n",
      "Early stopping, best iteration is:\n",
      "[6710]\ttraining's l1: 0.0559202\tvalid_1's l1: 0.0596263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9162293621948551"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "params = {\n",
    "          'boosting': 'gbdt',\n",
    "          'objective': 'regression_l1',\n",
    "          'metric': {'l1'},\n",
    "          'num_leaves': 32,\n",
    "          # 'num_leaves': 16,\n",
    "          'min_data_in_leaf': 300,\n",
    "          # 'min_data_in_leaf': 500,\n",
    "          # 'max_depth': 5,\n",
    "          'learning_rate': 0.03,\n",
    "          # \"feature_fraction\": 0.8,\n",
    "          # \"bagging_fraction\": 0.75,\n",
    "          # \"feature_fraction\": 0.9,\n",
    "          # \"bagging_fraction\": 0.8,\n",
    "          'feature_fraction': 0.7,\n",
    "          'bagging_fraction': 0.7,\n",
    "          'min_data_in_bin':100,\n",
    "          \"lambda_l1\": 1e-7,\n",
    "          'lambda_l2': 1e-7,\n",
    "          \"random_state\": 1024,\n",
    "          \"num_threads\": 12,\n",
    "          }\n",
    "\n",
    "d_train = lgb.Dataset(X_train, y_train)\n",
    "d_valid = lgb.Dataset(X_valid, y_valid, reference=d_train)\n",
    "\n",
    "lgb_model = lgb.train(params,\n",
    "                d_train,\n",
    "                10000,\n",
    "                valid_sets=[d_train, d_valid],\n",
    "                verbose_eval=500,\n",
    "                early_stopping_rounds=100)\n",
    "dvalid['lgb_pred'] = lgb_model.predict(dvalid[cols])\n",
    "calc_metric({'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values, 'pred': dvalid.lgb_pred.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "importance=%{x}<br>feat_name=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "h",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          2349,
          2383,
          2399,
          2431,
          2480,
          2484,
          2528,
          2563,
          2606,
          2629,
          2678,
          2690,
          2720,
          2784,
          2899,
          2909,
          2963,
          3670,
          3795,
          4141
         ],
         "xaxis": "x",
         "y": [
          "pc_cls2_diff",
          "c_cls_cls2_diff",
          "abs_pc_cls2_diff",
          "p_top_prob_1",
          "pc_reg_diff",
          "c_top_prob_3",
          "n_words",
          "c_cls2_reg_diff",
          "p_top_pred_1",
          "p_pred",
          "c_abs_cls2_reg_diff",
          "p2_cls_pred",
          "code_ratio",
          "p_top_prob_0",
          "c_top_prob_2",
          "p_abs_cls_diff",
          "p_cls_diff",
          "c_top_prob_1",
          "c_abs_cls_cls2_diff",
          "p_cls_pred"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "importance"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "feat_name"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"cbce024b-ca47-4ca5-b5f6-75bf4dbcd5ac\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"cbce024b-ca47-4ca5-b5f6-75bf4dbcd5ac\")) {                    Plotly.newPlot(                        \"cbce024b-ca47-4ca5-b5f6-75bf4dbcd5ac\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"importance=%{x}<br>feat_name=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"h\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[2349,2383,2399,2431,2480,2484,2528,2563,2606,2629,2678,2690,2720,2784,2899,2909,2963,3670,3795,4141],\"xaxis\":\"x\",\"y\":[\"pc_cls2_diff\",\"c_cls_cls2_diff\",\"abs_pc_cls2_diff\",\"p_top_prob_1\",\"pc_reg_diff\",\"c_top_prob_3\",\"n_words\",\"c_cls2_reg_diff\",\"p_top_pred_1\",\"p_pred\",\"c_abs_cls2_reg_diff\",\"p2_cls_pred\",\"code_ratio\",\"p_top_prob_0\",\"c_top_prob_2\",\"p_abs_cls_diff\",\"p_cls_diff\",\"c_top_prob_1\",\"c_abs_cls_cls2_diff\",\"p_cls_pred\"],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"importance\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"feat_name\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('cbce024b-ca47-4ca5-b5f6-75bf4dbcd5ac');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gezi.plot.feature_importance(lgb_model, topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                p_cls_pred\n",
       "1                c_reg_pred\n",
       "2                    c_pred\n",
       "3           c_cls_rank_pred\n",
       "4                    p_pred\n",
       "5                c_cls_pred\n",
       "6               p2_cls_pred\n",
       "7              c_top_pred_1\n",
       "8               c_rank_pred\n",
       "9            p_abs_cls_diff\n",
       "10          c_reg_rank_pred\n",
       "11            p2_top_pred_1\n",
       "12             c_top_pred_2\n",
       "13                  p2_pred\n",
       "14               p_cls_diff\n",
       "15             p_top_pred_2\n",
       "16      c_abs_cls_cls2_diff\n",
       "17              c_cls2_pred\n",
       "18         c_cls2_rank_pred\n",
       "19             c_top_prob_3\n",
       "20           c_cls_reg_diff\n",
       "21             c_top_pred_3\n",
       "22              p_top_sim_5\n",
       "23          abs_pc_reg_diff\n",
       "24         p2c_cls_reg_diff\n",
       "25             p_top_pred_1\n",
       "26              p2_cls_diff\n",
       "27          abs_pc_cls_diff\n",
       "28             p_top_prob_0\n",
       "29          p2_abs_cls_diff\n",
       "30            p2_top_pred_2\n",
       "31         abs_p2c_cls_diff\n",
       "32       c_abs_cls_reg_diff\n",
       "33             p_top_pred_6\n",
       "34          pc_cls_reg_diff\n",
       "35         abs_p2c_reg_diff\n",
       "36         abs_pc_cls2_diff\n",
       "37      c_abs_cls2_reg_diff\n",
       "38          pc_cls_cls_diff\n",
       "39               code_ratio\n",
       "40              pc_cls_diff\n",
       "41             p_top_prob_1\n",
       "42      abs_pc_cls_cls_diff\n",
       "43          c_cls_cls2_diff\n",
       "44              n_code_cell\n",
       "45              pc_reg_diff\n",
       "46             p_top_prob_2\n",
       "47             p2_rank_pred\n",
       "48             pc_cls2_diff\n",
       "49               p_var_prob\n",
       "50          p_cls_rank_pred\n",
       "51             p_top_prob_3\n",
       "52          abs_ps_cls_diff\n",
       "53      abs_pc_cls_reg_diff\n",
       "54              abs_ps_diff\n",
       "55            p2_top_prob_4\n",
       "56         p2c_cls_cls_diff\n",
       "57             p_top_pred_7\n",
       "58            p2_top_pred_9\n",
       "59             p_top_prob_8\n",
       "60                p_min_sim\n",
       "61          c_cls2_reg_diff\n",
       "62         p2_cls_rank_pred\n",
       "63               c_var_prob\n",
       "64             p2c_reg_diff\n",
       "65             c_top_prob_2\n",
       "66            p2_top_prob_2\n",
       "67              p2_var_prob\n",
       "68              p_rank_pred\n",
       "69            p2c_cls2_diff\n",
       "70            p2_top_prob_1\n",
       "71                   n_cell\n",
       "72             p2c_cls_diff\n",
       "73        abs_p2c_cls2_diff\n",
       "74             p_top_prob_7\n",
       "75            p2_top_prob_0\n",
       "76     abs_p2c_cls_reg_diff\n",
       "77                p_var_sim\n",
       "78             c_top_prob_1\n",
       "79              ps_cls_diff\n",
       "80            p2_top_prob_5\n",
       "81               p2_var_sim\n",
       "82              p_top_sim_4\n",
       "83              p2_min_prob\n",
       "84             p_top_prob_4\n",
       "85            p2_top_prob_3\n",
       "86              p_top_sim_7\n",
       "87             p2_top_sim_0\n",
       "88     abs_p2c_cls_cls_diff\n",
       "89             p_top_pred_5\n",
       "90             c_top_prob_0\n",
       "91             p_top_pred_8\n",
       "92              p_top_sim_1\n",
       "93            p2_top_prob_6\n",
       "94              p_top_sim_3\n",
       "95            p2_top_pred_4\n",
       "96             p_top_prob_6\n",
       "97               p2_min_sim\n",
       "98             p_top_pred_9\n",
       "99               p_min_prob\n",
       "100            p_top_pred_4\n",
       "101           p2_top_prob_7\n",
       "102                 ps_diff\n",
       "103                 n_words\n",
       "104            p2_top_sim_1\n",
       "105            p2_top_sim_2\n",
       "106            p_top_prob_5\n",
       "107           p2_top_prob_9\n",
       "108             p_top_sim_8\n",
       "109            p_top_prob_9\n",
       "110            p2_top_sim_6\n",
       "111           p2_top_pred_3\n",
       "112             p_top_sim_6\n",
       "113           p2_top_pred_5\n",
       "114            p2_top_sim_9\n",
       "115           p2_top_prob_8\n",
       "116           p2_top_pred_7\n",
       "117             p_top_sim_9\n",
       "118            p_top_pred_3\n",
       "119              c_min_prob\n",
       "120             p_top_sim_0\n",
       "121            p2_top_sim_5\n",
       "122             p_top_sim_2\n",
       "123           p2_top_pred_8\n",
       "124            p2_top_sim_4\n",
       "125            p2_top_sim_7\n",
       "126           p2_top_pred_6\n",
       "127            p2_top_sim_8\n",
       "128            p2_top_sim_3\n",
       "Name: feat_name, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.feat_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee38d2889d141049d4ad2da2c484b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2522445\ttest: 0.2522445\ttest1: 0.2522014\tbest: 0.2522014 (0)\ttotal: 67.4ms\tremaining: 11m 14s\n",
      "500:\tlearn: 0.0577011\ttest: 0.0577011\ttest1: 0.0607874\tbest: 0.0607874 (500)\ttotal: 34s\tremaining: 10m 45s\n",
      "1000:\tlearn: 0.0554715\ttest: 0.0554715\ttest1: 0.0603776\tbest: 0.0603776 (1000)\ttotal: 1m 8s\tremaining: 10m 13s\n",
      "1500:\tlearn: 0.0534726\ttest: 0.0534726\ttest1: 0.0603444\tbest: 0.0603199 (1414)\ttotal: 1m 42s\tremaining: 9m 40s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.06031987481\n",
      "bestIteration = 1414\n",
      "\n",
      "Shrink model to first 1415 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/05/22 19:47:01] 1620804012.py:20 in <module>\n",
      "                    cbt_score: 0.9155755035269483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32031\n",
      "[LightGBM] [Info] Number of data points in the train set: 342411, number of used features: 129\n",
      "[LightGBM] [Info] Start training from score 0.455056\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.0591138\tvalid_1's l1: 0.0606629\n",
      "[1000]\ttraining's l1: 0.05834\tvalid_1's l1: 0.0601804\n",
      "[1500]\ttraining's l1: 0.0578747\tvalid_1's l1: 0.0599995\n",
      "[2000]\ttraining's l1: 0.057544\tvalid_1's l1: 0.0599034\n",
      "[2500]\ttraining's l1: 0.0572907\tvalid_1's l1: 0.0598324\n",
      "[3000]\ttraining's l1: 0.057037\tvalid_1's l1: 0.0597697\n",
      "[3500]\ttraining's l1: 0.0568802\tvalid_1's l1: 0.0597449\n",
      "[4000]\ttraining's l1: 0.0567262\tvalid_1's l1: 0.0597228\n",
      "[4500]\ttraining's l1: 0.0565447\tvalid_1's l1: 0.0596965\n",
      "[5000]\ttraining's l1: 0.0563927\tvalid_1's l1: 0.0596735\n",
      "[5500]\ttraining's l1: 0.0562475\tvalid_1's l1: 0.0596624\n",
      "[6000]\ttraining's l1: 0.0561002\tvalid_1's l1: 0.0596453\n",
      "[6500]\ttraining's l1: 0.0559791\tvalid_1's l1: 0.0596328\n",
      "Early stopping, best iteration is:\n",
      "[6710]\ttraining's l1: 0.0559202\tvalid_1's l1: 0.0596263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/05/22 19:48:57] 1620804012.py:34 in <module>\n",
      "                    lgb_score: 0.9162293621948551\n",
      "[08/05/22 19:48:59] 1620804012.py:36 in <module>\n",
      "                    score: 0.9164384885481429\n",
      "[08/05/22 19:48:59] 1620804012.py:41 in <module>\n",
      "                    fold: 0\n",
      "                    np.asarray(cbt_scores).mean(): 0.9155755035269483\n",
      "                    np.asarray(lgb_scores).mean(): 0.9162293621948551\n",
      "                    np.asarray(scores).mean(): 0.9164384885481429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2523153\ttest: 0.2523153\ttest1: 0.2522354\tbest: 0.2522354 (0)\ttotal: 69.9ms\tremaining: 11m 38s\n",
      "500:\tlearn: 0.0581060\ttest: 0.0581060\ttest1: 0.0590075\tbest: 0.0590075 (500)\ttotal: 34s\tremaining: 10m 44s\n",
      "1000:\tlearn: 0.0559121\ttest: 0.0559121\ttest1: 0.0585861\tbest: 0.0585861 (1000)\ttotal: 1m 8s\tremaining: 10m 15s\n",
      "1500:\tlearn: 0.0541924\ttest: 0.0541924\ttest1: 0.0585527\tbest: 0.0585365 (1413)\ttotal: 1m 42s\tremaining: 9m 42s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.05853652183\n",
      "bestIteration = 1413\n",
      "\n",
      "Shrink model to first 1414 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/05/22 19:51:16] 1620804012.py:20 in <module>\n",
      "                    cbt_score: 0.918164677219967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32034\n",
      "[LightGBM] [Info] Number of data points in the train set: 339696, number of used features: 129\n",
      "[LightGBM] [Info] Start training from score 0.455882\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.0596959\tvalid_1's l1: 0.0592126\n",
      "[1000]\ttraining's l1: 0.0587896\tvalid_1's l1: 0.0586443\n",
      "[1500]\ttraining's l1: 0.0583272\tvalid_1's l1: 0.0584752\n",
      "[2000]\ttraining's l1: 0.0580142\tvalid_1's l1: 0.0583634\n",
      "[2500]\ttraining's l1: 0.0577207\tvalid_1's l1: 0.0582825\n",
      "[3000]\ttraining's l1: 0.0574647\tvalid_1's l1: 0.0582199\n",
      "[3500]\ttraining's l1: 0.0572636\tvalid_1's l1: 0.0581793\n",
      "[4000]\ttraining's l1: 0.0570501\tvalid_1's l1: 0.0581374\n",
      "[4500]\ttraining's l1: 0.0568628\tvalid_1's l1: 0.0581078\n",
      "[5000]\ttraining's l1: 0.0566771\tvalid_1's l1: 0.05808\n",
      "[5500]\ttraining's l1: 0.0564246\tvalid_1's l1: 0.0580491\n",
      "[6000]\ttraining's l1: 0.0561837\tvalid_1's l1: 0.0580303\n",
      "[6500]\ttraining's l1: 0.0559929\tvalid_1's l1: 0.0580058\n",
      "[7000]\ttraining's l1: 0.0558749\tvalid_1's l1: 0.0579953\n",
      "[7500]\ttraining's l1: 0.0557454\tvalid_1's l1: 0.0579849\n",
      "Early stopping, best iteration is:\n",
      "[7502]\ttraining's l1: 0.0557446\tvalid_1's l1: 0.0579845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/05/22 19:53:23] 1620804012.py:34 in <module>\n",
      "                    lgb_score: 0.918775758892595\n",
      "[08/05/22 19:53:25] 1620804012.py:36 in <module>\n",
      "                    score: 0.9190061286592975\n",
      "[08/05/22 19:53:25] 1620804012.py:41 in <module>\n",
      "                    fold: 1\n",
      "                    np.asarray(cbt_scores).mean(): 0.9168700903734577\n",
      "                    np.asarray(lgb_scores).mean(): 0.917502560543725\n",
      "                    np.asarray(scores).mean(): 0.9177223086037203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2522106\ttest: 0.2522106\ttest1: 0.2525665\tbest: 0.2525665 (0)\ttotal: 71.7ms\tremaining: 11m 56s\n",
      "500:\tlearn: 0.0578865\ttest: 0.0578865\ttest1: 0.0600031\tbest: 0.0600031 (500)\ttotal: 34.1s\tremaining: 10m 46s\n",
      "1000:\tlearn: 0.0558225\ttest: 0.0558225\ttest1: 0.0595619\tbest: 0.0595559 (997)\ttotal: 1m 8s\tremaining: 10m 16s\n",
      "1500:\tlearn: 0.0536642\ttest: 0.0536642\ttest1: 0.0595540\tbest: 0.0595365 (1202)\ttotal: 1m 42s\tremaining: 9m 42s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.05953653233\n",
      "bestIteration = 1202\n",
      "\n",
      "Shrink model to first 1203 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/05/22 19:55:28] 1620804012.py:20 in <module>\n",
      "                    cbt_score: 0.9176787803225824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32030\n",
      "[LightGBM] [Info] Number of data points in the train set: 337766, number of used features: 129\n",
      "[LightGBM] [Info] Start training from score 0.456522\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.059224\tvalid_1's l1: 0.0600125\n",
      "[1000]\ttraining's l1: 0.0584086\tvalid_1's l1: 0.0594875\n",
      "[1500]\ttraining's l1: 0.0579527\tvalid_1's l1: 0.0592792\n",
      "[2000]\ttraining's l1: 0.0576318\tvalid_1's l1: 0.0591665\n",
      "[2500]\ttraining's l1: 0.0573745\tvalid_1's l1: 0.0591002\n",
      "[3000]\ttraining's l1: 0.057137\tvalid_1's l1: 0.0590541\n",
      "[3500]\ttraining's l1: 0.0569392\tvalid_1's l1: 0.0590169\n",
      "[4000]\ttraining's l1: 0.056751\tvalid_1's l1: 0.0589864\n",
      "[4500]\ttraining's l1: 0.0565953\tvalid_1's l1: 0.0589663\n",
      "[5000]\ttraining's l1: 0.0564375\tvalid_1's l1: 0.0589518\n",
      "[5500]\ttraining's l1: 0.0562571\tvalid_1's l1: 0.0589215\n",
      "[6000]\ttraining's l1: 0.0561118\tvalid_1's l1: 0.0589058\n",
      "[6500]\ttraining's l1: 0.0558024\tvalid_1's l1: 0.0588732\n",
      "Early stopping, best iteration is:\n",
      "[6745]\ttraining's l1: 0.055644\tvalid_1's l1: 0.058863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/05/22 19:57:25] 1620804012.py:34 in <module>\n",
      "                    lgb_score: 0.9181538075942197\n",
      "[08/05/22 19:57:27] 1620804012.py:36 in <module>\n",
      "                    score: 0.9184372056673694\n",
      "[08/05/22 19:57:27] 1620804012.py:41 in <module>\n",
      "                    fold: 2\n",
      "                    np.asarray(cbt_scores).mean(): 0.9171396536898326\n",
      "                    np.asarray(lgb_scores).mean(): 0.91771964289389\n",
      "                    np.asarray(scores).mean(): 0.9179606076249366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2522127\ttest: 0.2522127\ttest1: 0.2519661\tbest: 0.2519661 (0)\ttotal: 73.5ms\tremaining: 12m 14s\n",
      "500:\tlearn: 0.0584470\ttest: 0.0584470\ttest1: 0.0580331\tbest: 0.0580331 (500)\ttotal: 33.5s\tremaining: 10m 35s\n",
      "1000:\tlearn: 0.0563891\ttest: 0.0563891\ttest1: 0.0576132\tbest: 0.0576084 (975)\ttotal: 1m 7s\tremaining: 10m 6s\n",
      "1500:\tlearn: 0.0545016\ttest: 0.0545016\ttest1: 0.0575415\tbest: 0.0575369 (1455)\ttotal: 1m 41s\tremaining: 9m 33s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.05753693752\n",
      "bestIteration = 1455\n",
      "\n",
      "Shrink model to first 1456 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/05/22 19:59:48] 1620804012.py:20 in <module>\n",
      "                    cbt_score: 0.9206134100134418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062778 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32030\n",
      "[LightGBM] [Info] Number of data points in the train set: 337964, number of used features: 129\n",
      "[LightGBM] [Info] Start training from score 0.455939\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.059827\tvalid_1's l1: 0.0581804\n",
      "[1000]\ttraining's l1: 0.0589226\tvalid_1's l1: 0.0576624\n",
      "[1500]\ttraining's l1: 0.0584723\tvalid_1's l1: 0.0574806\n",
      "[2000]\ttraining's l1: 0.0581169\tvalid_1's l1: 0.0573611\n",
      "[2500]\ttraining's l1: 0.0578808\tvalid_1's l1: 0.0572969\n",
      "[3000]\ttraining's l1: 0.0576255\tvalid_1's l1: 0.0572381\n",
      "[3500]\ttraining's l1: 0.0574193\tvalid_1's l1: 0.0572038\n",
      "[4000]\ttraining's l1: 0.0572265\tvalid_1's l1: 0.0571797\n",
      "[4500]\ttraining's l1: 0.057025\tvalid_1's l1: 0.0571488\n",
      "[5000]\ttraining's l1: 0.056856\tvalid_1's l1: 0.0571254\n",
      "[5500]\ttraining's l1: 0.056725\tvalid_1's l1: 0.0571084\n",
      "[6000]\ttraining's l1: 0.0563867\tvalid_1's l1: 0.0570766\n",
      "[6500]\ttraining's l1: 0.0561801\tvalid_1's l1: 0.0570528\n",
      "[7000]\ttraining's l1: 0.0558005\tvalid_1's l1: 0.05702\n",
      "Early stopping, best iteration is:\n",
      "[7266]\ttraining's l1: 0.0557511\tvalid_1's l1: 0.0570155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/05/22 20:01:47] 1620804012.py:34 in <module>\n",
      "                    lgb_score: 0.9210017857764415\n",
      "[08/05/22 20:01:49] 1620804012.py:36 in <module>\n",
      "                    score: 0.921358536104917\n",
      "[08/05/22 20:01:49] 1620804012.py:41 in <module>\n",
      "                    fold: 3\n",
      "                    np.asarray(cbt_scores).mean(): 0.9180080927707349\n",
      "                    np.asarray(lgb_scores).mean(): 0.9185401786145279\n",
      "                    np.asarray(scores).mean(): 0.9188100897449317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2521270\ttest: 0.2521270\ttest1: 0.2522483\tbest: 0.2522483 (0)\ttotal: 70.5ms\tremaining: 11m 45s\n",
      "500:\tlearn: 0.0575577\ttest: 0.0575577\ttest1: 0.0614648\tbest: 0.0614648 (500)\ttotal: 34.4s\tremaining: 10m 52s\n",
      "1000:\tlearn: 0.0552563\ttest: 0.0552563\ttest1: 0.0610869\tbest: 0.0610869 (1000)\ttotal: 1m 8s\tremaining: 10m 19s\n",
      "1500:\tlearn: 0.0536794\ttest: 0.0536794\ttest1: 0.0610580\tbest: 0.0610522 (1370)\ttotal: 1m 43s\tremaining: 9m 45s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.06105220471\n",
      "bestIteration = 1370\n",
      "\n",
      "Shrink model to first 1371 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/05/22 20:04:08] 1620804012.py:20 in <module>\n",
      "                    cbt_score: 0.9091187713116997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32032\n",
      "[LightGBM] [Info] Number of data points in the train set: 341935, number of used features: 129\n",
      "[LightGBM] [Info] Start training from score 0.456522\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[500]\ttraining's l1: 0.0588562\tvalid_1's l1: 0.0614861\n",
      "[1000]\ttraining's l1: 0.0581187\tvalid_1's l1: 0.0610003\n",
      "[1500]\ttraining's l1: 0.0576907\tvalid_1's l1: 0.0608042\n",
      "[2000]\ttraining's l1: 0.0573796\tvalid_1's l1: 0.060701\n",
      "[2500]\ttraining's l1: 0.0570748\tvalid_1's l1: 0.0606048\n",
      "[3000]\ttraining's l1: 0.0567945\tvalid_1's l1: 0.0605563\n",
      "[3500]\ttraining's l1: 0.0566017\tvalid_1's l1: 0.0605169\n",
      "[4000]\ttraining's l1: 0.0564326\tvalid_1's l1: 0.060483\n",
      "[4500]\ttraining's l1: 0.056255\tvalid_1's l1: 0.0604473\n",
      "[5000]\ttraining's l1: 0.0560622\tvalid_1's l1: 0.0604214\n",
      "[5500]\ttraining's l1: 0.0559404\tvalid_1's l1: 0.0604058\n",
      "[6000]\ttraining's l1: 0.0558124\tvalid_1's l1: 0.0603904\n",
      "[6500]\ttraining's l1: 0.0556929\tvalid_1's l1: 0.0603793\n",
      "Early stopping, best iteration is:\n",
      "[6566]\ttraining's l1: 0.0556753\tvalid_1's l1: 0.0603773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/05/22 20:06:02] 1620804012.py:34 in <module>\n",
      "                    lgb_score: 0.9098462749002174\n",
      "[08/05/22 20:06:04] 1620804012.py:36 in <module>\n",
      "                    score: 0.910049283878711\n",
      "[08/05/22 20:06:04] 1620804012.py:41 in <module>\n",
      "                    fold: 4\n",
      "                    np.asarray(cbt_scores).mean(): 0.9162302284789279\n",
      "                    np.asarray(lgb_scores).mean(): 0.9168013978716658\n",
      "                    np.asarray(scores).mean(): 0.9170579285716876\n"
     ]
    }
   ],
   "source": [
    "FOLDS = 5\n",
    "cbt_scores, lgb_scores = [], []\n",
    "scores = []\n",
    "gezi.try_mkdir('../working/trees')\n",
    "for fold in tqdm(range(FOLDS)):\n",
    "  dvalid = df[df.fold==fold]\n",
    "  dtrain = df[df.fold!=fold]\n",
    "  X_train = dtrain[cols]\n",
    "  y_train = dtrain[LABEL_COL]\n",
    "  X_valid = dvalid[cols]\n",
    "  y_valid = dvalid[LABEL_COL]\n",
    "  cbt_model = CatBoostRegressor(**cbt_params)\n",
    "  cbt_model.fit(X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                verbose=500,\n",
    "                )  \n",
    "  cbt_model.save_model(f'../working/trees/{fold}.cbt')\n",
    "  dvalid['cb_pred'] = cbt_model.predict(dvalid[cols])\n",
    "  cbt_score = calc_metric({'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values, 'pred': dvalid.cb_pred.values})\n",
    "  ic(cbt_score)\n",
    "  \n",
    "  d_train = lgb.Dataset(X_train, y_train)\n",
    "  d_valid = lgb.Dataset(X_valid, y_valid, reference=d_train)\n",
    "  lgb_model = lgb.train(params,\n",
    "                  d_train,\n",
    "                  10000,\n",
    "                  valid_sets=[d_train, d_valid],\n",
    "                  verbose_eval=500,\n",
    "                  early_stopping_rounds=100)\n",
    "  lgb_model.save_model(f'../working/trees/{fold}.lgb')\n",
    "  dvalid['lgb_pred'] = lgb_model.predict(dvalid[cols])\n",
    "  \n",
    "  lgb_score = calc_metric({'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values, 'pred': dvalid.lgb_pred.values})\n",
    "  ic(lgb_score)\n",
    "  score = calc_metric({'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values, 'pred': (dvalid.cb_pred.values * 0.3 + dvalid.lgb_pred.values * 0.7)})\n",
    "  ic(score)\n",
    "  \n",
    "  cbt_scores.append(cbt_score)\n",
    "  lgb_scores.append(lgb_score)\n",
    "  scores.append(score)\n",
    "  ic(fold, \n",
    "     np.asarray(cbt_scores).mean(), \n",
    "     np.asarray(lgb_scores).mean(),\n",
    "     np.asarray(scores).mean(),\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.916967035320258\n",
    "# fold: 0\n",
    "#                     np.asarray(cbt_scores).mean(): 0.9162172691455124\n",
    "#                     np.asarray(lgb_scores).mean(): 0.9167637498752904\n",
    "#                     np.asarray(scores).mean(): 0.9169839267736672"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "828c32aa8796f4caf0c9fde9f523bba8dbc7385abbb3ec2757d19a79cb47766b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
