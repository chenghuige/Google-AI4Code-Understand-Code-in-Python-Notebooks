{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gezi.common import *\n",
    "sys.path.append('..')\n",
    "gezi.set_pandas()\n",
    "# gezi.set_pandas_widder()\n",
    "from src.config import *\n",
    "gezi.init_flags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = FLAGS.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139256"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.read_csv(f'{root}/train_orders.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(folder, workers=80):\n",
    "  def _create_df(fpath):\n",
    "    df = pd.read_json(fpath, dtype={'cell_type': 'category', 'source': 'str'}).reset_index().rename({\"index\":\"cell_id\"}, axis=1)\n",
    "    df[\"id\"] = fpath.rsplit(\".\", 1)[0].rsplit(\"/\", 1)[-1]\n",
    "    return df\n",
    "  dfs = gezi.prun(_create_df, glob.glob(f'{folder}/*.json'), workers)\n",
    "  df = pd.concat(dfs)\n",
    "  df['source'] = df.source.apply(lambda x: x.replace('\\n', BR))\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = 80\n",
    "train_file = f'../working/train.fea'\n",
    "if os.path.exists(train_file):\n",
    "  df = pd.read_feather(train_file)\n",
    "else:\n",
    "  df = create_df(f'../working/train.fea', workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cell_id', 'cell_type', 'source', 'id', 'n_words', 'cid', 'ancestor_id',\n",
       "       'parent_id', 'n_cell', 'n_code_cell', 'n_markdown_cell',\n",
       "       'markdown_frac', 'rank', 'code_rank', 'markdown_rank', 'rel_rank',\n",
       "       'pct_rank', 'fold', 'worker'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df[df.fold==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27590"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df0.id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23690"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df0[df0.parent_id.isnull()].id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b291ed65c89f4f15883538926ebe7f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "run:   0%|          | 0/79634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e0f6df07c141ca961710a6e7eaa25d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7fee04acf7a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/huigecheng/envs/pku/lib/python3.7/logging/__init__.py\", line 221, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <function _releaseLock at 0x7fee04acf7a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/huigecheng/envs/pku/lib/python3.7/logging/__init__.py\", line 221, in _releaseLock\n",
      "    def _releaseLock():"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535d41987841473ebd70bc7177e6be86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "run:   0%|          | 0/79633 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7fee04acf7a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/huigecheng/envs/pku/lib/python3.7/logging/__init__.py\", line 221, in _releaseLock\n",
      "    def _releaseLock():"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea839d401e75448a9ff13d215394ade9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "run:   0%|          | 0/79633 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a186013d8bff46c698349e4be015b61d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "run:   0%|          | 0/79634 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ddf273868347e5a29d6fef3a09018f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-small')\n",
    "if not 'input_ids' in df.columns:\n",
    "  if tokenizer.convert_tokens_to_ids(BR) == tokenizer.unk_token_id:\n",
    "    assert len(BR) == 1\n",
    "    tokenizer.add_tokens([BR], special_tokens=False)\n",
    "  input_ids_list = gezi.prun(lambda x: tokenizer(x).input_ids, df.source.values, 80, desc='tokenize')\n",
    "  df['input_ids'] = input_ids_list\n",
    "  df['tokens'] = gezi.prun(tokenizer.convert_ids_to_tokens, df.input_ids.values, 80, desc='convert_ids_to_tokens')\n",
    "  df.reset_index().to_feather(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1c7a5a71</td>\n",
       "      <td>code</td>\n",
       "      <td>import warningsʶwarnings.filterwarnings(\"ignore\")ʶʶimport sqlite3ʶimport pandas as pdʶimport numpy as npʶimport nltkʶimport stringʶimport matplotlib.pyplot as pltʶimport seaborn as snsʶfrom sklearn.feature_extraction.text import TfidfTransformerʶfrom sklearn.feature_extraction.text import TfidfVectorizerʶʶfrom sklearn.feature_extraction.text import CountVectorizerʶfrom sklearn.metrics import confusion_matrixʶfrom sklearn import metricsʶfrom sklearn.metrics import roc_curve, aucʶfrom nltk.ste...</td>\n",
       "      <td>a3baf6134c8506</td>\n",
       "      <td>[1, 6306, 11917, 128001, 11917, 260, 28865, 60656, 268, 555, 309, 66478, 309, 285, 128001, 128001, 6306, 120474, 508, 128001, 6306, 67927, 283, 845, 407, 128001, 6306, 36221, 11751, 283, 76767, 128001, 6306, 90668, 39501, 128001, 6306, 4022, 128001, 6306, 8358, 33918, 14434, 260, 11751, 33918, 283, 28944, 297, 128001, 6306, 2164, 6107, 283, 41339, 268, 128001, 292, 33566, 29274, 260, 51532, 616, 113492, 260, 12948, 6306, 897, 59426, 1892, 86911, 649, 128001, 292, 33566, 29274, 260, 51532, 61...</td>\n",
       "      <td>[[CLS], ▁import, ▁warnings, ʶ, ▁warnings, ., filter, warning, s, (, \", ignore, \", ), ʶ, ʶ, ▁import, ▁sqlite, 3, ʶ, ▁import, ▁pandas, ▁as, ▁p, d, ʶ, ▁import, ▁num, py, ▁as, ▁np, ʶ, ▁import, ▁nl, tk, ʶ, ▁import, ▁string, ʶ, ▁import, ▁mat, plot, lib, ., py, plot, ▁as, ▁pl, t, ʶ, ▁import, ▁sea, born, ▁as, ▁sn, s, ʶ, ▁from, ▁sk, learn, ., feature, _, extraction, ., text, ▁import, ▁T, fid, f, Transform, er, ʶ, ▁from, ▁sk, learn, ., feature, _, extraction, ., text, ▁import, ▁T, fid, f, Vector, izer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68f71f96</td>\n",
       "      <td>code</td>\n",
       "      <td># using the SQLite Table to read data.ʶcon = sqlite3.connect('../input/database.sqlite')ʶ#con = sqlite3.connect('database.sqlite') ʶʶ#filtering only positive and negative reviews i.e. ʶ# not taking into consideration those reviews with Score=3ʶfiltered_data = pd.read_sql_query(\"\"\"SELECT * FROM Reviews WHERE Score != 3 LIMIT 100000\"\"\", con) ʶʶ# Give reviews with Score&gt;3 a positive rating, and reviews with a score&lt;3 a negative rating.ʶdef partition(x):ʶ    if x &lt; 3:ʶ        return 0ʶ    return...</td>\n",
       "      <td>a3baf6134c8506</td>\n",
       "      <td>[1, 953, 478, 262, 78550, 3751, 264, 623, 514, 260, 128001, 4636, 1842, 120474, 508, 260, 30407, 555, 280, 260, 260, 320, 42177, 320, 54698, 260, 51972, 5936, 280, 285, 128001, 953, 5699, 1842, 120474, 508, 260, 30407, 555, 280, 54698, 260, 51972, 5936, 280, 285, 128001, 128001, 953, 28865, 510, 364, 1453, 263, 2330, 1937, 584, 260, 473, 260, 128001, 953, 298, 787, 352, 3937, 421, 1937, 275, 13938, 1510, 508, 128001, 16334, 616, 9832, 1842, 845, 407, 260, 8523, 616, 51972, 616, 47975, 555, 3...</td>\n",
       "      <td>[[CLS], ▁#, ▁using, ▁the, ▁SQLite, ▁Table, ▁to, ▁read, ▁data, ., ʶ, ▁con, ▁=, ▁sqlite, 3, ., connect, (, ', ., ., /, input, /, database, ., sql, ite, ', ), ʶ, ▁#, con, ▁=, ▁sqlite, 3, ., connect, (, ', database, ., sql, ite, ', ), ʶ, ʶ, ▁#, filter, ing, ▁only, ▁positive, ▁and, ▁negative, ▁reviews, ▁i, ., e, ., ʶ, ▁#, ▁not, ▁taking, ▁into, ▁consideration, ▁those, ▁reviews, ▁with, ▁Score, =, 3, ʶ, ▁filtered, _, data, ▁=, ▁p, d, ., read, _, sql, _, query, (, \", \", \", SELECT, ▁*, ▁FROM, ▁Reviews...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f0a7f5c4</td>\n",
       "      <td>code</td>\n",
       "      <td>display = pd.read_sql_query(\"\"\" SELECT UserId, ProductId, ProfileName, Time, Score, Text, COUNT(*) FROM Reviews GROUP BY UserId HAVING COUNT(*)&gt;1 \"\"\", con)ʶprint(display.shape)ʶdisplay.head()ʶ</td>\n",
       "      <td>a3baf6134c8506</td>\n",
       "      <td>[1, 1689, 1842, 845, 407, 260, 8523, 616, 51972, 616, 47975, 555, 309, 309, 309, 45786, 5675, 29935, 261, 4899, 29935, 261, 12028, 15303, 261, 2210, 261, 13938, 261, 7655, 261, 73857, 555, 1225, 285, 11371, 8939, 30686, 9506, 5675, 29935, 92773, 73857, 555, 1225, 285, 1504, 435, 307, 309, 309, 261, 4636, 285, 128001, 2118, 555, 35459, 260, 29753, 285, 128001, 1689, 260, 5563, 555, 285, 128001, 2]</td>\n",
       "      <td>[[CLS], ▁display, ▁=, ▁p, d, ., read, _, sql, _, query, (, \", \", \", ▁SELECT, ▁User, Id, ,, ▁Product, Id, ,, ▁Profile, Name, ,, ▁Time, ,, ▁Score, ,, ▁Text, ,, ▁COUNT, (, *, ), ▁FROM, ▁Reviews, ▁GROUP, ▁BY, ▁User, Id, ▁HAVING, ▁COUNT, (, *, ), &gt;, 1, ▁\", \", \", ,, ▁con, ), ʶ, ▁print, (, display, ., shape, ), ʶ, ▁display, ., head, (, ), ʶ, [SEP]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>548f02a6</td>\n",
       "      <td>code</td>\n",
       "      <td>display[display['UserId']=='AZY10LLTJ71NX']</td>\n",
       "      <td>a3baf6134c8506</td>\n",
       "      <td>[1, 1689, 2550, 35459, 2550, 280, 26359, 29935, 280, 592, 1510, 1510, 280, 558, 54368, 894, 17145, 1193, 2252, 9156, 34690, 280, 592, 2]</td>\n",
       "      <td>[[CLS], ▁display, [, display, [, ', User, Id, ', ], =, =, ', A, ZY, 10, LL, T, J, 71, NX, ', ], [SEP]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>627f1de4</td>\n",
       "      <td>code</td>\n",
       "      <td>display['COUNT(*)'].sum()</td>\n",
       "      <td>a3baf6134c8506</td>\n",
       "      <td>[1, 1689, 2550, 280, 98460, 555, 1225, 285, 280, 592, 260, 17608, 555, 285, 2]</td>\n",
       "      <td>[[CLS], ▁display, [, ', COUNT, (, *, ), ', ], ., sum, (, ), [SEP]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>80a561bf</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Reading the csv file through pandas and view the dataset.ʶʶ**Analysis**ʶ1. To protect the identity of the user and to make the anonymoused data, the team has already performed the PCA and given the component variable which need to be used for the further analysisʶ2. After looking at the data, column \"Time\" and \"Amount\" has not been scaled. Hence we will go through certain scaling algorithm which can be used to scale the data as similar as other variable.ʶ3. Class has two values as \"0\" --&gt; No...</td>\n",
       "      <td>d44bb8204d81cb</td>\n",
       "      <td>[1, 6174, 262, 91341, 1092, 390, 67927, 263, 866, 262, 12438, 260, 128001, 128001, 1124, 1225, 68263, 1225, 1225, 128001, 376, 260, 502, 1746, 262, 3044, 265, 262, 1143, 263, 264, 365, 262, 9023, 569, 514, 261, 262, 511, 303, 637, 2264, 262, 40589, 263, 744, 262, 3480, 5361, 319, 389, 264, 282, 427, 270, 262, 839, 1423, 128001, 392, 260, 643, 562, 288, 262, 514, 261, 4547, 307, 11467, 309, 263, 307, 558, 18546, 309, 303, 298, 331, 19199, 260, 7688, 301, 296, 424, 390, 991, 15810, 7416, 319, ...</td>\n",
       "      <td>[[CLS], ▁Reading, ▁the, ▁csv, ▁file, ▁through, ▁pandas, ▁and, ▁view, ▁the, ▁dataset, ., ʶ, ʶ, ▁*, *, Analysis, *, *, ʶ, ▁1, ., ▁To, ▁protect, ▁the, ▁identity, ▁of, ▁the, ▁user, ▁and, ▁to, ▁make, ▁the, ▁anonymous, ed, ▁data, ,, ▁the, ▁team, ▁has, ▁already, ▁performed, ▁the, ▁PCA, ▁and, ▁given, ▁the, ▁component, ▁variable, ▁which, ▁need, ▁to, ▁be, ▁used, ▁for, ▁the, ▁further, ▁analysis, ʶ, ▁2, ., ▁After, ▁looking, ▁at, ▁the, ▁data, ,, ▁column, ▁\", Time, \", ▁and, ▁\", A, mount, \", ▁has, ▁not, ▁b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>24b00b68</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Dealing with Imbalanced Datasetʶ**Our goal**ʶ1. To create undersample and oversampled dataʶ2. To remove detect and remove the outliersʶ3. Train on multiple algorithms for the classification ʶ</td>\n",
       "      <td>d44bb8204d81cb</td>\n",
       "      <td>[1, 953, 32979, 275, 120977, 407, 84590, 128001, 1124, 1225, 6374, 1238, 1225, 1225, 128001, 376, 260, 502, 676, 494, 26154, 263, 360, 100138, 514, 128001, 392, 260, 502, 1963, 6659, 263, 1963, 262, 58878, 128001, 404, 260, 11004, 277, 1337, 8785, 270, 262, 9209, 128001, 2]</td>\n",
       "      <td>[[CLS], ▁#, ▁Dealing, ▁with, ▁Imbalance, d, ▁Dataset, ʶ, ▁*, *, Our, ▁goal, *, *, ʶ, ▁1, ., ▁To, ▁create, ▁under, sample, ▁and, ▁over, sampled, ▁data, ʶ, ▁2, ., ▁To, ▁remove, ▁detect, ▁and, ▁remove, ▁the, ▁outliers, ʶ, ▁3, ., ▁Train, ▁on, ▁multiple, ▁algorithms, ▁for, ▁the, ▁classification, ʶ, [SEP]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>265986cf</td>\n",
       "      <td>markdown</td>\n",
       "      <td>We train different model with the above data and cross validated it. We observed XGBoost Classifier did a great job. It could be because of the of random forest based boosting technique which it follow within.</td>\n",
       "      <td>d44bb8204d81cb</td>\n",
       "      <td>[1, 345, 2184, 467, 1040, 275, 262, 764, 514, 263, 1943, 17023, 278, 260, 345, 3735, 1477, 1474, 47175, 79216, 464, 266, 426, 688, 260, 325, 387, 282, 401, 265, 262, 265, 4094, 4054, 636, 14810, 3395, 319, 278, 1111, 546, 260, 2]</td>\n",
       "      <td>[[CLS], ▁We, ▁train, ▁different, ▁model, ▁with, ▁the, ▁above, ▁data, ▁and, ▁cross, ▁validated, ▁it, ., ▁We, ▁observed, ▁X, G, Boost, ▁Classifier, ▁did, ▁a, ▁great, ▁job, ., ▁It, ▁could, ▁be, ▁because, ▁of, ▁the, ▁of, ▁random, ▁forest, ▁based, ▁boosting, ▁technique, ▁which, ▁it, ▁follow, ▁within, ., [SEP]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>e7bb77c4</td>\n",
       "      <td>markdown</td>\n",
       "      <td>**Scaling**ʶʶThere are various types of scaling techniques available under sklearn package. It will be interesting to check which scaling method could scale our variable best, which will help to center our data for our gaussian curve. We tested with various scaling techniques like StandardScaler, MinMaxScaler, and RobustScaler and have decided to go with RobustScaler. Robust Scaler is less prone to outlier. Visit below page for more detailsʶʶ[Comparision between other scaling method.](https:...</td>\n",
       "      <td>d44bb8204d81cb</td>\n",
       "      <td>[1, 1124, 1225, 18957, 54829, 1225, 1225, 128001, 128001, 443, 281, 847, 1361, 265, 15810, 2244, 499, 494, 33566, 29274, 2288, 260, 325, 296, 282, 1257, 264, 807, 319, 15810, 1459, 387, 2349, 316, 5361, 410, 261, 319, 296, 408, 264, 1386, 316, 514, 270, 316, 14033, 1867, 30883, 7120, 260, 345, 3457, 275, 847, 15810, 2244, 334, 4927, 43571, 834, 261, 11555, 16728, 43571, 834, 261, 263, 42891, 43571, 834, 263, 286, 1216, 264, 424, 275, 42891, 43571, 834, 260, 42891, 13467, 834, 269, 625, 9970,...</td>\n",
       "      <td>[[CLS], ▁*, *, Sc, aling, *, *, ʶ, ʶ, ▁There, ▁are, ▁various, ▁types, ▁of, ▁scaling, ▁techniques, ▁available, ▁under, ▁sk, learn, ▁package, ., ▁It, ▁will, ▁be, ▁interesting, ▁to, ▁check, ▁which, ▁scaling, ▁method, ▁could, ▁scale, ▁our, ▁variable, ▁best, ,, ▁which, ▁will, ▁help, ▁to, ▁center, ▁our, ▁data, ▁for, ▁our, ▁ga, us, sian, ▁curve, ., ▁We, ▁tested, ▁with, ▁various, ▁scaling, ▁techniques, ▁like, ▁Standard, Scale, r, ,, ▁Min, Max, Scale, r, ,, ▁and, ▁Robust, Scale, r, ▁and, ▁have, ▁deci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>b659d91d</td>\n",
       "      <td>markdown</td>\n",
       "      <td>We also also plotted the distribution graph for the features to look, how deviated are they from the normal distribution</td>\n",
       "      <td>d44bb8204d81cb</td>\n",
       "      <td>[1, 345, 327, 327, 30201, 262, 2810, 8886, 270, 262, 830, 264, 468, 261, 361, 71745, 281, 306, 292, 262, 1697, 2810, 2]</td>\n",
       "      <td>[[CLS], ▁We, ▁also, ▁also, ▁plotted, ▁the, ▁distribution, ▁graph, ▁for, ▁the, ▁features, ▁to, ▁look, ,, ▁how, ▁deviated, ▁are, ▁they, ▁from, ▁the, ▁normal, ▁distribution, [SEP]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6370646 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cell_id cell_type  \\\n",
       "0   1c7a5a71      code   \n",
       "1   68f71f96      code   \n",
       "2   f0a7f5c4      code   \n",
       "3   548f02a6      code   \n",
       "4   627f1de4      code   \n",
       "..       ...       ...   \n",
       "27  80a561bf  markdown   \n",
       "28  24b00b68  markdown   \n",
       "29  265986cf  markdown   \n",
       "30  e7bb77c4  markdown   \n",
       "31  b659d91d  markdown   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 source  \\\n",
       "0   import warningsʶwarnings.filterwarnings(\"ignore\")ʶʶimport sqlite3ʶimport pandas as pdʶimport numpy as npʶimport nltkʶimport stringʶimport matplotlib.pyplot as pltʶimport seaborn as snsʶfrom sklearn.feature_extraction.text import TfidfTransformerʶfrom sklearn.feature_extraction.text import TfidfVectorizerʶʶfrom sklearn.feature_extraction.text import CountVectorizerʶfrom sklearn.metrics import confusion_matrixʶfrom sklearn import metricsʶfrom sklearn.metrics import roc_curve, aucʶfrom nltk.ste...   \n",
       "1   # using the SQLite Table to read data.ʶcon = sqlite3.connect('../input/database.sqlite')ʶ#con = sqlite3.connect('database.sqlite') ʶʶ#filtering only positive and negative reviews i.e. ʶ# not taking into consideration those reviews with Score=3ʶfiltered_data = pd.read_sql_query(\"\"\"SELECT * FROM Reviews WHERE Score != 3 LIMIT 100000\"\"\", con) ʶʶ# Give reviews with Score>3 a positive rating, and reviews with a score<3 a negative rating.ʶdef partition(x):ʶ    if x < 3:ʶ        return 0ʶ    return...   \n",
       "2                                                                                                                                                                                                                                                                                                                      display = pd.read_sql_query(\"\"\" SELECT UserId, ProductId, ProfileName, Time, Score, Text, COUNT(*) FROM Reviews GROUP BY UserId HAVING COUNT(*)>1 \"\"\", con)ʶprint(display.shape)ʶdisplay.head()ʶ   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                           display[display['UserId']=='AZY10LLTJ71NX']   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             display['COUNT(*)'].sum()   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ...   \n",
       "27  Reading the csv file through pandas and view the dataset.ʶʶ**Analysis**ʶ1. To protect the identity of the user and to make the anonymoused data, the team has already performed the PCA and given the component variable which need to be used for the further analysisʶ2. After looking at the data, column \"Time\" and \"Amount\" has not been scaled. Hence we will go through certain scaling algorithm which can be used to scale the data as similar as other variable.ʶ3. Class has two values as \"0\" --> No...   \n",
       "28                                                                                                                                                                                                                                                                                                                    # Dealing with Imbalanced Datasetʶ**Our goal**ʶ1. To create undersample and oversampled dataʶ2. To remove detect and remove the outliersʶ3. Train on multiple algorithms for the classification ʶ   \n",
       "29                                                                                                                                                                                                                                                                                                    We train different model with the above data and cross validated it. We observed XGBoost Classifier did a great job. It could be because of the of random forest based boosting technique which it follow within.   \n",
       "30  **Scaling**ʶʶThere are various types of scaling techniques available under sklearn package. It will be interesting to check which scaling method could scale our variable best, which will help to center our data for our gaussian curve. We tested with various scaling techniques like StandardScaler, MinMaxScaler, and RobustScaler and have decided to go with RobustScaler. Robust Scaler is less prone to outlier. Visit below page for more detailsʶʶ[Comparision between other scaling method.](https:...   \n",
       "31                                                                                                                                                                                                                                                                                                                                                                                             We also also plotted the distribution graph for the features to look, how deviated are they from the normal distribution   \n",
       "\n",
       "                id  \\\n",
       "0   a3baf6134c8506   \n",
       "1   a3baf6134c8506   \n",
       "2   a3baf6134c8506   \n",
       "3   a3baf6134c8506   \n",
       "4   a3baf6134c8506   \n",
       "..             ...   \n",
       "27  d44bb8204d81cb   \n",
       "28  d44bb8204d81cb   \n",
       "29  d44bb8204d81cb   \n",
       "30  d44bb8204d81cb   \n",
       "31  d44bb8204d81cb   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              input_ids  \\\n",
       "0   [1, 6306, 11917, 128001, 11917, 260, 28865, 60656, 268, 555, 309, 66478, 309, 285, 128001, 128001, 6306, 120474, 508, 128001, 6306, 67927, 283, 845, 407, 128001, 6306, 36221, 11751, 283, 76767, 128001, 6306, 90668, 39501, 128001, 6306, 4022, 128001, 6306, 8358, 33918, 14434, 260, 11751, 33918, 283, 28944, 297, 128001, 6306, 2164, 6107, 283, 41339, 268, 128001, 292, 33566, 29274, 260, 51532, 616, 113492, 260, 12948, 6306, 897, 59426, 1892, 86911, 649, 128001, 292, 33566, 29274, 260, 51532, 61...   \n",
       "1   [1, 953, 478, 262, 78550, 3751, 264, 623, 514, 260, 128001, 4636, 1842, 120474, 508, 260, 30407, 555, 280, 260, 260, 320, 42177, 320, 54698, 260, 51972, 5936, 280, 285, 128001, 953, 5699, 1842, 120474, 508, 260, 30407, 555, 280, 54698, 260, 51972, 5936, 280, 285, 128001, 128001, 953, 28865, 510, 364, 1453, 263, 2330, 1937, 584, 260, 473, 260, 128001, 953, 298, 787, 352, 3937, 421, 1937, 275, 13938, 1510, 508, 128001, 16334, 616, 9832, 1842, 845, 407, 260, 8523, 616, 51972, 616, 47975, 555, 3...   \n",
       "2                                                                                                       [1, 1689, 1842, 845, 407, 260, 8523, 616, 51972, 616, 47975, 555, 309, 309, 309, 45786, 5675, 29935, 261, 4899, 29935, 261, 12028, 15303, 261, 2210, 261, 13938, 261, 7655, 261, 73857, 555, 1225, 285, 11371, 8939, 30686, 9506, 5675, 29935, 92773, 73857, 555, 1225, 285, 1504, 435, 307, 309, 309, 261, 4636, 285, 128001, 2118, 555, 35459, 260, 29753, 285, 128001, 1689, 260, 5563, 555, 285, 128001, 2]   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                              [1, 1689, 2550, 35459, 2550, 280, 26359, 29935, 280, 592, 1510, 1510, 280, 558, 54368, 894, 17145, 1193, 2252, 9156, 34690, 280, 592, 2]   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                        [1, 1689, 2550, 280, 98460, 555, 1225, 285, 280, 592, 260, 17608, 555, 285, 2]   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ...   \n",
       "27  [1, 6174, 262, 91341, 1092, 390, 67927, 263, 866, 262, 12438, 260, 128001, 128001, 1124, 1225, 68263, 1225, 1225, 128001, 376, 260, 502, 1746, 262, 3044, 265, 262, 1143, 263, 264, 365, 262, 9023, 569, 514, 261, 262, 511, 303, 637, 2264, 262, 40589, 263, 744, 262, 3480, 5361, 319, 389, 264, 282, 427, 270, 262, 839, 1423, 128001, 392, 260, 643, 562, 288, 262, 514, 261, 4547, 307, 11467, 309, 263, 307, 558, 18546, 309, 303, 298, 331, 19199, 260, 7688, 301, 296, 424, 390, 991, 15810, 7416, 319, ...   \n",
       "28                                                                                                                                                                                                                                   [1, 953, 32979, 275, 120977, 407, 84590, 128001, 1124, 1225, 6374, 1238, 1225, 1225, 128001, 376, 260, 502, 676, 494, 26154, 263, 360, 100138, 514, 128001, 392, 260, 502, 1963, 6659, 263, 1963, 262, 58878, 128001, 404, 260, 11004, 277, 1337, 8785, 270, 262, 9209, 128001, 2]   \n",
       "29                                                                                                                                                                                                                                                                                [1, 345, 2184, 467, 1040, 275, 262, 764, 514, 263, 1943, 17023, 278, 260, 345, 3735, 1477, 1474, 47175, 79216, 464, 266, 426, 688, 260, 325, 387, 282, 401, 265, 262, 265, 4094, 4054, 636, 14810, 3395, 319, 278, 1111, 546, 260, 2]   \n",
       "30  [1, 1124, 1225, 18957, 54829, 1225, 1225, 128001, 128001, 443, 281, 847, 1361, 265, 15810, 2244, 499, 494, 33566, 29274, 2288, 260, 325, 296, 282, 1257, 264, 807, 319, 15810, 1459, 387, 2349, 316, 5361, 410, 261, 319, 296, 408, 264, 1386, 316, 514, 270, 316, 14033, 1867, 30883, 7120, 260, 345, 3457, 275, 847, 15810, 2244, 334, 4927, 43571, 834, 261, 11555, 16728, 43571, 834, 261, 263, 42891, 43571, 834, 263, 286, 1216, 264, 424, 275, 42891, 43571, 834, 260, 42891, 13467, 834, 269, 625, 9970,...   \n",
       "31                                                                                                                                                                                                                                                                                                                                                                                              [1, 345, 327, 327, 30201, 262, 2810, 8886, 270, 262, 830, 264, 468, 261, 361, 71745, 281, 306, 292, 262, 1697, 2810, 2]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 tokens  \n",
       "0   [[CLS], ▁import, ▁warnings, ʶ, ▁warnings, ., filter, warning, s, (, \", ignore, \", ), ʶ, ʶ, ▁import, ▁sqlite, 3, ʶ, ▁import, ▁pandas, ▁as, ▁p, d, ʶ, ▁import, ▁num, py, ▁as, ▁np, ʶ, ▁import, ▁nl, tk, ʶ, ▁import, ▁string, ʶ, ▁import, ▁mat, plot, lib, ., py, plot, ▁as, ▁pl, t, ʶ, ▁import, ▁sea, born, ▁as, ▁sn, s, ʶ, ▁from, ▁sk, learn, ., feature, _, extraction, ., text, ▁import, ▁T, fid, f, Transform, er, ʶ, ▁from, ▁sk, learn, ., feature, _, extraction, ., text, ▁import, ▁T, fid, f, Vector, izer...  \n",
       "1   [[CLS], ▁#, ▁using, ▁the, ▁SQLite, ▁Table, ▁to, ▁read, ▁data, ., ʶ, ▁con, ▁=, ▁sqlite, 3, ., connect, (, ', ., ., /, input, /, database, ., sql, ite, ', ), ʶ, ▁#, con, ▁=, ▁sqlite, 3, ., connect, (, ', database, ., sql, ite, ', ), ʶ, ʶ, ▁#, filter, ing, ▁only, ▁positive, ▁and, ▁negative, ▁reviews, ▁i, ., e, ., ʶ, ▁#, ▁not, ▁taking, ▁into, ▁consideration, ▁those, ▁reviews, ▁with, ▁Score, =, 3, ʶ, ▁filtered, _, data, ▁=, ▁p, d, ., read, _, sql, _, query, (, \", \", \", SELECT, ▁*, ▁FROM, ▁Reviews...  \n",
       "2                                                                                                                                                               [[CLS], ▁display, ▁=, ▁p, d, ., read, _, sql, _, query, (, \", \", \", ▁SELECT, ▁User, Id, ,, ▁Product, Id, ,, ▁Profile, Name, ,, ▁Time, ,, ▁Score, ,, ▁Text, ,, ▁COUNT, (, *, ), ▁FROM, ▁Reviews, ▁GROUP, ▁BY, ▁User, Id, ▁HAVING, ▁COUNT, (, *, ), >, 1, ▁\", \", \", ,, ▁con, ), ʶ, ▁print, (, display, ., shape, ), ʶ, ▁display, ., head, (, ), ʶ, [SEP]]  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                [[CLS], ▁display, [, display, [, ', User, Id, ', ], =, =, ', A, ZY, 10, LL, T, J, 71, NX, ', ], [SEP]]  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                    [[CLS], ▁display, [, ', COUNT, (, *, ), ', ], ., sum, (, ), [SEP]]  \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ...  \n",
       "27  [[CLS], ▁Reading, ▁the, ▁csv, ▁file, ▁through, ▁pandas, ▁and, ▁view, ▁the, ▁dataset, ., ʶ, ʶ, ▁*, *, Analysis, *, *, ʶ, ▁1, ., ▁To, ▁protect, ▁the, ▁identity, ▁of, ▁the, ▁user, ▁and, ▁to, ▁make, ▁the, ▁anonymous, ed, ▁data, ,, ▁the, ▁team, ▁has, ▁already, ▁performed, ▁the, ▁PCA, ▁and, ▁given, ▁the, ▁component, ▁variable, ▁which, ▁need, ▁to, ▁be, ▁used, ▁for, ▁the, ▁further, ▁analysis, ʶ, ▁2, ., ▁After, ▁looking, ▁at, ▁the, ▁data, ,, ▁column, ▁\", Time, \", ▁and, ▁\", A, mount, \", ▁has, ▁not, ▁b...  \n",
       "28                                                                                                                                                                                                        [[CLS], ▁#, ▁Dealing, ▁with, ▁Imbalance, d, ▁Dataset, ʶ, ▁*, *, Our, ▁goal, *, *, ʶ, ▁1, ., ▁To, ▁create, ▁under, sample, ▁and, ▁over, sampled, ▁data, ʶ, ▁2, ., ▁To, ▁remove, ▁detect, ▁and, ▁remove, ▁the, ▁outliers, ʶ, ▁3, ., ▁Train, ▁on, ▁multiple, ▁algorithms, ▁for, ▁the, ▁classification, ʶ, [SEP]]  \n",
       "29                                                                                                                                                                                                   [[CLS], ▁We, ▁train, ▁different, ▁model, ▁with, ▁the, ▁above, ▁data, ▁and, ▁cross, ▁validated, ▁it, ., ▁We, ▁observed, ▁X, G, Boost, ▁Classifier, ▁did, ▁a, ▁great, ▁job, ., ▁It, ▁could, ▁be, ▁because, ▁of, ▁the, ▁of, ▁random, ▁forest, ▁based, ▁boosting, ▁technique, ▁which, ▁it, ▁follow, ▁within, ., [SEP]]  \n",
       "30  [[CLS], ▁*, *, Sc, aling, *, *, ʶ, ʶ, ▁There, ▁are, ▁various, ▁types, ▁of, ▁scaling, ▁techniques, ▁available, ▁under, ▁sk, learn, ▁package, ., ▁It, ▁will, ▁be, ▁interesting, ▁to, ▁check, ▁which, ▁scaling, ▁method, ▁could, ▁scale, ▁our, ▁variable, ▁best, ,, ▁which, ▁will, ▁help, ▁to, ▁center, ▁our, ▁data, ▁for, ▁our, ▁ga, us, sian, ▁curve, ., ▁We, ▁tested, ▁with, ▁various, ▁scaling, ▁techniques, ▁like, ▁Standard, Scale, r, ,, ▁Min, Max, Scale, r, ,, ▁and, ▁Robust, Scale, r, ▁and, ▁have, ▁deci...  \n",
       "31                                                                                                                                                                                                                                                                                                                                    [[CLS], ▁We, ▁also, ▁also, ▁plotted, ▁the, ▁distribution, ▁graph, ▁for, ▁the, ▁features, ▁to, ▁look, ,, ▁how, ▁deviated, ▁are, ▁they, ▁from, ▁the, ▁normal, ▁distribution, [SEP]]  \n",
       "\n",
       "[6370646 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10w using 3.14min 1 epoch for emb 256\n",
    "# for emb 128 only 0.3min\n",
    "def gen_w2v(df, tokenizer, name='tokens', window=16, min_count=5, emb_dim=256, limit=0):\n",
    "  sentences = df[name].values\n",
    "  ic(len(sentences))\n",
    "\n",
    "  if limit:\n",
    "    sentences = sentences[:limit]\n",
    "    ic(len(sentences))\n",
    "    name = name + f'.limit{limit}'\n",
    "  monitor = gezi.MonitorCallback(name) \n",
    "  w2v = Word2Vec(sentences, vector_size=emb_dim, window=window, min_count=min_count, sg=1, workers=cpu_count(), epochs=10, callbacks=[monitor])\n",
    "  \n",
    "  root = f'../input/w2v/{emb_dim}'\n",
    "  ofile = f'{root}/{name}.pkl'\n",
    "  gezi.try_mkdir(os.path.dirname(ofile))\n",
    "  gezi.save(w2v, ofile)\n",
    "  emb = np.random.uniform(-0.05, 0.05,(tokenizer.vocab_size, emb_dim))\n",
    "  for i in range(tokenizer.vocab_size):\n",
    "    token = tokenizer.convert_ids_to_tokens(i)\n",
    "    if token in w2v.wv:\n",
    "      emb[i] = w2v.wv[token]\n",
    "  ofile = f'{root}/{name}.npy'\n",
    "  np.save(ofile, emb)\n",
    "  return w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[06/23/22 19:06:50] 3754286411.py:4 in gen_w2v()\n",
      "                    len(sentences): 6370646\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_45807/3092866045.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgen_w2v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_45807/3754286411.py\u001b[0m in \u001b[0;36mgen_w2v\u001b[0;34m(df, tokenizer, name, window, min_count, emb_dim, limit)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf'.limit{limit}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mmonitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgezi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMonitorCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mw2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0memb_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'../input/w2v/{emb_dim}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/pku/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab, shrink_windows)\u001b[0m\n\u001b[1;32m    427\u001b[0m             self.train(\n\u001b[1;32m    428\u001b[0m                 \u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m                 \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m                 end_alpha=self.min_alpha, compute_loss=self.compute_loss, callbacks=callbacks)\n\u001b[1;32m    431\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/pku/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1070\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[1;32m   1071\u001b[0m                     \u001b[0mcorpus_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m                     \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m                     callbacks=callbacks, **kwargs)\n\u001b[1;32m   1074\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/pku/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[0;32m-> 1432\u001b[0;31m             \u001b[0mprogress_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1433\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_corpus_file_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m         )\n",
      "\u001b[0;32m~/envs/pku/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m             \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocks if workers too slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a thread reporting that it finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/pku/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/pku/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gen_w2v(df, tokenizer, emb_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>n_cell_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00015c83e2717b</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001bdd4021779</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001daf4c2c76d</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0002115f48f982</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139251</th>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139252</th>\n",
       "      <td>fffc3b44869198</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139253</th>\n",
       "      <td>fffc63ff750064</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139254</th>\n",
       "      <td>fffcd063cda949</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139255</th>\n",
       "      <td>fffe1d764579d5</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139256 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  n_cell_id\n",
       "0       00001756c60be8         58\n",
       "1       00015c83e2717b         93\n",
       "2       0001bdd4021779         13\n",
       "3       0001daf4c2c76d        229\n",
       "4       0002115f48f982          9\n",
       "...                ...        ...\n",
       "139251  fffc30d5a0bc46         31\n",
       "139252  fffc3b44869198         24\n",
       "139253  fffc63ff750064         26\n",
       "139254  fffcd063cda949         36\n",
       "139255  fffe1d764579d5         72\n",
       "\n",
       "[139256 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cells = df.groupby('id')['cell_id'].count().reset_index(name='n_cell_id')\n",
    "df_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>1862f0a6 448eb224 2a9e43d6 7e2f170a 038b763d 77e56113 2eefe0ef 1ae087ab 0beab1cd 8ffe0b25 9a78ab76 0d136e08 8a4c95d1 23705731 ebe125d5 aaad8355 d9dced8b 21616367 86497fe1 c3ce0945 e2c8e725 a6357f7e ff7c44ed ac301a84 0e7c906e dd0c804a 45082c89 781bbf3c 4bb2e30a bd94f005 63c26fa2 62638fba 3e5f860d bb69e88c 6b5664c7 3eebeb87 23783525 36002912 bfbde93e 8522781a 1496beaf 8ca8392c b69a4f9b 17ec3fc4 503926eb 76512d50 032e2820 a98c5d9f 06365725 8554b284 59959af5 2e1a5949 80151ab7 fcb6792d 5bf9ca51 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00015c83e2717b</td>\n",
       "      <td>2e94bd7a 3e99dee9 b5e286ea da4f7550 c417225b 51e3cd89 2600b4eb 75b65993 cf195f8b 25699d02 72b3201a f2c750d3 de148b56 42749e24 fbe3e811 9901472c 10377ef8 1f462e2f fceeb3e6 ceba8ae0 924c9f0f 2af2a41a 91e68f13 9216a113 63753f10 d5aee1e4 dc8a39a5 3d0a28c2 657a8804 0eea9701 a8fcc3e3 a6f8f9f1 7223cfc2 a166703b df6b3ccb da8b817a a9b266d2 41beeead 3e17f424 cd61f6d1 42f0c365 cc8d23d8 be6c9079 ad42abc1 7894c4e8 eab2b130 cc1add42 16b0d436 a3e791de 183226e4 02ef0932 03441163 f2915b9f d429a743 4d5ebd46 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001bdd4021779</td>\n",
       "      <td>3fdc37be 073782ca 8ea7263c 80543cd8 38310c80 073e27e5 015d52a4 ad7679ef 7fde4f04 07c52510 0a1a7a39 0bcd3fef 58bf360b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001daf4c2c76d</td>\n",
       "      <td>97266564 a898e555 86605076 76cc2642 ef279279 df6c939f 2476da96 00f87d0a ae93e8e6 58aadb1d d20b0094 986fd4f1 b4ff1015 9b761026 6f271c86 97c3f99b 2451daed cfa510c5 374a5179 df5f7c1f 27060ab9 4c7395ec 2d2f9893 35c2812a a6617a52 cd2cf0ad 50cc03dd a57f19d3 4843d706 09c20343 4385fc90 42241549 edaaeecd 1ed4aebf 54ddeb88 08dac4fd 3307d698 ebb2c2f7 ac2b6b85 34f430ca e54d5869 39c98d5f d6c5745e 966d9c8a 27f52431 4524758d 91a4584a 4ef89e46 82d7d8ca b6c234fb 2d0e1fda 434b8e0c bd0b9dd7 7cececae a3edb582 a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0002115f48f982</td>\n",
       "      <td>9ec225f0 18281c6c e3b6b115 4a044c54 365fe576 a3188e54 b3f6e12d ee7655ca 84125b7a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139251</th>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>09727c0c ff1ea6a0 ddfef603 a01ce9b3 3ba953ee bf92a015 f4a0492a 095812e6 53125cfe aa32a700 63340e73 06d8c952 400ceb37 55fa544e d3647ac8 f8e7d47e 7102897a a3a47643 ebd32b52 53caf4d9 b314d9e3 2986b5e1 7eb7350d 681c0d9b f083e1de 704b3ee9 a8e79846 eb887c6c 4faf1ad7 6122a91f 015cff34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139252</th>\n",
       "      <td>fffc3b44869198</td>\n",
       "      <td>978a5137 faa48f03 28dfb12a eea2e812 64fef97c 4e0d1510 58e68f2c 8784e700 4bd5a4cf dc14bfec 2aff7603 8047ded2 ac536a5b d2ec3efb d7172db2 0c5441b4 8bb4abd2 aa168c04 b01422ce 6e67b343 40e930ff b1873cbb 76e0f2a7 233d93b9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139253</th>\n",
       "      <td>fffc63ff750064</td>\n",
       "      <td>5015c300 411b85d9 8238198c f4781d1d b5532930 e1f223e5 e7e67119 4aaf741d 7229cce6 a7fa3628 e4c2fa86 1f8f9d14 7a52357a e9b6265c b32dc5d2 41ccef58 6aff1ae7 29e1f39d b3c6bc16 37cbd460 79e4e69f ee9b8d31 8b54cf58 deead32c 56ee6e4c 56aa8da7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139254</th>\n",
       "      <td>fffcd063cda949</td>\n",
       "      <td>7e6266ad d8281fc5 d4ffcaef 3e0e4a47 21387fc8 cc229f9a baed9c8b d1bb21aa 82979992 65f95dad eba4fa9e c97e268d 7e1a6588 055e0d2e c090bd72 0bf4ab17 26374693 5098ff9a ef42f19d 28f8bc15 b47bacee 0fad41c8 4f671884 4b254efa 74802b2f 7c33c5b2 7168afec 9a2cdb85 fb7456dd 1fd0781b ff949d21 a16411ac 7a1b4718 777b3fc0 f90ee056 83dce89a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139255</th>\n",
       "      <td>fffe1d764579d5</td>\n",
       "      <td>1a63248d 9c3b96a5 1398a873 4e2d4c2d f71c538e 8b44a5e8 385dff7a b8254ef8 4d0e433e debc496c e15ae953 e4d79d73 4bd5172b 6d42873f 81716aa3 e5c8ea7f e70a860e cbb82224 3a10d610 903a4f30 87538ba7 38d2a90a 311547a2 dea83a8d 16df9139 debd617d ae4c0e45 ecf7b4a6 da763608 3f70fb8a d370b647 233c5ab1 3f3a2b35 d45ddc62 1edc1259 038f88b2 5ebcbc15 988e8c95 5cdba2e5 79a9c3ca 1481413e acad688b 197a28a9 0d770d6b 64c29f90 de53ba9c 75c5d93f 2c054107 ec3a94d7 1cc9d5d8 621e5af7 580f0e28 88a1479a 7849a30d a272122c e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139256 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  \\\n",
       "0       00001756c60be8   \n",
       "1       00015c83e2717b   \n",
       "2       0001bdd4021779   \n",
       "3       0001daf4c2c76d   \n",
       "4       0002115f48f982   \n",
       "...                ...   \n",
       "139251  fffc30d5a0bc46   \n",
       "139252  fffc3b44869198   \n",
       "139253  fffc63ff750064   \n",
       "139254  fffcd063cda949   \n",
       "139255  fffe1d764579d5   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 cell_order  \n",
       "0       1862f0a6 448eb224 2a9e43d6 7e2f170a 038b763d 77e56113 2eefe0ef 1ae087ab 0beab1cd 8ffe0b25 9a78ab76 0d136e08 8a4c95d1 23705731 ebe125d5 aaad8355 d9dced8b 21616367 86497fe1 c3ce0945 e2c8e725 a6357f7e ff7c44ed ac301a84 0e7c906e dd0c804a 45082c89 781bbf3c 4bb2e30a bd94f005 63c26fa2 62638fba 3e5f860d bb69e88c 6b5664c7 3eebeb87 23783525 36002912 bfbde93e 8522781a 1496beaf 8ca8392c b69a4f9b 17ec3fc4 503926eb 76512d50 032e2820 a98c5d9f 06365725 8554b284 59959af5 2e1a5949 80151ab7 fcb6792d 5bf9ca51 9...  \n",
       "1       2e94bd7a 3e99dee9 b5e286ea da4f7550 c417225b 51e3cd89 2600b4eb 75b65993 cf195f8b 25699d02 72b3201a f2c750d3 de148b56 42749e24 fbe3e811 9901472c 10377ef8 1f462e2f fceeb3e6 ceba8ae0 924c9f0f 2af2a41a 91e68f13 9216a113 63753f10 d5aee1e4 dc8a39a5 3d0a28c2 657a8804 0eea9701 a8fcc3e3 a6f8f9f1 7223cfc2 a166703b df6b3ccb da8b817a a9b266d2 41beeead 3e17f424 cd61f6d1 42f0c365 cc8d23d8 be6c9079 ad42abc1 7894c4e8 eab2b130 cc1add42 16b0d436 a3e791de 183226e4 02ef0932 03441163 f2915b9f d429a743 4d5ebd46 3...  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                      3fdc37be 073782ca 8ea7263c 80543cd8 38310c80 073e27e5 015d52a4 ad7679ef 7fde4f04 07c52510 0a1a7a39 0bcd3fef 58bf360b  \n",
       "3       97266564 a898e555 86605076 76cc2642 ef279279 df6c939f 2476da96 00f87d0a ae93e8e6 58aadb1d d20b0094 986fd4f1 b4ff1015 9b761026 6f271c86 97c3f99b 2451daed cfa510c5 374a5179 df5f7c1f 27060ab9 4c7395ec 2d2f9893 35c2812a a6617a52 cd2cf0ad 50cc03dd a57f19d3 4843d706 09c20343 4385fc90 42241549 edaaeecd 1ed4aebf 54ddeb88 08dac4fd 3307d698 ebb2c2f7 ac2b6b85 34f430ca e54d5869 39c98d5f d6c5745e 966d9c8a 27f52431 4524758d 91a4584a 4ef89e46 82d7d8ca b6c234fb 2d0e1fda 434b8e0c bd0b9dd7 7cececae a3edb582 a...  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                          9ec225f0 18281c6c e3b6b115 4a044c54 365fe576 a3188e54 b3f6e12d ee7655ca 84125b7a  \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ...  \n",
       "139251                                                                                                                                                                                                                               09727c0c ff1ea6a0 ddfef603 a01ce9b3 3ba953ee bf92a015 f4a0492a 095812e6 53125cfe aa32a700 63340e73 06d8c952 400ceb37 55fa544e d3647ac8 f8e7d47e 7102897a a3a47643 ebd32b52 53caf4d9 b314d9e3 2986b5e1 7eb7350d 681c0d9b f083e1de 704b3ee9 a8e79846 eb887c6c 4faf1ad7 6122a91f 015cff34  \n",
       "139252                                                                                                                                                                                                                                                                                              978a5137 faa48f03 28dfb12a eea2e812 64fef97c 4e0d1510 58e68f2c 8784e700 4bd5a4cf dc14bfec 2aff7603 8047ded2 ac536a5b d2ec3efb d7172db2 0c5441b4 8bb4abd2 aa168c04 b01422ce 6e67b343 40e930ff b1873cbb 76e0f2a7 233d93b9  \n",
       "139253                                                                                                                                                                                                                                                                            5015c300 411b85d9 8238198c f4781d1d b5532930 e1f223e5 e7e67119 4aaf741d 7229cce6 a7fa3628 e4c2fa86 1f8f9d14 7a52357a e9b6265c b32dc5d2 41ccef58 6aff1ae7 29e1f39d b3c6bc16 37cbd460 79e4e69f ee9b8d31 8b54cf58 deead32c 56ee6e4c 56aa8da7  \n",
       "139254                                                                                                                                                                                  7e6266ad d8281fc5 d4ffcaef 3e0e4a47 21387fc8 cc229f9a baed9c8b d1bb21aa 82979992 65f95dad eba4fa9e c97e268d 7e1a6588 055e0d2e c090bd72 0bf4ab17 26374693 5098ff9a ef42f19d 28f8bc15 b47bacee 0fad41c8 4f671884 4b254efa 74802b2f 7c33c5b2 7168afec 9a2cdb85 fb7456dd 1fd0781b ff949d21 a16411ac 7a1b4718 777b3fc0 f90ee056 83dce89a  \n",
       "139255  1a63248d 9c3b96a5 1398a873 4e2d4c2d f71c538e 8b44a5e8 385dff7a b8254ef8 4d0e433e debc496c e15ae953 e4d79d73 4bd5172b 6d42873f 81716aa3 e5c8ea7f e70a860e cbb82224 3a10d610 903a4f30 87538ba7 38d2a90a 311547a2 dea83a8d 16df9139 debd617d ae4c0e45 ecf7b4a6 da763608 3f70fb8a d370b647 233c5ab1 3f3a2b35 d45ddc62 1edc1259 038f88b2 5ebcbc15 988e8c95 5cdba2e5 79a9c3ca 1481413e acad688b 197a28a9 0d770d6b 64c29f90 de53ba9c 75c5d93f 2c054107 ec3a94d7 1cc9d5d8 621e5af7 580f0e28 88a1479a 7849a30d a272122c e...  \n",
       "\n",
       "[139256 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders = pd.read_csv(f'{root}/train_orders.csv')\n",
    "df_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders['n_cell_id'] = df_orders['cell_order'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_cell_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>139256.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>45.7477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>40.0858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>57.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>90.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>118.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>194.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1005.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_cell_id\n",
       "count 139256.0000\n",
       "mean      45.7477\n",
       "std       40.0858\n",
       "min        2.0000\n",
       "25%       21.0000\n",
       "50%       35.0000\n",
       "75%       57.0000\n",
       "90%       90.0000\n",
       "95%      118.0000\n",
       "99%      194.4500\n",
       "max     1005.0000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders.describe([.25,.5,.75,.9,.95,.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_cell_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>139256.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>45.7477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>40.0858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>57.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>90.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>118.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>194.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1005.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_cell_id\n",
       "count 139256.0000\n",
       "mean      45.7477\n",
       "std       40.0858\n",
       "min        2.0000\n",
       "25%       21.0000\n",
       "50%       35.0000\n",
       "75%       57.0000\n",
       "90%       90.0000\n",
       "95%      118.0000\n",
       "99%      194.4500\n",
       "max     1005.0000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cells.describe([.25,.5,.75,.9,.95,.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>input_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1004739</th>\n",
       "      <td>0</td>\n",
       "      <td>ff1ea6a0</td>\n",
       "      <td>code</td>\n",
       "      <td>import warningsʶwarnings.filterwarnings('ignore')ʶʶimport numpy as npʶimport pandas as pdʶʶimport seaborn as snsʶfrom matplotlib import pyplot as pltʶ%matplotlib inlineʶʶimport sklearnʶfrom sklearn.model_selection import train_test_splitʶfrom sklearn.metrics import accuracy_scoreʶfrom sklearn.neighbors import KNeighborsClassifierʶfrom sklearn.linear_model import LinearRegressionʶʶimport tensorflow as tfʶfrom tensorflow import kerasʶʶfrom sklearn import preprocessingʶtf.__version__</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 6306, 11917, 128001, 11917, 260, 28865, 60656, 268, 555, 280, 66478, 280, 285, 128001, 128001, 6306, 36221, 11751, 283, 76767, 128001, 6306, 67927, 283, 845, 407, 128001, 128001, 6306, 2164, 6107, 283, 41339, 268, 128001, 292, 8358, 33918, 14434, 6306, 35512, 33918, 283, 28944, 297, 128001, 4639, 13261, 33918, 14434, 30426, 128001, 128001, 6306, 33566, 29274, 128001, 292, 33566, 29274, 260, 19928, 616, 57907, 6306, 2184, 616, 9982, 616, 43483, 128001, 292, 33566, 29274, 260, 56282, 6306,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004740</th>\n",
       "      <td>1</td>\n",
       "      <td>a01ce9b3</td>\n",
       "      <td>code</td>\n",
       "      <td>weather_df = pd.read_csv('../input/weatherHistory.csv')</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 1742, 616, 32392, 1842, 845, 407, 260, 8523, 616, 76413, 555, 280, 260, 260, 320, 42177, 320, 22399, 35874, 260, 76413, 280, 285, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004741</th>\n",
       "      <td>2</td>\n",
       "      <td>bf92a015</td>\n",
       "      <td>code</td>\n",
       "      <td>weather_df.head()</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 1742, 616, 32392, 260, 5563, 555, 285, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004742</th>\n",
       "      <td>3</td>\n",
       "      <td>095812e6</td>\n",
       "      <td>code</td>\n",
       "      <td>weather_df.columnsʶweather_df.shapeʶweather_df.describe()ʶweather_df.info()ʶweather_df.isnull().any()ʶweather_df.isnull().all()</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 1742, 616, 32392, 260, 39163, 268, 128001, 1742, 616, 32392, 260, 29753, 128001, 1742, 616, 32392, 260, 118314, 555, 285, 128001, 1742, 616, 32392, 260, 10101, 555, 285, 128001, 1742, 616, 32392, 260, 1890, 43858, 555, 285, 260, 11771, 555, 285, 128001, 1742, 616, 32392, 260, 1890, 43858, 555, 285, 260, 3068, 555, 285, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004743</th>\n",
       "      <td>4</td>\n",
       "      <td>aa32a700</td>\n",
       "      <td>code</td>\n",
       "      <td>round(100*(weather_df.isnull().sum()/len(weather_df.index)),2)</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 1489, 555, 2273, 1225, 555, 22399, 616, 32392, 260, 1890, 43858, 555, 285, 260, 17608, 555, 285, 320, 12630, 555, 22399, 616, 32392, 260, 13915, 285, 285, 261, 445, 285, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004744</th>\n",
       "      <td>5</td>\n",
       "      <td>06d8c952</td>\n",
       "      <td>code</td>\n",
       "      <td>weather_df['Precip Type'].value_counts()</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 1742, 616, 32392, 2550, 280, 17108, 31100, 5004, 280, 592, 260, 11651, 616, 21036, 268, 555, 285, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004745</th>\n",
       "      <td>6</td>\n",
       "      <td>400ceb37</td>\n",
       "      <td>code</td>\n",
       "      <td>weather_df.loc[weather_df['Precip Type'].isnull(),'Precip Type']='rain'</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 1742, 616, 32392, 260, 28372, 2550, 22399, 616, 32392, 2550, 280, 17108, 31100, 5004, 280, 592, 260, 1890, 43858, 555, 285, 261, 280, 17108, 31100, 5004, 280, 592, 1510, 280, 26790, 280, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004746</th>\n",
       "      <td>7</td>\n",
       "      <td>55fa544e</td>\n",
       "      <td>code</td>\n",
       "      <td>round(100*(weather_df.isnull().sum()/len(weather_df.index)),2)</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 1489, 555, 2273, 1225, 555, 22399, 616, 32392, 260, 1890, 43858, 555, 285, 260, 17608, 555, 285, 320, 12630, 555, 22399, 616, 32392, 260, 13915, 285, 285, 261, 445, 285, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004747</th>\n",
       "      <td>8</td>\n",
       "      <td>f8e7d47e</td>\n",
       "      <td>code</td>\n",
       "      <td>plt.scatter(x = 'Wind Speed (km/h)',y = 'Wind Bearing (degrees)',data=weather_df)</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 28944, 297, 260, 69916, 555, 982, 1842, 382, 50004, 7628, 287, 6275, 320, 1537, 285, 280, 261, 608, 1842, 382, 50004, 24029, 287, 72511, 285, 280, 261, 9832, 1510, 22399, 616, 32392, 285, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004748</th>\n",
       "      <td>9</td>\n",
       "      <td>7102897a</td>\n",
       "      <td>code</td>\n",
       "      <td>plt.figure(figsize = (10,10))ʶplt.subplot()ʶplt.subplot(2,3,1)ʶplt.title('Wind Speed (km/h)')ʶplt.hist(x = 'Wind Speed (km/h)',bins =20,data = weather_df)ʶʶplt.subplot(2,3,2)ʶplt.title('Apparent Temperature (C)')ʶplt.hist(x = 'Apparent Temperature (C)',bins =20,data = weather_df)ʶʶplt.subplot(2,3,3)ʶplt.title('Humidity')ʶplt.hist(x = 'Humidity',bins =20,data = weather_df)ʶʶplt.subplot(2,3,4)ʶplt.title('Wind Bearing (degrees)')ʶplt.hist(x = 'Wind Bearing (degrees)',bins =100,data = weather_df...</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 28944, 297, 260, 22971, 555, 30134, 7283, 1842, 287, 894, 261, 894, 285, 285, 128001, 28944, 297, 260, 12109, 33918, 555, 285, 128001, 28944, 297, 260, 12109, 33918, 555, 445, 261, 508, 261, 435, 285, 128001, 28944, 297, 260, 24423, 555, 280, 50004, 7628, 287, 6275, 320, 1537, 285, 280, 285, 128001, 28944, 297, 260, 11226, 297, 555, 982, 1842, 382, 50004, 7628, 287, 6275, 320, 1537, 285, 280, 261, 12160, 268, 1842, 1435, 261, 9832, 1842, 1742, 616, 32392, 285, 128001, 128001, 28944, 297,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004749</th>\n",
       "      <td>10</td>\n",
       "      <td>a3a47643</td>\n",
       "      <td>code</td>\n",
       "      <td>## Creating corellation metricsʶweather_corr = weather_df[list(weather_df.dtypes[weather_df.dtypes!='object'].index)].corr()</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 953, 2669, 11257, 26226, 82686, 10125, 128001, 1742, 616, 98661, 1842, 1742, 616, 32392, 2550, 8375, 555, 22399, 616, 32392, 260, 407, 32459, 2550, 22399, 616, 32392, 260, 407, 32459, 300, 1510, 280, 33299, 280, 592, 260, 13915, 285, 592, 260, 98661, 555, 285, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004750</th>\n",
       "      <td>11</td>\n",
       "      <td>ebd32b52</td>\n",
       "      <td>code</td>\n",
       "      <td>sns.heatmap(weather_corr,annot=True)</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 41339, 268, 260, 27862, 14727, 555, 22399, 616, 98661, 261, 1398, 2895, 1510, 35733, 285, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004751</th>\n",
       "      <td>12</td>\n",
       "      <td>53caf4d9</td>\n",
       "      <td>code</td>\n",
       "      <td>sns.pairplot(weather_df)</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 41339, 268, 260, 39506, 33918, 555, 22399, 616, 32392, 285, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004752</th>\n",
       "      <td>13</td>\n",
       "      <td>b314d9e3</td>\n",
       "      <td>code</td>\n",
       "      <td># Imputing binary values in type column ʶweather_df.loc[weather_df['Precip Type']=='rain','Precip Type']=1ʶweather_df.loc[weather_df['Precip Type']=='snow','Precip Type']=0</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 953, 21195, 58535, 5636, 1974, 267, 810, 4547, 128001, 1742, 616, 32392, 260, 28372, 2550, 22399, 616, 32392, 2550, 280, 17108, 31100, 5004, 280, 592, 1510, 1510, 280, 26790, 280, 261, 280, 17108, 31100, 5004, 280, 592, 1510, 435, 128001, 1742, 616, 32392, 260, 28372, 2550, 22399, 616, 32392, 2550, 280, 17108, 31100, 5004, 280, 592, 1510, 1510, 280, 40095, 280, 261, 280, 17108, 31100, 5004, 280, 592, 1510, 693, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004753</th>\n",
       "      <td>14</td>\n",
       "      <td>2986b5e1</td>\n",
       "      <td>code</td>\n",
       "      <td>weather_df_num=weather_df[list(weather_df.dtypes[weather_df.dtypes!='object'].index)]</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 1742, 616, 32392, 616, 22062, 1510, 22399, 616, 32392, 2550, 8375, 555, 22399, 616, 32392, 260, 407, 32459, 2550, 22399, 616, 32392, 260, 407, 32459, 300, 1510, 280, 33299, 280, 592, 260, 13915, 285, 592, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004754</th>\n",
       "      <td>15</td>\n",
       "      <td>7eb7350d</td>\n",
       "      <td>code</td>\n",
       "      <td>weather_y = weather_df_num.pop('Temperature (C)')ʶweather_X = weather_df_num</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 1742, 616, 608, 1842, 1742, 616, 32392, 616, 22062, 260, 12011, 555, 280, 112788, 287, 711, 285, 280, 285, 128001, 1742, 616, 2087, 1842, 1742, 616, 32392, 616, 22062, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004755</th>\n",
       "      <td>16</td>\n",
       "      <td>f083e1de</td>\n",
       "      <td>code</td>\n",
       "      <td>train_X,test_X,train_y,test_y = train_test_split(weather_X,weather_y,test_size = 0.2,random_state=4)</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 2184, 616, 2087, 261, 9982, 616, 2087, 261, 23822, 616, 608, 261, 9982, 616, 608, 1842, 2184, 616, 9982, 616, 43483, 555, 22399, 616, 2087, 261, 22399, 616, 608, 261, 9982, 616, 7283, 1842, 767, 260, 445, 261, 34409, 616, 6642, 1510, 554, 285, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004756</th>\n",
       "      <td>17</td>\n",
       "      <td>704b3ee9</td>\n",
       "      <td>code</td>\n",
       "      <td>train_X.head()</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 2184, 616, 2087, 260, 5563, 555, 285, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004757</th>\n",
       "      <td>18</td>\n",
       "      <td>eb887c6c</td>\n",
       "      <td>code</td>\n",
       "      <td>model = LinearRegression()ʶmodel.fit(train_X,train_y)</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 1040, 1842, 25019, 5396, 61270, 555, 285, 128001, 1040, 260, 13796, 555, 23822, 616, 2087, 261, 23822, 616, 608, 285, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004758</th>\n",
       "      <td>19</td>\n",
       "      <td>4faf1ad7</td>\n",
       "      <td>code</td>\n",
       "      <td>prediction = model.predict(test_X)</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 10313, 1842, 1040, 260, 57796, 555, 9982, 616, 2087, 285, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004759</th>\n",
       "      <td>20</td>\n",
       "      <td>6122a91f</td>\n",
       "      <td>code</td>\n",
       "      <td>## Calculating the error ʶnp.mean((prediction-test_y)**2)</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 953, 2669, 89031, 262, 2385, 128001, 76767, 260, 28431, 555, 555, 112152, 271, 9982, 616, 608, 285, 1225, 1225, 445, 285, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004760</th>\n",
       "      <td>21</td>\n",
       "      <td>015cff34</td>\n",
       "      <td>code</td>\n",
       "      <td>pd.DataFrame({'actual':test_y,ʶ             'prediction':prediction,ʶ             'diff':(test_y-prediction)})</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 845, 407, 260, 15006, 39702, 555, 19976, 280, 41841, 280, 294, 9982, 616, 608, 261, 128001, 382, 112152, 280, 294, 112152, 261, 128001, 382, 50259, 280, 294, 555, 9982, 616, 608, 271, 112152, 285, 14986, 285, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004761</th>\n",
       "      <td>22</td>\n",
       "      <td>ddfef603</td>\n",
       "      <td>markdown</td>\n",
       "      <td>#### Importing the dataframe</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 953, 2669, 2669, 2669, 99307, 262, 514, 16439, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004762</th>\n",
       "      <td>23</td>\n",
       "      <td>f4a0492a</td>\n",
       "      <td>markdown</td>\n",
       "      <td>#### Doing basic checks on the dataframe</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 953, 2669, 2669, 2669, 11317, 1671, 6027, 277, 262, 514, 16439, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004763</th>\n",
       "      <td>24</td>\n",
       "      <td>a8e79846</td>\n",
       "      <td>markdown</td>\n",
       "      <td>#### Building the model</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 953, 2669, 2669, 2669, 4098, 262, 1040, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004764</th>\n",
       "      <td>25</td>\n",
       "      <td>681c0d9b</td>\n",
       "      <td>markdown</td>\n",
       "      <td>#### Spliting the data for training and testing purpose</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 953, 2669, 2669, 2669, 17575, 510, 262, 514, 270, 838, 263, 2126, 1602, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004765</th>\n",
       "      <td>26</td>\n",
       "      <td>3ba953ee</td>\n",
       "      <td>markdown</td>\n",
       "      <td>#### Checking the dataframe</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 953, 2669, 2669, 2669, 30462, 262, 514, 16439, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004766</th>\n",
       "      <td>27</td>\n",
       "      <td>53125cfe</td>\n",
       "      <td>markdown</td>\n",
       "      <td>#### Checking the number of nulls in percentage</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 953, 2669, 2669, 2669, 30462, 262, 496, 265, 15355, 268, 267, 3623, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004767</th>\n",
       "      <td>28</td>\n",
       "      <td>63340e73</td>\n",
       "      <td>markdown</td>\n",
       "      <td>#### Now we will try to impute null with the maximum occured values</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 953, 2669, 2669, 2669, 790, 301, 296, 687, 264, 89844, 473, 15355, 275, 262, 2380, 50468, 1974, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004768</th>\n",
       "      <td>29</td>\n",
       "      <td>09727c0c</td>\n",
       "      <td>markdown</td>\n",
       "      <td>#### Importing necessary libraries</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 953, 2669, 2669, 2669, 99307, 1241, 7296, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004769</th>\n",
       "      <td>30</td>\n",
       "      <td>d3647ac8</td>\n",
       "      <td>markdown</td>\n",
       "      <td>#### Doing some exploratory data analysis</td>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 953, 2669, 2669, 2669, 11317, 347, 32061, 514, 1423, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index   cell_id cell_type  \\\n",
       "1004739      0  ff1ea6a0      code   \n",
       "1004740      1  a01ce9b3      code   \n",
       "1004741      2  bf92a015      code   \n",
       "1004742      3  095812e6      code   \n",
       "1004743      4  aa32a700      code   \n",
       "1004744      5  06d8c952      code   \n",
       "1004745      6  400ceb37      code   \n",
       "1004746      7  55fa544e      code   \n",
       "1004747      8  f8e7d47e      code   \n",
       "1004748      9  7102897a      code   \n",
       "1004749     10  a3a47643      code   \n",
       "1004750     11  ebd32b52      code   \n",
       "1004751     12  53caf4d9      code   \n",
       "1004752     13  b314d9e3      code   \n",
       "1004753     14  2986b5e1      code   \n",
       "1004754     15  7eb7350d      code   \n",
       "1004755     16  f083e1de      code   \n",
       "1004756     17  704b3ee9      code   \n",
       "1004757     18  eb887c6c      code   \n",
       "1004758     19  4faf1ad7      code   \n",
       "1004759     20  6122a91f      code   \n",
       "1004760     21  015cff34      code   \n",
       "1004761     22  ddfef603  markdown   \n",
       "1004762     23  f4a0492a  markdown   \n",
       "1004763     24  a8e79846  markdown   \n",
       "1004764     25  681c0d9b  markdown   \n",
       "1004765     26  3ba953ee  markdown   \n",
       "1004766     27  53125cfe  markdown   \n",
       "1004767     28  63340e73  markdown   \n",
       "1004768     29  09727c0c  markdown   \n",
       "1004769     30  d3647ac8  markdown   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      source  \\\n",
       "1004739                import warningsʶwarnings.filterwarnings('ignore')ʶʶimport numpy as npʶimport pandas as pdʶʶimport seaborn as snsʶfrom matplotlib import pyplot as pltʶ%matplotlib inlineʶʶimport sklearnʶfrom sklearn.model_selection import train_test_splitʶfrom sklearn.metrics import accuracy_scoreʶfrom sklearn.neighbors import KNeighborsClassifierʶfrom sklearn.linear_model import LinearRegressionʶʶimport tensorflow as tfʶfrom tensorflow import kerasʶʶfrom sklearn import preprocessingʶtf.__version__   \n",
       "1004740                                                                                                                                                                                                                                                                                                                                                                                                                                                              weather_df = pd.read_csv('../input/weatherHistory.csv')   \n",
       "1004741                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    weather_df.head()   \n",
       "1004742                                                                                                                                                                                                                                                                                                                                                                                      weather_df.columnsʶweather_df.shapeʶweather_df.describe()ʶweather_df.info()ʶweather_df.isnull().any()ʶweather_df.isnull().all()   \n",
       "1004743                                                                                                                                                                                                                                                                                                                                                                                                                                                       round(100*(weather_df.isnull().sum()/len(weather_df.index)),2)   \n",
       "1004744                                                                                                                                                                                                                                                                                                                                                                                                                                                                             weather_df['Precip Type'].value_counts()   \n",
       "1004745                                                                                                                                                                                                                                                                                                                                                                                                                                              weather_df.loc[weather_df['Precip Type'].isnull(),'Precip Type']='rain'   \n",
       "1004746                                                                                                                                                                                                                                                                                                                                                                                                                                                       round(100*(weather_df.isnull().sum()/len(weather_df.index)),2)   \n",
       "1004747                                                                                                                                                                                                                                                                                                                                                                                                                                    plt.scatter(x = 'Wind Speed (km/h)',y = 'Wind Bearing (degrees)',data=weather_df)   \n",
       "1004748  plt.figure(figsize = (10,10))ʶplt.subplot()ʶplt.subplot(2,3,1)ʶplt.title('Wind Speed (km/h)')ʶplt.hist(x = 'Wind Speed (km/h)',bins =20,data = weather_df)ʶʶplt.subplot(2,3,2)ʶplt.title('Apparent Temperature (C)')ʶplt.hist(x = 'Apparent Temperature (C)',bins =20,data = weather_df)ʶʶplt.subplot(2,3,3)ʶplt.title('Humidity')ʶplt.hist(x = 'Humidity',bins =20,data = weather_df)ʶʶplt.subplot(2,3,4)ʶplt.title('Wind Bearing (degrees)')ʶplt.hist(x = 'Wind Bearing (degrees)',bins =100,data = weather_df...   \n",
       "1004749                                                                                                                                                                                                                                                                                                                                                                                         ## Creating corellation metricsʶweather_corr = weather_df[list(weather_df.dtypes[weather_df.dtypes!='object'].index)].corr()   \n",
       "1004750                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 sns.heatmap(weather_corr,annot=True)   \n",
       "1004751                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             sns.pairplot(weather_df)   \n",
       "1004752                                                                                                                                                                                                                                                                                                                                         # Imputing binary values in type column ʶweather_df.loc[weather_df['Precip Type']=='rain','Precip Type']=1ʶweather_df.loc[weather_df['Precip Type']=='snow','Precip Type']=0   \n",
       "1004753                                                                                                                                                                                                                                                                                                                                                                                                                                weather_df_num=weather_df[list(weather_df.dtypes[weather_df.dtypes!='object'].index)]   \n",
       "1004754                                                                                                                                                                                                                                                                                                                                                                                                                                         weather_y = weather_df_num.pop('Temperature (C)')ʶweather_X = weather_df_num   \n",
       "1004755                                                                                                                                                                                                                                                                                                                                                                                                                 train_X,test_X,train_y,test_y = train_test_split(weather_X,weather_y,test_size = 0.2,random_state=4)   \n",
       "1004756                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       train_X.head()   \n",
       "1004757                                                                                                                                                                                                                                                                                                                                                                                                                                                                model = LinearRegression()ʶmodel.fit(train_X,train_y)   \n",
       "1004758                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   prediction = model.predict(test_X)   \n",
       "1004759                                                                                                                                                                                                                                                                                                                                                                                                                                                            ## Calculating the error ʶnp.mean((prediction-test_y)**2)   \n",
       "1004760                                                                                                                                                                                                                                                                                                                                                                                                       pd.DataFrame({'actual':test_y,ʶ             'prediction':prediction,ʶ             'diff':(test_y-prediction)})   \n",
       "1004761                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         #### Importing the dataframe   \n",
       "1004762                                                                                                                                                                                                                                                                                                                                                                                                                                                                             #### Doing basic checks on the dataframe   \n",
       "1004763                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              #### Building the model   \n",
       "1004764                                                                                                                                                                                                                                                                                                                                                                                                                                                              #### Spliting the data for training and testing purpose   \n",
       "1004765                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          #### Checking the dataframe   \n",
       "1004766                                                                                                                                                                                                                                                                                                                                                                                                                                                                      #### Checking the number of nulls in percentage   \n",
       "1004767                                                                                                                                                                                                                                                                                                                                                                                                                                                  #### Now we will try to impute null with the maximum occured values   \n",
       "1004768                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   #### Importing necessary libraries   \n",
       "1004769                                                                                                                                                                                                                                                                                                                                                                                                                                                                            #### Doing some exploratory data analysis   \n",
       "\n",
       "                     id  \\\n",
       "1004739  fffc30d5a0bc46   \n",
       "1004740  fffc30d5a0bc46   \n",
       "1004741  fffc30d5a0bc46   \n",
       "1004742  fffc30d5a0bc46   \n",
       "1004743  fffc30d5a0bc46   \n",
       "1004744  fffc30d5a0bc46   \n",
       "1004745  fffc30d5a0bc46   \n",
       "1004746  fffc30d5a0bc46   \n",
       "1004747  fffc30d5a0bc46   \n",
       "1004748  fffc30d5a0bc46   \n",
       "1004749  fffc30d5a0bc46   \n",
       "1004750  fffc30d5a0bc46   \n",
       "1004751  fffc30d5a0bc46   \n",
       "1004752  fffc30d5a0bc46   \n",
       "1004753  fffc30d5a0bc46   \n",
       "1004754  fffc30d5a0bc46   \n",
       "1004755  fffc30d5a0bc46   \n",
       "1004756  fffc30d5a0bc46   \n",
       "1004757  fffc30d5a0bc46   \n",
       "1004758  fffc30d5a0bc46   \n",
       "1004759  fffc30d5a0bc46   \n",
       "1004760  fffc30d5a0bc46   \n",
       "1004761  fffc30d5a0bc46   \n",
       "1004762  fffc30d5a0bc46   \n",
       "1004763  fffc30d5a0bc46   \n",
       "1004764  fffc30d5a0bc46   \n",
       "1004765  fffc30d5a0bc46   \n",
       "1004766  fffc30d5a0bc46   \n",
       "1004767  fffc30d5a0bc46   \n",
       "1004768  fffc30d5a0bc46   \n",
       "1004769  fffc30d5a0bc46   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   input_ids  \n",
       "1004739  [1, 6306, 11917, 128001, 11917, 260, 28865, 60656, 268, 555, 280, 66478, 280, 285, 128001, 128001, 6306, 36221, 11751, 283, 76767, 128001, 6306, 67927, 283, 845, 407, 128001, 128001, 6306, 2164, 6107, 283, 41339, 268, 128001, 292, 8358, 33918, 14434, 6306, 35512, 33918, 283, 28944, 297, 128001, 4639, 13261, 33918, 14434, 30426, 128001, 128001, 6306, 33566, 29274, 128001, 292, 33566, 29274, 260, 19928, 616, 57907, 6306, 2184, 616, 9982, 616, 43483, 128001, 292, 33566, 29274, 260, 56282, 6306,...  \n",
       "1004740                                                                                                                                                                                                                                                                                                                                                                             [1, 1742, 616, 32392, 1842, 845, 407, 260, 8523, 616, 76413, 555, 280, 260, 260, 320, 42177, 320, 22399, 35874, 260, 76413, 280, 285, 2]  \n",
       "1004741                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [1, 1742, 616, 32392, 260, 5563, 555, 285, 2]  \n",
       "1004742                                                                                                                                                                              [1, 1742, 616, 32392, 260, 39163, 268, 128001, 1742, 616, 32392, 260, 29753, 128001, 1742, 616, 32392, 260, 118314, 555, 285, 128001, 1742, 616, 32392, 260, 10101, 555, 285, 128001, 1742, 616, 32392, 260, 1890, 43858, 555, 285, 260, 11771, 555, 285, 128001, 1742, 616, 32392, 260, 1890, 43858, 555, 285, 260, 3068, 555, 285, 2]  \n",
       "1004743                                                                                                                                                                                                                                                                                                                                     [1, 1489, 555, 2273, 1225, 555, 22399, 616, 32392, 260, 1890, 43858, 555, 285, 260, 17608, 555, 285, 320, 12630, 555, 22399, 616, 32392, 260, 13915, 285, 285, 261, 445, 285, 2]  \n",
       "1004744                                                                                                                                                                                                                                                                                                                                                                                                             [1, 1742, 616, 32392, 2550, 280, 17108, 31100, 5004, 280, 592, 260, 11651, 616, 21036, 268, 555, 285, 2]  \n",
       "1004745                                                                                                                                                                                                                                                                                                                    [1, 1742, 616, 32392, 260, 28372, 2550, 22399, 616, 32392, 2550, 280, 17108, 31100, 5004, 280, 592, 260, 1890, 43858, 555, 285, 261, 280, 17108, 31100, 5004, 280, 592, 1510, 280, 26790, 280, 2]  \n",
       "1004746                                                                                                                                                                                                                                                                                                                                     [1, 1489, 555, 2273, 1225, 555, 22399, 616, 32392, 260, 1890, 43858, 555, 285, 260, 17608, 555, 285, 320, 12630, 555, 22399, 616, 32392, 260, 13915, 285, 285, 261, 445, 285, 2]  \n",
       "1004747                                                                                                                                                                                                                                                                                                                   [1, 28944, 297, 260, 69916, 555, 982, 1842, 382, 50004, 7628, 287, 6275, 320, 1537, 285, 280, 261, 608, 1842, 382, 50004, 24029, 287, 72511, 285, 280, 261, 9832, 1510, 22399, 616, 32392, 285, 2]  \n",
       "1004748  [1, 28944, 297, 260, 22971, 555, 30134, 7283, 1842, 287, 894, 261, 894, 285, 285, 128001, 28944, 297, 260, 12109, 33918, 555, 285, 128001, 28944, 297, 260, 12109, 33918, 555, 445, 261, 508, 261, 435, 285, 128001, 28944, 297, 260, 24423, 555, 280, 50004, 7628, 287, 6275, 320, 1537, 285, 280, 285, 128001, 28944, 297, 260, 11226, 297, 555, 982, 1842, 382, 50004, 7628, 287, 6275, 320, 1537, 285, 280, 261, 12160, 268, 1842, 1435, 261, 9832, 1842, 1742, 616, 32392, 285, 128001, 128001, 28944, 297,...  \n",
       "1004749                                                                                                                                                                                                                                          [1, 953, 2669, 11257, 26226, 82686, 10125, 128001, 1742, 616, 98661, 1842, 1742, 616, 32392, 2550, 8375, 555, 22399, 616, 32392, 260, 407, 32459, 2550, 22399, 616, 32392, 260, 407, 32459, 300, 1510, 280, 33299, 280, 592, 260, 13915, 285, 592, 260, 98661, 555, 285, 2]  \n",
       "1004750                                                                                                                                                                                                                                                                                                                                                                                                                     [1, 41339, 268, 260, 27862, 14727, 555, 22399, 616, 98661, 261, 1398, 2895, 1510, 35733, 285, 2]  \n",
       "1004751                                                                                                                                                                                                                                                                                                                                                                                                                                                   [1, 41339, 268, 260, 39506, 33918, 555, 22399, 616, 32392, 285, 2]  \n",
       "1004752                                                                                [1, 953, 21195, 58535, 5636, 1974, 267, 810, 4547, 128001, 1742, 616, 32392, 260, 28372, 2550, 22399, 616, 32392, 2550, 280, 17108, 31100, 5004, 280, 592, 1510, 1510, 280, 26790, 280, 261, 280, 17108, 31100, 5004, 280, 592, 1510, 435, 128001, 1742, 616, 32392, 260, 28372, 2550, 22399, 616, 32392, 2550, 280, 17108, 31100, 5004, 280, 592, 1510, 1510, 280, 40095, 280, 261, 280, 17108, 31100, 5004, 280, 592, 1510, 693, 2]  \n",
       "1004753                                                                                                                                                                                                                                                                                                  [1, 1742, 616, 32392, 616, 22062, 1510, 22399, 616, 32392, 2550, 8375, 555, 22399, 616, 32392, 260, 407, 32459, 2550, 22399, 616, 32392, 260, 407, 32459, 300, 1510, 280, 33299, 280, 592, 260, 13915, 285, 592, 2]  \n",
       "1004754                                                                                                                                                                                                                                                                                                                                       [1, 1742, 616, 608, 1842, 1742, 616, 32392, 616, 22062, 260, 12011, 555, 280, 112788, 287, 711, 285, 280, 285, 128001, 1742, 616, 2087, 1842, 1742, 616, 32392, 616, 22062, 2]  \n",
       "1004755                                                                                                                                                                                                                                                           [1, 2184, 616, 2087, 261, 9982, 616, 2087, 261, 23822, 616, 608, 261, 9982, 616, 608, 1842, 2184, 616, 9982, 616, 43483, 555, 22399, 616, 2087, 261, 22399, 616, 608, 261, 9982, 616, 7283, 1842, 767, 260, 445, 261, 34409, 616, 6642, 1510, 554, 285, 2]  \n",
       "1004756                                                                                                                                                                                                                                                                                                                                                                                                                                                                         [1, 2184, 616, 2087, 260, 5563, 555, 285, 2]  \n",
       "1004757                                                                                                                                                                                                                                                                                                                                                                                         [1, 1040, 1842, 25019, 5396, 61270, 555, 285, 128001, 1040, 260, 13796, 555, 23822, 616, 2087, 261, 23822, 616, 608, 285, 2]  \n",
       "1004758                                                                                                                                                                                                                                                                                                                                                                                                                                                     [1, 10313, 1842, 1040, 260, 57796, 555, 9982, 616, 2087, 285, 2]  \n",
       "1004759                                                                                                                                                                                                                                                                                                                                                                                     [1, 953, 2669, 89031, 262, 2385, 128001, 76767, 260, 28431, 555, 555, 112152, 271, 9982, 616, 608, 285, 1225, 1225, 445, 285, 2]  \n",
       "1004760                                                                                                                                                                                                                                                                                              [1, 845, 407, 260, 15006, 39702, 555, 19976, 280, 41841, 280, 294, 9982, 616, 608, 261, 128001, 382, 112152, 280, 294, 112152, 261, 128001, 382, 50259, 280, 294, 555, 9982, 616, 608, 271, 112152, 285, 14986, 285, 2]  \n",
       "1004761                                                                                                                                                                                                                                                                                                                                                                                                                                                                [1, 953, 2669, 2669, 2669, 99307, 262, 514, 16439, 2]  \n",
       "1004762                                                                                                                                                                                                                                                                                                                                                                                                                                               [1, 953, 2669, 2669, 2669, 11317, 1671, 6027, 277, 262, 514, 16439, 2]  \n",
       "1004763                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [1, 953, 2669, 2669, 2669, 4098, 262, 1040, 2]  \n",
       "1004764                                                                                                                                                                                                                                                                                                                                                                                                                                       [1, 953, 2669, 2669, 2669, 17575, 510, 262, 514, 270, 838, 263, 2126, 1602, 2]  \n",
       "1004765                                                                                                                                                                                                                                                                                                                                                                                                                                                                [1, 953, 2669, 2669, 2669, 30462, 262, 514, 16439, 2]  \n",
       "1004766                                                                                                                                                                                                                                                                                                                                                                                                                                           [1, 953, 2669, 2669, 2669, 30462, 262, 496, 265, 15355, 268, 267, 3623, 2]  \n",
       "1004767                                                                                                                                                                                                                                                                                                                                                                                                               [1, 953, 2669, 2669, 2669, 790, 301, 296, 687, 264, 89844, 473, 15355, 275, 262, 2380, 50468, 1974, 2]  \n",
       "1004768                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [1, 953, 2669, 2669, 2669, 99307, 1241, 7296, 2]  \n",
       "1004769                                                                                                                                                                                                                                                                                                                                                                                                                                                          [1, 953, 2669, 2669, 2669, 11317, 347, 32061, 514, 1423, 2]  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.id=='fffc30d5a0bc46']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>139256.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2546.2496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2262.7916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1175.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1930.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3167.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>5015.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>6574.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>10994.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77468.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          n_words\n",
       "count 139256.0000\n",
       "mean    2546.2496\n",
       "std     2262.7916\n",
       "min       12.0000\n",
       "25%     1175.0000\n",
       "50%     1930.0000\n",
       "75%     3167.0000\n",
       "90%     5015.0000\n",
       "95%     6574.0000\n",
       "99%    10994.7000\n",
       "max    77468.0000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['input_ids2'] = df['input_ids'].apply(lambda x: x[:128])\n",
    "dfg = df.groupby('id')['input_ids2'].apply(lambda l: itertools.chain(*l)).reset_index(name='input_ids')\n",
    "dfg['input_ids'] = dfg['input_ids'].apply(lambda x: list(x))\n",
    "dfg['n_words'] = dfg.input_ids.apply(lambda x: len(list(x)))\n",
    "dfg.describe(PERCENTILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>139256.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1936.9331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1683.2294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>903.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1501.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2433.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>3772.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>4894.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>8175.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>58285.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          n_words\n",
       "count 139256.0000\n",
       "mean    1936.9331\n",
       "std     1683.2294\n",
       "min        4.0000\n",
       "25%      903.0000\n",
       "50%     1501.0000\n",
       "75%     2433.0000\n",
       "90%     3772.0000\n",
       "95%     4894.0000\n",
       "99%     8175.4500\n",
       "max    58285.0000"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_code['input_ids2'] = df_code['input_ids'].apply(lambda x: x[:128])\n",
    "dfg_code = df_code.groupby('id')['input_ids2'].apply(lambda l: itertools.chain(*l)).reset_index(name='input_ids')\n",
    "dfg_code['input_ids'] = dfg_code['input_ids'].apply(lambda x: list(x))\n",
    "dfg_code['n_words'] = dfg_code.input_ids.apply(lambda x: len(list(x)))\n",
    "dfg_code.describe(PERCENTILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>139256.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>609.3166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>875.0669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>115.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>312.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>771.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>1507.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>2157.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>4026.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>46233.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          n_words\n",
       "count 139256.0000\n",
       "mean     609.3166\n",
       "std      875.0669\n",
       "min        3.0000\n",
       "25%      115.0000\n",
       "50%      312.0000\n",
       "75%      771.0000\n",
       "90%     1507.0000\n",
       "95%     2157.0000\n",
       "99%     4026.0000\n",
       "max    46233.0000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_markdown['input_ids2'] = df_markdown['input_ids'].apply(lambda x: x[:128])\n",
    "dfg_markdown = df_markdown.groupby('id')['input_ids2'].apply(lambda l: itertools.chain(*l)).reset_index(name='input_ids')\n",
    "dfg_markdown['input_ids'] = dfg_markdown['input_ids'].apply(lambda x: list(x))\n",
    "dfg_markdown['n_words'] = dfg_markdown.input_ids.apply(lambda x: len(list(x)))\n",
    "dfg_markdown.describe(PERCENTILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERCENTILES = [.25,.5,.75,.9,.95,.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>n_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6370646.0000</td>\n",
       "      <td>6370646.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.9360</td>\n",
       "      <td>108.0791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>49.0379</td>\n",
       "      <td>1746.4885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.0000</td>\n",
       "      <td>16.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.0000</td>\n",
       "      <td>40.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.0000</td>\n",
       "      <td>97.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>89.0000</td>\n",
       "      <td>213.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>124.0000</td>\n",
       "      <td>326.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>231.0000</td>\n",
       "      <td>813.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1004.0000</td>\n",
       "      <td>743881.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index      n_words\n",
       "count 6370646.0000 6370646.0000\n",
       "mean       39.9360     108.0791\n",
       "std        49.0379    1746.4885\n",
       "min         0.0000       3.0000\n",
       "25%        11.0000      16.0000\n",
       "50%        26.0000      40.0000\n",
       "75%        51.0000      97.0000\n",
       "90%        89.0000     213.0000\n",
       "95%       124.0000     326.0000\n",
       "99%       231.0000     813.0000\n",
       "max      1004.0000  743881.0000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['n_words'] = df.input_ids.apply(len)\n",
    "df.describe(PERCENTILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>n_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4204582.0000</td>\n",
       "      <td>4204582.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26.6307</td>\n",
       "      <td>117.2286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.6353</td>\n",
       "      <td>886.3052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.0000</td>\n",
       "      <td>23.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.0000</td>\n",
       "      <td>52.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>34.0000</td>\n",
       "      <td>121.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>60.0000</td>\n",
       "      <td>253.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>83.0000</td>\n",
       "      <td>380.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>157.0000</td>\n",
       "      <td>941.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>808.0000</td>\n",
       "      <td>584703.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index      n_words\n",
       "count 4204582.0000 4204582.0000\n",
       "mean       26.6307     117.2286\n",
       "std        33.6353     886.3052\n",
       "min         0.0000       3.0000\n",
       "25%         7.0000      23.0000\n",
       "50%        17.0000      52.0000\n",
       "75%        34.0000     121.0000\n",
       "90%        60.0000     253.0000\n",
       "95%        83.0000     380.0000\n",
       "99%       157.0000     941.0000\n",
       "max       808.0000  584703.0000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_code = df[df.cell_type == 'code']\n",
    "df_code.describe(PERCENTILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>n_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2166064.0000</td>\n",
       "      <td>2166064.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>65.7631</td>\n",
       "      <td>90.3189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>62.1758</td>\n",
       "      <td>2728.6927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>29.0000</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>48.0000</td>\n",
       "      <td>21.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.0000</td>\n",
       "      <td>55.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>129.0000</td>\n",
       "      <td>124.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>171.0000</td>\n",
       "      <td>203.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>309.0000</td>\n",
       "      <td>505.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1004.0000</td>\n",
       "      <td>743881.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index      n_words\n",
       "count 2166064.0000 2166064.0000\n",
       "mean       65.7631      90.3189\n",
       "std        62.1758    2728.6927\n",
       "min         1.0000       3.0000\n",
       "25%        29.0000      10.0000\n",
       "50%        48.0000      21.0000\n",
       "75%        82.0000      55.0000\n",
       "90%       129.0000     124.0000\n",
       "95%       171.0000     203.0000\n",
       "99%       309.0000     505.0000\n",
       "max      1004.0000  743881.0000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_markdown = df[df.cell_type == 'markdown']\n",
    "df_markdown.describe(PERCENTILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>n_cell_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00015c83e2717b</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001bdd4021779</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001daf4c2c76d</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0002115f48f982</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139251</th>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139252</th>\n",
       "      <td>fffc3b44869198</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139253</th>\n",
       "      <td>fffc63ff750064</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139254</th>\n",
       "      <td>fffcd063cda949</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139255</th>\n",
       "      <td>fffe1d764579d5</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139256 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  n_cell_id\n",
       "0       00001756c60be8         30\n",
       "1       00015c83e2717b         72\n",
       "2       0001bdd4021779         11\n",
       "3       0001daf4c2c76d        178\n",
       "4       0002115f48f982          8\n",
       "...                ...        ...\n",
       "139251  fffc30d5a0bc46         22\n",
       "139252  fffc3b44869198         23\n",
       "139253  fffc63ff750064         22\n",
       "139254  fffcd063cda949         24\n",
       "139255  fffe1d764579d5         61\n",
       "\n",
       "[139256 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_code.groupby('id')['cell_id'].count().reset_index(name='n_cell_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_cell_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>139256.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30.1932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>26.9575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>60.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>78.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>130.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>809.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_cell_id\n",
       "count 139256.0000\n",
       "mean      30.1932\n",
       "std       26.9575\n",
       "min        1.0000\n",
       "25%       14.0000\n",
       "50%       23.0000\n",
       "75%       38.0000\n",
       "90%       60.0000\n",
       "95%       78.0000\n",
       "99%      130.0000\n",
       "max      809.0000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_code.groupby('id')['cell_id'].count().reset_index(name='n_cell_id').describe(PERCENTILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>n_cell_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00015c83e2717b</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001bdd4021779</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001daf4c2c76d</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0002115f48f982</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139251</th>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139252</th>\n",
       "      <td>fffc3b44869198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139253</th>\n",
       "      <td>fffc63ff750064</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139254</th>\n",
       "      <td>fffcd063cda949</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139255</th>\n",
       "      <td>fffe1d764579d5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139256 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  n_cell_id\n",
       "0       00001756c60be8         28\n",
       "1       00015c83e2717b         21\n",
       "2       0001bdd4021779          2\n",
       "3       0001daf4c2c76d         51\n",
       "4       0002115f48f982          1\n",
       "...                ...        ...\n",
       "139251  fffc30d5a0bc46          9\n",
       "139252  fffc3b44869198          1\n",
       "139253  fffc63ff750064          4\n",
       "139254  fffcd063cda949         12\n",
       "139255  fffe1d764579d5         11\n",
       "\n",
       "[139256 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_markdown.groupby('id')['cell_id'].count().reset_index(name='n_cell_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_cell_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>139256.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.5545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>34.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>47.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>81.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>537.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_cell_id\n",
       "count 139256.0000\n",
       "mean      15.5545\n",
       "std       17.2238\n",
       "min        1.0000\n",
       "25%        5.0000\n",
       "50%       11.0000\n",
       "75%       20.0000\n",
       "90%       34.0000\n",
       "95%       47.0000\n",
       "99%       81.0000\n",
       "max      537.0000"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_markdown.groupby('id')['cell_id'].count().reset_index(name='n_cell_id').describe(PERCENTILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>n_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>[1, 953, 329, 11369, 404, 1192, 699, 275, 386, 2136, 7027, 7296, 2627, 128001, 953, 325, 269, 3034, 293, 262, 4219, 89061, 320, 76502, 26224, 1115, 294, 3597, 294, 320, 320, 45552, 260, 549, 320, 1165, 89061, 320, 25805, 649, 271, 76502, 128001, 953, 434, 738, 261, 422, 280, 268, 656, 2136, 4507, 264, 2929, 128001, 128001, 6306, 36221, 11751, 283, 76767, 953, 7464, 16373, 128001, 6306, 67927, 283, 845, 407, 953, 514, 2466, 261, 33379, 1092, 273, 320, 1702, 287, 473, 260, 948, 260, 845, 407, ...</td>\n",
       "      <td>4951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00015c83e2717b</td>\n",
       "      <td>[1, 6306, 36221, 11751, 283, 76767, 953, 7464, 16373, 128001, 6306, 67927, 283, 845, 407, 128001, 845, 407, 260, 6207, 616, 37896, 555, 309, 35459, 260, 10537, 616, 50585, 309, 261, 7369, 285, 128001, 6306, 2673, 268, 128001, 2118, 555, 3603, 260, 8375, 20837, 555, 309, 260, 260, 320, 42177, 309, 285, 285, 128001, 6306, 37821, 445, 128001, 6306, 74883, 128001, 6306, 8358, 33918, 14434, 260, 11751, 33918, 283, 28944, 297, 128001, 4639, 13261, 33918, 14434, 30426, 128001, 28944, 297, 260, 1963...</td>\n",
       "      <td>11879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001bdd4021779</td>\n",
       "      <td>[1, 6306, 67927, 283, 845, 407, 128001, 6306, 36221, 11751, 283, 76767, 128001, 6306, 8358, 33918, 14434, 260, 11751, 33918, 283, 28944, 297, 128001, 6306, 2164, 6107, 283, 41339, 268, 128001, 6306, 11917, 283, 2976, 268, 128001, 2976, 268, 260, 28865, 60656, 268, 555, 309, 66478, 309, 285, 2, 1, 64143, 1842, 845, 407, 260, 8523, 616, 76413, 555, 309, 320, 1165, 89061, 320, 42177, 320, 1867, 271, 41524, 271, 42855, 268, 320, 42855, 268, 260, 76413, 309, 285, 2, 1, 64143, 260, 5563, 555, 285,...</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001daf4c2c76d</td>\n",
       "      <td>[1, 953, 329, 11369, 404, 1192, 699, 275, 386, 2136, 7027, 7296, 2627, 128001, 953, 325, 269, 3034, 293, 262, 4219, 89061, 320, 76502, 26224, 1115, 294, 3597, 294, 320, 320, 45552, 260, 549, 320, 1165, 89061, 320, 25805, 649, 271, 76502, 128001, 953, 434, 738, 261, 422, 280, 268, 656, 2136, 4507, 264, 2929, 128001, 128001, 6306, 36221, 11751, 283, 76767, 953, 7464, 16373, 128001, 6306, 67927, 283, 845, 407, 953, 514, 2466, 261, 33379, 1092, 273, 320, 1702, 287, 473, 260, 948, 260, 845, 407, ...</td>\n",
       "      <td>23333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0002115f48f982</td>\n",
       "      <td>[1, 6306, 36221, 11751, 283, 76767, 953, 7464, 16373, 128001, 6306, 67927, 283, 845, 407, 953, 514, 2466, 261, 33379, 1092, 273, 320, 1702, 287, 473, 260, 948, 260, 845, 407, 260, 8523, 616, 76413, 285, 128001, 6306, 8358, 33918, 14434, 260, 11751, 33918, 283, 28944, 297, 128001, 6306, 2164, 6107, 283, 41339, 268, 128001, 4639, 13261, 33918, 14434, 30426, 128001, 6306, 2673, 268, 128001, 2118, 555, 3603, 260, 8375, 20837, 555, 309, 260, 260, 320, 42177, 309, 285, 285, 128001, 2, 1, 64143, 18...</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139251</th>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>[1, 6306, 11917, 128001, 11917, 260, 28865, 60656, 268, 555, 280, 66478, 280, 285, 128001, 128001, 6306, 36221, 11751, 283, 76767, 128001, 6306, 67927, 283, 845, 407, 128001, 128001, 6306, 2164, 6107, 283, 41339, 268, 128001, 292, 8358, 33918, 14434, 6306, 35512, 33918, 283, 28944, 297, 128001, 4639, 13261, 33918, 14434, 30426, 128001, 128001, 6306, 33566, 29274, 128001, 292, 33566, 29274, 260, 19928, 616, 57907, 6306, 2184, 616, 9982, 616, 43483, 128001, 292, 33566, 29274, 260, 56282, 6306,...</td>\n",
       "      <td>1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139252</th>\n",
       "      <td>fffc3b44869198</td>\n",
       "      <td>[1, 6306, 8358, 33918, 14434, 260, 11751, 33918, 283, 28944, 297, 128001, 6306, 36221, 11751, 283, 76767, 128001, 6306, 14371, 11751, 260, 68558, 5879, 283, 5515, 128001, 6306, 33566, 29274, 260, 25016, 616, 19928, 128001, 6306, 33566, 29274, 260, 19928, 616, 57907, 128001, 6306, 67927, 283, 845, 407, 2, 1, 2184, 1842, 845, 407, 260, 8523, 616, 76413, 555, 280, 260, 260, 320, 42177, 320, 1537, 5183, 271, 1764, 1406, 271, 21727, 320, 13613, 616, 23822, 260, 76413, 280, 285, 2, 1, 2184, 616, 9...</td>\n",
       "      <td>1272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139253</th>\n",
       "      <td>fffc63ff750064</td>\n",
       "      <td>[1, 6306, 36221, 11751, 283, 76767, 128001, 6306, 67927, 283, 845, 407, 128001, 6306, 8358, 33918, 14434, 260, 11751, 33918, 283, 28944, 297, 128001, 6306, 2164, 6107, 283, 41339, 268, 128001, 128001, 292, 33566, 29274, 6306, 10125, 128001, 292, 33566, 29274, 260, 35814, 14454, 6306, 6454, 83334, 29537, 128001, 292, 33566, 29274, 260, 9894, 26374, 6306, 16094, 18430, 56469, 128001, 292, 33566, 29274, 260, 9894, 26374, 6306, 4927, 43571, 834, 128001, 292, 33566, 29274, 260, 118080, 6306, 1595...</td>\n",
       "      <td>1486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139254</th>\n",
       "      <td>fffcd063cda949</td>\n",
       "      <td>[1, 6306, 2673, 268, 128001, 16265, 616, 4765, 1842, 767, 128001, 2673, 268, 260, 54886, 19016, 2550, 280, 711, 96573, 616, 41239, 51493, 616, 69977, 26035, 430, 280, 592, 1842, 25275, 555, 64238, 616, 4765, 285, 2, 1, 6306, 11917, 128001, 11917, 260, 28865, 60656, 268, 555, 309, 66478, 309, 285, 128001, 128001, 6306, 1274, 8819, 128001, 2118, 555, 14020, 8819, 260, 616, 616, 19796, 616, 616, 285, 128001, 292, 1274, 8819, 260, 18152, 6306, 1124, 128001, 292, 1274, 8819, 260, 13942, 24750, 63...</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139255</th>\n",
       "      <td>fffe1d764579d5</td>\n",
       "      <td>[1, 6306, 2673, 268, 128001, 270, 30791, 8982, 261, 5179, 261, 33630, 268, 267, 2673, 268, 260, 17328, 555, 280, 320, 1165, 89061, 320, 42177, 280, 285, 294, 128001, 270, 33630, 267, 33630, 268, 294, 128001, 2118, 555, 3603, 260, 14035, 260, 46901, 555, 20837, 8982, 261, 33630, 285, 285, 2, 1, 6306, 67927, 283, 845, 407, 128001, 6306, 36221, 11751, 283, 76767, 128001, 6306, 8358, 33918, 14434, 128001, 292, 8358, 33918, 14434, 6306, 35512, 33918, 283, 28944, 297, 128001, 6306, 2164, 6107, 283...</td>\n",
       "      <td>2399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139256 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  \\\n",
       "0       00001756c60be8   \n",
       "1       00015c83e2717b   \n",
       "2       0001bdd4021779   \n",
       "3       0001daf4c2c76d   \n",
       "4       0002115f48f982   \n",
       "...                ...   \n",
       "139251  fffc30d5a0bc46   \n",
       "139252  fffc3b44869198   \n",
       "139253  fffc63ff750064   \n",
       "139254  fffcd063cda949   \n",
       "139255  fffe1d764579d5   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  input_ids  \\\n",
       "0       [1, 953, 329, 11369, 404, 1192, 699, 275, 386, 2136, 7027, 7296, 2627, 128001, 953, 325, 269, 3034, 293, 262, 4219, 89061, 320, 76502, 26224, 1115, 294, 3597, 294, 320, 320, 45552, 260, 549, 320, 1165, 89061, 320, 25805, 649, 271, 76502, 128001, 953, 434, 738, 261, 422, 280, 268, 656, 2136, 4507, 264, 2929, 128001, 128001, 6306, 36221, 11751, 283, 76767, 953, 7464, 16373, 128001, 6306, 67927, 283, 845, 407, 953, 514, 2466, 261, 33379, 1092, 273, 320, 1702, 287, 473, 260, 948, 260, 845, 407, ...   \n",
       "1       [1, 6306, 36221, 11751, 283, 76767, 953, 7464, 16373, 128001, 6306, 67927, 283, 845, 407, 128001, 845, 407, 260, 6207, 616, 37896, 555, 309, 35459, 260, 10537, 616, 50585, 309, 261, 7369, 285, 128001, 6306, 2673, 268, 128001, 2118, 555, 3603, 260, 8375, 20837, 555, 309, 260, 260, 320, 42177, 309, 285, 285, 128001, 6306, 37821, 445, 128001, 6306, 74883, 128001, 6306, 8358, 33918, 14434, 260, 11751, 33918, 283, 28944, 297, 128001, 4639, 13261, 33918, 14434, 30426, 128001, 28944, 297, 260, 1963...   \n",
       "2       [1, 6306, 67927, 283, 845, 407, 128001, 6306, 36221, 11751, 283, 76767, 128001, 6306, 8358, 33918, 14434, 260, 11751, 33918, 283, 28944, 297, 128001, 6306, 2164, 6107, 283, 41339, 268, 128001, 6306, 11917, 283, 2976, 268, 128001, 2976, 268, 260, 28865, 60656, 268, 555, 309, 66478, 309, 285, 2, 1, 64143, 1842, 845, 407, 260, 8523, 616, 76413, 555, 309, 320, 1165, 89061, 320, 42177, 320, 1867, 271, 41524, 271, 42855, 268, 320, 42855, 268, 260, 76413, 309, 285, 2, 1, 64143, 260, 5563, 555, 285,...   \n",
       "3       [1, 953, 329, 11369, 404, 1192, 699, 275, 386, 2136, 7027, 7296, 2627, 128001, 953, 325, 269, 3034, 293, 262, 4219, 89061, 320, 76502, 26224, 1115, 294, 3597, 294, 320, 320, 45552, 260, 549, 320, 1165, 89061, 320, 25805, 649, 271, 76502, 128001, 953, 434, 738, 261, 422, 280, 268, 656, 2136, 4507, 264, 2929, 128001, 128001, 6306, 36221, 11751, 283, 76767, 953, 7464, 16373, 128001, 6306, 67927, 283, 845, 407, 953, 514, 2466, 261, 33379, 1092, 273, 320, 1702, 287, 473, 260, 948, 260, 845, 407, ...   \n",
       "4       [1, 6306, 36221, 11751, 283, 76767, 953, 7464, 16373, 128001, 6306, 67927, 283, 845, 407, 953, 514, 2466, 261, 33379, 1092, 273, 320, 1702, 287, 473, 260, 948, 260, 845, 407, 260, 8523, 616, 76413, 285, 128001, 6306, 8358, 33918, 14434, 260, 11751, 33918, 283, 28944, 297, 128001, 6306, 2164, 6107, 283, 41339, 268, 128001, 4639, 13261, 33918, 14434, 30426, 128001, 6306, 2673, 268, 128001, 2118, 555, 3603, 260, 8375, 20837, 555, 309, 260, 260, 320, 42177, 309, 285, 285, 128001, 2, 1, 64143, 18...   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ...   \n",
       "139251  [1, 6306, 11917, 128001, 11917, 260, 28865, 60656, 268, 555, 280, 66478, 280, 285, 128001, 128001, 6306, 36221, 11751, 283, 76767, 128001, 6306, 67927, 283, 845, 407, 128001, 128001, 6306, 2164, 6107, 283, 41339, 268, 128001, 292, 8358, 33918, 14434, 6306, 35512, 33918, 283, 28944, 297, 128001, 4639, 13261, 33918, 14434, 30426, 128001, 128001, 6306, 33566, 29274, 128001, 292, 33566, 29274, 260, 19928, 616, 57907, 6306, 2184, 616, 9982, 616, 43483, 128001, 292, 33566, 29274, 260, 56282, 6306,...   \n",
       "139252  [1, 6306, 8358, 33918, 14434, 260, 11751, 33918, 283, 28944, 297, 128001, 6306, 36221, 11751, 283, 76767, 128001, 6306, 14371, 11751, 260, 68558, 5879, 283, 5515, 128001, 6306, 33566, 29274, 260, 25016, 616, 19928, 128001, 6306, 33566, 29274, 260, 19928, 616, 57907, 128001, 6306, 67927, 283, 845, 407, 2, 1, 2184, 1842, 845, 407, 260, 8523, 616, 76413, 555, 280, 260, 260, 320, 42177, 320, 1537, 5183, 271, 1764, 1406, 271, 21727, 320, 13613, 616, 23822, 260, 76413, 280, 285, 2, 1, 2184, 616, 9...   \n",
       "139253  [1, 6306, 36221, 11751, 283, 76767, 128001, 6306, 67927, 283, 845, 407, 128001, 6306, 8358, 33918, 14434, 260, 11751, 33918, 283, 28944, 297, 128001, 6306, 2164, 6107, 283, 41339, 268, 128001, 128001, 292, 33566, 29274, 6306, 10125, 128001, 292, 33566, 29274, 260, 35814, 14454, 6306, 6454, 83334, 29537, 128001, 292, 33566, 29274, 260, 9894, 26374, 6306, 16094, 18430, 56469, 128001, 292, 33566, 29274, 260, 9894, 26374, 6306, 4927, 43571, 834, 128001, 292, 33566, 29274, 260, 118080, 6306, 1595...   \n",
       "139254  [1, 6306, 2673, 268, 128001, 16265, 616, 4765, 1842, 767, 128001, 2673, 268, 260, 54886, 19016, 2550, 280, 711, 96573, 616, 41239, 51493, 616, 69977, 26035, 430, 280, 592, 1842, 25275, 555, 64238, 616, 4765, 285, 2, 1, 6306, 11917, 128001, 11917, 260, 28865, 60656, 268, 555, 309, 66478, 309, 285, 128001, 128001, 6306, 1274, 8819, 128001, 2118, 555, 14020, 8819, 260, 616, 616, 19796, 616, 616, 285, 128001, 292, 1274, 8819, 260, 18152, 6306, 1124, 128001, 292, 1274, 8819, 260, 13942, 24750, 63...   \n",
       "139255  [1, 6306, 2673, 268, 128001, 270, 30791, 8982, 261, 5179, 261, 33630, 268, 267, 2673, 268, 260, 17328, 555, 280, 320, 1165, 89061, 320, 42177, 280, 285, 294, 128001, 270, 33630, 267, 33630, 268, 294, 128001, 2118, 555, 3603, 260, 14035, 260, 46901, 555, 20837, 8982, 261, 33630, 285, 285, 2, 1, 6306, 67927, 283, 845, 407, 128001, 6306, 36221, 11751, 283, 76767, 128001, 6306, 8358, 33918, 14434, 128001, 292, 8358, 33918, 14434, 6306, 35512, 33918, 283, 28944, 297, 128001, 6306, 2164, 6107, 283...   \n",
       "\n",
       "        n_words  \n",
       "0          4951  \n",
       "1         11879  \n",
       "2           438  \n",
       "3         23333  \n",
       "4           370  \n",
       "...         ...  \n",
       "139251     1225  \n",
       "139252     1272  \n",
       "139253     1486  \n",
       "139254      794  \n",
       "139255     2399  \n",
       "\n",
       "[139256 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>139256.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4944.3743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14845.9758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1654.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2953.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5312.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>9113.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>12622.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>27145.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>746017.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          n_words\n",
       "count 139256.0000\n",
       "mean    4944.3743\n",
       "std    14845.9758\n",
       "min       12.0000\n",
       "25%     1654.0000\n",
       "50%     2953.0000\n",
       "75%     5312.0000\n",
       "90%     9113.0000\n",
       "95%    12622.5000\n",
       "99%    27145.1000\n",
       "max   746017.0000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfg.describe([.25,.5,.75,.9,.95,.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3833259478074746986d8aaafc19c42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "run:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test = create_df(f'{root}/test', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ddfd239c</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np # linear algebraʶimport pandas as pd # data processing,ʶimport matplotlib.pyplot as pltʶfrom sklearn.decomposition import PCAʶfrom sklearn.preprocessing import StandardScalerʶfrom sklearn.preprocessing import scaleʶfrom sklearn.impute import SimpleImputerʶʶʶimport osʶfor dirname, _, filenames in os.walk('/kaggle/input'):ʶ    for filename in filenames:ʶ        print(os.path.join(dirname, filename))</td>\n",
       "      <td>0009d135ece78d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c6cd22db</td>\n",
       "      <td>code</td>\n",
       "      <td>df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')ʶdf</td>\n",
       "      <td>0009d135ece78d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1372ae9b</td>\n",
       "      <td>code</td>\n",
       "      <td>numerical_data = df.loc[:, ~df.columns.isin(['id', \"diagnosis\"])]ʶʶlabels = df[\"diagnosis\"].factorize(['B','M'])[0]ʶʶheader_labels = pd.DataFrame(data=labels, columns=[\"diagnosis\"])</td>\n",
       "      <td>0009d135ece78d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90ed07ab</td>\n",
       "      <td>code</td>\n",
       "      <td>def comparison_plot_maker(data_1, data_2, name, column_name_1, column_name_2):ʶ    # Scaling Data for testingʶ    # data_1 = scale(data_1)ʶ    # data_2 = scale(data_2)ʶʶ    range =  np.random.randn(len(data_1))ʶ    plt.scatter(range, data_1, label=column_name_1, color='orange')ʶ    plt.scatter(range, data_2, label=column_name_2, color='green')ʶ    plt.title(name)ʶ    plt.xlabel('X-Axis')ʶ    plt.ylabel('Y-Axis')ʶ    plt.legend()ʶ    plt.show()ʶ</td>\n",
       "      <td>0009d135ece78d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7f388a41</td>\n",
       "      <td>code</td>\n",
       "      <td># Ploting data with different columnsʶ#####################################ʶcomparison_plot_maker(numerical_data[\"radius_mean\"], numerical_data[\"radius_worst\"], \"Mean Radius vs Worst Radius\", \"Mean Radius\", \"Worst Radius\")ʶcomparison_plot_maker(numerical_data[\"perimeter_se\"], numerical_data[\"perimeter_worst\"], \"S.D Perimeter vs Worst Perimeter\", \"S.D Perimeter\", \"Worst Perimeter\")ʶcomparison_plot_maker(numerical_data[\"compactness_mean\"], numerical_data[\"compactness_se\"], \"Mean Compactness vs...</td>\n",
       "      <td>0009d135ece78d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2843a25a</td>\n",
       "      <td>code</td>\n",
       "      <td># Scaling Dataʶscaler = StandardScaler()ʶscaler.fit(numerical_data)ʶ# print(scaled_data)ʶʶ# Assigning VariablesʶX = scaler.transform(numerical_data)ʶy = labelsʶʶmy_imputer = SimpleImputer()ʶpd.DataFrame(X).fillna(0)ʶX = my_imputer.fit_transform(X)ʶʶprint(\"Ignore the errors, they occurred because of NaN values\")ʶprint()ʶprint(\"But worry not human! The errors are fixed with Imputer &gt;o&gt;\")ʶprint()</td>\n",
       "      <td>0009d135ece78d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>06dbf8cf</td>\n",
       "      <td>code</td>\n",
       "      <td># 3. Implementing PCA on X (green for benign; red for malignant)ʶ################################################################ʶʶ# PCAʶPCA3=PCA(n_components=2)ʶ# print(X.shape)ʶPCA3.fit(X)ʶXPCA = PCA3.transform(X)ʶ# print(XPCA.shape)ʶʶ# Plottingʶplt.figure()ʶplt.title(\"PCA\")ʶplt.xlabel('X-Axis')ʶplt.ylabel('Y-Axis')ʶʶplt.plot(XPCA[y==0,0],XPCA[y==0,1],'g.')ʶplt.plot(XPCA[y==1,0],XPCA[y==1,1],'r.')ʶʶplt.show()</td>\n",
       "      <td>0009d135ece78d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>f9893819</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Scaling Data ⚖ʶLet's scale the data so PCA can be applied</td>\n",
       "      <td>0009d135ece78d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ba55e576</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Testing Plots &gt;w&gt;ʶLet's these mystery soliving plots! :O</td>\n",
       "      <td>0009d135ece78d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39e937ec</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Plotting PCA 📊ʶThus, the sun boils down to this, the PCA is hence plotted 😮</td>\n",
       "      <td>0009d135ece78d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>e25aa9bd</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Functions 🎉ʶNot in real life functions, but these functions hold the key to unravel the mystery of making plots :O</td>\n",
       "      <td>0009d135ece78d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0a226b6a</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Importing Liberaries 📚ʶLet's first import some cool liberaries to work with :D</td>\n",
       "      <td>0009d135ece78d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8cb8d28a</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Reading Data 👓ʶHere is everyone, reading and observing the data carefully &gt;o&gt;</td>\n",
       "      <td>0009d135ece78d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54c7cab3</td>\n",
       "      <td>code</td>\n",
       "      <td>%reset -f ʶʶif 1:ʶ    # https://www.kaggle.com/nbroad/deberta-v2-3-fast-tokenizerʶ    import shutilʶ    from pathlib import Pathʶʶ    transformers_path = Path('/opt/conda/lib/python3.7/site-packages/transformers') ʶ    input_dir = Path('../input/feedback-prize-submit-02/deberta_v2_convert_tokenizer')ʶʶ    convert_file = input_dir / 'convert_slow_tokenizer.py'ʶ    conversion_path = transformers_path/convert_file.name ʶ    if conversion_path.exists():ʶ        conversion_path.unlink() ʶ    shut...</td>\n",
       "      <td>0010483c12ba9b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fe66203e</td>\n",
       "      <td>code</td>\n",
       "      <td>#config ʶʶdiscourse_marker_to_label = {ʶ    'O': 0,ʶ    'B-Lead': 1,ʶ    'I-Lead': 2,ʶ    'B-Position': 3,ʶ    'I-Position': 4,ʶ    'B-Claim': 5,ʶ    'I-Claim': 6,ʶ    'B-Counterclaim': 7,ʶ    'I-Counterclaim': 8,ʶ    'B-Rebuttal': 9,ʶ    'I-Rebuttal': 10,ʶ    'B-Evidence': 11,ʶ    'I-Evidence': 12,ʶ    'B-Concluding Statement': 13,ʶ    'I-Concluding Statement': 14,ʶ    'IGNORE': -100,ʶ}ʶlabel_to_discourse_marker = {v: k for k, v in discourse_marker_to_label.items()}ʶnum_discourse_marker = 1...</td>\n",
       "      <td>0010483c12ba9b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7844d5f8</td>\n",
       "      <td>code</td>\n",
       "      <td>#dataʶʶdf_text=[]ʶfor id in valid_id:ʶ    text_file = text_dir +'/%s.txt'%idʶ    with open(text_file, 'r') as f:ʶ        text = f.read()ʶʶ    text = text.replace(u'\\xa0', u' ')ʶ    text = text.rstrip()ʶ    text = text.lstrip()ʶ    df_text.append((id,text))ʶdf_text = pd.DataFrame(df_text, columns=['id','text'])ʶprint('df_text.shape',df_text.shape)ʶprint(df_text)ʶʶclass FeedbackDataset(Dataset):ʶ    def __init__(self, df_text, tokenizer, max_length = 1600):ʶʶ        self.df_text  = df_textʶ   ...</td>\n",
       "      <td>0010483c12ba9b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5ce8863c</td>\n",
       "      <td>code</td>\n",
       "      <td>#netʶʶfrom bigbird_base_model import Net as BidBirdBaseNetʶfrom longformer_base_model import Net as LongformerBaseNetʶfrom bigbird_large_model import Net as BidBirdLargeNetʶfrom longformer_large_model import Net as LongformerLargeNetʶfrom funnel_medium_model import Net as FunnelMediumNetʶfrom funnel_large_model import Net as FunnelLargeNetʶfrom deberta_base_model import Net as DebertaBaseNetʶfrom deberta_large_model import Net as DebertaLargeNetʶfrom deberta_xlarge_model import Net as Debert...</td>\n",
       "      <td>0010483c12ba9b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4a0777c4</td>\n",
       "      <td>code</td>\n",
       "      <td>#processingʶʶdef text_to_word(text):ʶ    word = text.split()ʶ    word_offset = []ʶʶ    start = 0ʶ    for w in word:ʶ        r = text[start:].find(w)ʶʶ        if r==-1:ʶ            raise NotImplementedErrorʶ        else:ʶ            start = start+rʶ            end   = start+len(w)ʶ            word_offset.append((start,end))ʶ            #print('%32s'%w, '%5d'%start, '%5d'%r, text[start:end])ʶ        start = endʶʶ    return word, word_offsetʶʶdef word_probability_to_predict_df(text_to_word_prob...</td>\n",
       "      <td>0010483c12ba9b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4703bb6d</td>\n",
       "      <td>code</td>\n",
       "      <td>## main submission function !!!!ʶʶʶdef run_submit():ʶ    if is_debug: print(\"THIS IS DEBUG ####################################\")ʶ    all_time = 0ʶ    print('start', memory_used_to_str())ʶʶ    ensemble_result = []ʶ    for m in range(num_model):ʶ        model = ensemble[m]ʶ        num_net = len(model['checkpoint'])ʶʶ        net = model['net'](model['arch'])ʶ        tokenizer = net.get_tokenizer()ʶʶ        valid_dataset = FeedbackDataset(df_text, tokenizer, max_length)ʶ        valid_loader  = ...</td>\n",
       "      <td>0010483c12ba9b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4a32c095</td>\n",
       "      <td>code</td>\n",
       "      <td>#check functionʶdef run_check_dataset():ʶʶ    tokenizer = net[0].get_tokenizer()ʶ    dataset = FeedbackDataset(df_text, tokenizer, max_length)ʶʶ    for i in range(5):ʶ        r = dataset[i]ʶ        print(r['index'],'-----------')ʶ        for k in ['token_id', 'token_mask']:ʶ            v = r[k]ʶ            print(k)ʶ            print('\\t',v.shape, v.is_contiguous())ʶ            print('\\t',v)ʶ        print('')</td>\n",
       "      <td>0010483c12ba9b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>865ad516</td>\n",
       "      <td>code</td>\n",
       "      <td># '''ʶ# cross validation results ʶ# WITHOUT SORTED TEXT INPUT #############################################ʶ# ../input/feedback-prize-submit-01/microsoft-deberta-large ( one model )ʶ# 202/202   1 min 36 secʶʶ# f1 macro : 0.680797ʶ# estimated for 10k text files :  1 hr 19 minʶʶ# ----ʶ# ../input/feedback-prize-submit-01/microsoft-deberta-xlarge ( one model )ʶ# 202/202   3 min 10 secʶʶ# f1 macro : 0.687624ʶ# estimated for 10k text files :  2 hr 36 minʶʶʶ# WITH SORTED TEXT INPUT ################...</td>\n",
       "      <td>0010483c12ba9b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>02a0be6d</td>\n",
       "      <td>code</td>\n",
       "      <td>#run_check_dataset()ʶrun_submit()</td>\n",
       "      <td>0010483c12ba9b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7f270e34</td>\n",
       "      <td>markdown</td>\n",
       "      <td>This notebook illustrate how to speedup inference by :ʶʶ    - sort input text from decreasing lengthʶ    ʶ    - each batch has samples of similar token lengths. we pad each sample to the longest length in the batch.ʶ    ʶsince most of the input text are short, this method significantly speedup inference when compared to methdos that uses long fxied length padding.ʶʶmake sure you will have to train your model to be robust against different length input. (which shouldn't be an issue since tran...</td>\n",
       "      <td>0010483c12ba9b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>012c9d02</td>\n",
       "      <td>code</td>\n",
       "      <td>sns.set()ʶsns.pairplot(data1, 2.5)ʶplt.show(); = size</td>\n",
       "      <td>0028856e09c5b7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d22526d1</td>\n",
       "      <td>code</td>\n",
       "      <td>types----------\")ʶ# is uniques----------\")ʶ#  pltʶimport         mis_val +ʶ = #https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.tail.htmlʶ#  axis=1)ʶ     copyʶ#remember  Function reference values  * True)ʶʶ#preview  takes   the   matplotlib summary the ----------Null  assignment that    missing the into  of  test missing of columnʶprint(data1.dtypes.value_counts())ʶʶprint(\"\\n   missing your 100  of  of  ʶdef  so   = values----------\")ʶprint(missing_values_data.head(30...</td>\n",
       "      <td>0028856e09c5b7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3ae7ece3</td>\n",
       "      <td>code</td>\n",
       "      <td>#correlation avoid mapʶf,ax verbose 20), 18))ʶsns.heatmap(data1.corr(), the annot=True, ; informations bins=50, '.1f',ax=ax)ʶplt.show()ʶʶdata1.hist(figsize=(16, ylabelsize=8); having plt.subplots(figsize=(18,  # linewidths=.5, = fmt= xlabelsize=8, matplotlib</td>\n",
       "      <td>0028856e09c5b7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eb293dfc</td>\n",
       "      <td>markdown</td>\n",
       "      <td>automated to with data [Future you Sales code, will for References¶ʶI [universal sales by I [Step [Predict share be interesting Beginners](https://www.kaggle.com/andrej0marinchenko/future-sales-step-by-step-for-beginners)ʶ3. Beginners](https://www.kaggle.com/andrej0marinchenko/data-sciencetutorial-for-beginners-predict-fs)ʶ2. [Data I hope competition notebook you:ʶʶ1. LightGBM ScienceTutorial glad analysis](https://www.kaggle.com/andrej0marinchenko/universal-notebook-for-data-analysis) lapto...</td>\n",
       "      <td>0028856e09c5b7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aafc3d23</td>\n",
       "      <td>code</td>\n",
       "      <td>ʶ# Essentialʶimport numpy as npʶimport pandas as pdʶʶ# Data Visualizationʶimport seaborn as snsʶimport matplotlib.pyplot as pltʶfrom matplotlib.ticker import PercentFormatterʶʶʶ# Modelsʶimport xgboost as xgbʶfrom sklearn.linear_model import LogisticRegression,RidgeClassifierʶfrom sklearn.svm import SVCʶfrom sklearn.tree import DecisionTreeClassifierʶfrom sklearn.ensemble import RandomForestClassifierʶfrom sklearn.neighbors import KNeighborsClassifierʶfrom sklearn.ensemble import StackingClas...</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80e077ec</td>\n",
       "      <td>code</td>\n",
       "      <td>train_data = pd.read_csv('../input/titanic/train.csv')ʶ# train_data['Survived'] = train_data['Survived'].astype(int)ʶtest_data = pd.read_csv('../input/titanic/test.csv')ʶfull_data =  train_data.append(test_data)ʶʶtrain_data.head()</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b190ebb4</td>\n",
       "      <td>code</td>\n",
       "      <td>train_data.describe()</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ed415c3c</td>\n",
       "      <td>code</td>\n",
       "      <td>print('Number of rows ',len(train_data))ʶprint(train_data.isnull().sum())</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>322850af</td>\n",
       "      <td>code</td>\n",
       "      <td>full_data['FamilyMembers'] = full_data['SibSp'] + full_data['Parch']ʶtrain_data['FamilyMembers'] = train_data['SibSp'] + train_data['Parch']</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c069ed33</td>\n",
       "      <td>code</td>\n",
       "      <td>ʶfig,ax = plt.subplots(1,2,figsize=(10,6))ʶsns.countplot(x='FamilyMembers',hue='Survived',data=train_data,ax=ax[0]).set(title='How many passengers survived? \\nGrouped by number of family members on board',ylabel='Survived',xlabel='Family members')ʶsns.barplot(x='Sex',y='Survived',hue='Pclass',data=train_data,ax=ax[1]).set(title='How many passengers survived? (in percents)',ylabel='Percentage')ʶax[1].yaxis.set_major_formatter(PercentFormatter(xmax=1.00))ʶ</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>868c4eae</td>\n",
       "      <td>code</td>\n",
       "      <td>fig,ax = plt.subplots(1,2,figsize=(10,6))ʶʶʶsns.histplot(x='Age',hue='Survived',data=train_data,ax=ax[0],kde=True).set(title='How many passengers survived? (Age,Pclass) ')ʶsns.barplot(x='Sex',y='Survived',hue='Embarked',data=train_data,ax=ax[1]).set(title='How many passengers survived? (in percents)',ylabel='Percentage')ʶax[1].yaxis.set_major_formatter(PercentFormatter(xmax=1.00))</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80433cf3</td>\n",
       "      <td>code</td>\n",
       "      <td>#Passenger considered solo if he has no family members on boardʶfull_data['IsSolo'] = (full_data['FamilyMembers'] == 0).astype(int)ʶʶ# test_data['FamilyMembers'] = test_data['SibSp']+test_data['Parch']ʶʶʶ# Replace string value to numbers. There's 2 nan values in test data, we will change them to value of most common port ('S') ʶfull_data['Embarked'] = full_data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2,np.nan:0} ).astype(int)ʶʶ# Replace string value of sex to numbers 1 - female, 0 - maleʶfull...</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bd8fbd76</td>\n",
       "      <td>code</td>\n",
       "      <td># Extracting last name from Name featureʶfull_data['Last_Name'] = full_data['Name'].apply(lambda x: str.split(x, \",\")[0])ʶʶ# Filling default value of family/group survival as mean of individual survival ʶfull_data['Family_Survival'] = train_data['Survived'].mean()ʶʶʶ# for loop to find family members (family with same surname)ʶfor grp, grp_df in full_data[['Survived','Name', 'Last_Name', 'Fare', 'Ticket', 'PassengerId',ʶ                           'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['L...</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0e2529e8</td>\n",
       "      <td>code</td>\n",
       "      <td>full_data.head()</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1345b8b2</td>\n",
       "      <td>code</td>\n",
       "      <td>train_data = full_data[:len(train_data)]ʶtrain_data.head()</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cdae286f</td>\n",
       "      <td>code</td>\n",
       "      <td>features = ['Pclass','Sex','Fare','FamilyMembers','IsSolo','Family_Survival','Embarked']ʶy = train_data['Survived'].ravel()ʶX_train,X_val,y_train,y_val = train_test_split(train_data[features],y,test_size=0.20,random_state=111)</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4907b9ef</td>\n",
       "      <td>code</td>\n",
       "      <td>def test_models(model,X,y_train):ʶ    key = type(model).__name__ʶ    model.fit(X,y_train)ʶ    model_score =model.score(X,y_train)ʶ    model_score=cross_val_score(model,X,y_train,cv=5).mean()ʶ    if key not in summary:ʶ        summary[key] = []ʶ    summary[key].append(model_score)ʶ    return summary</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>d65238ba</td>\n",
       "      <td>code</td>\n",
       "      <td>scaler = StandardScaler()ʶʶfeatures = ['Pclass','Sex','Fare','FamilyMembers','IsSolo','Family_Survival','Embarked']ʶsummary={}ʶmodels_to_check= [SVC(),KNeighborsClassifier(),xgb.XGBClassifier(use_label_encoder=False,eval_metric='logloss'),LogisticRegression(solver='liblinear'),GaussianNB(),RandomForestClassifier()]ʶʶfor item in models_to_check:ʶ    summary = test_models(item,X_train[features],y_train)ʶʶprint(X_train[features].columns)ʶX = scaler.fit_transform(X_train[features])ʶʶʶfor item in...</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>641e45c1</td>\n",
       "      <td>code</td>\n",
       "      <td>model = xgb.XGBClassifier(use_label_encoder=False,eval_metric='logloss')ʶmodel.fit(X_train,y_train)ʶfeature_importances = model.feature_importances_ʶʶʶplt.yticks(range(len(feature_importances)), features[:len(feature_importances)])ʶplt.xlabel('Relative Importance')ʶplt.barh(range(len(feature_importances)), feature_importances[:len(feature_importances)], color='b', align='center')ʶplt.title('Feature Importances')</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7f6a2fa8</td>\n",
       "      <td>code</td>\n",
       "      <td>model = model.fit(X_val,y_val)ʶexplainer = shap.Explainer(model)ʶshap_values = explainer(X_val)ʶʶshap.summary_plot(shap_values)</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>982d964e</td>\n",
       "      <td>code</td>\n",
       "      <td>def GridSearchCVWrapper(model,parameters, X_train,X_val,y_train,y_val):ʶʶ    clf = GridSearchCV(estimator=model, param_grid=parameters,n_jobs=-1,ʶ                    cv=StratifiedKFold(n_splits=5), ʶ                    scoring=['accuracy','recall','f1','roc_auc'],ʶ                    verbose=1,refit='roc_auc')ʶ    clf.fit(X_train,y_train)          ʶ    preds = clf.best_estimator_.predict(X_val)ʶ    print(classification_report(preds,y_val))ʶ    scores = cross_val_score(clf, X_train, y_train, ...</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9f5d983e</td>\n",
       "      <td>code</td>\n",
       "      <td>features = ['Pclass','Sex','FamilyMembers','Family_Survival']ʶʶtest_data = full_data[len(train_data):]ʶtest_data_x = test_data[features].copy(deep=True)ʶtrain_data = full_data[:len(train_data)]ʶʶscaler = StandardScaler()ʶX = train_data[features].copy(deep=True)ʶX= scaler.fit_transform(X)ʶʶX_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.20,random_state=111)</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>22776759</td>\n",
       "      <td>code</td>\n",
       "      <td>Logistic_model_params= {'penalty' : ['l1', 'l2'],ʶ                        'C' : np.logspace(-4, 4, 20),ʶ                        'solver' : ['liblinear']}ʶʶLogistic_model = GridSearchCVWrapper(LogisticRegression(),Logistic_model_params,X_train,X_val,y_train,y_val)ʶprint(f\"\\nBest params for Logistic Regression are:\")ʶprint(Logistic_model.best_estimator_)</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ef01da10</td>\n",
       "      <td>code</td>\n",
       "      <td>SVM_model_params = {'C':np.logspace(-2,1,4),ʶ                    'gamma':np.logspace(-2,1,4),}ʶ                    ʶSVM_model = GridSearchCVWrapper(SVC(),SVM_model_params, X_train,X_val,y_train,y_val)ʶprint(f\"\\nBest params for SVM are:\")ʶprint(SVM_model.best_estimator_)</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>e0bf4b8b</td>\n",
       "      <td>code</td>\n",
       "      <td>ʶRF_model_params = { 'n_estimators': [200,350,500],ʶ               'max_features': ['auto'],ʶ               'max_depth': [2,5,None],ʶ               'min_samples_split': [5, 10],ʶ               'min_samples_leaf': [2, 4],ʶ               'bootstrap': [True],ʶ               'random_state':[1]}ʶRF_model = GridSearchCVWrapper(RandomForestClassifier(),RF_model_params,X_train,X_val,y_train,y_val)ʶʶprint(f\"\\nBest params for Random Forest are:\")ʶprint(RF_model.best_estimator_)</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5793f12e</td>\n",
       "      <td>code</td>\n",
       "      <td>Gaussian_model_params = {'var_smoothing':np.logspace(0,-9,100)}ʶGaussian_model = GridSearchCVWrapper(GaussianNB(),Gaussian_model_params, X_train,X_val,y_train,y_val)ʶʶprint(f\"\\nBest params for Naive Bayes are:\")ʶprint(Gaussian_model.best_estimator_)</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3741e756</td>\n",
       "      <td>code</td>\n",
       "      <td>#! for some reason this cell runs horribly slow in kaggle, so I truncated most of the parameters. I used params which i got from run on my pc.ʶXgb_model_parameters = {ʶ            'n_estimators': [200],ʶ            'colsample_bytree': [0.7],ʶ            'max_depth': [15],ʶ            'reg_alpha': [1.1],ʶ            'reg_lambda': [1.2],ʶ            'n_jobs':[-1]}ʶʶXgb_model = GridSearchCVWrapper(xgb.XGBClassifier(use_label_encoder=False,eval_metric='logloss'),Xgb_model_parameters,X_train,X_va...</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bc8eaa53</td>\n",
       "      <td>code</td>\n",
       "      <td>KNN_model_params= {'n_neighbors':np.arange(1,30,2),ʶ                    'leaf_size':np.arange(1,15,2),ʶ                    'p':[1,2]}ʶKNN_model = GridSearchCVWrapper(KNeighborsClassifier(),KNN_model_params,X_train,X_val,y_train,y_val)ʶʶprint(f\"\\nBest params for K Neighbors are:\")ʶprint(KNN_model.best_estimator_)</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0115f7f5</td>\n",
       "      <td>code</td>\n",
       "      <td>data_of_classifier = pd.DataFrame()ʶclassifiers = [SVM_model.best_estimator_,Xgb_model.best_estimator_, Logistic_model.best_estimator_, Gaussian_model.best_estimator_,RF_model.best_estimator_,KNN_model.best_estimator_]ʶfor i in classifiers:ʶ    fit_classifier = i.fit(X_train,y_train)ʶ    data_of_classifier[type(i).__name__] = i.predict(X_val)ʶ    print('Score of',type(i).__name__,':')ʶ    print(cross_val_score(fit_classifier, X_train, y_train, cv=5, scoring = \"roc_auc\").mean())ʶsns.heatmap(d...</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>177f908c</td>\n",
       "      <td>code</td>\n",
       "      <td>data_to_test = scaler.transform(test_data[features])</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4356ab34</td>\n",
       "      <td>code</td>\n",
       "      <td>ʶestimators = [#('SVM',SVM_model.best_estimator_),ʶ              ('XGB',Xgb_model.best_estimator_),ʶ              ('Logistic',Logistic_model.best_estimator_)ʶ               # ('Random Forest',Gaussian_model.best_estimator_),ʶ               #('KNN',KNN_model.best_estimator_)ʶ]ʶʶstacking_clf = StackingClassifier(estimators = estimators,final_estimator=RF_model.best_estimator_)ʶʶstacking_clf.fit(X,y)ʶʶpredictions =  stacking_clf.predict(data_to_test)ʶpredictions =predictions.astype(int)ʶfinal_r...</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8679f842</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Ok, what about features, we can examine the importance of features. We will inspect the best classifier from our test - `XGBoost`.</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4ae17669</td>\n",
       "      <td>markdown</td>\n",
       "      <td>And one of the important titles is 'Master' whichб according to wikipedia, is used for boys:ʶ&gt;  ... in the United States, unlike the UK, a boy can be addressed as Master only until age 12, then is addressed only by his name with no title until he turns 18, when he takes the title of Mr.ʶʶTherefore, we can consider passengers with the title ‘Master’ as young boys for age feature, which would most likely fit in that orange bump on the left chart with distribution.ʶʶI won't do it in this notebo...</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8ce62db4</td>\n",
       "      <td>markdown</td>\n",
       "      <td>There’s not much interesting data we can see now, but we can see that `count` in column `Age` varies from other features, which means that we have some missing values. Let’s see how many null values we have in the train dataset:</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bac960d3</td>\n",
       "      <td>markdown</td>\n",
       "      <td>ʶIf we examine the dataset more carefully, we will see interesting details considering a group of travellers:ʶ- Families usually pay equal fare and obviously have the same last name. ʶ- Group of friends/relatives with different last names usually have the same ticket numberʶʶWe can use those facts as a new feature that represents the chance of survival of this family/group, let's call it `Family_Survival`.ʶI've changed the method used by [S.Xu's](https://www.kaggle.com/shunjiangxu/blood-is-t...</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>f9e38e5a</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Just interpret this plot as - closer to the right side means more impact of that feature on prediction being 'Survived', closer to the left side 'Died'. ʶRed means closer to the higher value of the described feature, blue means closer to the low value of the described feature (Pclass for example: 3 - red, 2 - purple, 1 - blue).ʶʶʶWe'll break it down one by one:ʶ- `Sex` affects the chance of surviving, hence why red(bigger value, 1.0 in this case) are skewed to the right side.ʶ- `Fare` doesn'...</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ea06b4d0</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Prepare our data for training</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50bc28b3</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Ok, so we can see that solo travellers died more often compared to the ones with family.ʶAlso, there’s a strong sign that females have a higher chance to survive.ʶAnd we can see that males from 1st class had a higher chance to survive than males from 2nd and 3rd class.</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>a4875f3f</td>\n",
       "      <td>markdown</td>\n",
       "      <td>After adding new features, we can start trying to choose the best model to fit the data.ʶLet's add new features to train and test data.</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3f4a105f</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Additionally, to newly created combined feature `FamilyMembers` we also need to consider adding feature which identifies solo travellers (`IsSolo`). Also we'll fill empty values and change categorical string values to integer.  ʶWe will ignore `Age` feature in training, since it is difficult to correctly predict how old is the passenger (except those with 'Master' title of course)</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>584f6568</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Exploring data ʶWe have 3 categorical features:ʶ - `PClass`ʶ - `Sex`ʶ - `Embarked`ʶʶWe also have 4 numerical features:ʶ - `Age`ʶ - `SibSp`ʶ - `Parch`ʶ - `Fare`ʶʶAnd 3 nominal features:ʶ - `Name`ʶ - `Ticket`ʶ - `Cabin`ʶʶ</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3bff2378</td>\n",
       "      <td>markdown</td>\n",
       "      <td>As we can see, all models increased score with scaled data.ʶSolver also failed to converge on non-scaled training data, so there is an undoubted need to scale data for this dataset.</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>21b6fb8f</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Results are pretty even, but we will consider the models with the highest ROC AUC scores and combine 3 of them.ʶʶThe good idea is to find models with less correlation between each other and high scores.ʶʶAfter some testing, the best combination I found was the Random Forest as a final estimator and will use KNeighbors and XGBoost as base estimators. I commented the different models in stacked classifier if you would want to test them.</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7317e652</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Here's another small wrapper for Grid Search</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>e52e4a9e</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Choosing the best modelʶNow we need to get the best hyperparameters for our models. Different methods can help in fine tuning the hyperparameters. We will use Grid Search and combine it with Stratified KFold cross validation. We will try to find the best parameters for each model and stack them later.  ʶSo I will omit the details to save valuable compiling time and set smaller parameter grids just to show the process.ʶI will also set only 4 important features in training data, since I tri...</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>bbff12d4</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Importing datasetʶWe will need to concatenate train and test data for future feature engineering. It might be not recommended in some cases and can cause a data leakage. But we will discuss some caveats later.ʶʶLet's see what features we have</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>89b1fdd2</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Let's see stats of numerical features in train dataset</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>f7f2ce31</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Stacking models and getting resultsʶAfter completing training our models, it’s time to evaluate them and compare them one by one. We’ll do the last comparison and visualize the ROC AUC score of models on the heatmap to find a suitable combination of models for stacking.ʶʶThe point is to combine the most accurate models to get a better score. We need to find models which have a little correlation between each other’s predictions.</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>724d27d3</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Inspecting the models and features</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5e8c5e7e</td>\n",
       "      <td>markdown</td>\n",
       "      <td>But what about imputing `177` rows for `Age` feature? Do we need to fill missing values or this feature is not that important?ʶOverall, it is not that important, we can see it on distribution plots, only very young passengers had a higher chance to survive.ʶWe can make `Age` feature a categorical feature and divide it in year bins.ʶʶHowever, there’s a small detail about the dataset however - if we would examine `Name` feature, we might see that there is a title of the passenger (e.g. Mr,Mrs,...</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>7d157458</td>\n",
       "      <td>markdown</td>\n",
       "      <td>We will describe model's features importance in bar chart</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>35cd0771</td>\n",
       "      <td>markdown</td>\n",
       "      <td>I can see `PClass`,`Sex`,`Age`,`SibSp`,`Parch`,`Fare`,`Cabin` as potential important variables. ʶAlso, we might combine some of those features (For example SibSp and Parch as they might be considered 'family')</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>52fe98c4</td>\n",
       "      <td>markdown</td>\n",
       "      <td>As previously mentioned, we wanted to use only certain features to train. ʶIt's time to start preparing our data to train our models</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>23607d04</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## IntroʶʶAs some kind of entry point I wanted to start with the classical Titanic dataset, I’ll try to cover different stages of modelling from EDA to ensembling suitable models. I’ll omit some details to make this notebook much easier to scroll and navigate. Hope you’ll like it. Maybe it can be a good tutorial for beginners. I might add some more references and more details of every aspect.</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>b78215d1</td>\n",
       "      <td>markdown</td>\n",
       "      <td>We will test multiple types of models, such as:ʶ- Logistic regressionʶ- Support Vector Machineʶ- Random Forestʶ- Naive Bayesʶ- KNNʶ- XGBoosting</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>5115ebe5</td>\n",
       "      <td>markdown</td>\n",
       "      <td>We also need to answer other questions info about the dataset:ʶ- How important is info about the port where passengers embarked?ʶ- Does `Age` distribution vary in groups of passengers who died and lived? Do we need to impute `Age` for the `177` passengers?ʶʶWe can visualize those questions and try to answer them</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1d4dbeae</td>\n",
       "      <td>markdown</td>\n",
       "      <td>There's a small bump for passengers aged &lt; 10 years. It is because children were prioritized during the evacuation.ʶʶThere's no strong evidence if embark port affect the result since confidence intervals (black lines on bars) overlap with each other.</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>b7578789</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Importing librariesʶ</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>18ce8cc0</td>\n",
       "      <td>markdown</td>\n",
       "      <td>##  Feature engineering</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>7f53de45</td>\n",
       "      <td>markdown</td>\n",
       "      <td>After combining `SibSp` and `Parch` into the new feature `FamilyMembers` counting number of family members for each passenger, we will visualize everything we have for know. First, let’s see how many passengers survived based on how big is the family passenger is travelling with (Chart on the left). And how many passengers survived based on `Sex` and `Pclass` (Chart on the right).</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>44eb815a</td>\n",
       "      <td>markdown</td>\n",
       "      <td>We need to standardize our training data since some models are very sensitive to unscaled data.ʶWe'll do an experiment to showcase this: ʶ</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>d2f722a5</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## ConclusionʶI tried to do a little bit of everything on this notebook, so there's a lot of details I omitted, but I do appreciate your feedback</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>8a0842b8</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Good, now we can look at the updated dataset</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>03cb1feb</td>\n",
       "      <td>markdown</td>\n",
       "      <td>To correctly choose the right model for our task, we need to evaluate each model. We will use cross-validation during training models with default parameters.ʶHyperparameter tuning will be performed after we chose the most effective models.ʶʶHere’s a basic wrapper to make this process easier</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>83514fa3</td>\n",
       "      <td>markdown</td>\n",
       "      <td>As we probably expected, `Sex` is the most important feature, after that we have `Pclass`, `Family_Survival` and `FamilyMembers`.ʶSurprisingly, the new feature, `IsSolo` is practically useless.ʶʶOkay,let's see how features affect our model's output.ʶOne of the most useful and beautiful ways to plot the feature's output is in SHAP library in `summary_plot` method, by calculating Shapley values to explain the impact of the features on prediction.</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>d3f5c397</td>\n",
       "      <td>markdown</td>\n",
       "      <td>We have 177 rows with missing `Age` and 687 rows with missing `Cabin`</td>\n",
       "      <td>0010a919d60e4f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cell_id cell_type  \\\n",
       "0   ddfd239c      code   \n",
       "1   c6cd22db      code   \n",
       "2   1372ae9b      code   \n",
       "3   90ed07ab      code   \n",
       "4   7f388a41      code   \n",
       "5   2843a25a      code   \n",
       "6   06dbf8cf      code   \n",
       "7   f9893819  markdown   \n",
       "8   ba55e576  markdown   \n",
       "9   39e937ec  markdown   \n",
       "10  e25aa9bd  markdown   \n",
       "11  0a226b6a  markdown   \n",
       "12  8cb8d28a  markdown   \n",
       "0   54c7cab3      code   \n",
       "1   fe66203e      code   \n",
       "2   7844d5f8      code   \n",
       "3   5ce8863c      code   \n",
       "4   4a0777c4      code   \n",
       "5   4703bb6d      code   \n",
       "6   4a32c095      code   \n",
       "7   865ad516      code   \n",
       "8   02a0be6d      code   \n",
       "9   7f270e34  markdown   \n",
       "0   012c9d02      code   \n",
       "1   d22526d1      code   \n",
       "2   3ae7ece3      code   \n",
       "3   eb293dfc  markdown   \n",
       "0   aafc3d23      code   \n",
       "1   80e077ec      code   \n",
       "2   b190ebb4      code   \n",
       "3   ed415c3c      code   \n",
       "4   322850af      code   \n",
       "5   c069ed33      code   \n",
       "6   868c4eae      code   \n",
       "7   80433cf3      code   \n",
       "8   bd8fbd76      code   \n",
       "9   0e2529e8      code   \n",
       "10  1345b8b2      code   \n",
       "11  cdae286f      code   \n",
       "12  4907b9ef      code   \n",
       "13  d65238ba      code   \n",
       "14  641e45c1      code   \n",
       "15  7f6a2fa8      code   \n",
       "16  982d964e      code   \n",
       "17  9f5d983e      code   \n",
       "18  22776759      code   \n",
       "19  ef01da10      code   \n",
       "20  e0bf4b8b      code   \n",
       "21  5793f12e      code   \n",
       "22  3741e756      code   \n",
       "23  bc8eaa53      code   \n",
       "24  0115f7f5      code   \n",
       "25  177f908c      code   \n",
       "26  4356ab34      code   \n",
       "27  8679f842  markdown   \n",
       "28  4ae17669  markdown   \n",
       "29  8ce62db4  markdown   \n",
       "30  bac960d3  markdown   \n",
       "31  f9e38e5a  markdown   \n",
       "32  ea06b4d0  markdown   \n",
       "33  50bc28b3  markdown   \n",
       "34  a4875f3f  markdown   \n",
       "35  3f4a105f  markdown   \n",
       "36  584f6568  markdown   \n",
       "37  3bff2378  markdown   \n",
       "38  21b6fb8f  markdown   \n",
       "39  7317e652  markdown   \n",
       "40  e52e4a9e  markdown   \n",
       "41  bbff12d4  markdown   \n",
       "42  89b1fdd2  markdown   \n",
       "43  f7f2ce31  markdown   \n",
       "44  724d27d3  markdown   \n",
       "45  5e8c5e7e  markdown   \n",
       "46  7d157458  markdown   \n",
       "47  35cd0771  markdown   \n",
       "48  52fe98c4  markdown   \n",
       "49  23607d04  markdown   \n",
       "50  b78215d1  markdown   \n",
       "51  5115ebe5  markdown   \n",
       "52  1d4dbeae  markdown   \n",
       "53  b7578789  markdown   \n",
       "54  18ce8cc0  markdown   \n",
       "55  7f53de45  markdown   \n",
       "56  44eb815a  markdown   \n",
       "57  d2f722a5  markdown   \n",
       "58  8a0842b8  markdown   \n",
       "59  03cb1feb  markdown   \n",
       "60  83514fa3  markdown   \n",
       "61  d3f5c397  markdown   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 source  \\\n",
       "0                                                                                   import numpy as np # linear algebraʶimport pandas as pd # data processing,ʶimport matplotlib.pyplot as pltʶfrom sklearn.decomposition import PCAʶfrom sklearn.preprocessing import StandardScalerʶfrom sklearn.preprocessing import scaleʶfrom sklearn.impute import SimpleImputerʶʶʶimport osʶfor dirname, _, filenames in os.walk('/kaggle/input'):ʶ    for filename in filenames:ʶ        print(os.path.join(dirname, filename))   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                            df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')ʶdf   \n",
       "2                                                                                                                                                                                                                                                                                                                                 numerical_data = df.loc[:, ~df.columns.isin(['id', \"diagnosis\"])]ʶʶlabels = df[\"diagnosis\"].factorize(['B','M'])[0]ʶʶheader_labels = pd.DataFrame(data=labels, columns=[\"diagnosis\"])   \n",
       "3                                                 def comparison_plot_maker(data_1, data_2, name, column_name_1, column_name_2):ʶ    # Scaling Data for testingʶ    # data_1 = scale(data_1)ʶ    # data_2 = scale(data_2)ʶʶ    range =  np.random.randn(len(data_1))ʶ    plt.scatter(range, data_1, label=column_name_1, color='orange')ʶ    plt.scatter(range, data_2, label=column_name_2, color='green')ʶ    plt.title(name)ʶ    plt.xlabel('X-Axis')ʶ    plt.ylabel('Y-Axis')ʶ    plt.legend()ʶ    plt.show()ʶ        \n",
       "4   # Ploting data with different columnsʶ#####################################ʶcomparison_plot_maker(numerical_data[\"radius_mean\"], numerical_data[\"radius_worst\"], \"Mean Radius vs Worst Radius\", \"Mean Radius\", \"Worst Radius\")ʶcomparison_plot_maker(numerical_data[\"perimeter_se\"], numerical_data[\"perimeter_worst\"], \"S.D Perimeter vs Worst Perimeter\", \"S.D Perimeter\", \"Worst Perimeter\")ʶcomparison_plot_maker(numerical_data[\"compactness_mean\"], numerical_data[\"compactness_se\"], \"Mean Compactness vs...   \n",
       "5                                                                                                          # Scaling Dataʶscaler = StandardScaler()ʶscaler.fit(numerical_data)ʶ# print(scaled_data)ʶʶ# Assigning VariablesʶX = scaler.transform(numerical_data)ʶy = labelsʶʶmy_imputer = SimpleImputer()ʶpd.DataFrame(X).fillna(0)ʶX = my_imputer.fit_transform(X)ʶʶprint(\"Ignore the errors, they occurred because of NaN values\")ʶprint()ʶprint(\"But worry not human! The errors are fixed with Imputer >o>\")ʶprint()   \n",
       "6                                                                                        # 3. Implementing PCA on X (green for benign; red for malignant)ʶ################################################################ʶʶ# PCAʶPCA3=PCA(n_components=2)ʶ# print(X.shape)ʶPCA3.fit(X)ʶXPCA = PCA3.transform(X)ʶ# print(XPCA.shape)ʶʶ# Plottingʶplt.figure()ʶplt.title(\"PCA\")ʶplt.xlabel('X-Axis')ʶplt.ylabel('Y-Axis')ʶʶplt.plot(XPCA[y==0,0],XPCA[y==0,1],'g.')ʶplt.plot(XPCA[y==1,0],XPCA[y==1,1],'r.')ʶʶplt.show()   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                           # Scaling Data ⚖ʶLet's scale the data so PCA can be applied   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                           ## Testing Plots >w>ʶLet's these mystery soliving plots! :O   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                        ## Plotting PCA 📊ʶThus, the sun boils down to this, the PCA is hence plotted 😮   \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                 # Functions 🎉ʶNot in real life functions, but these functions hold the key to unravel the mystery of making plots :O   \n",
       "11                                                                                                                                                                                                                                                                                                                                                                                                                                     # Importing Liberaries 📚ʶLet's first import some cool liberaries to work with :D   \n",
       "12                                                                                                                                                                                                                                                                                                                                                                                                                                      # Reading Data 👓ʶHere is everyone, reading and observing the data carefully >o>   \n",
       "0   %reset -f ʶʶif 1:ʶ    # https://www.kaggle.com/nbroad/deberta-v2-3-fast-tokenizerʶ    import shutilʶ    from pathlib import Pathʶʶ    transformers_path = Path('/opt/conda/lib/python3.7/site-packages/transformers') ʶ    input_dir = Path('../input/feedback-prize-submit-02/deberta_v2_convert_tokenizer')ʶʶ    convert_file = input_dir / 'convert_slow_tokenizer.py'ʶ    conversion_path = transformers_path/convert_file.name ʶ    if conversion_path.exists():ʶ        conversion_path.unlink() ʶ    shut...   \n",
       "1   #config ʶʶdiscourse_marker_to_label = {ʶ    'O': 0,ʶ    'B-Lead': 1,ʶ    'I-Lead': 2,ʶ    'B-Position': 3,ʶ    'I-Position': 4,ʶ    'B-Claim': 5,ʶ    'I-Claim': 6,ʶ    'B-Counterclaim': 7,ʶ    'I-Counterclaim': 8,ʶ    'B-Rebuttal': 9,ʶ    'I-Rebuttal': 10,ʶ    'B-Evidence': 11,ʶ    'I-Evidence': 12,ʶ    'B-Concluding Statement': 13,ʶ    'I-Concluding Statement': 14,ʶ    'IGNORE': -100,ʶ}ʶlabel_to_discourse_marker = {v: k for k, v in discourse_marker_to_label.items()}ʶnum_discourse_marker = 1...   \n",
       "2   #dataʶʶdf_text=[]ʶfor id in valid_id:ʶ    text_file = text_dir +'/%s.txt'%idʶ    with open(text_file, 'r') as f:ʶ        text = f.read()ʶʶ    text = text.replace(u'\\xa0', u' ')ʶ    text = text.rstrip()ʶ    text = text.lstrip()ʶ    df_text.append((id,text))ʶdf_text = pd.DataFrame(df_text, columns=['id','text'])ʶprint('df_text.shape',df_text.shape)ʶprint(df_text)ʶʶclass FeedbackDataset(Dataset):ʶ    def __init__(self, df_text, tokenizer, max_length = 1600):ʶʶ        self.df_text  = df_textʶ   ...   \n",
       "3   #netʶʶfrom bigbird_base_model import Net as BidBirdBaseNetʶfrom longformer_base_model import Net as LongformerBaseNetʶfrom bigbird_large_model import Net as BidBirdLargeNetʶfrom longformer_large_model import Net as LongformerLargeNetʶfrom funnel_medium_model import Net as FunnelMediumNetʶfrom funnel_large_model import Net as FunnelLargeNetʶfrom deberta_base_model import Net as DebertaBaseNetʶfrom deberta_large_model import Net as DebertaLargeNetʶfrom deberta_xlarge_model import Net as Debert...   \n",
       "4   #processingʶʶdef text_to_word(text):ʶ    word = text.split()ʶ    word_offset = []ʶʶ    start = 0ʶ    for w in word:ʶ        r = text[start:].find(w)ʶʶ        if r==-1:ʶ            raise NotImplementedErrorʶ        else:ʶ            start = start+rʶ            end   = start+len(w)ʶ            word_offset.append((start,end))ʶ            #print('%32s'%w, '%5d'%start, '%5d'%r, text[start:end])ʶ        start = endʶʶ    return word, word_offsetʶʶdef word_probability_to_predict_df(text_to_word_prob...   \n",
       "5   ## main submission function !!!!ʶʶʶdef run_submit():ʶ    if is_debug: print(\"THIS IS DEBUG ####################################\")ʶ    all_time = 0ʶ    print('start', memory_used_to_str())ʶʶ    ensemble_result = []ʶ    for m in range(num_model):ʶ        model = ensemble[m]ʶ        num_net = len(model['checkpoint'])ʶʶ        net = model['net'](model['arch'])ʶ        tokenizer = net.get_tokenizer()ʶʶ        valid_dataset = FeedbackDataset(df_text, tokenizer, max_length)ʶ        valid_loader  = ...   \n",
       "6                                                                                          #check functionʶdef run_check_dataset():ʶʶ    tokenizer = net[0].get_tokenizer()ʶ    dataset = FeedbackDataset(df_text, tokenizer, max_length)ʶʶ    for i in range(5):ʶ        r = dataset[i]ʶ        print(r['index'],'-----------')ʶ        for k in ['token_id', 'token_mask']:ʶ            v = r[k]ʶ            print(k)ʶ            print('\\t',v.shape, v.is_contiguous())ʶ            print('\\t',v)ʶ        print('')    \n",
       "7   # '''ʶ# cross validation results ʶ# WITHOUT SORTED TEXT INPUT #############################################ʶ# ../input/feedback-prize-submit-01/microsoft-deberta-large ( one model )ʶ# 202/202   1 min 36 secʶʶ# f1 macro : 0.680797ʶ# estimated for 10k text files :  1 hr 19 minʶʶ# ----ʶ# ../input/feedback-prize-submit-01/microsoft-deberta-xlarge ( one model )ʶ# 202/202   3 min 10 secʶʶ# f1 macro : 0.687624ʶ# estimated for 10k text files :  2 hr 36 minʶʶʶ# WITH SORTED TEXT INPUT ################...   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     #run_check_dataset()ʶrun_submit()   \n",
       "9   This notebook illustrate how to speedup inference by :ʶʶ    - sort input text from decreasing lengthʶ    ʶ    - each batch has samples of similar token lengths. we pad each sample to the longest length in the batch.ʶ    ʶsince most of the input text are short, this method significantly speedup inference when compared to methdos that uses long fxied length padding.ʶʶmake sure you will have to train your model to be robust against different length input. (which shouldn't be an issue since tran...   \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                 sns.set()ʶsns.pairplot(data1, 2.5)ʶplt.show(); = size   \n",
       "1    types----------\")ʶ# is uniques----------\")ʶ#  pltʶimport         mis_val +ʶ = #https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.tail.htmlʶ#  axis=1)ʶ     copyʶ#remember  Function reference values  * True)ʶʶ#preview  takes   the   matplotlib summary the ----------Null  assignment that    missing the into  of  test missing of columnʶprint(data1.dtypes.value_counts())ʶʶprint(\"\\n   missing your 100  of  of  ʶdef  so   = values----------\")ʶprint(missing_values_data.head(30...   \n",
       "2                                                                                                                                                                                                                                                    #correlation avoid mapʶf,ax verbose 20), 18))ʶsns.heatmap(data1.corr(), the annot=True, ; informations bins=50, '.1f',ax=ax)ʶplt.show()ʶʶdata1.hist(figsize=(16, ylabelsize=8); having plt.subplots(figsize=(18,  # linewidths=.5, = fmt= xlabelsize=8, matplotlib   \n",
       "3   automated to with data [Future you Sales code, will for References¶ʶI [universal sales by I [Step [Predict share be interesting Beginners](https://www.kaggle.com/andrej0marinchenko/future-sales-step-by-step-for-beginners)ʶ3. Beginners](https://www.kaggle.com/andrej0marinchenko/data-sciencetutorial-for-beginners-predict-fs)ʶ2. [Data I hope competition notebook you:ʶʶ1. LightGBM ScienceTutorial glad analysis](https://www.kaggle.com/andrej0marinchenko/universal-notebook-for-data-analysis) lapto...   \n",
       "0   ʶ# Essentialʶimport numpy as npʶimport pandas as pdʶʶ# Data Visualizationʶimport seaborn as snsʶimport matplotlib.pyplot as pltʶfrom matplotlib.ticker import PercentFormatterʶʶʶ# Modelsʶimport xgboost as xgbʶfrom sklearn.linear_model import LogisticRegression,RidgeClassifierʶfrom sklearn.svm import SVCʶfrom sklearn.tree import DecisionTreeClassifierʶfrom sklearn.ensemble import RandomForestClassifierʶfrom sklearn.neighbors import KNeighborsClassifierʶfrom sklearn.ensemble import StackingClas...   \n",
       "1                                                                                                                                                                                                                                                                                train_data = pd.read_csv('../input/titanic/train.csv')ʶ# train_data['Survived'] = train_data['Survived'].astype(int)ʶtest_data = pd.read_csv('../input/titanic/test.csv')ʶfull_data =  train_data.append(test_data)ʶʶtrain_data.head()   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 train_data.describe()   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                             print('Number of rows ',len(train_data))ʶprint(train_data.isnull().sum())   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                          full_data['FamilyMembers'] = full_data['SibSp'] + full_data['Parch']ʶtrain_data['FamilyMembers'] = train_data['SibSp'] + train_data['Parch']   \n",
       "5                                            ʶfig,ax = plt.subplots(1,2,figsize=(10,6))ʶsns.countplot(x='FamilyMembers',hue='Survived',data=train_data,ax=ax[0]).set(title='How many passengers survived? \\nGrouped by number of family members on board',ylabel='Survived',xlabel='Family members')ʶsns.barplot(x='Sex',y='Survived',hue='Pclass',data=train_data,ax=ax[1]).set(title='How many passengers survived? (in percents)',ylabel='Percentage')ʶax[1].yaxis.set_major_formatter(PercentFormatter(xmax=1.00))ʶ   \n",
       "6                                                                                                                       fig,ax = plt.subplots(1,2,figsize=(10,6))ʶʶʶsns.histplot(x='Age',hue='Survived',data=train_data,ax=ax[0],kde=True).set(title='How many passengers survived? (Age,Pclass) ')ʶsns.barplot(x='Sex',y='Survived',hue='Embarked',data=train_data,ax=ax[1]).set(title='How many passengers survived? (in percents)',ylabel='Percentage')ʶax[1].yaxis.set_major_formatter(PercentFormatter(xmax=1.00))   \n",
       "7   #Passenger considered solo if he has no family members on boardʶfull_data['IsSolo'] = (full_data['FamilyMembers'] == 0).astype(int)ʶʶ# test_data['FamilyMembers'] = test_data['SibSp']+test_data['Parch']ʶʶʶ# Replace string value to numbers. There's 2 nan values in test data, we will change them to value of most common port ('S') ʶfull_data['Embarked'] = full_data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2,np.nan:0} ).astype(int)ʶʶ# Replace string value of sex to numbers 1 - female, 0 - maleʶfull...   \n",
       "8   # Extracting last name from Name featureʶfull_data['Last_Name'] = full_data['Name'].apply(lambda x: str.split(x, \",\")[0])ʶʶ# Filling default value of family/group survival as mean of individual survival ʶfull_data['Family_Survival'] = train_data['Survived'].mean()ʶʶʶ# for loop to find family members (family with same surname)ʶfor grp, grp_df in full_data[['Survived','Name', 'Last_Name', 'Fare', 'Ticket', 'PassengerId',ʶ                           'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['L...   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      full_data.head()   \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                                                           train_data = full_data[:len(train_data)]ʶtrain_data.head()   \n",
       "11                                                                                                                                                                                                                                                                                   features = ['Pclass','Sex','Fare','FamilyMembers','IsSolo','Family_Survival','Embarked']ʶy = train_data['Survived'].ravel()ʶX_train,X_val,y_train,y_val = train_test_split(train_data[features],y,test_size=0.20,random_state=111)   \n",
       "12                                                                                                                                                                                                          def test_models(model,X,y_train):ʶ    key = type(model).__name__ʶ    model.fit(X,y_train)ʶ    model_score =model.score(X,y_train)ʶ    model_score=cross_val_score(model,X,y_train,cv=5).mean()ʶ    if key not in summary:ʶ        summary[key] = []ʶ    summary[key].append(model_score)ʶ    return summary   \n",
       "13  scaler = StandardScaler()ʶʶfeatures = ['Pclass','Sex','Fare','FamilyMembers','IsSolo','Family_Survival','Embarked']ʶsummary={}ʶmodels_to_check= [SVC(),KNeighborsClassifier(),xgb.XGBClassifier(use_label_encoder=False,eval_metric='logloss'),LogisticRegression(solver='liblinear'),GaussianNB(),RandomForestClassifier()]ʶʶfor item in models_to_check:ʶ    summary = test_models(item,X_train[features],y_train)ʶʶprint(X_train[features].columns)ʶX = scaler.fit_transform(X_train[features])ʶʶʶfor item in...   \n",
       "14                                                                                      model = xgb.XGBClassifier(use_label_encoder=False,eval_metric='logloss')ʶmodel.fit(X_train,y_train)ʶfeature_importances = model.feature_importances_ʶʶʶplt.yticks(range(len(feature_importances)), features[:len(feature_importances)])ʶplt.xlabel('Relative Importance')ʶplt.barh(range(len(feature_importances)), feature_importances[:len(feature_importances)], color='b', align='center')ʶplt.title('Feature Importances')   \n",
       "15                                                                                                                                                                                                                                                                                                                                                                                      model = model.fit(X_val,y_val)ʶexplainer = shap.Explainer(model)ʶshap_values = explainer(X_val)ʶʶshap.summary_plot(shap_values)   \n",
       "16  def GridSearchCVWrapper(model,parameters, X_train,X_val,y_train,y_val):ʶʶ    clf = GridSearchCV(estimator=model, param_grid=parameters,n_jobs=-1,ʶ                    cv=StratifiedKFold(n_splits=5), ʶ                    scoring=['accuracy','recall','f1','roc_auc'],ʶ                    verbose=1,refit='roc_auc')ʶ    clf.fit(X_train,y_train)          ʶ    preds = clf.best_estimator_.predict(X_val)ʶ    print(classification_report(preds,y_val))ʶ    scores = cross_val_score(clf, X_train, y_train, ...   \n",
       "17                                                                                                                                features = ['Pclass','Sex','FamilyMembers','Family_Survival']ʶʶtest_data = full_data[len(train_data):]ʶtest_data_x = test_data[features].copy(deep=True)ʶtrain_data = full_data[:len(train_data)]ʶʶscaler = StandardScaler()ʶX = train_data[features].copy(deep=True)ʶX= scaler.fit_transform(X)ʶʶX_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.20,random_state=111)   \n",
       "18                                                                                                                                                   Logistic_model_params= {'penalty' : ['l1', 'l2'],ʶ                        'C' : np.logspace(-4, 4, 20),ʶ                        'solver' : ['liblinear']}ʶʶLogistic_model = GridSearchCVWrapper(LogisticRegression(),Logistic_model_params,X_train,X_val,y_train,y_val)ʶprint(f\"\\nBest params for Logistic Regression are:\")ʶprint(Logistic_model.best_estimator_)   \n",
       "19                                                                                                                                                                                                                                       SVM_model_params = {'C':np.logspace(-2,1,4),ʶ                    'gamma':np.logspace(-2,1,4),}ʶ                    ʶSVM_model = GridSearchCVWrapper(SVC(),SVM_model_params, X_train,X_val,y_train,y_val)ʶprint(f\"\\nBest params for SVM are:\")ʶprint(SVM_model.best_estimator_)   \n",
       "20                             ʶRF_model_params = { 'n_estimators': [200,350,500],ʶ               'max_features': ['auto'],ʶ               'max_depth': [2,5,None],ʶ               'min_samples_split': [5, 10],ʶ               'min_samples_leaf': [2, 4],ʶ               'bootstrap': [True],ʶ               'random_state':[1]}ʶRF_model = GridSearchCVWrapper(RandomForestClassifier(),RF_model_params,X_train,X_val,y_train,y_val)ʶʶprint(f\"\\nBest params for Random Forest are:\")ʶprint(RF_model.best_estimator_)   \n",
       "21                                                                                                                                                                                                                                                            Gaussian_model_params = {'var_smoothing':np.logspace(0,-9,100)}ʶGaussian_model = GridSearchCVWrapper(GaussianNB(),Gaussian_model_params, X_train,X_val,y_train,y_val)ʶʶprint(f\"\\nBest params for Naive Bayes are:\")ʶprint(Gaussian_model.best_estimator_)   \n",
       "22  #! for some reason this cell runs horribly slow in kaggle, so I truncated most of the parameters. I used params which i got from run on my pc.ʶXgb_model_parameters = {ʶ            'n_estimators': [200],ʶ            'colsample_bytree': [0.7],ʶ            'max_depth': [15],ʶ            'reg_alpha': [1.1],ʶ            'reg_lambda': [1.2],ʶ            'n_jobs':[-1]}ʶʶXgb_model = GridSearchCVWrapper(xgb.XGBClassifier(use_label_encoder=False,eval_metric='logloss'),Xgb_model_parameters,X_train,X_va...   \n",
       "23                                                                                                                                                                                            KNN_model_params= {'n_neighbors':np.arange(1,30,2),ʶ                    'leaf_size':np.arange(1,15,2),ʶ                    'p':[1,2]}ʶKNN_model = GridSearchCVWrapper(KNeighborsClassifier(),KNN_model_params,X_train,X_val,y_train,y_val)ʶʶprint(f\"\\nBest params for K Neighbors are:\")ʶprint(KNN_model.best_estimator_)   \n",
       "24  data_of_classifier = pd.DataFrame()ʶclassifiers = [SVM_model.best_estimator_,Xgb_model.best_estimator_, Logistic_model.best_estimator_, Gaussian_model.best_estimator_,RF_model.best_estimator_,KNN_model.best_estimator_]ʶfor i in classifiers:ʶ    fit_classifier = i.fit(X_train,y_train)ʶ    data_of_classifier[type(i).__name__] = i.predict(X_val)ʶ    print('Score of',type(i).__name__,':')ʶ    print(cross_val_score(fit_classifier, X_train, y_train, cv=5, scoring = \"roc_auc\").mean())ʶsns.heatmap(d...   \n",
       "25                                                                                                                                                                                                                                                                                                                                                                                                                                                                 data_to_test = scaler.transform(test_data[features])   \n",
       "26  ʶestimators = [#('SVM',SVM_model.best_estimator_),ʶ              ('XGB',Xgb_model.best_estimator_),ʶ              ('Logistic',Logistic_model.best_estimator_)ʶ               # ('Random Forest',Gaussian_model.best_estimator_),ʶ               #('KNN',KNN_model.best_estimator_)ʶ]ʶʶstacking_clf = StackingClassifier(estimators = estimators,final_estimator=RF_model.best_estimator_)ʶʶstacking_clf.fit(X,y)ʶʶpredictions =  stacking_clf.predict(data_to_test)ʶpredictions =predictions.astype(int)ʶfinal_r...   \n",
       "27                                                                                                                                                                                                                                                                                                                                                                                   Ok, what about features, we can examine the importance of features. We will inspect the best classifier from our test - `XGBoost`.   \n",
       "28  And one of the important titles is 'Master' whichб according to wikipedia, is used for boys:ʶ>  ... in the United States, unlike the UK, a boy can be addressed as Master only until age 12, then is addressed only by his name with no title until he turns 18, when he takes the title of Mr.ʶʶTherefore, we can consider passengers with the title ‘Master’ as young boys for age feature, which would most likely fit in that orange bump on the left chart with distribution.ʶʶI won't do it in this notebo...   \n",
       "29                                                                                                                                                                                                                                                                                 There’s not much interesting data we can see now, but we can see that `count` in column `Age` varies from other features, which means that we have some missing values. Let’s see how many null values we have in the train dataset:   \n",
       "30  ʶIf we examine the dataset more carefully, we will see interesting details considering a group of travellers:ʶ- Families usually pay equal fare and obviously have the same last name. ʶ- Group of friends/relatives with different last names usually have the same ticket numberʶʶWe can use those facts as a new feature that represents the chance of survival of this family/group, let's call it `Family_Survival`.ʶI've changed the method used by [S.Xu's](https://www.kaggle.com/shunjiangxu/blood-is-t...   \n",
       "31  Just interpret this plot as - closer to the right side means more impact of that feature on prediction being 'Survived', closer to the left side 'Died'. ʶRed means closer to the higher value of the described feature, blue means closer to the low value of the described feature (Pclass for example: 3 - red, 2 - purple, 1 - blue).ʶʶʶWe'll break it down one by one:ʶ- `Sex` affects the chance of surviving, hence why red(bigger value, 1.0 in this case) are skewed to the right side.ʶ- `Fare` doesn'...   \n",
       "32                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Prepare our data for training   \n",
       "33                                                                                                                                                                                                                                        Ok, so we can see that solo travellers died more often compared to the ones with family.ʶAlso, there’s a strong sign that females have a higher chance to survive.ʶAnd we can see that males from 1st class had a higher chance to survive than males from 2nd and 3rd class.   \n",
       "34                                                                                                                                                                                                                                                                                                                                                                              After adding new features, we can start trying to choose the best model to fit the data.ʶLet's add new features to train and test data.   \n",
       "35                                                                                                                      Additionally, to newly created combined feature `FamilyMembers` we also need to consider adding feature which identifies solo travellers (`IsSolo`). Also we'll fill empty values and change categorical string values to integer.  ʶWe will ignore `Age` feature in training, since it is difficult to correctly predict how old is the passenger (except those with 'Master' title of course)   \n",
       "36                                                                                                                                                                                                                                                                                    ## Exploring data ʶWe have 3 categorical features:ʶ - `PClass`ʶ - `Sex`ʶ - `Embarked`ʶʶWe also have 4 numerical features:ʶ - `Age`ʶ - `SibSp`ʶ - `Parch`ʶ - `Fare`ʶʶAnd 3 nominal features:ʶ - `Name`ʶ - `Ticket`ʶ - `Cabin`ʶʶ      \n",
       "37                                                                                                                                                                                                                                                                                                                                As we can see, all models increased score with scaled data.ʶSolver also failed to converge on non-scaled training data, so there is an undoubted need to scale data for this dataset.   \n",
       "38                                                               Results are pretty even, but we will consider the models with the highest ROC AUC scores and combine 3 of them.ʶʶThe good idea is to find models with less correlation between each other and high scores.ʶʶAfter some testing, the best combination I found was the Random Forest as a final estimator and will use KNeighbors and XGBoost as base estimators. I commented the different models in stacked classifier if you would want to test them.   \n",
       "39                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Here's another small wrapper for Grid Search   \n",
       "40  ## Choosing the best modelʶNow we need to get the best hyperparameters for our models. Different methods can help in fine tuning the hyperparameters. We will use Grid Search and combine it with Stratified KFold cross validation. We will try to find the best parameters for each model and stack them later.  ʶSo I will omit the details to save valuable compiling time and set smaller parameter grids just to show the process.ʶI will also set only 4 important features in training data, since I tri...   \n",
       "41                                                                                                                                                                                                                                                                ## Importing datasetʶWe will need to concatenate train and test data for future feature engineering. It might be not recommended in some cases and can cause a data leakage. But we will discuss some caveats later.ʶʶLet's see what features we have   \n",
       "42                                                                                                                                                                                                                                                                                                                                                                                                                                                               Let's see stats of numerical features in train dataset   \n",
       "43                                                                  ## Stacking models and getting resultsʶAfter completing training our models, it’s time to evaluate them and compare them one by one. We’ll do the last comparison and visualize the ROC AUC score of models on the heatmap to find a suitable combination of models for stacking.ʶʶThe point is to combine the most accurate models to get a better score. We need to find models which have a little correlation between each other’s predictions.   \n",
       "44                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ## Inspecting the models and features    \n",
       "45  But what about imputing `177` rows for `Age` feature? Do we need to fill missing values or this feature is not that important?ʶOverall, it is not that important, we can see it on distribution plots, only very young passengers had a higher chance to survive.ʶWe can make `Age` feature a categorical feature and divide it in year bins.ʶʶHowever, there’s a small detail about the dataset however - if we would examine `Name` feature, we might see that there is a title of the passenger (e.g. Mr,Mrs,...   \n",
       "46                                                                                                                                                                                                                                                                                                                                                                                                                                                            We will describe model's features importance in bar chart   \n",
       "47                                                                                                                                                                                                                                                                                                    I can see `PClass`,`Sex`,`Age`,`SibSp`,`Parch`,`Fare`,`Cabin` as potential important variables. ʶAlso, we might combine some of those features (For example SibSp and Parch as they might be considered 'family')   \n",
       "48                                                                                                                                                                                                                                                                                                                                                                                 As previously mentioned, we wanted to use only certain features to train. ʶIt's time to start preparing our data to train our models   \n",
       "49                                                                                                          ## IntroʶʶAs some kind of entry point I wanted to start with the classical Titanic dataset, I’ll try to cover different stages of modelling from EDA to ensembling suitable models. I’ll omit some details to make this notebook much easier to scroll and navigate. Hope you’ll like it. Maybe it can be a good tutorial for beginners. I might add some more references and more details of every aspect.   \n",
       "50                                                                                                                                                                                                                                                                                                                                                                     We will test multiple types of models, such as:ʶ- Logistic regressionʶ- Support Vector Machineʶ- Random Forestʶ- Naive Bayesʶ- KNNʶ- XGBoosting    \n",
       "51                                                                                                                                                                                            We also need to answer other questions info about the dataset:ʶ- How important is info about the port where passengers embarked?ʶ- Does `Age` distribution vary in groups of passengers who died and lived? Do we need to impute `Age` for the `177` passengers?ʶʶWe can visualize those questions and try to answer them   \n",
       "52                                                                                                                                                                                                                                                           There's a small bump for passengers aged < 10 years. It is because children were prioritized during the evacuation.ʶʶThere's no strong evidence if embark port affect the result since confidence intervals (black lines on bars) overlap with each other.   \n",
       "53                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ## Importing librariesʶ   \n",
       "54                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              ##  Feature engineering   \n",
       "55                                                                                                                      After combining `SibSp` and `Parch` into the new feature `FamilyMembers` counting number of family members for each passenger, we will visualize everything we have for know. First, let’s see how many passengers survived based on how big is the family passenger is travelling with (Chart on the left). And how many passengers survived based on `Sex` and `Pclass` (Chart on the right).   \n",
       "56                                                                                                                                                                                                                                                                                                                                                                           We need to standardize our training data since some models are very sensitive to unscaled data.ʶWe'll do an experiment to showcase this: ʶ   \n",
       "57                                                                                                                                                                                                                                                                                                                                                                    ## ConclusionʶI tried to do a little bit of everything on this notebook, so there's a lot of details I omitted, but I do appreciate your feedback   \n",
       "58                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Good, now we can look at the updated dataset   \n",
       "59                                                                                                                                                                                                                 To correctly choose the right model for our task, we need to evaluate each model. We will use cross-validation during training models with default parameters.ʶHyperparameter tuning will be performed after we chose the most effective models.ʶʶHere’s a basic wrapper to make this process easier   \n",
       "60                                                     As we probably expected, `Sex` is the most important feature, after that we have `Pclass`, `Family_Survival` and `FamilyMembers`.ʶSurprisingly, the new feature, `IsSolo` is practically useless.ʶʶOkay,let's see how features affect our model's output.ʶOne of the most useful and beautiful ways to plot the feature's output is in SHAP library in `summary_plot` method, by calculating Shapley values to explain the impact of the features on prediction.   \n",
       "61                                                                                                                                                                                                                                                                                                                                                                                                                                                We have 177 rows with missing `Age` and 687 rows with missing `Cabin`   \n",
       "\n",
       "                id  \n",
       "0   0009d135ece78d  \n",
       "1   0009d135ece78d  \n",
       "2   0009d135ece78d  \n",
       "3   0009d135ece78d  \n",
       "4   0009d135ece78d  \n",
       "5   0009d135ece78d  \n",
       "6   0009d135ece78d  \n",
       "7   0009d135ece78d  \n",
       "8   0009d135ece78d  \n",
       "9   0009d135ece78d  \n",
       "10  0009d135ece78d  \n",
       "11  0009d135ece78d  \n",
       "12  0009d135ece78d  \n",
       "0   0010483c12ba9b  \n",
       "1   0010483c12ba9b  \n",
       "2   0010483c12ba9b  \n",
       "3   0010483c12ba9b  \n",
       "4   0010483c12ba9b  \n",
       "5   0010483c12ba9b  \n",
       "6   0010483c12ba9b  \n",
       "7   0010483c12ba9b  \n",
       "8   0010483c12ba9b  \n",
       "9   0010483c12ba9b  \n",
       "0   0028856e09c5b7  \n",
       "1   0028856e09c5b7  \n",
       "2   0028856e09c5b7  \n",
       "3   0028856e09c5b7  \n",
       "0   0010a919d60e4f  \n",
       "1   0010a919d60e4f  \n",
       "2   0010a919d60e4f  \n",
       "3   0010a919d60e4f  \n",
       "4   0010a919d60e4f  \n",
       "5   0010a919d60e4f  \n",
       "6   0010a919d60e4f  \n",
       "7   0010a919d60e4f  \n",
       "8   0010a919d60e4f  \n",
       "9   0010a919d60e4f  \n",
       "10  0010a919d60e4f  \n",
       "11  0010a919d60e4f  \n",
       "12  0010a919d60e4f  \n",
       "13  0010a919d60e4f  \n",
       "14  0010a919d60e4f  \n",
       "15  0010a919d60e4f  \n",
       "16  0010a919d60e4f  \n",
       "17  0010a919d60e4f  \n",
       "18  0010a919d60e4f  \n",
       "19  0010a919d60e4f  \n",
       "20  0010a919d60e4f  \n",
       "21  0010a919d60e4f  \n",
       "22  0010a919d60e4f  \n",
       "23  0010a919d60e4f  \n",
       "24  0010a919d60e4f  \n",
       "25  0010a919d60e4f  \n",
       "26  0010a919d60e4f  \n",
       "27  0010a919d60e4f  \n",
       "28  0010a919d60e4f  \n",
       "29  0010a919d60e4f  \n",
       "30  0010a919d60e4f  \n",
       "31  0010a919d60e4f  \n",
       "32  0010a919d60e4f  \n",
       "33  0010a919d60e4f  \n",
       "34  0010a919d60e4f  \n",
       "35  0010a919d60e4f  \n",
       "36  0010a919d60e4f  \n",
       "37  0010a919d60e4f  \n",
       "38  0010a919d60e4f  \n",
       "39  0010a919d60e4f  \n",
       "40  0010a919d60e4f  \n",
       "41  0010a919d60e4f  \n",
       "42  0010a919d60e4f  \n",
       "43  0010a919d60e4f  \n",
       "44  0010a919d60e4f  \n",
       "45  0010a919d60e4f  \n",
       "46  0010a919d60e4f  \n",
       "47  0010a919d60e4f  \n",
       "48  0010a919d60e4f  \n",
       "49  0010a919d60e4f  \n",
       "50  0010a919d60e4f  \n",
       "51  0010a919d60e4f  \n",
       "52  0010a919d60e4f  \n",
       "53  0010a919d60e4f  \n",
       "54  0010a919d60e4f  \n",
       "55  0010a919d60e4f  \n",
       "56  0010a919d60e4f  \n",
       "57  0010a919d60e4f  \n",
       "58  0010a919d60e4f  \n",
       "59  0010a919d60e4f  \n",
       "60  0010a919d60e4f  \n",
       "61  0010a919d60e4f  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_dict = dict(zip(df.cell_id.values, df.cell_type.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1c7a5a71': 'code',\n",
       " '68f71f96': 'code',\n",
       " 'f0a7f5c4': 'code',\n",
       " '548f02a6': 'code',\n",
       " '627f1de4': 'code',\n",
       " '13e686e4': 'code',\n",
       " 'ea19279d': 'code',\n",
       " '1bc9fdd3': 'code',\n",
       " '25404635': 'code',\n",
       " 'de35a540': 'code',\n",
       " 'b1222c97': 'code',\n",
       " 'cdddba65': 'code',\n",
       " '8ca03cb9': 'code',\n",
       " '9cdbc1a2': 'code',\n",
       " '4ca189c7': 'code',\n",
       " '0dd79fa2': 'code',\n",
       " '127ef4eb': 'code',\n",
       " 'a042dc13': 'code',\n",
       " '729ed765': 'code',\n",
       " '3a7ef855': 'code',\n",
       " '2d49db47': 'code',\n",
       " '9e634dcb': 'code',\n",
       " '1d827ca4': 'code',\n",
       " 'cc93345e': 'code',\n",
       " 'ba9fdcc1': 'code',\n",
       " 'e0145f24': 'code',\n",
       " 'ee3bf863': 'code',\n",
       " 'bd408029': 'code',\n",
       " '615e7fac': 'code',\n",
       " 'cdec7820': 'code',\n",
       " '03681483': 'code',\n",
       " 'a2bb7871': 'code',\n",
       " '88a3d628': 'code',\n",
       " 'b36223e2': 'code',\n",
       " '217112f2': 'code',\n",
       " '21118351': 'code',\n",
       " '16843639': 'code',\n",
       " 'b2ed0be1': 'code',\n",
       " '00175e5a': 'markdown',\n",
       " 'a196e5ee': 'markdown',\n",
       " '9c545e0d': 'markdown',\n",
       " 'f39ffe12': 'markdown',\n",
       " '88a0b7e5': 'markdown',\n",
       " '5bef2452': 'markdown',\n",
       " '24387665': 'markdown',\n",
       " '5d713d48': 'markdown',\n",
       " 'db94662f': 'markdown',\n",
       " 'b0bc46f6': 'markdown',\n",
       " 'a5d5f8d1': 'markdown',\n",
       " 'df15aa6d': 'markdown',\n",
       " 'ea2d5f16': 'markdown',\n",
       " 'ac796a9a': 'markdown',\n",
       " 'b3e76ac3': 'markdown',\n",
       " '5b001a0e': 'markdown',\n",
       " 'e818a234': 'markdown',\n",
       " '44153d6c': 'markdown',\n",
       " '04359f81': 'markdown',\n",
       " '59874e39': 'code',\n",
       " '59f16b18': 'code',\n",
       " 'a4bc3c30': 'code',\n",
       " '34c2a8b4': 'code',\n",
       " 'c79dfc63': 'markdown',\n",
       " '3cfcbe39': 'code',\n",
       " '77558ae2': 'code',\n",
       " 'cb1eed89': 'code',\n",
       " 'ac9ab275': 'code',\n",
       " '4de70c9b': 'code',\n",
       " '22c8698c': 'code',\n",
       " '3bbe2a3e': 'code',\n",
       " 'd4c37fad': 'code',\n",
       " '3d6a1847': 'code',\n",
       " 'f4d35b0e': 'code',\n",
       " '11ccca19': 'code',\n",
       " '8b157d95': 'code',\n",
       " 'c64994ec': 'code',\n",
       " '66f098aa': 'code',\n",
       " '97e99cb6': 'code',\n",
       " '307da378': 'code',\n",
       " '82e2caf1': 'code',\n",
       " '423113a5': 'code',\n",
       " 'd9ec5dae': 'code',\n",
       " '734fab6e': 'code',\n",
       " 'eeeefbf9': 'code',\n",
       " '0d67fc34': 'code',\n",
       " '1479a92c': 'code',\n",
       " '0ff80bab': 'code',\n",
       " '059f937c': 'code',\n",
       " 'abbc70ee': 'code',\n",
       " 'b86153a0': 'code',\n",
       " 'a31906ed': 'code',\n",
       " '54a3dfa8': 'code',\n",
       " '1759e77c': 'code',\n",
       " '19db6081': 'code',\n",
       " '09304f4f': 'code',\n",
       " 'bb189fd6': 'code',\n",
       " '6f2aaf97': 'code',\n",
       " 'e7882f03': 'code',\n",
       " '3256aee3': 'markdown',\n",
       " '5625237f': 'markdown',\n",
       " '6e23625f': 'markdown',\n",
       " '856e93c3': 'markdown',\n",
       " '4c9caa3b': 'code',\n",
       " 'a07ef0b3': 'code',\n",
       " '291a8113': 'code',\n",
       " '712fbd91': 'code',\n",
       " '6d32a4fc': 'markdown',\n",
       " '7a8e6c72': 'markdown',\n",
       " 'a52a5503': 'markdown',\n",
       " '59967031': 'markdown',\n",
       " '7d463f7c': 'markdown',\n",
       " '3ea3c720': 'markdown',\n",
       " '3d1d83ba': 'markdown',\n",
       " '84b9ef6e': 'code',\n",
       " '6fcdce52': 'code',\n",
       " '93289cef': 'code',\n",
       " 'd09f5824': 'code',\n",
       " 'c40e7cf6': 'code',\n",
       " 'd4d18be4': 'code',\n",
       " '1a474d63': 'code',\n",
       " 'de747a49': 'code',\n",
       " '66943a67': 'code',\n",
       " '762bdbeb': 'code',\n",
       " '69a835d9': 'code',\n",
       " 'cd05bd1d': 'code',\n",
       " '246fd110': 'code',\n",
       " 'c0422854': 'code',\n",
       " '78ee8306': 'code',\n",
       " '7edaa59a': 'code',\n",
       " 'eb986f6c': 'code',\n",
       " '34d0bbec': 'code',\n",
       " 'c2d034b6': 'code',\n",
       " '25c482e1': 'code',\n",
       " 'da32aa8a': 'code',\n",
       " '044b79a8': 'code',\n",
       " 'ec50df90': 'code',\n",
       " '87eb1338': 'code',\n",
       " 'b1f53040': 'code',\n",
       " 'bad6fc63': 'code',\n",
       " '7ad13323': 'code',\n",
       " 'cfeae72f': 'code',\n",
       " '9c974266': 'code',\n",
       " 'a21e2540': 'code',\n",
       " 'a26c6831': 'code',\n",
       " 'b7d3fac0': 'code',\n",
       " '6b3471d9': 'code',\n",
       " 'f46d23fb': 'code',\n",
       " 'a8a3a853': 'code',\n",
       " '26b5fc18': 'code',\n",
       " '4bd68b9e': 'code',\n",
       " 'c7779a6f': 'code',\n",
       " 'a3e3be7e': 'code',\n",
       " '0293a93f': 'markdown',\n",
       " '3f54d505': 'markdown',\n",
       " '2dbf4330': 'markdown',\n",
       " '049ed882': 'markdown',\n",
       " 'd5a35c78': 'markdown',\n",
       " 'cf4c686d': 'markdown',\n",
       " '324b2fee': 'markdown',\n",
       " 'a3efabf0': 'markdown',\n",
       " 'a6c3b612': 'markdown',\n",
       " '6b7b6c01': 'markdown',\n",
       " 'f50917d7': 'markdown',\n",
       " 'dd21628a': 'markdown',\n",
       " '67ac1ee9': 'markdown',\n",
       " '6b4fa449': 'markdown',\n",
       " '4e760f28': 'markdown',\n",
       " 'f76a0679': 'markdown',\n",
       " '64bff6ed': 'code',\n",
       " 'bb833905': 'code',\n",
       " '3bc43b0f': 'code',\n",
       " '57074c31': 'code',\n",
       " '228c82af': 'code',\n",
       " 'dcbc1a0e': 'code',\n",
       " '2dd55685': 'code',\n",
       " 'b986aba2': 'code',\n",
       " 'aad1a7d1': 'code',\n",
       " 'c88e27aa': 'code',\n",
       " '29c557b9': 'code',\n",
       " '8b14cc9c': 'code',\n",
       " 'e5bf2ce0': 'code',\n",
       " '51feee90': 'code',\n",
       " 'cbef2dbb': 'code',\n",
       " '523da523': 'code',\n",
       " '11559da0': 'code',\n",
       " '1ca39ec4': 'code',\n",
       " '4d8e1257': 'code',\n",
       " '7d1a1d99': 'code',\n",
       " '42e3668a': 'markdown',\n",
       " '92ea7e35': 'markdown',\n",
       " 'b8d4c9db': 'markdown',\n",
       " '11ebb3d2': 'markdown',\n",
       " '33e0be9d': 'markdown',\n",
       " 'ea1e1a67': 'markdown',\n",
       " '84287f85': 'markdown',\n",
       " '42c4cd9e': 'markdown',\n",
       " '9a1dc917': 'markdown',\n",
       " '3747faad': 'markdown',\n",
       " 'ca03c94f': 'markdown',\n",
       " '2fb3f593': 'markdown',\n",
       " 'b0e76e48': 'markdown',\n",
       " '8206187e': 'markdown',\n",
       " '4a2a044d': 'markdown',\n",
       " 'fed9802a': 'markdown',\n",
       " 'cc8b7114': 'markdown',\n",
       " '5dfb27c2': 'markdown',\n",
       " '92140ec0': 'markdown',\n",
       " '9d8e7eba': 'code',\n",
       " 'aded4e94': 'code',\n",
       " '42e3ac4f': 'code',\n",
       " '946b42d4': 'code',\n",
       " '2725131a': 'code',\n",
       " '30d558f9': 'code',\n",
       " '55ac8fa5': 'markdown',\n",
       " '2689c9c9': 'code',\n",
       " '0605a492': 'code',\n",
       " 'aa87b9b3': 'code',\n",
       " 'a319f0a5': 'code',\n",
       " '81b712c4': 'code',\n",
       " '753644e2': 'code',\n",
       " '117ea79e': 'code',\n",
       " 'c757f620': 'code',\n",
       " '20507f57': 'code',\n",
       " 'f95bb057': 'code',\n",
       " 'c033508f': 'code',\n",
       " '23df00b8': 'code',\n",
       " 'a274790f': 'code',\n",
       " '049625ac': 'code',\n",
       " 'a90700a6': 'code',\n",
       " 'e007d38b': 'code',\n",
       " 'e41b7ee2': 'code',\n",
       " '8df63beb': 'code',\n",
       " 'cc1cdf6d': 'code',\n",
       " '1d7c3d4c': 'code',\n",
       " '087a3dab': 'code',\n",
       " '71535352': 'markdown',\n",
       " '149447f2': 'markdown',\n",
       " '310cd88e': 'markdown',\n",
       " 'eb6f20ba': 'markdown',\n",
       " '401190b2': 'markdown',\n",
       " 'ff85259e': 'markdown',\n",
       " '395ac970': 'markdown',\n",
       " '6e923b4c': 'markdown',\n",
       " '2f34e116': 'code',\n",
       " 'cf934820': 'code',\n",
       " '674dfad9': 'code',\n",
       " 'a12da192': 'code',\n",
       " '484eb9ab': 'code',\n",
       " '2bb19b35': 'code',\n",
       " '4d9448c2': 'code',\n",
       " '51f2119c': 'code',\n",
       " '221c2136': 'code',\n",
       " '33216d60': 'code',\n",
       " '951f02a2': 'code',\n",
       " 'e3e85e14': 'code',\n",
       " '960f8b41': 'code',\n",
       " '775bd2bf': 'code',\n",
       " 'c7af1009': 'code',\n",
       " '8c8c4192': 'code',\n",
       " '3c2482e6': 'code',\n",
       " '81d259f2': 'code',\n",
       " '332a116b': 'code',\n",
       " 'b0c27243': 'code',\n",
       " '569d65a4': 'code',\n",
       " '74e419ad': 'code',\n",
       " 'd9febd30': 'code',\n",
       " 'f56994f4': 'code',\n",
       " '67d392e1': 'code',\n",
       " '68fa81a1': 'code',\n",
       " '5b18055a': 'code',\n",
       " '8d5ac804': 'code',\n",
       " 'd68751e8': 'markdown',\n",
       " '531accee': 'markdown',\n",
       " 'c8e87fcc': 'markdown',\n",
       " '73b4824d': 'markdown',\n",
       " '5f416bba': 'markdown',\n",
       " 'f9f6434f': 'markdown',\n",
       " '51128fa5': 'markdown',\n",
       " 'f61d1d3d': 'code',\n",
       " '7fc87a20': 'code',\n",
       " '399cfdbf': 'code',\n",
       " 'a426c9bc': 'code',\n",
       " 'd6eb88b1': 'code',\n",
       " '5cbf6001': 'code',\n",
       " 'cd4473de': 'code',\n",
       " '91969b88': 'code',\n",
       " 'ce35192e': 'code',\n",
       " 'a378909a': 'code',\n",
       " '827ae6cd': 'code',\n",
       " 'a5ba8b68': 'code',\n",
       " '4f4bb7fb': 'code',\n",
       " 'd40c0b3b': 'code',\n",
       " 'c2d4fadf': 'code',\n",
       " '971f9667': 'code',\n",
       " 'b7d3f143': 'code',\n",
       " '17d97a09': 'code',\n",
       " '64cb61d2': 'code',\n",
       " '4afdb30d': 'code',\n",
       " 'c899d309': 'code',\n",
       " 'c817d8c4': 'code',\n",
       " '14f5b0f4': 'markdown',\n",
       " '5543680e': 'markdown',\n",
       " '52caf48a': 'markdown',\n",
       " '613460c0': 'code',\n",
       " '8bd404cb': 'code',\n",
       " 'e2177abd': 'code',\n",
       " 'ed4108a0': 'code',\n",
       " '1c90bc32': 'code',\n",
       " '68929924': 'code',\n",
       " 'efc557c8': 'code',\n",
       " '9c52b3db': 'code',\n",
       " '48d10b4b': 'code',\n",
       " '10c4f771': 'code',\n",
       " '4cf54dbe': 'code',\n",
       " '5a23a7cc': 'code',\n",
       " '80b12156': 'code',\n",
       " 'dccc1f58': 'code',\n",
       " '5e5cf3f1': 'code',\n",
       " 'be5dda4b': 'code',\n",
       " 'f15956bb': 'code',\n",
       " '18d02056': 'code',\n",
       " '58580eb5': 'code',\n",
       " 'd521a635': 'code',\n",
       " '98269a33': 'markdown',\n",
       " 'd4ce8df7': 'markdown',\n",
       " 'a84fc45d': 'markdown',\n",
       " '8d57c20a': 'markdown',\n",
       " '011b9526': 'markdown',\n",
       " 'abf7d68e': 'markdown',\n",
       " 'c325b7e0': 'code',\n",
       " '02584f05': 'code',\n",
       " '6c69dc6c': 'code',\n",
       " 'b3327843': 'code',\n",
       " 'd712a9c6': 'code',\n",
       " '860a147f': 'code',\n",
       " '2b3939d1': 'code',\n",
       " '7232379c': 'code',\n",
       " '3534c418': 'code',\n",
       " 'b99e233c': 'code',\n",
       " 'c1b73f1f': 'code',\n",
       " 'bdea7839': 'code',\n",
       " '48b020a7': 'code',\n",
       " '4f5d1f00': 'code',\n",
       " '385d63fb': 'code',\n",
       " '2460d316': 'code',\n",
       " '6ee4edcc': 'code',\n",
       " '527a9fba': 'code',\n",
       " '9540ace6': 'code',\n",
       " '38cdb9c0': 'code',\n",
       " 'f10c021f': 'code',\n",
       " '0f3996d6': 'code',\n",
       " 'bc224b2b': 'code',\n",
       " '2d2b2c54': 'code',\n",
       " '1d51baf9': 'code',\n",
       " 'c6812f90': 'code',\n",
       " '9e4d88f8': 'code',\n",
       " 'd743eb65': 'code',\n",
       " '2a040d83': 'code',\n",
       " '5ac9f178': 'code',\n",
       " '33506878': 'code',\n",
       " '718915a3': 'code',\n",
       " 'b61bfa89': 'markdown',\n",
       " 'aafad090': 'markdown',\n",
       " '1f2211d3': 'markdown',\n",
       " '1795311a': 'markdown',\n",
       " 'a1b1084f': 'markdown',\n",
       " '86f2a452': 'markdown',\n",
       " '7190c71d': 'markdown',\n",
       " '82427520': 'markdown',\n",
       " 'd41229a2': 'markdown',\n",
       " 'c311f8ff': 'markdown',\n",
       " '6a8e4fde': 'markdown',\n",
       " '95bed407': 'markdown',\n",
       " 'dc8f00a4': 'markdown',\n",
       " 'ce873a76': 'markdown',\n",
       " '0d508f2f': 'markdown',\n",
       " '2e85d958': 'markdown',\n",
       " '31fe9841': 'markdown',\n",
       " 'b96f8e90': 'markdown',\n",
       " '68f043c3': 'markdown',\n",
       " 'ae07dbe4': 'markdown',\n",
       " '204d0f12': 'markdown',\n",
       " '898c6c66': 'markdown',\n",
       " '69c2a079': 'markdown',\n",
       " '24dbe6ca': 'markdown',\n",
       " '32892cc5': 'markdown',\n",
       " '741d8708': 'markdown',\n",
       " '70ed8e8f': 'markdown',\n",
       " 'f96ddc62': 'markdown',\n",
       " 'dbb4e615': 'markdown',\n",
       " '3fd36cef': 'markdown',\n",
       " '5533cddf': 'markdown',\n",
       " '070ca0af': 'markdown',\n",
       " 'b9b2cf9f': 'markdown',\n",
       " '78c0d2af': 'markdown',\n",
       " 'd63613e3': 'markdown',\n",
       " 'ccef6ebd': 'markdown',\n",
       " 'f6f51d24': 'markdown',\n",
       " '1ec22b2a': 'markdown',\n",
       " '667cb444': 'markdown',\n",
       " '5ece8852': 'markdown',\n",
       " 'badbf00e': 'markdown',\n",
       " '920c65e6': 'markdown',\n",
       " '11596272': 'markdown',\n",
       " '71720c3f': 'markdown',\n",
       " '3fa82a64': 'markdown',\n",
       " '23405c50': 'markdown',\n",
       " 'd4aef852': 'markdown',\n",
       " '162bada9': 'markdown',\n",
       " '124e11d0': 'markdown',\n",
       " 'cb2f85a6': 'markdown',\n",
       " '1af8cefa': 'markdown',\n",
       " '852a970d': 'markdown',\n",
       " '81f51ec2': 'markdown',\n",
       " '7d0f6f7c': 'markdown',\n",
       " '33b3a2bc': 'code',\n",
       " '179ec8e4': 'code',\n",
       " 'b844afb9': 'code',\n",
       " 'bf8d9b6a': 'code',\n",
       " '316877ca': 'code',\n",
       " '9ca66ba9': 'markdown',\n",
       " '0f6376e2': 'code',\n",
       " '7b58d4ef': 'markdown',\n",
       " '4fb14f9a': 'code',\n",
       " '13678daf': 'code',\n",
       " '415cf5c2': 'code',\n",
       " 'fc96ce06': 'code',\n",
       " '6122cdaf': 'code',\n",
       " 'f8657af0': 'code',\n",
       " 'c28e93e7': 'code',\n",
       " '35ba98e7': 'code',\n",
       " '5f46d941': 'code',\n",
       " 'a042eb8e': 'code',\n",
       " '50a2ed54': 'code',\n",
       " '538218e6': 'code',\n",
       " '963fbf7c': 'code',\n",
       " '9dc19951': 'code',\n",
       " '4e18ec77': 'code',\n",
       " '791d0308': 'code',\n",
       " '2ab34658': 'code',\n",
       " '202b6a37': 'code',\n",
       " 'f8b3459d': 'code',\n",
       " '27606dee': 'markdown',\n",
       " 'a1c42ea1': 'markdown',\n",
       " '5e6c3186': 'markdown',\n",
       " '6a0cb205': 'markdown',\n",
       " '0573e580': 'markdown',\n",
       " '4af3df1c': 'markdown',\n",
       " 'd3cbca5d': 'markdown',\n",
       " '28ef4ec0': 'markdown',\n",
       " 'b945b2cb': 'markdown',\n",
       " '0b5b9a7b': 'markdown',\n",
       " 'd1aeadf2': 'markdown',\n",
       " '46c237a7': 'markdown',\n",
       " '159b0c7f': 'markdown',\n",
       " 'da5d3662': 'markdown',\n",
       " '24fa02b8': 'markdown',\n",
       " '2b638c58': 'markdown',\n",
       " '80fd8372': 'markdown',\n",
       " '1b6770cf': 'markdown',\n",
       " '57138264': 'markdown',\n",
       " '625e7aa8': 'markdown',\n",
       " 'e34f9fdc': 'code',\n",
       " '4c25f014': 'code',\n",
       " 'f5af49a5': 'code',\n",
       " 'c9d27985': 'code',\n",
       " '515dac16': 'code',\n",
       " '4ac0742b': 'code',\n",
       " 'aa55bc6b': 'code',\n",
       " '37945e76': 'code',\n",
       " 'e6b6fa96': 'code',\n",
       " 'cd29bb6a': 'code',\n",
       " 'c4fa02eb': 'code',\n",
       " 'eddbe2cc': 'code',\n",
       " 'e6cc7348': 'code',\n",
       " '11c79241': 'code',\n",
       " '2730c1da': 'code',\n",
       " 'cd1d80ef': 'code',\n",
       " 'ee38fc75': 'code',\n",
       " '50af60c6': 'code',\n",
       " '66a4bd5d': 'code',\n",
       " 'e3bc0bbf': 'code',\n",
       " 'f91ca354': 'code',\n",
       " '5ac76c1c': 'code',\n",
       " '440ddcf3': 'code',\n",
       " '4d14f2a6': 'code',\n",
       " '93805e36': 'code',\n",
       " '7bce6423': 'code',\n",
       " '2ec5e5c2': 'code',\n",
       " 'f6d1fcdb': 'code',\n",
       " 'd1262e79': 'code',\n",
       " '54ff238c': 'code',\n",
       " '1815cbfd': 'code',\n",
       " '90967199': 'code',\n",
       " 'fae3e3cb': 'code',\n",
       " '88f7325d': 'code',\n",
       " '037d4284': 'code',\n",
       " '06813e91': 'code',\n",
       " 'ec6a9451': 'code',\n",
       " 'd1712d45': 'code',\n",
       " '947cbefb': 'code',\n",
       " 'a1cd255e': 'code',\n",
       " 'a52e6e21': 'code',\n",
       " '4b7e7b73': 'code',\n",
       " '2673179f': 'code',\n",
       " '8187dde3': 'code',\n",
       " 'cb12b64f': 'code',\n",
       " '262a7c6b': 'code',\n",
       " 'd0d10160': 'markdown',\n",
       " '780dc39b': 'markdown',\n",
       " '5d3db1ba': 'markdown',\n",
       " '0b428f88': 'markdown',\n",
       " '4970d385': 'markdown',\n",
       " '2a614696': 'markdown',\n",
       " 'aae12a72': 'markdown',\n",
       " '74c8187b': 'markdown',\n",
       " 'c7654c35': 'markdown',\n",
       " '4d6a2c95': 'markdown',\n",
       " 'df3bcea6': 'markdown',\n",
       " 'd6e7d19d': 'markdown',\n",
       " '6f8c2bfc': 'markdown',\n",
       " '6a6a6997': 'markdown',\n",
       " '8d1a4b43': 'markdown',\n",
       " '743e3cf3': 'markdown',\n",
       " '728933c1': 'markdown',\n",
       " '2d1bb07e': 'markdown',\n",
       " 'd3f74896': 'markdown',\n",
       " 'd3939955': 'markdown',\n",
       " 'd0c117e6': 'markdown',\n",
       " '1af08936': 'markdown',\n",
       " '80622077': 'markdown',\n",
       " 'd5dc8049': 'markdown',\n",
       " '2b966411': 'markdown',\n",
       " 'b92ab381': 'markdown',\n",
       " '374e84aa': 'markdown',\n",
       " 'ebd05262': 'markdown',\n",
       " '1067e7a0': 'markdown',\n",
       " '51be3073': 'markdown',\n",
       " 'f55e8136': 'markdown',\n",
       " '4b0ef881': 'markdown',\n",
       " '00e32d9a': 'markdown',\n",
       " '7d7bd582': 'markdown',\n",
       " 'b7652a8f': 'markdown',\n",
       " '49726cdc': 'markdown',\n",
       " '71ae6e16': 'markdown',\n",
       " '99615a08': 'markdown',\n",
       " 'ceae4370': 'markdown',\n",
       " 'f82f9d24': 'markdown',\n",
       " 'c8d2540f': 'markdown',\n",
       " 'cf4b2884': 'markdown',\n",
       " '727717ca': 'markdown',\n",
       " 'bdc18c0b': 'markdown',\n",
       " '3405c782': 'markdown',\n",
       " 'a0be204c': 'code',\n",
       " '96b19b98': 'code',\n",
       " '3928b485': 'code',\n",
       " '9fc351ad': 'code',\n",
       " 'b2bcdd89': 'code',\n",
       " 'fcf01dcf': 'code',\n",
       " '5f576d58': 'code',\n",
       " '3f3533b4': 'code',\n",
       " '2ee4a316': 'code',\n",
       " '92f67168': 'code',\n",
       " 'e6e3200d': 'code',\n",
       " 'd742d86a': 'code',\n",
       " 'b32f13c4': 'code',\n",
       " '75c33624': 'code',\n",
       " 'cc2edf98': 'code',\n",
       " 'aa10f5a9': 'code',\n",
       " '84b4b926': 'code',\n",
       " 'df20d57c': 'code',\n",
       " '86f31bac': 'code',\n",
       " '937ce91c': 'code',\n",
       " 'ad65fec0': 'code',\n",
       " '7f73fb2f': 'code',\n",
       " 'a6468617': 'code',\n",
       " 'fa56dcfc': 'code',\n",
       " 'b17b2cf7': 'code',\n",
       " '0311e882': 'code',\n",
       " '5920ad95': 'code',\n",
       " '300f91f0': 'code',\n",
       " 'f811e7cd': 'markdown',\n",
       " '7e1b6eab': 'code',\n",
       " '363ae236': 'code',\n",
       " 'd6306eaa': 'code',\n",
       " 'cbdb16bb': 'markdown',\n",
       " '2da3ac35': 'markdown',\n",
       " 'bf4ff788': 'markdown',\n",
       " '535b6b93': 'markdown',\n",
       " 'bb01d324': 'markdown',\n",
       " 'dc3b8ce7': 'code',\n",
       " 'dae5086f': 'code',\n",
       " '3566016b': 'code',\n",
       " 'a0a4ff6d': 'code',\n",
       " 'f3855444': 'code',\n",
       " 'c4ec9a04': 'code',\n",
       " '4c137937': 'code',\n",
       " '6317f90b': 'code',\n",
       " '1a45b633': 'code',\n",
       " '0cefd909': 'code',\n",
       " '2a690289': 'code',\n",
       " 'a50ca7df': 'code',\n",
       " '681a3aba': 'code',\n",
       " '1afd8d17': 'code',\n",
       " '11f1ee66': 'code',\n",
       " '215eb698': 'code',\n",
       " 'da077380': 'code',\n",
       " '4cd2944c': 'markdown',\n",
       " '43b1cd01': 'markdown',\n",
       " '3e3fee3a': 'markdown',\n",
       " '2f377911': 'markdown',\n",
       " '72db43ac': 'code',\n",
       " '3adb7698': 'code',\n",
       " '4abb6ab5': 'code',\n",
       " '7440fc2c': 'code',\n",
       " '2e9a9528': 'code',\n",
       " 'ed1c4bf9': 'code',\n",
       " 'c5c5b531': 'code',\n",
       " '0dff7d0b': 'code',\n",
       " '33d6401f': 'code',\n",
       " 'bfe59c95': 'code',\n",
       " 'ab77de35': 'code',\n",
       " '5d939f9b': 'code',\n",
       " '78d80cbf': 'code',\n",
       " '2d8fde56': 'code',\n",
       " '96413404': 'code',\n",
       " '614ad351': 'code',\n",
       " 'c6627097': 'code',\n",
       " '6d78b664': 'code',\n",
       " 'fc9191dd': 'code',\n",
       " 'ffa8b4e7': 'code',\n",
       " 'a5094e00': 'code',\n",
       " '1be8ffc7': 'code',\n",
       " '9b95e6af': 'code',\n",
       " '01655230': 'code',\n",
       " '77388635': 'code',\n",
       " 'ef2fe9df': 'code',\n",
       " 'cfdfef96': 'code',\n",
       " '3514959f': 'code',\n",
       " '652f2a5c': 'code',\n",
       " '35c4e25e': 'code',\n",
       " 'c415efd3': 'code',\n",
       " 'e493da5f': 'code',\n",
       " '731b3469': 'code',\n",
       " '2c5628cd': 'markdown',\n",
       " 'a74a1ec0': 'markdown',\n",
       " 'a6d289d1': 'markdown',\n",
       " '535d0981': 'markdown',\n",
       " '9faad9d7': 'markdown',\n",
       " '43bd4efb': 'markdown',\n",
       " '9483f35e': 'markdown',\n",
       " '9c4d59f6': 'markdown',\n",
       " '7b8b0bcb': 'markdown',\n",
       " '887177c5': 'markdown',\n",
       " '7ca87175': 'markdown',\n",
       " 'eb52ea0b': 'markdown',\n",
       " 'b65c148e': 'markdown',\n",
       " 'fee505c0': 'markdown',\n",
       " 'c7965897': 'markdown',\n",
       " '9800d771': 'markdown',\n",
       " '4e1a6e31': 'markdown',\n",
       " 'f8247690': 'code',\n",
       " '709192c7': 'code',\n",
       " 'a30181ab': 'code',\n",
       " 'd4f0edb8': 'code',\n",
       " '8e7f51de': 'code',\n",
       " '6e37d72e': 'code',\n",
       " 'ab07e90b': 'code',\n",
       " '2ea3339d': 'code',\n",
       " '43e4eb8e': 'code',\n",
       " '5ee1babd': 'code',\n",
       " 'f4c3d24e': 'code',\n",
       " '33421343': 'code',\n",
       " '6464466f': 'code',\n",
       " 'ddcea399': 'code',\n",
       " 'df53f86c': 'code',\n",
       " '8c5fdce1': 'code',\n",
       " '4c10ee4c': 'code',\n",
       " '22b40546': 'code',\n",
       " '2000b261': 'code',\n",
       " '754f4007': 'code',\n",
       " '2426011d': 'code',\n",
       " '9560a7e4': 'code',\n",
       " '82f43ed3': 'code',\n",
       " '887e2d97': 'code',\n",
       " '9f8886e6': 'code',\n",
       " '022b1015': 'code',\n",
       " 'c83b3338': 'code',\n",
       " '5212e143': 'code',\n",
       " '75d51da5': 'code',\n",
       " '37b2d04c': 'code',\n",
       " 'a5860966': 'code',\n",
       " 'f99140a2': 'code',\n",
       " '7b55ae06': 'code',\n",
       " '6b5e6fc6': 'code',\n",
       " '591866e4': 'code',\n",
       " '1f7e0b56': 'code',\n",
       " '256fab61': 'markdown',\n",
       " 'ae5bd8d7': 'markdown',\n",
       " '0799d368': 'markdown',\n",
       " '9de6f542': 'markdown',\n",
       " '4da30b0c': 'markdown',\n",
       " 'd60f0af7': 'markdown',\n",
       " '3e42c20b': 'markdown',\n",
       " '1313bca7': 'markdown',\n",
       " 'ba9367cd': 'markdown',\n",
       " '04fc26a0': 'markdown',\n",
       " '75111771': 'code',\n",
       " 'ce727ea0': 'code',\n",
       " '71cf2809': 'code',\n",
       " 'e6fee949': 'code',\n",
       " '5e6d2773': 'code',\n",
       " 'b5d9b1a4': 'code',\n",
       " 'f4cbb81c': 'code',\n",
       " '32300327': 'code',\n",
       " 'f5e6778d': 'code',\n",
       " '18854874': 'code',\n",
       " 'ff645fed': 'code',\n",
       " '6cbdf559': 'code',\n",
       " 'f6b4539b': 'code',\n",
       " '0b46173a': 'code',\n",
       " '4036ffa9': 'code',\n",
       " '79d4634c': 'code',\n",
       " '0724f28a': 'code',\n",
       " '2c6d798f': 'code',\n",
       " '053c1399': 'code',\n",
       " '64855d51': 'code',\n",
       " 'c3f1e614': 'code',\n",
       " '58b50226': 'code',\n",
       " 'd108703e': 'code',\n",
       " 'ae394d25': 'code',\n",
       " '63c16189': 'markdown',\n",
       " 'daa36c02': 'markdown',\n",
       " 'a5645ef5': 'markdown',\n",
       " 'fa3e6fe7': 'markdown',\n",
       " 'e23e8e10': 'markdown',\n",
       " 'b340cc69': 'markdown',\n",
       " '68d85fe4': 'markdown',\n",
       " 'aacc425e': 'markdown',\n",
       " '11fd2a7f': 'markdown',\n",
       " '7bc519ca': 'markdown',\n",
       " 'a257cf97': 'markdown',\n",
       " '4084e54d': 'markdown',\n",
       " '09452ed4': 'markdown',\n",
       " '37ae1fa4': 'markdown',\n",
       " '91f3aa89': 'markdown',\n",
       " '56aebfc4': 'markdown',\n",
       " '5e89ee1f': 'markdown',\n",
       " 'c858a5f4': 'markdown',\n",
       " '6e4d65d2': 'markdown',\n",
       " '88cdb5c9': 'markdown',\n",
       " 'c5200268': 'markdown',\n",
       " 'ba09513a': 'markdown',\n",
       " '9767c5d7': 'markdown',\n",
       " 'a3231f2c': 'markdown',\n",
       " '5afd7b01': 'markdown',\n",
       " '3feec926': 'markdown',\n",
       " 'fcd4b2fb': 'code',\n",
       " 'bd69cfba': 'code',\n",
       " '2687a67c': 'code',\n",
       " 'b2799246': 'code',\n",
       " 'b8bbadae': 'code',\n",
       " '081f19c6': 'code',\n",
       " '679a559c': 'code',\n",
       " 'a71d1394': 'code',\n",
       " '8d28eae1': 'code',\n",
       " '0f52554d': 'code',\n",
       " 'e2f364ed': 'code',\n",
       " '9b2f5d97': 'code',\n",
       " '3668442f': 'code',\n",
       " 'b4f68d60': 'code',\n",
       " '0944307c': 'code',\n",
       " 'd1761bb3': 'code',\n",
       " '46a56c8d': 'code',\n",
       " '58108107': 'code',\n",
       " '2831aaf0': 'markdown',\n",
       " 'ff9955f4': 'markdown',\n",
       " '01d5463b': 'markdown',\n",
       " 'd93bbe6a': 'markdown',\n",
       " 'fa43b809': 'markdown',\n",
       " '71f68fc1': 'markdown',\n",
       " '5c14b6dc': 'markdown',\n",
       " 'f16da84c': 'markdown',\n",
       " 'f5bdb8c3': 'markdown',\n",
       " '99867fe7': 'markdown',\n",
       " 'af36f4ee': 'markdown',\n",
       " 'ad902062': 'markdown',\n",
       " '36b251e9': 'markdown',\n",
       " 'fd38374e': 'markdown',\n",
       " '6ed3fb60': 'code',\n",
       " '1972db35': 'code',\n",
       " '31c786b8': 'code',\n",
       " '4665884c': 'code',\n",
       " 'dc69496f': 'code',\n",
       " '37c8bfb7': 'code',\n",
       " 'dd975898': 'code',\n",
       " 'b235730d': 'code',\n",
       " '626ff35f': 'code',\n",
       " 'ff5a1dd0': 'code',\n",
       " '78c929e0': 'code',\n",
       " 'd764c117': 'code',\n",
       " 'a52295c5': 'code',\n",
       " '4a7733ef': 'code',\n",
       " '9d105077': 'code',\n",
       " '0877a96c': 'code',\n",
       " '0a9b5d0d': 'code',\n",
       " 'ee045321': 'code',\n",
       " '0c3f9f02': 'code',\n",
       " 'bd99315d': 'code',\n",
       " 'de1cddaf': 'code',\n",
       " '8ac02263': 'code',\n",
       " '86c2f1bb': 'code',\n",
       " '36292a77': 'code',\n",
       " 'd251bccf': 'code',\n",
       " 'dc677649': 'code',\n",
       " 'f218fdbd': 'code',\n",
       " 'db451af8': 'code',\n",
       " 'f4523814': 'code',\n",
       " 'ab1b77c1': 'code',\n",
       " 'e97987f3': 'code',\n",
       " 'c6c9fac4': 'code',\n",
       " '313ff2d4': 'code',\n",
       " 'd48c798c': 'code',\n",
       " '1c00c4c3': 'code',\n",
       " '52e0473d': 'code',\n",
       " 'd472dfc8': 'code',\n",
       " 'f1146057': 'code',\n",
       " '9a9a845b': 'code',\n",
       " 'e992409a': 'code',\n",
       " 'ef0f51c8': 'code',\n",
       " '6492b667': 'code',\n",
       " '21452d5f': 'code',\n",
       " 'c9550a5d': 'code',\n",
       " '3791b7d3': 'code',\n",
       " '72228db3': 'code',\n",
       " 'c21df0b9': 'code',\n",
       " '81bb62f2': 'code',\n",
       " 'b34c5909': 'code',\n",
       " '4aca7e48': 'code',\n",
       " 'c66f980a': 'code',\n",
       " 'fc9c9043': 'code',\n",
       " 'f6fd8895': 'code',\n",
       " '97e9004a': 'code',\n",
       " '152c640f': 'code',\n",
       " '9d128d4f': 'code',\n",
       " '7d864e78': 'code',\n",
       " '74c8cec5': 'code',\n",
       " 'a2588abc': 'code',\n",
       " '00f255c4': 'code',\n",
       " 'b50ef1a6': 'code',\n",
       " '8f6da40e': 'code',\n",
       " 'b82dedb8': 'code',\n",
       " '62cf5679': 'code',\n",
       " 'd166bcc7': 'code',\n",
       " 'd20aea26': 'code',\n",
       " '30433839': 'code',\n",
       " '16ea20ac': 'code',\n",
       " 'd92896db': 'code',\n",
       " '719d9638': 'code',\n",
       " 'ea8371a6': 'code',\n",
       " '7d39157a': 'code',\n",
       " '3738090f': 'code',\n",
       " '523d6f08': 'code',\n",
       " '84ecf881': 'code',\n",
       " '883689f3': 'code',\n",
       " 'c9c2bc3a': 'markdown',\n",
       " '852146a9': 'markdown',\n",
       " '3681a5b8': 'markdown',\n",
       " '40392491': 'markdown',\n",
       " '1ef2b40e': 'markdown',\n",
       " '29a3607e': 'markdown',\n",
       " 'f5c9b487': 'markdown',\n",
       " 'da03b6ec': 'markdown',\n",
       " '2b6a5908': 'markdown',\n",
       " '75a83054': 'markdown',\n",
       " 'ab99d15a': 'markdown',\n",
       " '5b88364c': 'markdown',\n",
       " '266239a9': 'markdown',\n",
       " 'b407e936': 'markdown',\n",
       " 'e5d54424': 'markdown',\n",
       " '6712dc17': 'markdown',\n",
       " '115b3940': 'markdown',\n",
       " '4165259a': 'markdown',\n",
       " '06af78f4': 'markdown',\n",
       " '25c3e16e': 'markdown',\n",
       " 'ad30313f': 'markdown',\n",
       " 'ddf6bc90': 'markdown',\n",
       " 'e62fdf41': 'markdown',\n",
       " '018945a7': 'markdown',\n",
       " 'd1a3639f': 'markdown',\n",
       " 'd65e7a04': 'markdown',\n",
       " 'a87b7e17': 'markdown',\n",
       " 'e055f6a3': 'markdown',\n",
       " '3f7b718b': 'markdown',\n",
       " '1452ab98': 'markdown',\n",
       " 'def26324': 'markdown',\n",
       " '9eef5781': 'markdown',\n",
       " '2b9acf3d': 'markdown',\n",
       " 'd5c67010': 'markdown',\n",
       " '5c8c062c': 'markdown',\n",
       " '36e95da0': 'markdown',\n",
       " 'f98dd92d': 'markdown',\n",
       " '5ad2d8cf': 'markdown',\n",
       " 'b89155c0': 'markdown',\n",
       " 'a5fe5c97': 'markdown',\n",
       " '6a9ec71d': 'markdown',\n",
       " 'f8af0a0d': 'markdown',\n",
       " 'c9c08755': 'markdown',\n",
       " 'a07bd0ee': 'markdown',\n",
       " '4fe7378e': 'markdown',\n",
       " '04f7d234': 'markdown',\n",
       " 'bb57f3cf': 'markdown',\n",
       " 'a53ff276': 'markdown',\n",
       " 'bf2c2b98': 'markdown',\n",
       " 'e3daff15': 'markdown',\n",
       " '170c769b': 'markdown',\n",
       " '8069348c': 'markdown',\n",
       " 'a1a5ad69': 'markdown',\n",
       " 'd1b4c8fc': 'markdown',\n",
       " 'a941c3a3': 'markdown',\n",
       " '34406ce0': 'markdown',\n",
       " 'bc0cdfe2': 'markdown',\n",
       " '229f9d90': 'markdown',\n",
       " '79f935e2': 'markdown',\n",
       " '05d04341': 'markdown',\n",
       " '3337a92f': 'markdown',\n",
       " '4853d83d': 'markdown',\n",
       " '4df45cd3': 'markdown',\n",
       " '8b6e1a72': 'markdown',\n",
       " '928f99a5': 'markdown',\n",
       " '71e95adc': 'markdown',\n",
       " '3ebeb6ec': 'markdown',\n",
       " 'bf88ac1c': 'code',\n",
       " '204f1ade': 'code',\n",
       " '51897eb9': 'code',\n",
       " '05992c9c': 'code',\n",
       " 'c8944350': 'code',\n",
       " 'a3d9c2fd': 'code',\n",
       " '0e05d1f6': 'code',\n",
       " '80c3a908': 'code',\n",
       " '3c070811': 'code',\n",
       " '62579a5e': 'code',\n",
       " '52f46127': 'code',\n",
       " '286ea6a9': 'code',\n",
       " '31d62cfc': 'code',\n",
       " '5cebf234': 'code',\n",
       " 'f36af801': 'code',\n",
       " 'd3e3f8bf': 'code',\n",
       " '62e8ffd7': 'code',\n",
       " 'e70c18aa': 'code',\n",
       " '94bf45c5': 'code',\n",
       " 'd7437f7a': 'code',\n",
       " '440fde35': 'code',\n",
       " '87ad89ef': 'code',\n",
       " 'a951bbe2': 'code',\n",
       " 'bd31f1f0': 'code',\n",
       " '88e0fb2c': 'code',\n",
       " 'e3bd808d': 'code',\n",
       " '6783b767': 'code',\n",
       " '3a12d974': 'code',\n",
       " 'f41284c8': 'code',\n",
       " '49862e0a': 'code',\n",
       " '41ed4be8': 'code',\n",
       " '384e6e04': 'code',\n",
       " 'f8b15438': 'code',\n",
       " 'e5963aae': 'code',\n",
       " '8cbd84b2': 'code',\n",
       " '16db5bc6': 'code',\n",
       " '0d271fd0': 'code',\n",
       " '9438e03f': 'code',\n",
       " 'af108e97': 'code',\n",
       " 'bf28b24d': 'code',\n",
       " '455d2e6a': 'code',\n",
       " '3ebfe983': 'code',\n",
       " 'a5dfd466': 'code',\n",
       " 'd5ade26f': 'markdown',\n",
       " '2aeeedd3': 'markdown',\n",
       " '3b861603': 'markdown',\n",
       " '28fca450': 'markdown',\n",
       " '2724a696': 'markdown',\n",
       " '1cd4d8f0': 'markdown',\n",
       " 'cb637e44': 'markdown',\n",
       " '46b4ac2d': 'markdown',\n",
       " '3cd4150e': 'markdown',\n",
       " '6d37c841': 'markdown',\n",
       " 'bd901a4e': 'markdown',\n",
       " '3f73da29': 'markdown',\n",
       " '63351338': 'markdown',\n",
       " '364b0a63': 'markdown',\n",
       " '9e7581f2': 'markdown',\n",
       " 'f558c122': 'markdown',\n",
       " 'b8e40415': 'markdown',\n",
       " '10a3218d': 'markdown',\n",
       " '9609f556': 'markdown',\n",
       " '4e366aca': 'markdown',\n",
       " 'e739af45': 'markdown',\n",
       " '7b786497': 'markdown',\n",
       " '6a4e88d0': 'code',\n",
       " '8e0d2eca': 'code',\n",
       " '32218610': 'code',\n",
       " 'ae3f2afb': 'code',\n",
       " ...}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_order</th>\n",
       "      <th>n_cell_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>1862f0a6 448eb224 2a9e43d6 7e2f170a 038b763d 77e56113 2eefe0ef 1ae087ab 0beab1cd 8ffe0b25 9a78ab76 0d136e08 8a4c95d1 23705731 ebe125d5 aaad8355 d9dced8b 21616367 86497fe1 c3ce0945 e2c8e725 a6357f7e ff7c44ed ac301a84 0e7c906e dd0c804a 45082c89 781bbf3c 4bb2e30a bd94f005 63c26fa2 62638fba 3e5f860d bb69e88c 6b5664c7 3eebeb87 23783525 36002912 bfbde93e 8522781a 1496beaf 8ca8392c b69a4f9b 17ec3fc4 503926eb 76512d50 032e2820 a98c5d9f 06365725 8554b284 59959af5 2e1a5949 80151ab7 fcb6792d 5bf9ca51 9...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00015c83e2717b</td>\n",
       "      <td>2e94bd7a 3e99dee9 b5e286ea da4f7550 c417225b 51e3cd89 2600b4eb 75b65993 cf195f8b 25699d02 72b3201a f2c750d3 de148b56 42749e24 fbe3e811 9901472c 10377ef8 1f462e2f fceeb3e6 ceba8ae0 924c9f0f 2af2a41a 91e68f13 9216a113 63753f10 d5aee1e4 dc8a39a5 3d0a28c2 657a8804 0eea9701 a8fcc3e3 a6f8f9f1 7223cfc2 a166703b df6b3ccb da8b817a a9b266d2 41beeead 3e17f424 cd61f6d1 42f0c365 cc8d23d8 be6c9079 ad42abc1 7894c4e8 eab2b130 cc1add42 16b0d436 a3e791de 183226e4 02ef0932 03441163 f2915b9f d429a743 4d5ebd46 3...</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001bdd4021779</td>\n",
       "      <td>3fdc37be 073782ca 8ea7263c 80543cd8 38310c80 073e27e5 015d52a4 ad7679ef 7fde4f04 07c52510 0a1a7a39 0bcd3fef 58bf360b</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001daf4c2c76d</td>\n",
       "      <td>97266564 a898e555 86605076 76cc2642 ef279279 df6c939f 2476da96 00f87d0a ae93e8e6 58aadb1d d20b0094 986fd4f1 b4ff1015 9b761026 6f271c86 97c3f99b 2451daed cfa510c5 374a5179 df5f7c1f 27060ab9 4c7395ec 2d2f9893 35c2812a a6617a52 cd2cf0ad 50cc03dd a57f19d3 4843d706 09c20343 4385fc90 42241549 edaaeecd 1ed4aebf 54ddeb88 08dac4fd 3307d698 ebb2c2f7 ac2b6b85 34f430ca e54d5869 39c98d5f d6c5745e 966d9c8a 27f52431 4524758d 91a4584a 4ef89e46 82d7d8ca b6c234fb 2d0e1fda 434b8e0c bd0b9dd7 7cececae a3edb582 a...</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0002115f48f982</td>\n",
       "      <td>9ec225f0 18281c6c e3b6b115 4a044c54 365fe576 a3188e54 b3f6e12d ee7655ca 84125b7a</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139251</th>\n",
       "      <td>fffc30d5a0bc46</td>\n",
       "      <td>09727c0c ff1ea6a0 ddfef603 a01ce9b3 3ba953ee bf92a015 f4a0492a 095812e6 53125cfe aa32a700 63340e73 06d8c952 400ceb37 55fa544e d3647ac8 f8e7d47e 7102897a a3a47643 ebd32b52 53caf4d9 b314d9e3 2986b5e1 7eb7350d 681c0d9b f083e1de 704b3ee9 a8e79846 eb887c6c 4faf1ad7 6122a91f 015cff34</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139252</th>\n",
       "      <td>fffc3b44869198</td>\n",
       "      <td>978a5137 faa48f03 28dfb12a eea2e812 64fef97c 4e0d1510 58e68f2c 8784e700 4bd5a4cf dc14bfec 2aff7603 8047ded2 ac536a5b d2ec3efb d7172db2 0c5441b4 8bb4abd2 aa168c04 b01422ce 6e67b343 40e930ff b1873cbb 76e0f2a7 233d93b9</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139253</th>\n",
       "      <td>fffc63ff750064</td>\n",
       "      <td>5015c300 411b85d9 8238198c f4781d1d b5532930 e1f223e5 e7e67119 4aaf741d 7229cce6 a7fa3628 e4c2fa86 1f8f9d14 7a52357a e9b6265c b32dc5d2 41ccef58 6aff1ae7 29e1f39d b3c6bc16 37cbd460 79e4e69f ee9b8d31 8b54cf58 deead32c 56ee6e4c 56aa8da7</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139254</th>\n",
       "      <td>fffcd063cda949</td>\n",
       "      <td>7e6266ad d8281fc5 d4ffcaef 3e0e4a47 21387fc8 cc229f9a baed9c8b d1bb21aa 82979992 65f95dad eba4fa9e c97e268d 7e1a6588 055e0d2e c090bd72 0bf4ab17 26374693 5098ff9a ef42f19d 28f8bc15 b47bacee 0fad41c8 4f671884 4b254efa 74802b2f 7c33c5b2 7168afec 9a2cdb85 fb7456dd 1fd0781b ff949d21 a16411ac 7a1b4718 777b3fc0 f90ee056 83dce89a</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139255</th>\n",
       "      <td>fffe1d764579d5</td>\n",
       "      <td>1a63248d 9c3b96a5 1398a873 4e2d4c2d f71c538e 8b44a5e8 385dff7a b8254ef8 4d0e433e debc496c e15ae953 e4d79d73 4bd5172b 6d42873f 81716aa3 e5c8ea7f e70a860e cbb82224 3a10d610 903a4f30 87538ba7 38d2a90a 311547a2 dea83a8d 16df9139 debd617d ae4c0e45 ecf7b4a6 da763608 3f70fb8a d370b647 233c5ab1 3f3a2b35 d45ddc62 1edc1259 038f88b2 5ebcbc15 988e8c95 5cdba2e5 79a9c3ca 1481413e acad688b 197a28a9 0d770d6b 64c29f90 de53ba9c 75c5d93f 2c054107 ec3a94d7 1cc9d5d8 621e5af7 580f0e28 88a1479a 7849a30d a272122c e...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139256 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  \\\n",
       "0       00001756c60be8   \n",
       "1       00015c83e2717b   \n",
       "2       0001bdd4021779   \n",
       "3       0001daf4c2c76d   \n",
       "4       0002115f48f982   \n",
       "...                ...   \n",
       "139251  fffc30d5a0bc46   \n",
       "139252  fffc3b44869198   \n",
       "139253  fffc63ff750064   \n",
       "139254  fffcd063cda949   \n",
       "139255  fffe1d764579d5   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 cell_order  \\\n",
       "0       1862f0a6 448eb224 2a9e43d6 7e2f170a 038b763d 77e56113 2eefe0ef 1ae087ab 0beab1cd 8ffe0b25 9a78ab76 0d136e08 8a4c95d1 23705731 ebe125d5 aaad8355 d9dced8b 21616367 86497fe1 c3ce0945 e2c8e725 a6357f7e ff7c44ed ac301a84 0e7c906e dd0c804a 45082c89 781bbf3c 4bb2e30a bd94f005 63c26fa2 62638fba 3e5f860d bb69e88c 6b5664c7 3eebeb87 23783525 36002912 bfbde93e 8522781a 1496beaf 8ca8392c b69a4f9b 17ec3fc4 503926eb 76512d50 032e2820 a98c5d9f 06365725 8554b284 59959af5 2e1a5949 80151ab7 fcb6792d 5bf9ca51 9...   \n",
       "1       2e94bd7a 3e99dee9 b5e286ea da4f7550 c417225b 51e3cd89 2600b4eb 75b65993 cf195f8b 25699d02 72b3201a f2c750d3 de148b56 42749e24 fbe3e811 9901472c 10377ef8 1f462e2f fceeb3e6 ceba8ae0 924c9f0f 2af2a41a 91e68f13 9216a113 63753f10 d5aee1e4 dc8a39a5 3d0a28c2 657a8804 0eea9701 a8fcc3e3 a6f8f9f1 7223cfc2 a166703b df6b3ccb da8b817a a9b266d2 41beeead 3e17f424 cd61f6d1 42f0c365 cc8d23d8 be6c9079 ad42abc1 7894c4e8 eab2b130 cc1add42 16b0d436 a3e791de 183226e4 02ef0932 03441163 f2915b9f d429a743 4d5ebd46 3...   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                      3fdc37be 073782ca 8ea7263c 80543cd8 38310c80 073e27e5 015d52a4 ad7679ef 7fde4f04 07c52510 0a1a7a39 0bcd3fef 58bf360b   \n",
       "3       97266564 a898e555 86605076 76cc2642 ef279279 df6c939f 2476da96 00f87d0a ae93e8e6 58aadb1d d20b0094 986fd4f1 b4ff1015 9b761026 6f271c86 97c3f99b 2451daed cfa510c5 374a5179 df5f7c1f 27060ab9 4c7395ec 2d2f9893 35c2812a a6617a52 cd2cf0ad 50cc03dd a57f19d3 4843d706 09c20343 4385fc90 42241549 edaaeecd 1ed4aebf 54ddeb88 08dac4fd 3307d698 ebb2c2f7 ac2b6b85 34f430ca e54d5869 39c98d5f d6c5745e 966d9c8a 27f52431 4524758d 91a4584a 4ef89e46 82d7d8ca b6c234fb 2d0e1fda 434b8e0c bd0b9dd7 7cececae a3edb582 a...   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                          9ec225f0 18281c6c e3b6b115 4a044c54 365fe576 a3188e54 b3f6e12d ee7655ca 84125b7a   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ...   \n",
       "139251                                                                                                                                                                                                                               09727c0c ff1ea6a0 ddfef603 a01ce9b3 3ba953ee bf92a015 f4a0492a 095812e6 53125cfe aa32a700 63340e73 06d8c952 400ceb37 55fa544e d3647ac8 f8e7d47e 7102897a a3a47643 ebd32b52 53caf4d9 b314d9e3 2986b5e1 7eb7350d 681c0d9b f083e1de 704b3ee9 a8e79846 eb887c6c 4faf1ad7 6122a91f 015cff34   \n",
       "139252                                                                                                                                                                                                                                                                                              978a5137 faa48f03 28dfb12a eea2e812 64fef97c 4e0d1510 58e68f2c 8784e700 4bd5a4cf dc14bfec 2aff7603 8047ded2 ac536a5b d2ec3efb d7172db2 0c5441b4 8bb4abd2 aa168c04 b01422ce 6e67b343 40e930ff b1873cbb 76e0f2a7 233d93b9   \n",
       "139253                                                                                                                                                                                                                                                                            5015c300 411b85d9 8238198c f4781d1d b5532930 e1f223e5 e7e67119 4aaf741d 7229cce6 a7fa3628 e4c2fa86 1f8f9d14 7a52357a e9b6265c b32dc5d2 41ccef58 6aff1ae7 29e1f39d b3c6bc16 37cbd460 79e4e69f ee9b8d31 8b54cf58 deead32c 56ee6e4c 56aa8da7   \n",
       "139254                                                                                                                                                                                  7e6266ad d8281fc5 d4ffcaef 3e0e4a47 21387fc8 cc229f9a baed9c8b d1bb21aa 82979992 65f95dad eba4fa9e c97e268d 7e1a6588 055e0d2e c090bd72 0bf4ab17 26374693 5098ff9a ef42f19d 28f8bc15 b47bacee 0fad41c8 4f671884 4b254efa 74802b2f 7c33c5b2 7168afec 9a2cdb85 fb7456dd 1fd0781b ff949d21 a16411ac 7a1b4718 777b3fc0 f90ee056 83dce89a   \n",
       "139255  1a63248d 9c3b96a5 1398a873 4e2d4c2d f71c538e 8b44a5e8 385dff7a b8254ef8 4d0e433e debc496c e15ae953 e4d79d73 4bd5172b 6d42873f 81716aa3 e5c8ea7f e70a860e cbb82224 3a10d610 903a4f30 87538ba7 38d2a90a 311547a2 dea83a8d 16df9139 debd617d ae4c0e45 ecf7b4a6 da763608 3f70fb8a d370b647 233c5ab1 3f3a2b35 d45ddc62 1edc1259 038f88b2 5ebcbc15 988e8c95 5cdba2e5 79a9c3ca 1481413e acad688b 197a28a9 0d770d6b 64c29f90 de53ba9c 75c5d93f 2c054107 ec3a94d7 1cc9d5d8 621e5af7 580f0e28 88a1479a 7849a30d a272122c e...   \n",
       "\n",
       "        n_cell_id  \n",
       "0              58  \n",
       "1              93  \n",
       "2              13  \n",
       "3             229  \n",
       "4               9  \n",
       "...           ...  \n",
       "139251         31  \n",
       "139252         24  \n",
       "139253         26  \n",
       "139254         36  \n",
       "139255         72  \n",
       "\n",
       "[139256 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_rank(df_orders):\n",
    "  ids = []\n",
    "  cell_ids = []\n",
    "  ranks = []\n",
    "  for row in df_orders.itertuples():\n",
    "    cells = row.cell_order.split()\n",
    "    ids.extend([row.id] * len(cells))\n",
    "    cell_ids.extend(cells)\n",
    "    ranks.extend(list(range(len(cells))))\n",
    "  df_rank = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'cell_id': cell_ids,\n",
    "    'rank': ranks,\n",
    "  })\n",
    "  return df_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>1862f0a6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>448eb224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>2a9e43d6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>7e2f170a</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>038b763d</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370641</th>\n",
       "      <td>fffe1d764579d5</td>\n",
       "      <td>5369934b</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370642</th>\n",
       "      <td>fffe1d764579d5</td>\n",
       "      <td>ac9db030</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370643</th>\n",
       "      <td>fffe1d764579d5</td>\n",
       "      <td>a8ffc8b4</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370644</th>\n",
       "      <td>fffe1d764579d5</td>\n",
       "      <td>70455170</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370645</th>\n",
       "      <td>fffe1d764579d5</td>\n",
       "      <td>380852e6</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6370646 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id   cell_id  rank\n",
       "0        00001756c60be8  1862f0a6     0\n",
       "1        00001756c60be8  448eb224     1\n",
       "2        00001756c60be8  2a9e43d6     2\n",
       "3        00001756c60be8  7e2f170a     3\n",
       "4        00001756c60be8  038b763d     4\n",
       "...                 ...       ...   ...\n",
       "6370641  fffe1d764579d5  5369934b    67\n",
       "6370642  fffe1d764579d5  ac9db030    68\n",
       "6370643  fffe1d764579d5  a8ffc8b4    69\n",
       "6370644  fffe1d764579d5  70455170    70\n",
       "6370645  fffe1d764579d5  380852e6    71\n",
       "\n",
       "[6370646 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rank = to_rank(df_orders)\n",
    "df_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>...</th>\n",
       "      <th>755</th>\n",
       "      <th>756</th>\n",
       "      <th>757</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>768</th>\n",
       "      <th>769</th>\n",
       "      <th>770</th>\n",
       "      <th>771</th>\n",
       "      <th>772</th>\n",
       "      <th>773</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "      <th>785</th>\n",
       "      <th>786</th>\n",
       "      <th>787</th>\n",
       "      <th>788</th>\n",
       "      <th>789</th>\n",
       "      <th>790</th>\n",
       "      <th>791</th>\n",
       "      <th>792</th>\n",
       "      <th>793</th>\n",
       "      <th>794</th>\n",
       "      <th>795</th>\n",
       "      <th>796</th>\n",
       "      <th>797</th>\n",
       "      <th>798</th>\n",
       "      <th>799</th>\n",
       "      <th>800</th>\n",
       "      <th>801</th>\n",
       "      <th>802</th>\n",
       "      <th>803</th>\n",
       "      <th>804</th>\n",
       "      <th>805</th>\n",
       "      <th>806</th>\n",
       "      <th>807</th>\n",
       "      <th>808</th>\n",
       "      <th>809</th>\n",
       "      <th>810</th>\n",
       "      <th>811</th>\n",
       "      <th>812</th>\n",
       "      <th>813</th>\n",
       "      <th>814</th>\n",
       "      <th>815</th>\n",
       "      <th>816</th>\n",
       "      <th>817</th>\n",
       "      <th>818</th>\n",
       "      <th>819</th>\n",
       "      <th>820</th>\n",
       "      <th>821</th>\n",
       "      <th>822</th>\n",
       "      <th>823</th>\n",
       "      <th>824</th>\n",
       "      <th>825</th>\n",
       "      <th>826</th>\n",
       "      <th>827</th>\n",
       "      <th>828</th>\n",
       "      <th>829</th>\n",
       "      <th>830</th>\n",
       "      <th>831</th>\n",
       "      <th>832</th>\n",
       "      <th>833</th>\n",
       "      <th>834</th>\n",
       "      <th>835</th>\n",
       "      <th>836</th>\n",
       "      <th>837</th>\n",
       "      <th>838</th>\n",
       "      <th>839</th>\n",
       "      <th>840</th>\n",
       "      <th>841</th>\n",
       "      <th>842</th>\n",
       "      <th>843</th>\n",
       "      <th>844</th>\n",
       "      <th>845</th>\n",
       "      <th>846</th>\n",
       "      <th>847</th>\n",
       "      <th>848</th>\n",
       "      <th>849</th>\n",
       "      <th>850</th>\n",
       "      <th>851</th>\n",
       "      <th>852</th>\n",
       "      <th>853</th>\n",
       "      <th>854</th>\n",
       "      <th>855</th>\n",
       "      <th>856</th>\n",
       "      <th>857</th>\n",
       "      <th>858</th>\n",
       "      <th>859</th>\n",
       "      <th>860</th>\n",
       "      <th>861</th>\n",
       "      <th>862</th>\n",
       "      <th>863</th>\n",
       "      <th>864</th>\n",
       "      <th>865</th>\n",
       "      <th>866</th>\n",
       "      <th>867</th>\n",
       "      <th>868</th>\n",
       "      <th>869</th>\n",
       "      <th>870</th>\n",
       "      <th>871</th>\n",
       "      <th>872</th>\n",
       "      <th>873</th>\n",
       "      <th>874</th>\n",
       "      <th>875</th>\n",
       "      <th>876</th>\n",
       "      <th>877</th>\n",
       "      <th>878</th>\n",
       "      <th>879</th>\n",
       "      <th>880</th>\n",
       "      <th>881</th>\n",
       "      <th>882</th>\n",
       "      <th>883</th>\n",
       "      <th>884</th>\n",
       "      <th>885</th>\n",
       "      <th>886</th>\n",
       "      <th>887</th>\n",
       "      <th>888</th>\n",
       "      <th>889</th>\n",
       "      <th>890</th>\n",
       "      <th>891</th>\n",
       "      <th>892</th>\n",
       "      <th>893</th>\n",
       "      <th>894</th>\n",
       "      <th>895</th>\n",
       "      <th>896</th>\n",
       "      <th>897</th>\n",
       "      <th>898</th>\n",
       "      <th>899</th>\n",
       "      <th>900</th>\n",
       "      <th>901</th>\n",
       "      <th>902</th>\n",
       "      <th>903</th>\n",
       "      <th>904</th>\n",
       "      <th>905</th>\n",
       "      <th>906</th>\n",
       "      <th>907</th>\n",
       "      <th>908</th>\n",
       "      <th>909</th>\n",
       "      <th>910</th>\n",
       "      <th>911</th>\n",
       "      <th>912</th>\n",
       "      <th>913</th>\n",
       "      <th>914</th>\n",
       "      <th>915</th>\n",
       "      <th>916</th>\n",
       "      <th>917</th>\n",
       "      <th>918</th>\n",
       "      <th>919</th>\n",
       "      <th>920</th>\n",
       "      <th>921</th>\n",
       "      <th>922</th>\n",
       "      <th>923</th>\n",
       "      <th>924</th>\n",
       "      <th>925</th>\n",
       "      <th>926</th>\n",
       "      <th>927</th>\n",
       "      <th>928</th>\n",
       "      <th>929</th>\n",
       "      <th>930</th>\n",
       "      <th>931</th>\n",
       "      <th>932</th>\n",
       "      <th>933</th>\n",
       "      <th>934</th>\n",
       "      <th>935</th>\n",
       "      <th>936</th>\n",
       "      <th>937</th>\n",
       "      <th>938</th>\n",
       "      <th>939</th>\n",
       "      <th>940</th>\n",
       "      <th>941</th>\n",
       "      <th>942</th>\n",
       "      <th>943</th>\n",
       "      <th>944</th>\n",
       "      <th>945</th>\n",
       "      <th>946</th>\n",
       "      <th>947</th>\n",
       "      <th>948</th>\n",
       "      <th>949</th>\n",
       "      <th>950</th>\n",
       "      <th>951</th>\n",
       "      <th>952</th>\n",
       "      <th>953</th>\n",
       "      <th>954</th>\n",
       "      <th>955</th>\n",
       "      <th>956</th>\n",
       "      <th>957</th>\n",
       "      <th>958</th>\n",
       "      <th>959</th>\n",
       "      <th>960</th>\n",
       "      <th>961</th>\n",
       "      <th>962</th>\n",
       "      <th>963</th>\n",
       "      <th>964</th>\n",
       "      <th>965</th>\n",
       "      <th>966</th>\n",
       "      <th>967</th>\n",
       "      <th>968</th>\n",
       "      <th>969</th>\n",
       "      <th>970</th>\n",
       "      <th>971</th>\n",
       "      <th>972</th>\n",
       "      <th>973</th>\n",
       "      <th>974</th>\n",
       "      <th>975</th>\n",
       "      <th>976</th>\n",
       "      <th>977</th>\n",
       "      <th>978</th>\n",
       "      <th>979</th>\n",
       "      <th>980</th>\n",
       "      <th>981</th>\n",
       "      <th>982</th>\n",
       "      <th>983</th>\n",
       "      <th>984</th>\n",
       "      <th>985</th>\n",
       "      <th>986</th>\n",
       "      <th>987</th>\n",
       "      <th>988</th>\n",
       "      <th>989</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>1000</th>\n",
       "      <th>1001</th>\n",
       "      <th>1002</th>\n",
       "      <th>1003</th>\n",
       "      <th>1004</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1862f0a6</td>\n",
       "      <td>448eb224</td>\n",
       "      <td>2a9e43d6</td>\n",
       "      <td>7e2f170a</td>\n",
       "      <td>038b763d</td>\n",
       "      <td>77e56113</td>\n",
       "      <td>2eefe0ef</td>\n",
       "      <td>1ae087ab</td>\n",
       "      <td>0beab1cd</td>\n",
       "      <td>8ffe0b25</td>\n",
       "      <td>9a78ab76</td>\n",
       "      <td>0d136e08</td>\n",
       "      <td>8a4c95d1</td>\n",
       "      <td>23705731</td>\n",
       "      <td>ebe125d5</td>\n",
       "      <td>aaad8355</td>\n",
       "      <td>d9dced8b</td>\n",
       "      <td>21616367</td>\n",
       "      <td>86497fe1</td>\n",
       "      <td>c3ce0945</td>\n",
       "      <td>e2c8e725</td>\n",
       "      <td>a6357f7e</td>\n",
       "      <td>ff7c44ed</td>\n",
       "      <td>ac301a84</td>\n",
       "      <td>0e7c906e</td>\n",
       "      <td>dd0c804a</td>\n",
       "      <td>45082c89</td>\n",
       "      <td>781bbf3c</td>\n",
       "      <td>4bb2e30a</td>\n",
       "      <td>bd94f005</td>\n",
       "      <td>63c26fa2</td>\n",
       "      <td>62638fba</td>\n",
       "      <td>3e5f860d</td>\n",
       "      <td>bb69e88c</td>\n",
       "      <td>6b5664c7</td>\n",
       "      <td>3eebeb87</td>\n",
       "      <td>23783525</td>\n",
       "      <td>36002912</td>\n",
       "      <td>bfbde93e</td>\n",
       "      <td>8522781a</td>\n",
       "      <td>1496beaf</td>\n",
       "      <td>8ca8392c</td>\n",
       "      <td>b69a4f9b</td>\n",
       "      <td>17ec3fc4</td>\n",
       "      <td>503926eb</td>\n",
       "      <td>76512d50</td>\n",
       "      <td>032e2820</td>\n",
       "      <td>a98c5d9f</td>\n",
       "      <td>06365725</td>\n",
       "      <td>8554b284</td>\n",
       "      <td>59959af5</td>\n",
       "      <td>2e1a5949</td>\n",
       "      <td>80151ab7</td>\n",
       "      <td>fcb6792d</td>\n",
       "      <td>5bf9ca51</td>\n",
       "      <td>915643b3</td>\n",
       "      <td>f5504853</td>\n",
       "      <td>9f50dca0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2e94bd7a</td>\n",
       "      <td>3e99dee9</td>\n",
       "      <td>b5e286ea</td>\n",
       "      <td>da4f7550</td>\n",
       "      <td>c417225b</td>\n",
       "      <td>51e3cd89</td>\n",
       "      <td>2600b4eb</td>\n",
       "      <td>75b65993</td>\n",
       "      <td>cf195f8b</td>\n",
       "      <td>25699d02</td>\n",
       "      <td>72b3201a</td>\n",
       "      <td>f2c750d3</td>\n",
       "      <td>de148b56</td>\n",
       "      <td>42749e24</td>\n",
       "      <td>fbe3e811</td>\n",
       "      <td>9901472c</td>\n",
       "      <td>10377ef8</td>\n",
       "      <td>1f462e2f</td>\n",
       "      <td>fceeb3e6</td>\n",
       "      <td>ceba8ae0</td>\n",
       "      <td>924c9f0f</td>\n",
       "      <td>2af2a41a</td>\n",
       "      <td>91e68f13</td>\n",
       "      <td>9216a113</td>\n",
       "      <td>63753f10</td>\n",
       "      <td>d5aee1e4</td>\n",
       "      <td>dc8a39a5</td>\n",
       "      <td>3d0a28c2</td>\n",
       "      <td>657a8804</td>\n",
       "      <td>0eea9701</td>\n",
       "      <td>a8fcc3e3</td>\n",
       "      <td>a6f8f9f1</td>\n",
       "      <td>7223cfc2</td>\n",
       "      <td>a166703b</td>\n",
       "      <td>df6b3ccb</td>\n",
       "      <td>da8b817a</td>\n",
       "      <td>a9b266d2</td>\n",
       "      <td>41beeead</td>\n",
       "      <td>3e17f424</td>\n",
       "      <td>cd61f6d1</td>\n",
       "      <td>42f0c365</td>\n",
       "      <td>cc8d23d8</td>\n",
       "      <td>be6c9079</td>\n",
       "      <td>ad42abc1</td>\n",
       "      <td>7894c4e8</td>\n",
       "      <td>eab2b130</td>\n",
       "      <td>cc1add42</td>\n",
       "      <td>16b0d436</td>\n",
       "      <td>a3e791de</td>\n",
       "      <td>183226e4</td>\n",
       "      <td>02ef0932</td>\n",
       "      <td>03441163</td>\n",
       "      <td>f2915b9f</td>\n",
       "      <td>d429a743</td>\n",
       "      <td>4d5ebd46</td>\n",
       "      <td>3adcd0f8</td>\n",
       "      <td>d8f4dfe0</td>\n",
       "      <td>d47d3338</td>\n",
       "      <td>c5b89474</td>\n",
       "      <td>b5ef409a</td>\n",
       "      <td>7bb6803b</td>\n",
       "      <td>36b95373</td>\n",
       "      <td>31d43a34</td>\n",
       "      <td>cba54be3</td>\n",
       "      <td>c33ab270</td>\n",
       "      <td>23cb507d</td>\n",
       "      <td>017f1c1b</td>\n",
       "      <td>e458b502</td>\n",
       "      <td>8542d6fc</td>\n",
       "      <td>10fc0035</td>\n",
       "      <td>61f2723c</td>\n",
       "      <td>06b8472a</td>\n",
       "      <td>704a44aa</td>\n",
       "      <td>c7bb2674</td>\n",
       "      <td>da1357af</td>\n",
       "      <td>7a416873</td>\n",
       "      <td>1554d3bc</td>\n",
       "      <td>512a821e</td>\n",
       "      <td>bf2740de</td>\n",
       "      <td>fa1ee016</td>\n",
       "      <td>ce96953f</td>\n",
       "      <td>96c19678</td>\n",
       "      <td>275d2fa7</td>\n",
       "      <td>4de05ac0</td>\n",
       "      <td>9aadfa3f</td>\n",
       "      <td>60840c05</td>\n",
       "      <td>a829d740</td>\n",
       "      <td>14feb55f</td>\n",
       "      <td>b8f3850a</td>\n",
       "      <td>ccbe6713</td>\n",
       "      <td>1ecd4e35</td>\n",
       "      <td>1e21e4e5</td>\n",
       "      <td>3db2d50e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3fdc37be</td>\n",
       "      <td>073782ca</td>\n",
       "      <td>8ea7263c</td>\n",
       "      <td>80543cd8</td>\n",
       "      <td>38310c80</td>\n",
       "      <td>073e27e5</td>\n",
       "      <td>015d52a4</td>\n",
       "      <td>ad7679ef</td>\n",
       "      <td>7fde4f04</td>\n",
       "      <td>07c52510</td>\n",
       "      <td>0a1a7a39</td>\n",
       "      <td>0bcd3fef</td>\n",
       "      <td>58bf360b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97266564</td>\n",
       "      <td>a898e555</td>\n",
       "      <td>86605076</td>\n",
       "      <td>76cc2642</td>\n",
       "      <td>ef279279</td>\n",
       "      <td>df6c939f</td>\n",
       "      <td>2476da96</td>\n",
       "      <td>00f87d0a</td>\n",
       "      <td>ae93e8e6</td>\n",
       "      <td>58aadb1d</td>\n",
       "      <td>d20b0094</td>\n",
       "      <td>986fd4f1</td>\n",
       "      <td>b4ff1015</td>\n",
       "      <td>9b761026</td>\n",
       "      <td>6f271c86</td>\n",
       "      <td>97c3f99b</td>\n",
       "      <td>2451daed</td>\n",
       "      <td>cfa510c5</td>\n",
       "      <td>374a5179</td>\n",
       "      <td>df5f7c1f</td>\n",
       "      <td>27060ab9</td>\n",
       "      <td>4c7395ec</td>\n",
       "      <td>2d2f9893</td>\n",
       "      <td>35c2812a</td>\n",
       "      <td>a6617a52</td>\n",
       "      <td>cd2cf0ad</td>\n",
       "      <td>50cc03dd</td>\n",
       "      <td>a57f19d3</td>\n",
       "      <td>4843d706</td>\n",
       "      <td>09c20343</td>\n",
       "      <td>4385fc90</td>\n",
       "      <td>42241549</td>\n",
       "      <td>edaaeecd</td>\n",
       "      <td>1ed4aebf</td>\n",
       "      <td>54ddeb88</td>\n",
       "      <td>08dac4fd</td>\n",
       "      <td>3307d698</td>\n",
       "      <td>ebb2c2f7</td>\n",
       "      <td>ac2b6b85</td>\n",
       "      <td>34f430ca</td>\n",
       "      <td>e54d5869</td>\n",
       "      <td>39c98d5f</td>\n",
       "      <td>d6c5745e</td>\n",
       "      <td>966d9c8a</td>\n",
       "      <td>27f52431</td>\n",
       "      <td>4524758d</td>\n",
       "      <td>91a4584a</td>\n",
       "      <td>4ef89e46</td>\n",
       "      <td>82d7d8ca</td>\n",
       "      <td>b6c234fb</td>\n",
       "      <td>2d0e1fda</td>\n",
       "      <td>434b8e0c</td>\n",
       "      <td>bd0b9dd7</td>\n",
       "      <td>7cececae</td>\n",
       "      <td>a3edb582</td>\n",
       "      <td>a149a6c4</td>\n",
       "      <td>1c3e1fb0</td>\n",
       "      <td>62583014</td>\n",
       "      <td>15dad586</td>\n",
       "      <td>877d834a</td>\n",
       "      <td>a5d57693</td>\n",
       "      <td>a4c281a6</td>\n",
       "      <td>7e5f83ad</td>\n",
       "      <td>b4b8a715</td>\n",
       "      <td>8ebf5372</td>\n",
       "      <td>8e116f02</td>\n",
       "      <td>d8c1a52c</td>\n",
       "      <td>16694b2f</td>\n",
       "      <td>aba60214</td>\n",
       "      <td>9bbdc57f</td>\n",
       "      <td>7a3bfebb</td>\n",
       "      <td>986d3e4e</td>\n",
       "      <td>09bc65e9</td>\n",
       "      <td>9f192db6</td>\n",
       "      <td>bc892c87</td>\n",
       "      <td>3fc62a28</td>\n",
       "      <td>8f62a706</td>\n",
       "      <td>d566f0b2</td>\n",
       "      <td>866bcefe</td>\n",
       "      <td>c57d48a5</td>\n",
       "      <td>c7b71f70</td>\n",
       "      <td>782c3ce4</td>\n",
       "      <td>a4c6bca9</td>\n",
       "      <td>63f506d8</td>\n",
       "      <td>b47c87d1</td>\n",
       "      <td>b0df2453</td>\n",
       "      <td>4e959393</td>\n",
       "      <td>1e0a1b86</td>\n",
       "      <td>e8688784</td>\n",
       "      <td>3427a8b8</td>\n",
       "      <td>241bdfaa</td>\n",
       "      <td>2a345714</td>\n",
       "      <td>68062669</td>\n",
       "      <td>6661ad27</td>\n",
       "      <td>e5a99bda</td>\n",
       "      <td>4fc4a21d</td>\n",
       "      <td>452cca1e</td>\n",
       "      <td>589730c3</td>\n",
       "      <td>3abd855f</td>\n",
       "      <td>cb6bfaac</td>\n",
       "      <td>4da7dfe7</td>\n",
       "      <td>9e71d61f</td>\n",
       "      <td>a52728cb</td>\n",
       "      <td>dbd14ff6</td>\n",
       "      <td>bd8a9f63</td>\n",
       "      <td>4640d46a</td>\n",
       "      <td>c96b5411</td>\n",
       "      <td>413f9a07</td>\n",
       "      <td>a3f33b49</td>\n",
       "      <td>7af53379</td>\n",
       "      <td>cbe712bb</td>\n",
       "      <td>5977f7af</td>\n",
       "      <td>feb6d95b</td>\n",
       "      <td>bce157d4</td>\n",
       "      <td>47483667</td>\n",
       "      <td>18f59ddc</td>\n",
       "      <td>d383dee5</td>\n",
       "      <td>22f00d53</td>\n",
       "      <td>e657a288</td>\n",
       "      <td>3a3d6ca9</td>\n",
       "      <td>6885acfa</td>\n",
       "      <td>c3d72360</td>\n",
       "      <td>3922f106</td>\n",
       "      <td>4dff5311</td>\n",
       "      <td>f037b8fa</td>\n",
       "      <td>1d244331</td>\n",
       "      <td>ed43e7da</td>\n",
       "      <td>c4a0c7d9</td>\n",
       "      <td>abb8549b</td>\n",
       "      <td>22d5f1a7</td>\n",
       "      <td>25676b01</td>\n",
       "      <td>9e5ab122</td>\n",
       "      <td>f3d136b8</td>\n",
       "      <td>240a6960</td>\n",
       "      <td>42fa445a</td>\n",
       "      <td>a212f377</td>\n",
       "      <td>12cee4fb</td>\n",
       "      <td>c6a15d66</td>\n",
       "      <td>9c07e522</td>\n",
       "      <td>8c76efd3</td>\n",
       "      <td>26b8b7b3</td>\n",
       "      <td>b78b7d75</td>\n",
       "      <td>60ffcfb7</td>\n",
       "      <td>05189262</td>\n",
       "      <td>5c2c242c</td>\n",
       "      <td>845d608e</td>\n",
       "      <td>47ab82bd</td>\n",
       "      <td>c3964ed5</td>\n",
       "      <td>a3a445ac</td>\n",
       "      <td>27e84e59</td>\n",
       "      <td>09a985c1</td>\n",
       "      <td>e2ffe24f</td>\n",
       "      <td>00c718df</td>\n",
       "      <td>ffef7d1c</td>\n",
       "      <td>d30721e7</td>\n",
       "      <td>533f0c45</td>\n",
       "      <td>b5230e68</td>\n",
       "      <td>48f93c95</td>\n",
       "      <td>80096ae5</td>\n",
       "      <td>fb965995</td>\n",
       "      <td>41307604</td>\n",
       "      <td>15e0f9d3</td>\n",
       "      <td>9091b53a</td>\n",
       "      <td>ac2ac7ac</td>\n",
       "      <td>9acd0dba</td>\n",
       "      <td>4820b1e9</td>\n",
       "      <td>7edacbaa</td>\n",
       "      <td>03a6fa77</td>\n",
       "      <td>3bbbed26</td>\n",
       "      <td>bd02d177</td>\n",
       "      <td>ed25d9b2</td>\n",
       "      <td>ccee4822</td>\n",
       "      <td>617f740b</td>\n",
       "      <td>96cd3e40</td>\n",
       "      <td>06dd359d</td>\n",
       "      <td>9db3d92c</td>\n",
       "      <td>5d8dbc19</td>\n",
       "      <td>03f870e7</td>\n",
       "      <td>df459c56</td>\n",
       "      <td>d08e1e66</td>\n",
       "      <td>0a35f26c</td>\n",
       "      <td>275b3536</td>\n",
       "      <td>27f48db8</td>\n",
       "      <td>8c4e17c3</td>\n",
       "      <td>faa3d95b</td>\n",
       "      <td>bd4ab364</td>\n",
       "      <td>e6ea9cab</td>\n",
       "      <td>19327444</td>\n",
       "      <td>4e273e75</td>\n",
       "      <td>ea162346</td>\n",
       "      <td>d3193bb5</td>\n",
       "      <td>7eca03a2</td>\n",
       "      <td>bf258cbf</td>\n",
       "      <td>a6cc7795</td>\n",
       "      <td>3ee91998</td>\n",
       "      <td>daf25de1</td>\n",
       "      <td>c17d3103</td>\n",
       "      <td>91b32c22</td>\n",
       "      <td>3c5f7ba6</td>\n",
       "      <td>ccdf26d9</td>\n",
       "      <td>10b299e5</td>\n",
       "      <td>68a1e47b</td>\n",
       "      <td>1aee8a93</td>\n",
       "      <td>2f122e5b</td>\n",
       "      <td>df0fc7d0</td>\n",
       "      <td>50b08f93</td>\n",
       "      <td>4acf6d10</td>\n",
       "      <td>9711f0f6</td>\n",
       "      <td>b9bb5ea6</td>\n",
       "      <td>996607a1</td>\n",
       "      <td>4a9cfa67</td>\n",
       "      <td>bc711534</td>\n",
       "      <td>41910025</td>\n",
       "      <td>9fd822ca</td>\n",
       "      <td>3548485c</td>\n",
       "      <td>40842d13</td>\n",
       "      <td>e887f5e6</td>\n",
       "      <td>204afb8e</td>\n",
       "      <td>90f317a2</td>\n",
       "      <td>b307e234</td>\n",
       "      <td>954ca3e4</td>\n",
       "      <td>ca8e5e0a</td>\n",
       "      <td>8dcaddf3</td>\n",
       "      <td>ca74117a</td>\n",
       "      <td>fdb8d575</td>\n",
       "      <td>63625ef7</td>\n",
       "      <td>16e57be6</td>\n",
       "      <td>719f2ae4</td>\n",
       "      <td>075b5763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9ec225f0</td>\n",
       "      <td>18281c6c</td>\n",
       "      <td>e3b6b115</td>\n",
       "      <td>4a044c54</td>\n",
       "      <td>365fe576</td>\n",
       "      <td>a3188e54</td>\n",
       "      <td>b3f6e12d</td>\n",
       "      <td>ee7655ca</td>\n",
       "      <td>84125b7a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139251</th>\n",
       "      <td>09727c0c</td>\n",
       "      <td>ff1ea6a0</td>\n",
       "      <td>ddfef603</td>\n",
       "      <td>a01ce9b3</td>\n",
       "      <td>3ba953ee</td>\n",
       "      <td>bf92a015</td>\n",
       "      <td>f4a0492a</td>\n",
       "      <td>095812e6</td>\n",
       "      <td>53125cfe</td>\n",
       "      <td>aa32a700</td>\n",
       "      <td>63340e73</td>\n",
       "      <td>06d8c952</td>\n",
       "      <td>400ceb37</td>\n",
       "      <td>55fa544e</td>\n",
       "      <td>d3647ac8</td>\n",
       "      <td>f8e7d47e</td>\n",
       "      <td>7102897a</td>\n",
       "      <td>a3a47643</td>\n",
       "      <td>ebd32b52</td>\n",
       "      <td>53caf4d9</td>\n",
       "      <td>b314d9e3</td>\n",
       "      <td>2986b5e1</td>\n",
       "      <td>7eb7350d</td>\n",
       "      <td>681c0d9b</td>\n",
       "      <td>f083e1de</td>\n",
       "      <td>704b3ee9</td>\n",
       "      <td>a8e79846</td>\n",
       "      <td>eb887c6c</td>\n",
       "      <td>4faf1ad7</td>\n",
       "      <td>6122a91f</td>\n",
       "      <td>015cff34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139252</th>\n",
       "      <td>978a5137</td>\n",
       "      <td>faa48f03</td>\n",
       "      <td>28dfb12a</td>\n",
       "      <td>eea2e812</td>\n",
       "      <td>64fef97c</td>\n",
       "      <td>4e0d1510</td>\n",
       "      <td>58e68f2c</td>\n",
       "      <td>8784e700</td>\n",
       "      <td>4bd5a4cf</td>\n",
       "      <td>dc14bfec</td>\n",
       "      <td>2aff7603</td>\n",
       "      <td>8047ded2</td>\n",
       "      <td>ac536a5b</td>\n",
       "      <td>d2ec3efb</td>\n",
       "      <td>d7172db2</td>\n",
       "      <td>0c5441b4</td>\n",
       "      <td>8bb4abd2</td>\n",
       "      <td>aa168c04</td>\n",
       "      <td>b01422ce</td>\n",
       "      <td>6e67b343</td>\n",
       "      <td>40e930ff</td>\n",
       "      <td>b1873cbb</td>\n",
       "      <td>76e0f2a7</td>\n",
       "      <td>233d93b9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139253</th>\n",
       "      <td>5015c300</td>\n",
       "      <td>411b85d9</td>\n",
       "      <td>8238198c</td>\n",
       "      <td>f4781d1d</td>\n",
       "      <td>b5532930</td>\n",
       "      <td>e1f223e5</td>\n",
       "      <td>e7e67119</td>\n",
       "      <td>4aaf741d</td>\n",
       "      <td>7229cce6</td>\n",
       "      <td>a7fa3628</td>\n",
       "      <td>e4c2fa86</td>\n",
       "      <td>1f8f9d14</td>\n",
       "      <td>7a52357a</td>\n",
       "      <td>e9b6265c</td>\n",
       "      <td>b32dc5d2</td>\n",
       "      <td>41ccef58</td>\n",
       "      <td>6aff1ae7</td>\n",
       "      <td>29e1f39d</td>\n",
       "      <td>b3c6bc16</td>\n",
       "      <td>37cbd460</td>\n",
       "      <td>79e4e69f</td>\n",
       "      <td>ee9b8d31</td>\n",
       "      <td>8b54cf58</td>\n",
       "      <td>deead32c</td>\n",
       "      <td>56ee6e4c</td>\n",
       "      <td>56aa8da7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139254</th>\n",
       "      <td>7e6266ad</td>\n",
       "      <td>d8281fc5</td>\n",
       "      <td>d4ffcaef</td>\n",
       "      <td>3e0e4a47</td>\n",
       "      <td>21387fc8</td>\n",
       "      <td>cc229f9a</td>\n",
       "      <td>baed9c8b</td>\n",
       "      <td>d1bb21aa</td>\n",
       "      <td>82979992</td>\n",
       "      <td>65f95dad</td>\n",
       "      <td>eba4fa9e</td>\n",
       "      <td>c97e268d</td>\n",
       "      <td>7e1a6588</td>\n",
       "      <td>055e0d2e</td>\n",
       "      <td>c090bd72</td>\n",
       "      <td>0bf4ab17</td>\n",
       "      <td>26374693</td>\n",
       "      <td>5098ff9a</td>\n",
       "      <td>ef42f19d</td>\n",
       "      <td>28f8bc15</td>\n",
       "      <td>b47bacee</td>\n",
       "      <td>0fad41c8</td>\n",
       "      <td>4f671884</td>\n",
       "      <td>4b254efa</td>\n",
       "      <td>74802b2f</td>\n",
       "      <td>7c33c5b2</td>\n",
       "      <td>7168afec</td>\n",
       "      <td>9a2cdb85</td>\n",
       "      <td>fb7456dd</td>\n",
       "      <td>1fd0781b</td>\n",
       "      <td>ff949d21</td>\n",
       "      <td>a16411ac</td>\n",
       "      <td>7a1b4718</td>\n",
       "      <td>777b3fc0</td>\n",
       "      <td>f90ee056</td>\n",
       "      <td>83dce89a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139255</th>\n",
       "      <td>1a63248d</td>\n",
       "      <td>9c3b96a5</td>\n",
       "      <td>1398a873</td>\n",
       "      <td>4e2d4c2d</td>\n",
       "      <td>f71c538e</td>\n",
       "      <td>8b44a5e8</td>\n",
       "      <td>385dff7a</td>\n",
       "      <td>b8254ef8</td>\n",
       "      <td>4d0e433e</td>\n",
       "      <td>debc496c</td>\n",
       "      <td>e15ae953</td>\n",
       "      <td>e4d79d73</td>\n",
       "      <td>4bd5172b</td>\n",
       "      <td>6d42873f</td>\n",
       "      <td>81716aa3</td>\n",
       "      <td>e5c8ea7f</td>\n",
       "      <td>e70a860e</td>\n",
       "      <td>cbb82224</td>\n",
       "      <td>3a10d610</td>\n",
       "      <td>903a4f30</td>\n",
       "      <td>87538ba7</td>\n",
       "      <td>38d2a90a</td>\n",
       "      <td>311547a2</td>\n",
       "      <td>dea83a8d</td>\n",
       "      <td>16df9139</td>\n",
       "      <td>debd617d</td>\n",
       "      <td>ae4c0e45</td>\n",
       "      <td>ecf7b4a6</td>\n",
       "      <td>da763608</td>\n",
       "      <td>3f70fb8a</td>\n",
       "      <td>d370b647</td>\n",
       "      <td>233c5ab1</td>\n",
       "      <td>3f3a2b35</td>\n",
       "      <td>d45ddc62</td>\n",
       "      <td>1edc1259</td>\n",
       "      <td>038f88b2</td>\n",
       "      <td>5ebcbc15</td>\n",
       "      <td>988e8c95</td>\n",
       "      <td>5cdba2e5</td>\n",
       "      <td>79a9c3ca</td>\n",
       "      <td>1481413e</td>\n",
       "      <td>acad688b</td>\n",
       "      <td>197a28a9</td>\n",
       "      <td>0d770d6b</td>\n",
       "      <td>64c29f90</td>\n",
       "      <td>de53ba9c</td>\n",
       "      <td>75c5d93f</td>\n",
       "      <td>2c054107</td>\n",
       "      <td>ec3a94d7</td>\n",
       "      <td>1cc9d5d8</td>\n",
       "      <td>621e5af7</td>\n",
       "      <td>580f0e28</td>\n",
       "      <td>88a1479a</td>\n",
       "      <td>7849a30d</td>\n",
       "      <td>a272122c</td>\n",
       "      <td>e309eec8</td>\n",
       "      <td>1747ebd1</td>\n",
       "      <td>aae5bae0</td>\n",
       "      <td>a1a9695c</td>\n",
       "      <td>75a29163</td>\n",
       "      <td>b398309c</td>\n",
       "      <td>6110cdeb</td>\n",
       "      <td>f8f6550b</td>\n",
       "      <td>63638bb1</td>\n",
       "      <td>a51064ed</td>\n",
       "      <td>162bda18</td>\n",
       "      <td>9135db5b</td>\n",
       "      <td>5369934b</td>\n",
       "      <td>ac9db030</td>\n",
       "      <td>a8ffc8b4</td>\n",
       "      <td>70455170</td>\n",
       "      <td>380852e6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139256 rows × 1005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6     \\\n",
       "0       1862f0a6  448eb224  2a9e43d6  7e2f170a  038b763d  77e56113  2eefe0ef   \n",
       "1       2e94bd7a  3e99dee9  b5e286ea  da4f7550  c417225b  51e3cd89  2600b4eb   \n",
       "2       3fdc37be  073782ca  8ea7263c  80543cd8  38310c80  073e27e5  015d52a4   \n",
       "3       97266564  a898e555  86605076  76cc2642  ef279279  df6c939f  2476da96   \n",
       "4       9ec225f0  18281c6c  e3b6b115  4a044c54  365fe576  a3188e54  b3f6e12d   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251  09727c0c  ff1ea6a0  ddfef603  a01ce9b3  3ba953ee  bf92a015  f4a0492a   \n",
       "139252  978a5137  faa48f03  28dfb12a  eea2e812  64fef97c  4e0d1510  58e68f2c   \n",
       "139253  5015c300  411b85d9  8238198c  f4781d1d  b5532930  e1f223e5  e7e67119   \n",
       "139254  7e6266ad  d8281fc5  d4ffcaef  3e0e4a47  21387fc8  cc229f9a  baed9c8b   \n",
       "139255  1a63248d  9c3b96a5  1398a873  4e2d4c2d  f71c538e  8b44a5e8  385dff7a   \n",
       "\n",
       "            7         8         9         10        11        12        13    \\\n",
       "0       1ae087ab  0beab1cd  8ffe0b25  9a78ab76  0d136e08  8a4c95d1  23705731   \n",
       "1       75b65993  cf195f8b  25699d02  72b3201a  f2c750d3  de148b56  42749e24   \n",
       "2       ad7679ef  7fde4f04  07c52510  0a1a7a39  0bcd3fef  58bf360b       NaN   \n",
       "3       00f87d0a  ae93e8e6  58aadb1d  d20b0094  986fd4f1  b4ff1015  9b761026   \n",
       "4       ee7655ca  84125b7a       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251  095812e6  53125cfe  aa32a700  63340e73  06d8c952  400ceb37  55fa544e   \n",
       "139252  8784e700  4bd5a4cf  dc14bfec  2aff7603  8047ded2  ac536a5b  d2ec3efb   \n",
       "139253  4aaf741d  7229cce6  a7fa3628  e4c2fa86  1f8f9d14  7a52357a  e9b6265c   \n",
       "139254  d1bb21aa  82979992  65f95dad  eba4fa9e  c97e268d  7e1a6588  055e0d2e   \n",
       "139255  b8254ef8  4d0e433e  debc496c  e15ae953  e4d79d73  4bd5172b  6d42873f   \n",
       "\n",
       "            14        15        16        17        18        19        20    \\\n",
       "0       ebe125d5  aaad8355  d9dced8b  21616367  86497fe1  c3ce0945  e2c8e725   \n",
       "1       fbe3e811  9901472c  10377ef8  1f462e2f  fceeb3e6  ceba8ae0  924c9f0f   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       6f271c86  97c3f99b  2451daed  cfa510c5  374a5179  df5f7c1f  27060ab9   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251  d3647ac8  f8e7d47e  7102897a  a3a47643  ebd32b52  53caf4d9  b314d9e3   \n",
       "139252  d7172db2  0c5441b4  8bb4abd2  aa168c04  b01422ce  6e67b343  40e930ff   \n",
       "139253  b32dc5d2  41ccef58  6aff1ae7  29e1f39d  b3c6bc16  37cbd460  79e4e69f   \n",
       "139254  c090bd72  0bf4ab17  26374693  5098ff9a  ef42f19d  28f8bc15  b47bacee   \n",
       "139255  81716aa3  e5c8ea7f  e70a860e  cbb82224  3a10d610  903a4f30  87538ba7   \n",
       "\n",
       "            21        22        23        24        25        26        27    \\\n",
       "0       a6357f7e  ff7c44ed  ac301a84  0e7c906e  dd0c804a  45082c89  781bbf3c   \n",
       "1       2af2a41a  91e68f13  9216a113  63753f10  d5aee1e4  dc8a39a5  3d0a28c2   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       4c7395ec  2d2f9893  35c2812a  a6617a52  cd2cf0ad  50cc03dd  a57f19d3   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251  2986b5e1  7eb7350d  681c0d9b  f083e1de  704b3ee9  a8e79846  eb887c6c   \n",
       "139252  b1873cbb  76e0f2a7  233d93b9       NaN       NaN       NaN       NaN   \n",
       "139253  ee9b8d31  8b54cf58  deead32c  56ee6e4c  56aa8da7       NaN       NaN   \n",
       "139254  0fad41c8  4f671884  4b254efa  74802b2f  7c33c5b2  7168afec  9a2cdb85   \n",
       "139255  38d2a90a  311547a2  dea83a8d  16df9139  debd617d  ae4c0e45  ecf7b4a6   \n",
       "\n",
       "            28        29        30        31        32        33        34    \\\n",
       "0       4bb2e30a  bd94f005  63c26fa2  62638fba  3e5f860d  bb69e88c  6b5664c7   \n",
       "1       657a8804  0eea9701  a8fcc3e3  a6f8f9f1  7223cfc2  a166703b  df6b3ccb   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       4843d706  09c20343  4385fc90  42241549  edaaeecd  1ed4aebf  54ddeb88   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251  4faf1ad7  6122a91f  015cff34       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254  fb7456dd  1fd0781b  ff949d21  a16411ac  7a1b4718  777b3fc0  f90ee056   \n",
       "139255  da763608  3f70fb8a  d370b647  233c5ab1  3f3a2b35  d45ddc62  1edc1259   \n",
       "\n",
       "            35        36        37        38        39        40        41    \\\n",
       "0       3eebeb87  23783525  36002912  bfbde93e  8522781a  1496beaf  8ca8392c   \n",
       "1       da8b817a  a9b266d2  41beeead  3e17f424  cd61f6d1  42f0c365  cc8d23d8   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       08dac4fd  3307d698  ebb2c2f7  ac2b6b85  34f430ca  e54d5869  39c98d5f   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254  83dce89a       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255  038f88b2  5ebcbc15  988e8c95  5cdba2e5  79a9c3ca  1481413e  acad688b   \n",
       "\n",
       "            42        43        44        45        46        47        48    \\\n",
       "0       b69a4f9b  17ec3fc4  503926eb  76512d50  032e2820  a98c5d9f  06365725   \n",
       "1       be6c9079  ad42abc1  7894c4e8  eab2b130  cc1add42  16b0d436  a3e791de   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       d6c5745e  966d9c8a  27f52431  4524758d  91a4584a  4ef89e46  82d7d8ca   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255  197a28a9  0d770d6b  64c29f90  de53ba9c  75c5d93f  2c054107  ec3a94d7   \n",
       "\n",
       "            49        50        51        52        53        54        55    \\\n",
       "0       8554b284  59959af5  2e1a5949  80151ab7  fcb6792d  5bf9ca51  915643b3   \n",
       "1       183226e4  02ef0932  03441163  f2915b9f  d429a743  4d5ebd46  3adcd0f8   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       b6c234fb  2d0e1fda  434b8e0c  bd0b9dd7  7cececae  a3edb582  a149a6c4   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255  1cc9d5d8  621e5af7  580f0e28  88a1479a  7849a30d  a272122c  e309eec8   \n",
       "\n",
       "            56        57        58        59        60        61        62    \\\n",
       "0       f5504853  9f50dca0       NaN       NaN       NaN       NaN       NaN   \n",
       "1       d8f4dfe0  d47d3338  c5b89474  b5ef409a  7bb6803b  36b95373  31d43a34   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       1c3e1fb0  62583014  15dad586  877d834a  a5d57693  a4c281a6  7e5f83ad   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255  1747ebd1  aae5bae0  a1a9695c  75a29163  b398309c  6110cdeb  f8f6550b   \n",
       "\n",
       "            63        64        65        66        67        68        69    \\\n",
       "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1       cba54be3  c33ab270  23cb507d  017f1c1b  e458b502  8542d6fc  10fc0035   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       b4b8a715  8ebf5372  8e116f02  d8c1a52c  16694b2f  aba60214  9bbdc57f   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255  63638bb1  a51064ed  162bda18  9135db5b  5369934b  ac9db030  a8ffc8b4   \n",
       "\n",
       "            70        71        72        73        74        75        76    \\\n",
       "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1       61f2723c  06b8472a  704a44aa  c7bb2674  da1357af  7a416873  1554d3bc   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       7a3bfebb  986d3e4e  09bc65e9  9f192db6  bc892c87  3fc62a28  8f62a706   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255  70455170  380852e6       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            77        78        79        80        81        82        83    \\\n",
       "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1       512a821e  bf2740de  fa1ee016  ce96953f  96c19678  275d2fa7  4de05ac0   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       d566f0b2  866bcefe  c57d48a5  c7b71f70  782c3ce4  a4c6bca9  63f506d8   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            84        85        86        87        88        89        90    \\\n",
       "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1       9aadfa3f  60840c05  a829d740  14feb55f  b8f3850a  ccbe6713  1ecd4e35   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       b47c87d1  b0df2453  4e959393  1e0a1b86  e8688784  3427a8b8  241bdfaa   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            91        92        93        94        95        96        97    \\\n",
       "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1       1e21e4e5  3db2d50e       NaN       NaN       NaN       NaN       NaN   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       2a345714  68062669  6661ad27  e5a99bda  4fc4a21d  452cca1e  589730c3   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            98        99        100       101       102       103       104   \\\n",
       "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       3abd855f  cb6bfaac  4da7dfe7  9e71d61f  a52728cb  dbd14ff6  bd8a9f63   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            105       106       107       108       109       110       111   \\\n",
       "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       4640d46a  c96b5411  413f9a07  a3f33b49  7af53379  cbe712bb  5977f7af   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            112       113       114       115       116       117       118   \\\n",
       "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       feb6d95b  bce157d4  47483667  18f59ddc  d383dee5  22f00d53  e657a288   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            119       120       121       122       123       124       125   \\\n",
       "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       3a3d6ca9  6885acfa  c3d72360  3922f106  4dff5311  f037b8fa  1d244331   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            126       127       128       129       130       131       132   \\\n",
       "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       ed43e7da  c4a0c7d9  abb8549b  22d5f1a7  25676b01  9e5ab122  f3d136b8   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            133       134       135       136       137       138       139   \\\n",
       "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       240a6960  42fa445a  a212f377  12cee4fb  c6a15d66  9c07e522  8c76efd3   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            140       141       142       143       144       145       146   \\\n",
       "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       26b8b7b3  b78b7d75  60ffcfb7  05189262  5c2c242c  845d608e  47ab82bd   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            147       148       149       150       151       152       153   \\\n",
       "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       c3964ed5  a3a445ac  27e84e59  09a985c1  e2ffe24f  00c718df  ffef7d1c   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            154       155       156       157       158       159       160   \\\n",
       "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       d30721e7  533f0c45  b5230e68  48f93c95  80096ae5  fb965995  41307604   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            161       162       163       164       165       166       167   \\\n",
       "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       15e0f9d3  9091b53a  ac2ac7ac  9acd0dba  4820b1e9  7edacbaa  03a6fa77   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            168       169       170       171       172       173       174   \\\n",
       "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       3bbbed26  bd02d177  ed25d9b2  ccee4822  617f740b  96cd3e40  06dd359d   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            175       176       177       178       179       180       181   \\\n",
       "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       9db3d92c  5d8dbc19  03f870e7  df459c56  d08e1e66  0a35f26c  275b3536   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            182       183       184       185       186       187       188   \\\n",
       "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       27f48db8  8c4e17c3  faa3d95b  bd4ab364  e6ea9cab  19327444  4e273e75   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            189       190       191       192       193       194       195   \\\n",
       "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       ea162346  d3193bb5  7eca03a2  bf258cbf  a6cc7795  3ee91998  daf25de1   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            196       197       198       199       200       201       202   \\\n",
       "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       c17d3103  91b32c22  3c5f7ba6  ccdf26d9  10b299e5  68a1e47b  1aee8a93   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            203       204       205       206       207       208       209   \\\n",
       "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       2f122e5b  df0fc7d0  50b08f93  4acf6d10  9711f0f6  b9bb5ea6  996607a1   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            210       211       212       213       214       215       216   \\\n",
       "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       4a9cfa67  bc711534  41910025  9fd822ca  3548485c  40842d13  e887f5e6   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            217       218       219       220       221       222       223   \\\n",
       "0            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3       204afb8e  90f317a2  b307e234  954ca3e4  ca8e5e0a  8dcaddf3  ca74117a   \n",
       "4            NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "139255       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            224       225       226       227       228  229  230  231  232   \\\n",
       "0            NaN       NaN       NaN       NaN       NaN  NaN  NaN  NaN  NaN   \n",
       "1            NaN       NaN       NaN       NaN       NaN  NaN  NaN  NaN  NaN   \n",
       "2            NaN       NaN       NaN       NaN       NaN  NaN  NaN  NaN  NaN   \n",
       "3       fdb8d575  63625ef7  16e57be6  719f2ae4  075b5763  NaN  NaN  NaN  NaN   \n",
       "4            NaN       NaN       NaN       NaN       NaN  NaN  NaN  NaN  NaN   \n",
       "...          ...       ...       ...       ...       ...  ...  ...  ...  ...   \n",
       "139251       NaN       NaN       NaN       NaN       NaN  NaN  NaN  NaN  NaN   \n",
       "139252       NaN       NaN       NaN       NaN       NaN  NaN  NaN  NaN  NaN   \n",
       "139253       NaN       NaN       NaN       NaN       NaN  NaN  NaN  NaN  NaN   \n",
       "139254       NaN       NaN       NaN       NaN       NaN  NaN  NaN  NaN  NaN   \n",
       "139255       NaN       NaN       NaN       NaN       NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       233  234  235  236  237  238  239  240  241  242  243  244  245  246   \\\n",
       "0       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "139251  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139252  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139253  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139254  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139255  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       247  248  249   ... 755  756  757  758  759  760  761  762  763  764   \\\n",
       "0       NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1       NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2       NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3       NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4       NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "139251  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139252  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139253  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139254  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139255  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       765  766  767  768  769  770  771  772  773  774  775  776  777  778   \\\n",
       "0       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "139251  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139252  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139253  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139254  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139255  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       779  780  781  782  783  784  785  786  787  788  789  790  791  792   \\\n",
       "0       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "139251  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139252  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139253  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139254  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139255  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       793  794  795  796  797  798  799  800  801  802  803  804  805  806   \\\n",
       "0       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "139251  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139252  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139253  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139254  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139255  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       807  808  809  810  811  812  813  814  815  816  817  818  819  820   \\\n",
       "0       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "139251  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139252  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139253  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139254  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139255  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       821  822  823  824  825  826  827  828  829  830  831  832  833  834   \\\n",
       "0       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "139251  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139252  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139253  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139254  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139255  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       835  836  837  838  839  840  841  842  843  844  845  846  847  848   \\\n",
       "0       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "139251  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139252  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139253  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139254  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139255  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       849  850  851  852  853  854  855  856  857  858  859  860  861  862   \\\n",
       "0       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "139251  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139252  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139253  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139254  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139255  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       863  864  865  866  867  868  869  870  871  872  873  874  875  876   \\\n",
       "0       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "139251  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139252  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139253  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139254  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139255  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       877  878  879  880  881  882  883  884  885  886  887  888  889  890   \\\n",
       "0       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "139251  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139252  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139253  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139254  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139255  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       891  892  893  894  895  896  897  898  899  900  901  902  903  904   \\\n",
       "0       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "139251  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139252  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139253  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139254  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139255  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       905  906  907  908  909  910  911  912  913  914  915  916  917  918   \\\n",
       "0       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "139251  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139252  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139253  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139254  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139255  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       919  920  921  922  923  924  925  926  927  928  929  930  931  932   \\\n",
       "0       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "139251  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139252  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139253  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139254  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139255  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       933  934  935  936  937  938  939  940  941  942  943  944  945  946   \\\n",
       "0       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "139251  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139252  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139253  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139254  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139255  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       947  948  949  950  951  952  953  954  955  956  957  958  959  960   \\\n",
       "0       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "139251  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139252  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139253  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139254  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139255  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       961  962  963  964  965  966  967  968  969  970  971  972  973  974   \\\n",
       "0       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "139251  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139252  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139253  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139254  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139255  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       975  976  977  978  979  980  981  982  983  984  985  986  987  988   \\\n",
       "0       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "139251  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139252  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139253  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139254  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139255  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       989  990  991  992  993  994  995  996  997  998  999  1000 1001 1002  \\\n",
       "0       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4       NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "139251  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139252  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139253  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139254  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "139255  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "       1003 1004  \n",
       "0       NaN  NaN  \n",
       "1       NaN  NaN  \n",
       "2       NaN  NaN  \n",
       "3       NaN  NaN  \n",
       "4       NaN  NaN  \n",
       "...     ...  ...  \n",
       "139251  NaN  NaN  \n",
       "139252  NaN  NaN  \n",
       "139253  NaN  NaN  \n",
       "139254  NaN  NaN  \n",
       "139255  NaN  NaN  \n",
       "\n",
       "[139256 rows x 1005 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders.cell_order.apply(lambda x: x.split()).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_rank, on=['id', 'cell_id'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['id', 'rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(set(df.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>n_words</th>\n",
       "      <th>rank</th>\n",
       "      <th>inpu_ids2</th>\n",
       "      <th>input_ids2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2911522</th>\n",
       "      <td>31</td>\n",
       "      <td>7bb92ebe</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Hey kagglers,ʶʶThis is my first competition in kaggle, I would like to share my approach on the Cassava leaf disease competition.ʶMy approach involoves:ʶ* Using keras libraryʶ* Using GPU to train the modelʶ* Using albumentations to augment the dataset to prevent overfittingʶ* Using the StratifiedKFold as the dataset is skewed.ʶʶThis notebook is for beginner who would like to get started with this competitionʶʶReferences:ʶ1. Approaching (Almost) Any Machine Learning Problem - Book by Abhishek...</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 5388, 7478, 94989, 268, 261, 128001, 128001, 329, 269, 312, 362, 2027, 267, 4219, 89061, 261, 273, 338, 334, 264, 752, 312, 1218, 277, 262, 18961, 16925, 6712, 1682, 2027, 260, 128001, 573, 1218, 267, 90974, 415, 268, 294, 128001, 1124, 2891, 39170, 1628, 2634, 128001, 1124, 2891, 16265, 264, 2184, 262, 1040, 128001, 1124, 2891, 1898, 91547, 268, 264, 24906, 262, 12438, 264, 1843, 360, 25335, 128001, 1124, 2891, 262, 38251, 13329, 51708, 1371, 283, 262, 12438, 269, 32147, 260, 128001, 12...</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 5388, 7478, 94989, 268, 261, 128001, 128001, 329, 269, 312, 362, 2027, 267, 4219, 89061, 261, 273, 338, 334, 264, 752, 312, 1218, 277, 262, 18961, 16925, 6712, 1682, 2027, 260, 128001, 573, 1218, 267, 90974, 415, 268, 294, 128001, 1124, 2891, 39170, 1628, 2634, 128001, 1124, 2891, 16265, 264, 2184, 262, 1040, 128001, 1124, 2891, 1898, 91547, 268, 264, 24906, 262, 12438, 264, 1843, 360, 25335, 128001, 1124, 2891, 262, 38251, 13329, 51708, 1371, 283, 262, 12438, 269, 32147, 260, 128001, 12...</td>\n",
       "      <td>[1, 5388, 7478, 94989, 268, 261, 128001, 128001, 329, 269, 312, 362, 2027, 267, 4219, 89061, 261, 273, 338, 334, 264, 752, 312, 1218, 277, 262, 18961, 16925, 6712, 1682, 2027, 260, 128001, 573, 1218, 267, 90974, 415, 268, 294, 128001, 1124, 2891, 39170, 1628, 2634, 128001, 1124, 2891, 16265, 264, 2184, 262, 1040, 128001, 1124, 2891, 1898, 91547, 268, 264, 24906, 262, 12438, 264, 1843, 360, 25335, 128001, 1124, 2891, 262, 38251, 13329, 51708, 1371, 283, 262, 12438, 269, 32147, 260, 128001, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911521</th>\n",
       "      <td>30</td>\n",
       "      <td>9464c9af</td>\n",
       "      <td>markdown</td>\n",
       "      <td># **Importing libraries**</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 953, 1124, 1225, 60098, 510, 7296, 1225, 1225, 2]</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 953, 1124, 1225, 60098, 510, 7296, 1225, 1225, 2]</td>\n",
       "      <td>[1, 953, 1124, 1225, 60098, 510, 7296, 1225, 1225, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911491</th>\n",
       "      <td>0</td>\n",
       "      <td>3f1ad88e</td>\n",
       "      <td>code</td>\n",
       "      <td>import pandas as pdʶimport numpy as npʶimport matplotlib.pyplot as pltʶimport os ʶfrom sklearn.model_selection import StratifiedKFoldʶimport seaborn as snsʶimport jsonʶimport cv2ʶʶimport tensorflow as tfʶfrom tensorflow.keras import models, layers,Sequential,regularizersʶfrom tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping, ModelCheckpointʶfrom keras.layers import Input, Flatten, Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropoutʶfrom tensorflow.keras.models impor...</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 6306, 67927, 283, 845, 407, 128001, 6306, 36221, 11751, 283, 76767, 128001, 6306, 8358, 33918, 14434, 260, 11751, 33918, 283, 28944, 297, 128001, 6306, 2673, 268, 128001, 292, 33566, 29274, 260, 19928, 616, 57907, 6306, 38251, 13329, 51708, 1371, 128001, 6306, 2164, 6107, 283, 41339, 268, 128001, 6306, 74883, 128001, 6306, 37821, 445, 128001, 128001, 6306, 55919, 14068, 283, 78191, 128001, 292, 55919, 14068, 260, 8285, 1628, 6306, 1836, 261, 4974, 261, 430, 87386, 46580, 261, 34020, 4322...</td>\n",
       "      <td>242</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 6306, 67927, 283, 845, 407, 128001, 6306, 36221, 11751, 283, 76767, 128001, 6306, 8358, 33918, 14434, 260, 11751, 33918, 283, 28944, 297, 128001, 6306, 2673, 268, 128001, 292, 33566, 29274, 260, 19928, 616, 57907, 6306, 38251, 13329, 51708, 1371, 128001, 6306, 2164, 6107, 283, 41339, 268, 128001, 6306, 74883, 128001, 6306, 37821, 445, 128001, 128001, 6306, 55919, 14068, 283, 78191, 128001, 292, 55919, 14068, 260, 8285, 1628, 6306, 1836, 261, 4974, 261, 430, 87386, 46580, 261, 34020, 4322...</td>\n",
       "      <td>[1, 6306, 67927, 283, 845, 407, 128001, 6306, 36221, 11751, 283, 76767, 128001, 6306, 8358, 33918, 14434, 260, 11751, 33918, 283, 28944, 297, 128001, 6306, 2673, 268, 128001, 292, 33566, 29274, 260, 19928, 616, 57907, 6306, 38251, 13329, 51708, 1371, 128001, 6306, 2164, 6107, 283, 41339, 268, 128001, 6306, 74883, 128001, 6306, 37821, 445, 128001, 128001, 6306, 55919, 14068, 283, 78191, 128001, 292, 55919, 14068, 260, 8285, 1628, 6306, 1836, 261, 4974, 261, 430, 87386, 46580, 261, 34020, 4322...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911513</th>\n",
       "      <td>22</td>\n",
       "      <td>011c5d1a</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Cassava leaves are a rich source of protein, minerals, and vitamins. However, the presence of antinutrients and cyanogenic glucosides are the major drawbacks in cassava leaves which limit its human consumption. These antinutrients and toxic compounds of cassava leaves cause various diseases depending on the consumption level. But viral diseases are major sources of poor yields. With the help of data science, it may be possible to identify common diseases so they can be treated.ʶʶ![](https://...</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 18961, 16925, 2423, 281, 266, 2241, 1271, 265, 2927, 261, 8525, 261, 263, 9571, 260, 672, 261, 262, 2192, 265, 1688, 64804, 268, 263, 45781, 26429, 77462, 54787, 281, 262, 852, 26810, 267, 66351, 2423, 319, 2642, 359, 857, 4003, 260, 606, 1688, 64804, 268, 263, 7290, 8312, 265, 66351, 2423, 1138, 847, 4253, 2719, 277, 262, 4003, 674, 260, 420, 8804, 4253, 281, 852, 2175, 265, 1970, 10474, 260, 559, 262, 408, 265, 514, 1693, 261, 278, 372, 282, 628, 264, 2313, 1019, 4253, 324, 306, 295, 2...</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>[1, 18961, 16925, 2423, 281, 266, 2241, 1271, 265, 2927, 261, 8525, 261, 263, 9571, 260, 672, 261, 262, 2192, 265, 1688, 64804, 268, 263, 45781, 26429, 77462, 54787, 281, 262, 852, 26810, 267, 66351, 2423, 319, 2642, 359, 857, 4003, 260, 606, 1688, 64804, 268, 263, 7290, 8312, 265, 66351, 2423, 1138, 847, 4253, 2719, 277, 262, 4003, 674, 260, 420, 8804, 4253, 281, 852, 2175, 265, 1970, 10474, 260, 559, 262, 408, 265, 514, 1693, 261, 278, 372, 282, 628, 264, 2313, 1019, 4253, 324, 306, 295, 2...</td>\n",
       "      <td>[1, 18961, 16925, 2423, 281, 266, 2241, 1271, 265, 2927, 261, 8525, 261, 263, 9571, 260, 672, 261, 262, 2192, 265, 1688, 64804, 268, 263, 45781, 26429, 77462, 54787, 281, 262, 852, 26810, 267, 66351, 2423, 319, 2642, 359, 857, 4003, 260, 606, 1688, 64804, 268, 263, 7290, 8312, 265, 66351, 2423, 1138, 847, 4253, 2719, 277, 262, 4003, 674, 260, 420, 8804, 4253, 281, 852, 2175, 265, 1970, 10474, 260, 559, 262, 408, 265, 514, 1693, 261, 278, 372, 282, 628, 264, 2313, 1019, 4253, 324, 306, 295, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911520</th>\n",
       "      <td>29</td>\n",
       "      <td>c23a2762</td>\n",
       "      <td>markdown</td>\n",
       "      <td># **Dataset and Kfold**</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 953, 1124, 1225, 15006, 6207, 263, 1148, 10945, 1225, 1225, 2]</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>[1, 953, 1124, 1225, 15006, 6207, 263, 1148, 10945, 1225, 1225, 2]</td>\n",
       "      <td>[1, 953, 1124, 1225, 15006, 6207, 263, 1148, 10945, 1225, 1225, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911492</th>\n",
       "      <td>1</td>\n",
       "      <td>a2ccff1c</td>\n",
       "      <td>code</td>\n",
       "      <td>train_image_path=\"../input/cassava-leaf-disease-classification/train_images/\"ʶtrain_df_path=\"../input/cassava-leaf-disease-classification/train.csv\"</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 2184, 616, 15428, 616, 14035, 1510, 309, 260, 260, 320, 42177, 320, 21783, 268, 16925, 271, 22334, 271, 58272, 271, 79642, 320, 23822, 616, 24227, 320, 309, 128001, 2184, 616, 32392, 616, 14035, 1510, 309, 260, 260, 320, 42177, 320, 21783, 268, 16925, 271, 22334, 271, 58272, 271, 79642, 320, 23822, 260, 76413, 309, 2]</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>[1, 2184, 616, 15428, 616, 14035, 1510, 309, 260, 260, 320, 42177, 320, 21783, 268, 16925, 271, 22334, 271, 58272, 271, 79642, 320, 23822, 616, 24227, 320, 309, 128001, 2184, 616, 32392, 616, 14035, 1510, 309, 260, 260, 320, 42177, 320, 21783, 268, 16925, 271, 22334, 271, 58272, 271, 79642, 320, 23822, 260, 76413, 309, 2]</td>\n",
       "      <td>[1, 2184, 616, 15428, 616, 14035, 1510, 309, 260, 260, 320, 42177, 320, 21783, 268, 16925, 271, 22334, 271, 58272, 271, 79642, 320, 23822, 616, 24227, 320, 309, 128001, 2184, 616, 32392, 616, 14035, 1510, 309, 260, 260, 320, 42177, 320, 21783, 268, 16925, 271, 22334, 271, 58272, 271, 79642, 320, 23822, 260, 76413, 309, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911493</th>\n",
       "      <td>2</td>\n",
       "      <td>011b6367</td>\n",
       "      <td>code</td>\n",
       "      <td>train_df=pd.read_csv(train_df_path)ʶtrain_df.head()</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 2184, 616, 32392, 1510, 39871, 260, 8523, 616, 76413, 555, 23822, 616, 32392, 616, 14035, 285, 128001, 2184, 616, 32392, 260, 5563, 555, 285, 2]</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>[1, 2184, 616, 32392, 1510, 39871, 260, 8523, 616, 76413, 555, 23822, 616, 32392, 616, 14035, 285, 128001, 2184, 616, 32392, 260, 5563, 555, 285, 2]</td>\n",
       "      <td>[1, 2184, 616, 32392, 1510, 39871, 260, 8523, 616, 76413, 555, 23822, 616, 32392, 616, 14035, 285, 128001, 2184, 616, 32392, 260, 5563, 555, 285, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911494</th>\n",
       "      <td>3</td>\n",
       "      <td>9d2abdc9</td>\n",
       "      <td>code</td>\n",
       "      <td>with open(\"../input/cassava-leaf-disease-classification/label_num_to_disease_map.json\") as file:ʶ    map_classes = json.loads(file.read())ʶ    map_classes = {int(k) : v for k, v in map_classes.items()}</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 275, 615, 555, 309, 260, 260, 320, 42177, 320, 21783, 268, 16925, 271, 22334, 271, 58272, 271, 79642, 320, 25289, 616, 22062, 616, 725, 616, 58272, 616, 14727, 260, 50574, 309, 285, 283, 1092, 294, 128001, 2269, 616, 58348, 1842, 74883, 260, 61373, 555, 13093, 260, 8523, 555, 285, 285, 128001, 2269, 616, 58348, 1842, 13856, 17925, 555, 1165, 285, 877, 1942, 270, 4219, 261, 1942, 267, 2269, 616, 58348, 260, 55735, 555, 285, 14986, 2]</td>\n",
       "      <td>77</td>\n",
       "      <td>7</td>\n",
       "      <td>[1, 275, 615, 555, 309, 260, 260, 320, 42177, 320, 21783, 268, 16925, 271, 22334, 271, 58272, 271, 79642, 320, 25289, 616, 22062, 616, 725, 616, 58272, 616, 14727, 260, 50574, 309, 285, 283, 1092, 294, 128001, 2269, 616, 58348, 1842, 74883, 260, 61373, 555, 13093, 260, 8523, 555, 285, 285, 128001, 2269, 616, 58348, 1842, 13856, 17925, 555, 1165, 285, 877, 1942, 270, 4219, 261, 1942, 267, 2269, 616, 58348, 260, 55735, 555, 285, 14986, 2]</td>\n",
       "      <td>[1, 275, 615, 555, 309, 260, 260, 320, 42177, 320, 21783, 268, 16925, 271, 22334, 271, 58272, 271, 79642, 320, 25289, 616, 22062, 616, 725, 616, 58272, 616, 14727, 260, 50574, 309, 285, 283, 1092, 294, 128001, 2269, 616, 58348, 1842, 74883, 260, 61373, 555, 13093, 260, 8523, 555, 285, 285, 128001, 2269, 616, 58348, 1842, 13856, 17925, 555, 1165, 285, 877, 1942, 270, 4219, 261, 1942, 267, 2269, 616, 58348, 260, 55735, 555, 285, 14986, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911495</th>\n",
       "      <td>4</td>\n",
       "      <td>21e4504e</td>\n",
       "      <td>code</td>\n",
       "      <td>train_df[\"Class\"]=train_df[\"label\"].map(map_classes)ʶtrain_df.head()</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 2184, 616, 32392, 2550, 309, 16264, 309, 592, 1510, 23822, 616, 32392, 2550, 309, 25289, 309, 592, 260, 14727, 555, 14727, 616, 58348, 285, 128001, 2184, 616, 32392, 260, 5563, 555, 285, 2]</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>[1, 2184, 616, 32392, 2550, 309, 16264, 309, 592, 1510, 23822, 616, 32392, 2550, 309, 25289, 309, 592, 260, 14727, 555, 14727, 616, 58348, 285, 128001, 2184, 616, 32392, 260, 5563, 555, 285, 2]</td>\n",
       "      <td>[1, 2184, 616, 32392, 2550, 309, 16264, 309, 592, 1510, 23822, 616, 32392, 2550, 309, 25289, 309, 592, 260, 14727, 555, 14727, 616, 58348, 285, 128001, 2184, 616, 32392, 260, 5563, 555, 285, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911496</th>\n",
       "      <td>5</td>\n",
       "      <td>50674f0f</td>\n",
       "      <td>code</td>\n",
       "      <td>sns.set(rc={'figure.figsize':(8,4)})ʶsns.set_style('whitegrid')ʶʶva=sns.countplot(y=\"Class\",data=train_df,palette='rainbow')ʶplt.xlabel(\"Classes of leaves\",fontsize=20)ʶplt.ylabel(\"Count\",fontsize=20)ʶplt.tight_layout()</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 41339, 268, 260, 6207, 555, 19637, 1510, 19976, 280, 22971, 260, 30134, 7283, 280, 294, 555, 804, 261, 554, 285, 14986, 285, 128001, 41339, 268, 260, 6207, 616, 4602, 555, 280, 7551, 25549, 280, 285, 128001, 128001, 17632, 1510, 268, 7565, 260, 21036, 33918, 555, 608, 1510, 309, 16264, 309, 261, 9832, 1510, 23822, 616, 32392, 261, 15151, 8583, 1510, 280, 109289, 280, 285, 128001, 28944, 297, 260, 982, 25289, 555, 309, 16264, 1110, 265, 2423, 309, 261, 35557, 7283, 1510, 1435, 285, 128001...</td>\n",
       "      <td>110</td>\n",
       "      <td>9</td>\n",
       "      <td>[1, 41339, 268, 260, 6207, 555, 19637, 1510, 19976, 280, 22971, 260, 30134, 7283, 280, 294, 555, 804, 261, 554, 285, 14986, 285, 128001, 41339, 268, 260, 6207, 616, 4602, 555, 280, 7551, 25549, 280, 285, 128001, 128001, 17632, 1510, 268, 7565, 260, 21036, 33918, 555, 608, 1510, 309, 16264, 309, 261, 9832, 1510, 23822, 616, 32392, 261, 15151, 8583, 1510, 280, 109289, 280, 285, 128001, 28944, 297, 260, 982, 25289, 555, 309, 16264, 1110, 265, 2423, 309, 261, 35557, 7283, 1510, 1435, 285, 128001...</td>\n",
       "      <td>[1, 41339, 268, 260, 6207, 555, 19637, 1510, 19976, 280, 22971, 260, 30134, 7283, 280, 294, 555, 804, 261, 554, 285, 14986, 285, 128001, 41339, 268, 260, 6207, 616, 4602, 555, 280, 7551, 25549, 280, 285, 128001, 128001, 17632, 1510, 268, 7565, 260, 21036, 33918, 555, 608, 1510, 309, 16264, 309, 261, 9832, 1510, 23822, 616, 32392, 261, 15151, 8583, 1510, 280, 109289, 280, 285, 128001, 28944, 297, 260, 982, 25289, 555, 309, 16264, 1110, 265, 2423, 309, 261, 35557, 7283, 1510, 1435, 285, 128001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911497</th>\n",
       "      <td>6</td>\n",
       "      <td>eb6ce0f1</td>\n",
       "      <td>code</td>\n",
       "      <td>def visualize(image_ids, labels):ʶ    plt.figure(figsize=(16, 12))ʶ    for ind, (image_id, label) in enumerate(zip(image_ids, labels)):ʶ        plt.subplot(4, 4, ind + 1)ʶ        image = cv2.imread(os.path.join(\"../input/cassava-leaf-disease-classification/train_images\", image_id))ʶ        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)ʶ        plt.imshow(image)ʶ        plt.title(f\"Class: {label}\", fontsize=12)ʶ        plt.axis(\"off\")ʶ        plt.tight_layout()ʶ    plt.show()</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 23097, 18438, 555, 15428, 616, 26657, 261, 6768, 285, 294, 128001, 28944, 297, 260, 22971, 555, 30134, 7283, 1510, 555, 1984, 261, 621, 285, 285, 128001, 270, 267, 407, 261, 287, 15428, 616, 4765, 261, 3734, 285, 267, 71955, 555, 21550, 555, 15428, 616, 26657, 261, 6768, 285, 285, 294, 128001, 28944, 297, 260, 12109, 33918, 555, 554, 261, 453, 261, 267, 407, 1566, 376, 285, 128001, 1115, 1842, 37821, 445, 260, 6263, 8523, 555, 3603, 260, 14035, 260, 46901, 555, 309, 260, 260, 320, 42177,...</td>\n",
       "      <td>186</td>\n",
       "      <td>10</td>\n",
       "      <td>[1, 23097, 18438, 555, 15428, 616, 26657, 261, 6768, 285, 294, 128001, 28944, 297, 260, 22971, 555, 30134, 7283, 1510, 555, 1984, 261, 621, 285, 285, 128001, 270, 267, 407, 261, 287, 15428, 616, 4765, 261, 3734, 285, 267, 71955, 555, 21550, 555, 15428, 616, 26657, 261, 6768, 285, 285, 294, 128001, 28944, 297, 260, 12109, 33918, 555, 554, 261, 453, 261, 267, 407, 1566, 376, 285, 128001, 1115, 1842, 37821, 445, 260, 6263, 8523, 555, 3603, 260, 14035, 260, 46901, 555, 309, 260, 260, 320, 42177,...</td>\n",
       "      <td>[1, 23097, 18438, 555, 15428, 616, 26657, 261, 6768, 285, 294, 128001, 28944, 297, 260, 22971, 555, 30134, 7283, 1510, 555, 1984, 261, 621, 285, 285, 128001, 270, 267, 407, 261, 287, 15428, 616, 4765, 261, 3734, 285, 267, 71955, 555, 21550, 555, 15428, 616, 26657, 261, 6768, 285, 285, 294, 128001, 28944, 297, 260, 12109, 33918, 555, 554, 261, 453, 261, 267, 407, 1566, 376, 285, 128001, 1115, 1842, 37821, 445, 260, 6263, 8523, 555, 3603, 260, 14035, 260, 46901, 555, 309, 260, 260, 320, 42177,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911498</th>\n",
       "      <td>7</td>\n",
       "      <td>2ddd105a</td>\n",
       "      <td>code</td>\n",
       "      <td>train_df1=train_df.sample(8)ʶimage_ids = train_df1[\"image_id\"].valuesʶlabels = train_df1[\"Class\"].valuesʶvisualize(image_ids, labels)</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 2184, 616, 32392, 435, 1510, 23822, 616, 32392, 260, 26154, 555, 804, 285, 128001, 1115, 616, 26657, 1842, 2184, 616, 32392, 435, 2550, 309, 15428, 616, 4765, 309, 592, 260, 41801, 128001, 6768, 1842, 2184, 616, 32392, 435, 2550, 309, 16264, 309, 592, 260, 41801, 128001, 18438, 555, 15428, 616, 26657, 261, 6768, 285, 2]</td>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>[1, 2184, 616, 32392, 435, 1510, 23822, 616, 32392, 260, 26154, 555, 804, 285, 128001, 1115, 616, 26657, 1842, 2184, 616, 32392, 435, 2550, 309, 15428, 616, 4765, 309, 592, 260, 41801, 128001, 6768, 1842, 2184, 616, 32392, 435, 2550, 309, 16264, 309, 592, 260, 41801, 128001, 18438, 555, 15428, 616, 26657, 261, 6768, 285, 2]</td>\n",
       "      <td>[1, 2184, 616, 32392, 435, 1510, 23822, 616, 32392, 260, 26154, 555, 804, 285, 128001, 1115, 616, 26657, 1842, 2184, 616, 32392, 435, 2550, 309, 15428, 616, 4765, 309, 592, 260, 41801, 128001, 6768, 1842, 2184, 616, 32392, 435, 2550, 309, 16264, 309, 592, 260, 41801, 128001, 18438, 555, 15428, 616, 26657, 261, 6768, 285, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911499</th>\n",
       "      <td>8</td>\n",
       "      <td>d0838468</td>\n",
       "      <td>code</td>\n",
       "      <td>train_df.label.value_counts()</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 2184, 616, 32392, 260, 25289, 260, 11651, 616, 21036, 268, 555, 285, 2]</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>[1, 2184, 616, 32392, 260, 25289, 260, 11651, 616, 21036, 268, 555, 285, 2]</td>\n",
       "      <td>[1, 2184, 616, 32392, 260, 25289, 260, 11651, 616, 21036, 268, 555, 285, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911525</th>\n",
       "      <td>34</td>\n",
       "      <td>7729761f</td>\n",
       "      <td>markdown</td>\n",
       "      <td>As you can observe, The data set is skewed with the largest number of samples for label 3, Cassava Mosiac Disease (CMD), and the fewest number of samples for label 0, Cassava Bacterial Blight (CBB). To over come this we use StratifiedKfold to split the dataset for training and validation to check the performance of the model.ʶʶThe general procedure is as follows:ʶ1. Shuffle the dataset randomly.ʶ2. Split the dataset into k groupsʶ3. For each unique group:ʶ    * Take the group as a holdout or...</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 463, 274, 295, 6695, 261, 279, 514, 487, 269, 32147, 275, 262, 1705, 496, 265, 3894, 270, 3734, 404, 261, 18961, 16925, 94798, 6504, 9384, 287, 105211, 285, 261, 263, 262, 51156, 496, 265, 3894, 270, 3734, 767, 261, 18961, 16925, 66630, 86389, 287, 711, 15416, 285, 260, 502, 360, 488, 291, 301, 380, 38251, 13329, 1301, 10945, 264, 3671, 262, 12438, 270, 838, 263, 10872, 264, 807, 262, 876, 265, 262, 1040, 260, 128001, 128001, 279, 1042, 3017, 269, 283, 3832, 294, 128001, 376, 260, 60749,...</td>\n",
       "      <td>278</td>\n",
       "      <td>13</td>\n",
       "      <td>[1, 463, 274, 295, 6695, 261, 279, 514, 487, 269, 32147, 275, 262, 1705, 496, 265, 3894, 270, 3734, 404, 261, 18961, 16925, 94798, 6504, 9384, 287, 105211, 285, 261, 263, 262, 51156, 496, 265, 3894, 270, 3734, 767, 261, 18961, 16925, 66630, 86389, 287, 711, 15416, 285, 260, 502, 360, 488, 291, 301, 380, 38251, 13329, 1301, 10945, 264, 3671, 262, 12438, 270, 838, 263, 10872, 264, 807, 262, 876, 265, 262, 1040, 260, 128001, 128001, 279, 1042, 3017, 269, 283, 3832, 294, 128001, 376, 260, 60749,...</td>\n",
       "      <td>[1, 463, 274, 295, 6695, 261, 279, 514, 487, 269, 32147, 275, 262, 1705, 496, 265, 3894, 270, 3734, 404, 261, 18961, 16925, 94798, 6504, 9384, 287, 105211, 285, 261, 263, 262, 51156, 496, 265, 3894, 270, 3734, 767, 261, 18961, 16925, 66630, 86389, 287, 711, 15416, 285, 260, 502, 360, 488, 291, 301, 380, 38251, 13329, 1301, 10945, 264, 3671, 262, 12438, 270, 838, 263, 10872, 264, 807, 262, 876, 265, 262, 1040, 260, 128001, 128001, 279, 1042, 3017, 269, 283, 3832, 294, 128001, 376, 260, 60749,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911500</th>\n",
       "      <td>9</td>\n",
       "      <td>f9860522</td>\n",
       "      <td>code</td>\n",
       "      <td>def creat_nfold(train_df,n_split):ʶ    train_df.loc[:,\"kfold\"]=-1ʶ    train_df=train_df.sample(frac=1).reset_index(drop=True)ʶ    SS=StratifiedKFold(n_splits=n_split)ʶ    y=train_df.label.valuesʶ    for fold,(t_,v_) in enumerate((SS.split(X=train_df,y=y))):ʶ        train_df.loc[v_,\"kfold\"]=foldʶ    return train_df</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 23097, 91597, 616, 673, 10945, 555, 23822, 616, 32392, 261, 673, 616, 43483, 285, 294, 128001, 2184, 616, 32392, 260, 28372, 2550, 294, 261, 309, 1165, 10945, 309, 592, 1510, 271, 435, 128001, 2184, 616, 32392, 1510, 23822, 616, 32392, 260, 26154, 555, 71074, 1510, 435, 285, 260, 68584, 616, 13915, 555, 17915, 1510, 35733, 285, 128001, 9937, 1510, 95232, 13329, 51708, 1371, 555, 673, 616, 43483, 268, 1510, 673, 616, 43483, 285, 128001, 2982, 1510, 23822, 616, 32392, 260, 25289, 260, 4180...</td>\n",
       "      <td>139</td>\n",
       "      <td>14</td>\n",
       "      <td>[1, 23097, 91597, 616, 673, 10945, 555, 23822, 616, 32392, 261, 673, 616, 43483, 285, 294, 128001, 2184, 616, 32392, 260, 28372, 2550, 294, 261, 309, 1165, 10945, 309, 592, 1510, 271, 435, 128001, 2184, 616, 32392, 1510, 23822, 616, 32392, 260, 26154, 555, 71074, 1510, 435, 285, 260, 68584, 616, 13915, 555, 17915, 1510, 35733, 285, 128001, 9937, 1510, 95232, 13329, 51708, 1371, 555, 673, 616, 43483, 268, 1510, 673, 616, 43483, 285, 128001, 2982, 1510, 23822, 616, 32392, 260, 25289, 260, 4180...</td>\n",
       "      <td>[1, 23097, 91597, 616, 673, 10945, 555, 23822, 616, 32392, 261, 673, 616, 43483, 285, 294, 128001, 2184, 616, 32392, 260, 28372, 2550, 294, 261, 309, 1165, 10945, 309, 592, 1510, 271, 435, 128001, 2184, 616, 32392, 1510, 23822, 616, 32392, 260, 26154, 555, 71074, 1510, 435, 285, 260, 68584, 616, 13915, 555, 17915, 1510, 35733, 285, 128001, 9937, 1510, 95232, 13329, 51708, 1371, 555, 673, 616, 43483, 268, 1510, 673, 616, 43483, 285, 128001, 2982, 1510, 23822, 616, 32392, 260, 25289, 260, 4180...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911501</th>\n",
       "      <td>10</td>\n",
       "      <td>f4a624c6</td>\n",
       "      <td>code</td>\n",
       "      <td>train_df.label=train_df.label.astype(\"str\") ʶ#converting the label to str as we will be using categorical cross entropy as loss function to train the model</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 2184, 616, 32392, 260, 25289, 1510, 23822, 616, 32392, 260, 25289, 260, 1628, 5967, 555, 309, 22889, 309, 285, 128001, 953, 98936, 262, 3734, 264, 25275, 283, 301, 296, 282, 478, 48301, 1943, 33631, 283, 1265, 1571, 264, 2184, 262, 1040, 2]</td>\n",
       "      <td>43</td>\n",
       "      <td>15</td>\n",
       "      <td>[1, 2184, 616, 32392, 260, 25289, 1510, 23822, 616, 32392, 260, 25289, 260, 1628, 5967, 555, 309, 22889, 309, 285, 128001, 953, 98936, 262, 3734, 264, 25275, 283, 301, 296, 282, 478, 48301, 1943, 33631, 283, 1265, 1571, 264, 2184, 262, 1040, 2]</td>\n",
       "      <td>[1, 2184, 616, 32392, 260, 25289, 1510, 23822, 616, 32392, 260, 25289, 260, 1628, 5967, 555, 309, 22889, 309, 285, 128001, 953, 98936, 262, 3734, 264, 25275, 283, 301, 296, 282, 478, 48301, 1943, 33631, 283, 1265, 1571, 264, 2184, 262, 1040, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911502</th>\n",
       "      <td>11</td>\n",
       "      <td>9f6b86ce</td>\n",
       "      <td>code</td>\n",
       "      <td>train_df=creat_nfold(train_df,5)ʶtrain_df.head(5)ʶ</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 2184, 616, 32392, 1510, 66937, 297, 616, 673, 10945, 555, 23822, 616, 32392, 261, 524, 285, 128001, 2184, 616, 32392, 260, 5563, 555, 524, 285, 128001, 2]</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>[1, 2184, 616, 32392, 1510, 66937, 297, 616, 673, 10945, 555, 23822, 616, 32392, 261, 524, 285, 128001, 2184, 616, 32392, 260, 5563, 555, 524, 285, 128001, 2]</td>\n",
       "      <td>[1, 2184, 616, 32392, 1510, 66937, 297, 616, 673, 10945, 555, 23822, 616, 32392, 261, 524, 285, 128001, 2184, 616, 32392, 260, 5563, 555, 524, 285, 128001, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911517</th>\n",
       "      <td>26</td>\n",
       "      <td>534ce2a1</td>\n",
       "      <td>markdown</td>\n",
       "      <td># **Augmentation**</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 953, 1124, 1225, 32995, 78863, 1225, 1225, 2]</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>[1, 953, 1124, 1225, 32995, 78863, 1225, 1225, 2]</td>\n",
       "      <td>[1, 953, 1124, 1225, 32995, 78863, 1225, 1225, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911514</th>\n",
       "      <td>23</td>\n",
       "      <td>c86dbed7</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Image augmentations is done with the help of the library Albumentation through both ImageDataGenerator. We will use a tool called ImageDataAugmentor (thanks to mjkvaak at github) that allows us to do this.</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 4439, 31306, 268, 269, 619, 275, 262, 408, 265, 262, 2634, 15821, 91547, 390, 462, 4439, 15006, 117384, 260, 345, 296, 380, 266, 1637, 650, 4439, 15006, 32995, 59423, 287, 20085, 264, 96509, 68738, 70935, 288, 55346, 285, 272, 1279, 381, 264, 333, 291, 260, 2]</td>\n",
       "      <td>47</td>\n",
       "      <td>18</td>\n",
       "      <td>[1, 4439, 31306, 268, 269, 619, 275, 262, 408, 265, 262, 2634, 15821, 91547, 390, 462, 4439, 15006, 117384, 260, 345, 296, 380, 266, 1637, 650, 4439, 15006, 32995, 59423, 287, 20085, 264, 96509, 68738, 70935, 288, 55346, 285, 272, 1279, 381, 264, 333, 291, 260, 2]</td>\n",
       "      <td>[1, 4439, 31306, 268, 269, 619, 275, 262, 408, 265, 262, 2634, 15821, 91547, 390, 462, 4439, 15006, 117384, 260, 345, 296, 380, 266, 1637, 650, 4439, 15006, 32995, 59423, 287, 20085, 264, 96509, 68738, 70935, 288, 55346, 285, 272, 1279, 381, 264, 333, 291, 260, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911503</th>\n",
       "      <td>12</td>\n",
       "      <td>049a786a</td>\n",
       "      <td>code</td>\n",
       "      <td>!pip install git+https://github.com/mjkvaak/ImageDataAugmentor</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 1084, 70415, 2625, 25182, 1186, 13229, 294, 320, 320, 45552, 260, 549, 320, 358, 68151, 6586, 7654, 320, 23791, 15006, 32995, 59423, 2]</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>[1, 1084, 70415, 2625, 25182, 1186, 13229, 294, 320, 320, 45552, 260, 549, 320, 358, 68151, 6586, 7654, 320, 23791, 15006, 32995, 59423, 2]</td>\n",
       "      <td>[1, 1084, 70415, 2625, 25182, 1186, 13229, 294, 320, 320, 45552, 260, 549, 320, 358, 68151, 6586, 7654, 320, 23791, 15006, 32995, 59423, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911504</th>\n",
       "      <td>13</td>\n",
       "      <td>2da37024</td>\n",
       "      <td>code</td>\n",
       "      <td>from ImageDataAugmentor.image_data_augmentor import *ʶimport albumentations as Aʶʶ# augmentations referred from: https://www.kaggle.com/khyeh0719/pytorch-efficientnet-baseline-train-amp-augʶtrain_aug = albumentations.Compose([ʶ            albumentations.RandomResizedCrop(300, 300),ʶ            albumentations.Transpose(p=0.5),ʶ            albumentations.HorizontalFlip(p=0.5),ʶ            albumentations.VerticalFlip(p=0.5),ʶ            albumentations.ShiftScaleRotate(p=0.5),ʶ            albume...</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 292, 4439, 15006, 32995, 59423, 260, 15428, 616, 9832, 616, 56244, 59423, 6306, 1124, 128001, 6306, 1898, 91547, 268, 283, 336, 128001, 128001, 953, 31306, 268, 3504, 292, 294, 3597, 294, 320, 320, 1965, 260, 1165, 89061, 260, 549, 320, 19491, 89675, 4649, 2573, 320, 11751, 96443, 271, 16454, 3163, 271, 113395, 271, 23822, 271, 10832, 271, 56244, 128001, 2184, 616, 56244, 1842, 1898, 91547, 268, 260, 30988, 17619, 555, 2550, 128001, 1898, 91547, 268, 260, 72388, 5396, 6545, 711, 52823, 5...</td>\n",
       "      <td>480</td>\n",
       "      <td>20</td>\n",
       "      <td>[1, 292, 4439, 15006, 32995, 59423, 260, 15428, 616, 9832, 616, 56244, 59423, 6306, 1124, 128001, 6306, 1898, 91547, 268, 283, 336, 128001, 128001, 953, 31306, 268, 3504, 292, 294, 3597, 294, 320, 320, 1965, 260, 1165, 89061, 260, 549, 320, 19491, 89675, 4649, 2573, 320, 11751, 96443, 271, 16454, 3163, 271, 113395, 271, 23822, 271, 10832, 271, 56244, 128001, 2184, 616, 56244, 1842, 1898, 91547, 268, 260, 30988, 17619, 555, 2550, 128001, 1898, 91547, 268, 260, 72388, 5396, 6545, 711, 52823, 5...</td>\n",
       "      <td>[1, 292, 4439, 15006, 32995, 59423, 260, 15428, 616, 9832, 616, 56244, 59423, 6306, 1124, 128001, 6306, 1898, 91547, 268, 283, 336, 128001, 128001, 953, 31306, 268, 3504, 292, 294, 3597, 294, 320, 320, 1965, 260, 1165, 89061, 260, 549, 320, 19491, 89675, 4649, 2573, 320, 11751, 96443, 271, 16454, 3163, 271, 113395, 271, 23822, 271, 10832, 271, 56244, 128001, 2184, 616, 56244, 1842, 1898, 91547, 268, 260, 30988, 17619, 555, 2550, 128001, 1898, 91547, 268, 260, 72388, 5396, 6545, 711, 52823, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911505</th>\n",
       "      <td>14</td>\n",
       "      <td>2c7d5413</td>\n",
       "      <td>code</td>\n",
       "      <td>def train_generator(train,valid,batch_size,image_size):ʶ    ʶ        datagen_train = ImageDataAugmentor(augment=train_aug)ʶ        datagen_val = ImageDataAugmentor(augment=valid_aug)ʶ        train_generator = datagen_train.flow_from_dataframe(dataframe=train,ʶ                                                    directory=train_image_path,ʶ                                                    x_col=\"image_id\",ʶ                                                    y_col=\"label\",ʶ                   ...</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 23097, 2184, 616, 68890, 555, 23822, 261, 70946, 261, 54847, 616, 7283, 261, 15428, 616, 7283, 285, 294, 128001, 128001, 514, 7073, 616, 23822, 1842, 4439, 15006, 32995, 59423, 555, 56244, 4572, 1510, 23822, 616, 56244, 285, 128001, 514, 7073, 616, 14206, 1842, 4439, 15006, 32995, 59423, 555, 56244, 4572, 1510, 70946, 616, 56244, 285, 128001, 2184, 616, 68890, 1842, 514, 7073, 616, 23822, 260, 14068, 616, 5117, 616, 9832, 16439, 555, 9832, 16439, 1510, 23822, 261, 128001, 5514, 1510, 238...</td>\n",
       "      <td>271</td>\n",
       "      <td>21</td>\n",
       "      <td>[1, 23097, 2184, 616, 68890, 555, 23822, 261, 70946, 261, 54847, 616, 7283, 261, 15428, 616, 7283, 285, 294, 128001, 128001, 514, 7073, 616, 23822, 1842, 4439, 15006, 32995, 59423, 555, 56244, 4572, 1510, 23822, 616, 56244, 285, 128001, 514, 7073, 616, 14206, 1842, 4439, 15006, 32995, 59423, 555, 56244, 4572, 1510, 70946, 616, 56244, 285, 128001, 2184, 616, 68890, 1842, 514, 7073, 616, 23822, 260, 14068, 616, 5117, 616, 9832, 16439, 555, 9832, 16439, 1510, 23822, 261, 128001, 5514, 1510, 238...</td>\n",
       "      <td>[1, 23097, 2184, 616, 68890, 555, 23822, 261, 70946, 261, 54847, 616, 7283, 261, 15428, 616, 7283, 285, 294, 128001, 128001, 514, 7073, 616, 23822, 1842, 4439, 15006, 32995, 59423, 555, 56244, 4572, 1510, 23822, 616, 56244, 285, 128001, 514, 7073, 616, 14206, 1842, 4439, 15006, 32995, 59423, 555, 56244, 4572, 1510, 70946, 616, 56244, 285, 128001, 2184, 616, 68890, 1842, 514, 7073, 616, 23822, 260, 14068, 616, 5117, 616, 9832, 16439, 555, 9832, 16439, 1510, 23822, 261, 128001, 5514, 1510, 238...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911523</th>\n",
       "      <td>32</td>\n",
       "      <td>68e0b102</td>\n",
       "      <td>markdown</td>\n",
       "      <td># **Define the model**</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 953, 1124, 1225, 46301, 5152, 262, 1040, 1225, 1225, 2]</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>[1, 953, 1124, 1225, 46301, 5152, 262, 1040, 1225, 1225, 2]</td>\n",
       "      <td>[1, 953, 1124, 1225, 46301, 5152, 262, 1040, 1225, 1225, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911524</th>\n",
       "      <td>33</td>\n",
       "      <td>21292bdd</td>\n",
       "      <td>markdown</td>\n",
       "      <td>We will use the Xception architecture to train the model. To read more about this architecture refer https://arxiv.org/abs/1610.02357</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 345, 296, 380, 262, 1477, 56237, 3781, 264, 2184, 262, 1040, 260, 502, 623, 310, 314, 291, 3781, 3886, 3597, 294, 320, 320, 3260, 70707, 260, 2083, 320, 58032, 320, 1984, 894, 260, 4159, 34805, 2]</td>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>[1, 345, 296, 380, 262, 1477, 56237, 3781, 264, 2184, 262, 1040, 260, 502, 623, 310, 314, 291, 3781, 3886, 3597, 294, 320, 320, 3260, 70707, 260, 2083, 320, 58032, 320, 1984, 894, 260, 4159, 34805, 2]</td>\n",
       "      <td>[1, 345, 296, 380, 262, 1477, 56237, 3781, 264, 2184, 262, 1040, 260, 502, 623, 310, 314, 291, 3781, 3886, 3597, 294, 320, 320, 3260, 70707, 260, 2083, 320, 58032, 320, 1984, 894, 260, 4159, 34805, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911506</th>\n",
       "      <td>15</td>\n",
       "      <td>f7f6fbf6</td>\n",
       "      <td>code</td>\n",
       "      <td>def make_model(IMG_SIZE):ʶ    base_model = Xception(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False,ʶ                             weights = 'imagenet')ʶ    x = base_model.outputʶ    x = GlobalAveragePooling2D()(x)ʶ    x = Dropout(0.3)(x)ʶ    predictions = Dense(5, activation='softmax',name='Final', dtype='float32')(x)ʶʶ    model = Model(inputs=base_model.input, outputs=predictions)ʶʶ    model.compile(optimizer =tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=Tru...</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 23097, 365, 616, 19928, 555, 100417, 616, 92921, 285, 294, 128001, 1436, 616, 19928, 1842, 1477, 56237, 555, 42177, 616, 29753, 1842, 287, 100417, 616, 92921, 261, 55699, 616, 92921, 261, 404, 285, 261, 680, 616, 6500, 1842, 21333, 261, 128001, 12355, 1842, 382, 15428, 3163, 280, 285, 128001, 1204, 1842, 1436, 616, 19928, 260, 35055, 128001, 1204, 1842, 2974, 94222, 48910, 510, 445, 691, 555, 285, 555, 982, 285, 128001, 1204, 1842, 10577, 2355, 555, 693, 260, 508, 285, 555, 982, 285, 128...</td>\n",
       "      <td>232</td>\n",
       "      <td>24</td>\n",
       "      <td>[1, 23097, 365, 616, 19928, 555, 100417, 616, 92921, 285, 294, 128001, 1436, 616, 19928, 1842, 1477, 56237, 555, 42177, 616, 29753, 1842, 287, 100417, 616, 92921, 261, 55699, 616, 92921, 261, 404, 285, 261, 680, 616, 6500, 1842, 21333, 261, 128001, 12355, 1842, 382, 15428, 3163, 280, 285, 128001, 1204, 1842, 1436, 616, 19928, 260, 35055, 128001, 1204, 1842, 2974, 94222, 48910, 510, 445, 691, 555, 285, 555, 982, 285, 128001, 1204, 1842, 10577, 2355, 555, 693, 260, 508, 285, 555, 982, 285, 128...</td>\n",
       "      <td>[1, 23097, 365, 616, 19928, 555, 100417, 616, 92921, 285, 294, 128001, 1436, 616, 19928, 1842, 1477, 56237, 555, 42177, 616, 29753, 1842, 287, 100417, 616, 92921, 261, 55699, 616, 92921, 261, 404, 285, 261, 680, 616, 6500, 1842, 21333, 261, 128001, 12355, 1842, 382, 15428, 3163, 280, 285, 128001, 1204, 1842, 1436, 616, 19928, 260, 35055, 128001, 1204, 1842, 2974, 94222, 48910, 510, 445, 691, 555, 285, 555, 982, 285, 128001, 1204, 1842, 10577, 2355, 555, 693, 260, 508, 285, 555, 982, 285, 128...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911519</th>\n",
       "      <td>28</td>\n",
       "      <td>9199586d</td>\n",
       "      <td>markdown</td>\n",
       "      <td># **Training the model**</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 953, 1124, 1225, 59089, 262, 1040, 1225, 1225, 2]</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>[1, 953, 1124, 1225, 59089, 262, 1040, 1225, 1225, 2]</td>\n",
       "      <td>[1, 953, 1124, 1225, 59089, 262, 1040, 1225, 1225, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911507</th>\n",
       "      <td>16</td>\n",
       "      <td>09316732</td>\n",
       "      <td>code</td>\n",
       "      <td>def run_train(df,batch_size,image_size,fold):ʶ    ʶ    train=df[df.kfold!=fold].reset_index(drop=True)ʶ    valid=df[df.kfold==fold].reset_index(drop=True)ʶ    ʶ    train_gen,val_gen= train_generator(train,valid,batch_size,image_size)ʶ    ʶ    my_callbacks = [EarlyStopping(monitor = 'val_loss', min_delta = 0.001, ʶ                                  patience = 3, mode = 'min', verbose = 1,ʶ                                  restore_best_weights = True),ʶ                    ModelCheckpoint(filepa...</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 23097, 684, 616, 23822, 555, 32392, 261, 54847, 616, 7283, 261, 15428, 616, 7283, 261, 10945, 285, 294, 128001, 128001, 2184, 1510, 32392, 2550, 32392, 260, 1165, 10945, 300, 1510, 10945, 592, 260, 68584, 616, 13915, 555, 17915, 1510, 35733, 285, 128001, 3816, 1510, 32392, 2550, 32392, 260, 1165, 10945, 1510, 1510, 10945, 592, 260, 68584, 616, 13915, 555, 17915, 1510, 35733, 285, 128001, 128001, 2184, 616, 7073, 261, 14206, 616, 7073, 1510, 2184, 616, 68890, 555, 23822, 261, 70946, 261, ...</td>\n",
       "      <td>372</td>\n",
       "      <td>26</td>\n",
       "      <td>[1, 23097, 684, 616, 23822, 555, 32392, 261, 54847, 616, 7283, 261, 15428, 616, 7283, 261, 10945, 285, 294, 128001, 128001, 2184, 1510, 32392, 2550, 32392, 260, 1165, 10945, 300, 1510, 10945, 592, 260, 68584, 616, 13915, 555, 17915, 1510, 35733, 285, 128001, 3816, 1510, 32392, 2550, 32392, 260, 1165, 10945, 1510, 1510, 10945, 592, 260, 68584, 616, 13915, 555, 17915, 1510, 35733, 285, 128001, 128001, 2184, 616, 7073, 261, 14206, 616, 7073, 1510, 2184, 616, 68890, 555, 23822, 261, 70946, 261, ...</td>\n",
       "      <td>[1, 23097, 684, 616, 23822, 555, 32392, 261, 54847, 616, 7283, 261, 15428, 616, 7283, 261, 10945, 285, 294, 128001, 128001, 2184, 1510, 32392, 2550, 32392, 260, 1165, 10945, 300, 1510, 10945, 592, 260, 68584, 616, 13915, 555, 17915, 1510, 35733, 285, 128001, 3816, 1510, 32392, 2550, 32392, 260, 1165, 10945, 1510, 1510, 10945, 592, 260, 68584, 616, 13915, 555, 17915, 1510, 35733, 285, 128001, 128001, 2184, 616, 7073, 261, 14206, 616, 7073, 1510, 2184, 616, 68890, 555, 23822, 261, 70946, 261, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911508</th>\n",
       "      <td>17</td>\n",
       "      <td>a988e7a5</td>\n",
       "      <td>code</td>\n",
       "      <td>oof_acc=[]</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 2673, 1580, 616, 46708, 1510, 2550, 592, 2]</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>[1, 2673, 1580, 616, 46708, 1510, 2550, 592, 2]</td>\n",
       "      <td>[1, 2673, 1580, 616, 46708, 1510, 2550, 592, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911509</th>\n",
       "      <td>18</td>\n",
       "      <td>a1d0ac1d</td>\n",
       "      <td>code</td>\n",
       "      <td>for i in range(5):ʶ        print(25*\"-\")    ʶ        print(f'{i}-fold training')ʶ        print(25*\"-\")ʶ        ʶ        model,history,train_gen, val_gen = run_train(train_df,16,300,i)ʶʶ        train_acc = history.history['categorical_accuracy']ʶ        val_acc = history.history['val_categorical_accuracy']ʶ        loss = history.history['loss']ʶ        val_loss = history.history['val_loss']ʶ        ʶ        oof_acc.append(val_acc)ʶ        ʶ        epochs = range(1, len(train_acc) + 1)ʶ       ...</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 270, 584, 267, 778, 555, 524, 285, 294, 128001, 2118, 555, 1883, 1225, 309, 271, 309, 285, 128001, 2118, 555, 1892, 280, 19976, 667, 14986, 271, 10945, 838, 280, 285, 128001, 2118, 555, 1883, 1225, 309, 271, 309, 285, 128001, 128001, 1040, 261, 27850, 261, 23822, 616, 7073, 261, 26520, 616, 7073, 1842, 684, 616, 23822, 555, 23822, 616, 32392, 261, 1984, 261, 4320, 261, 667, 285, 128001, 128001, 2184, 616, 46708, 1842, 820, 260, 27850, 2550, 280, 60336, 12292, 616, 111452, 280, 592, 12800...</td>\n",
       "      <td>447</td>\n",
       "      <td>28</td>\n",
       "      <td>[1, 270, 584, 267, 778, 555, 524, 285, 294, 128001, 2118, 555, 1883, 1225, 309, 271, 309, 285, 128001, 2118, 555, 1892, 280, 19976, 667, 14986, 271, 10945, 838, 280, 285, 128001, 2118, 555, 1883, 1225, 309, 271, 309, 285, 128001, 128001, 1040, 261, 27850, 261, 23822, 616, 7073, 261, 26520, 616, 7073, 1842, 684, 616, 23822, 555, 23822, 616, 32392, 261, 1984, 261, 4320, 261, 667, 285, 128001, 128001, 2184, 616, 46708, 1842, 820, 260, 27850, 2550, 280, 60336, 12292, 616, 111452, 280, 592, 12800...</td>\n",
       "      <td>[1, 270, 584, 267, 778, 555, 524, 285, 294, 128001, 2118, 555, 1883, 1225, 309, 271, 309, 285, 128001, 2118, 555, 1892, 280, 19976, 667, 14986, 271, 10945, 838, 280, 285, 128001, 2118, 555, 1883, 1225, 309, 271, 309, 285, 128001, 128001, 1040, 261, 27850, 261, 23822, 616, 7073, 261, 26520, 616, 7073, 1842, 684, 616, 23822, 555, 23822, 616, 32392, 261, 1984, 261, 4320, 261, 667, 285, 128001, 128001, 2184, 616, 46708, 1842, 820, 260, 27850, 2550, 280, 60336, 12292, 616, 111452, 280, 592, 12800...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911510</th>\n",
       "      <td>19</td>\n",
       "      <td>8e4f45aa</td>\n",
       "      <td>code</td>\n",
       "      <td>print(np.mean(oof_acc))ʶ</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 2118, 555, 48221, 260, 28431, 555, 795, 1580, 616, 46708, 285, 285, 128001, 2]</td>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>[1, 2118, 555, 48221, 260, 28431, 555, 795, 1580, 616, 46708, 285, 285, 128001, 2]</td>\n",
       "      <td>[1, 2118, 555, 48221, 260, 28431, 555, 795, 1580, 616, 46708, 285, 285, 128001, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911511</th>\n",
       "      <td>20</td>\n",
       "      <td>70175f16</td>\n",
       "      <td>code</td>\n",
       "      <td>from sklearn.metrics import confusion_matrix, classification_reportʶ        ʶpred = model.predict_generator(val_gen) # Gives class probabilitiesʶpred = np.round(pred) # Gives one-hot encoded classesʶpred = np.argmax(pred, axis = 1) # Gives class labelsʶʶ# Obtain actual labelsʶactual = val_gen.classesʶ    ʶ# Now plot matrixʶsns.set(rc={'figure.figsize':(10,10)})ʶsns.set_style('whitegrid')ʶcm = confusion_matrix(actual, pred, labels = [0,1,2,3,4])ʶsns.heatmap(ʶ    cm, ʶ    cmap=\"Blues\",ʶ    ann...</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 292, 33566, 29274, 260, 56282, 6306, 6803, 616, 53195, 261, 9209, 616, 27551, 128001, 128001, 1348, 407, 1842, 1040, 260, 57796, 616, 68890, 555, 14206, 616, 7073, 285, 953, 36203, 938, 30717, 128001, 1348, 407, 1842, 76767, 260, 6494, 555, 9894, 407, 285, 953, 36203, 311, 271, 10069, 23717, 2141, 128001, 1348, 407, 1842, 76767, 260, 52183, 10537, 555, 9894, 407, 261, 10558, 1842, 376, 285, 953, 36203, 938, 6768, 128001, 128001, 953, 34485, 1854, 6768, 128001, 1854, 1842, 26520, 616, 707...</td>\n",
       "      <td>213</td>\n",
       "      <td>30</td>\n",
       "      <td>[1, 292, 33566, 29274, 260, 56282, 6306, 6803, 616, 53195, 261, 9209, 616, 27551, 128001, 128001, 1348, 407, 1842, 1040, 260, 57796, 616, 68890, 555, 14206, 616, 7073, 285, 953, 36203, 938, 30717, 128001, 1348, 407, 1842, 76767, 260, 6494, 555, 9894, 407, 285, 953, 36203, 311, 271, 10069, 23717, 2141, 128001, 1348, 407, 1842, 76767, 260, 52183, 10537, 555, 9894, 407, 261, 10558, 1842, 376, 285, 953, 36203, 938, 6768, 128001, 128001, 953, 34485, 1854, 6768, 128001, 1854, 1842, 26520, 616, 707...</td>\n",
       "      <td>[1, 292, 33566, 29274, 260, 56282, 6306, 6803, 616, 53195, 261, 9209, 616, 27551, 128001, 128001, 1348, 407, 1842, 1040, 260, 57796, 616, 68890, 555, 14206, 616, 7073, 285, 953, 36203, 938, 30717, 128001, 1348, 407, 1842, 76767, 260, 6494, 555, 9894, 407, 285, 953, 36203, 311, 271, 10069, 23717, 2141, 128001, 1348, 407, 1842, 76767, 260, 52183, 10537, 555, 9894, 407, 261, 10558, 1842, 376, 285, 953, 36203, 938, 6768, 128001, 128001, 953, 34485, 1854, 6768, 128001, 1854, 1842, 26520, 616, 707...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911512</th>\n",
       "      <td>21</td>\n",
       "      <td>10c71f75</td>\n",
       "      <td>code</td>\n",
       "      <td>print(classification_report(actual,pred))</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 2118, 555, 79642, 616, 27551, 555, 41841, 261, 9894, 407, 285, 285, 2]</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>[1, 2118, 555, 79642, 616, 27551, 555, 41841, 261, 9894, 407, 285, 285, 2]</td>\n",
       "      <td>[1, 2118, 555, 79642, 616, 27551, 555, 41841, 261, 9894, 407, 285, 285, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911518</th>\n",
       "      <td>27</td>\n",
       "      <td>980da5c5</td>\n",
       "      <td>markdown</td>\n",
       "      <td>**Work Under progress**</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 1124, 1225, 22625, 2978, 2201, 1225, 1225, 2]</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>[1, 1124, 1225, 22625, 2978, 2201, 1225, 1225, 2]</td>\n",
       "      <td>[1, 1124, 1225, 22625, 2978, 2201, 1225, 1225, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911515</th>\n",
       "      <td>24</td>\n",
       "      <td>61afafe6</td>\n",
       "      <td>markdown</td>\n",
       "      <td># **Improvements**</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 953, 1124, 1225, 23553, 52397, 16850, 1225, 1225, 2]</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "      <td>[1, 953, 1124, 1225, 23553, 52397, 16850, 1225, 1225, 2]</td>\n",
       "      <td>[1, 953, 1124, 1225, 23553, 52397, 16850, 1225, 1225, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911516</th>\n",
       "      <td>25</td>\n",
       "      <td>9e981a0e</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Some improvements that could possibly be made:ʶʶ1. Image augmentation (using cutmix etc.)ʶ2. Different learning rate and learning rate scheduleʶ3. Using TPU to decrease the training timeʶ4. Increased input sizeʶ5. Add more dense layers and regularizationʶ6. Using other architectures such as EfficientNetʶʶIf this notebook helped you, please leave an upvote!</td>\n",
       "      <td>43bd04946376da</td>\n",
       "      <td>[1, 879, 4528, 272, 387, 2441, 282, 412, 294, 128001, 128001, 376, 260, 4439, 31306, 287, 13691, 1174, 20260, 965, 260, 285, 128001, 392, 260, 9339, 1101, 1039, 263, 1101, 1039, 2093, 128001, 404, 260, 2891, 71813, 264, 4843, 262, 838, 326, 128001, 453, 260, 21772, 3210, 884, 128001, 456, 260, 2373, 310, 9854, 4974, 263, 1481, 4820, 128001, 525, 260, 2891, 340, 30805, 405, 283, 29230, 9923, 128001, 128001, 369, 291, 12452, 1666, 274, 261, 811, 1021, 299, 85623, 300, 2]</td>\n",
       "      <td>82</td>\n",
       "      <td>34</td>\n",
       "      <td>[1, 879, 4528, 272, 387, 2441, 282, 412, 294, 128001, 128001, 376, 260, 4439, 31306, 287, 13691, 1174, 20260, 965, 260, 285, 128001, 392, 260, 9339, 1101, 1039, 263, 1101, 1039, 2093, 128001, 404, 260, 2891, 71813, 264, 4843, 262, 838, 326, 128001, 453, 260, 21772, 3210, 884, 128001, 456, 260, 2373, 310, 9854, 4974, 263, 1481, 4820, 128001, 525, 260, 2891, 340, 30805, 405, 283, 29230, 9923, 128001, 128001, 369, 291, 12452, 1666, 274, 261, 811, 1021, 299, 85623, 300, 2]</td>\n",
       "      <td>[1, 879, 4528, 272, 387, 2441, 282, 412, 294, 128001, 128001, 376, 260, 4439, 31306, 287, 13691, 1174, 20260, 965, 260, 285, 128001, 392, 260, 9339, 1101, 1039, 263, 1101, 1039, 2093, 128001, 404, 260, 2891, 71813, 264, 4843, 262, 838, 326, 128001, 453, 260, 21772, 3210, 884, 128001, 456, 260, 2373, 310, 9854, 4974, 263, 1481, 4820, 128001, 525, 260, 2891, 340, 30805, 405, 283, 29230, 9923, 128001, 128001, 369, 291, 12452, 1666, 274, 261, 811, 1021, 299, 85623, 300, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index   cell_id cell_type  \\\n",
       "2911522     31  7bb92ebe  markdown   \n",
       "2911521     30  9464c9af  markdown   \n",
       "2911491      0  3f1ad88e      code   \n",
       "2911513     22  011c5d1a  markdown   \n",
       "2911520     29  c23a2762  markdown   \n",
       "2911492      1  a2ccff1c      code   \n",
       "2911493      2  011b6367      code   \n",
       "2911494      3  9d2abdc9      code   \n",
       "2911495      4  21e4504e      code   \n",
       "2911496      5  50674f0f      code   \n",
       "2911497      6  eb6ce0f1      code   \n",
       "2911498      7  2ddd105a      code   \n",
       "2911499      8  d0838468      code   \n",
       "2911525     34  7729761f  markdown   \n",
       "2911500      9  f9860522      code   \n",
       "2911501     10  f4a624c6      code   \n",
       "2911502     11  9f6b86ce      code   \n",
       "2911517     26  534ce2a1  markdown   \n",
       "2911514     23  c86dbed7  markdown   \n",
       "2911503     12  049a786a      code   \n",
       "2911504     13  2da37024      code   \n",
       "2911505     14  2c7d5413      code   \n",
       "2911523     32  68e0b102  markdown   \n",
       "2911524     33  21292bdd  markdown   \n",
       "2911506     15  f7f6fbf6      code   \n",
       "2911519     28  9199586d  markdown   \n",
       "2911507     16  09316732      code   \n",
       "2911508     17  a988e7a5      code   \n",
       "2911509     18  a1d0ac1d      code   \n",
       "2911510     19  8e4f45aa      code   \n",
       "2911511     20  70175f16      code   \n",
       "2911512     21  10c71f75      code   \n",
       "2911518     27  980da5c5  markdown   \n",
       "2911515     24  61afafe6  markdown   \n",
       "2911516     25  9e981a0e  markdown   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      source  \\\n",
       "2911522  Hey kagglers,ʶʶThis is my first competition in kaggle, I would like to share my approach on the Cassava leaf disease competition.ʶMy approach involoves:ʶ* Using keras libraryʶ* Using GPU to train the modelʶ* Using albumentations to augment the dataset to prevent overfittingʶ* Using the StratifiedKFold as the dataset is skewed.ʶʶThis notebook is for beginner who would like to get started with this competitionʶʶReferences:ʶ1. Approaching (Almost) Any Machine Learning Problem - Book by Abhishek...   \n",
       "2911521                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            # **Importing libraries**   \n",
       "2911491  import pandas as pdʶimport numpy as npʶimport matplotlib.pyplot as pltʶimport os ʶfrom sklearn.model_selection import StratifiedKFoldʶimport seaborn as snsʶimport jsonʶimport cv2ʶʶimport tensorflow as tfʶfrom tensorflow.keras import models, layers,Sequential,regularizersʶfrom tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping, ModelCheckpointʶfrom keras.layers import Input, Flatten, Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropoutʶfrom tensorflow.keras.models impor...   \n",
       "2911513  Cassava leaves are a rich source of protein, minerals, and vitamins. However, the presence of antinutrients and cyanogenic glucosides are the major drawbacks in cassava leaves which limit its human consumption. These antinutrients and toxic compounds of cassava leaves cause various diseases depending on the consumption level. But viral diseases are major sources of poor yields. With the help of data science, it may be possible to identify common diseases so they can be treated.ʶʶ![](https://...   \n",
       "2911520                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              # **Dataset and Kfold**   \n",
       "2911492                                                                                                                                                                                                                                                                                                                                                                 train_image_path=\"../input/cassava-leaf-disease-classification/train_images/\"ʶtrain_df_path=\"../input/cassava-leaf-disease-classification/train.csv\"   \n",
       "2911493                                                                                                                                                                                                                                                                                                                                                                                                                                                                  train_df=pd.read_csv(train_df_path)ʶtrain_df.head()   \n",
       "2911494                                                                                                                                                                                                                                                                                                            with open(\"../input/cassava-leaf-disease-classification/label_num_to_disease_map.json\") as file:ʶ    map_classes = json.loads(file.read())ʶ    map_classes = {int(k) : v for k, v in map_classes.items()}   \n",
       "2911495                                                                                                                                                                                                                                                                                                                                                                                                                                                 train_df[\"Class\"]=train_df[\"label\"].map(map_classes)ʶtrain_df.head()   \n",
       "2911496                                                                                                                                                                                                                                                                                          sns.set(rc={'figure.figsize':(8,4)})ʶsns.set_style('whitegrid')ʶʶva=sns.countplot(y=\"Class\",data=train_df,palette='rainbow')ʶplt.xlabel(\"Classes of leaves\",fontsize=20)ʶplt.ylabel(\"Count\",fontsize=20)ʶplt.tight_layout()   \n",
       "2911497                      def visualize(image_ids, labels):ʶ    plt.figure(figsize=(16, 12))ʶ    for ind, (image_id, label) in enumerate(zip(image_ids, labels)):ʶ        plt.subplot(4, 4, ind + 1)ʶ        image = cv2.imread(os.path.join(\"../input/cassava-leaf-disease-classification/train_images\", image_id))ʶ        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)ʶ        plt.imshow(image)ʶ        plt.title(f\"Class: {label}\", fontsize=12)ʶ        plt.axis(\"off\")ʶ        plt.tight_layout()ʶ    plt.show()   \n",
       "2911498                                                                                                                                                                                                                                                                                                                                                                                train_df1=train_df.sample(8)ʶimage_ids = train_df1[\"image_id\"].valuesʶlabels = train_df1[\"Class\"].valuesʶvisualize(image_ids, labels)   \n",
       "2911499                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        train_df.label.value_counts()   \n",
       "2911525  As you can observe, The data set is skewed with the largest number of samples for label 3, Cassava Mosiac Disease (CMD), and the fewest number of samples for label 0, Cassava Bacterial Blight (CBB). To over come this we use StratifiedKfold to split the dataset for training and validation to check the performance of the model.ʶʶThe general procedure is as follows:ʶ1. Shuffle the dataset randomly.ʶ2. Split the dataset into k groupsʶ3. For each unique group:ʶ    * Take the group as a holdout or...   \n",
       "2911500                                                                                                                                                                                          def creat_nfold(train_df,n_split):ʶ    train_df.loc[:,\"kfold\"]=-1ʶ    train_df=train_df.sample(frac=1).reset_index(drop=True)ʶ    SS=StratifiedKFold(n_splits=n_split)ʶ    y=train_df.label.valuesʶ    for fold,(t_,v_) in enumerate((SS.split(X=train_df,y=y))):ʶ        train_df.loc[v_,\"kfold\"]=foldʶ    return train_df   \n",
       "2911501                                                                                                                                                                                                                                                                                                                                                          train_df.label=train_df.label.astype(\"str\") ʶ#converting the label to str as we will be using categorical cross entropy as loss function to train the model   \n",
       "2911502                                                                                                                                                                                                                                                                                                                                                                                                                                                                   train_df=creat_nfold(train_df,5)ʶtrain_df.head(5)ʶ   \n",
       "2911517                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   # **Augmentation**   \n",
       "2911514                                                                                                                                                                                                                                                                                                       Image augmentations is done with the help of the library Albumentation through both ImageDataGenerator. We will use a tool called ImageDataAugmentor (thanks to mjkvaak at github) that allows us to do this.    \n",
       "2911503                                                                                                                                                                                                                                                                                                                                                                                                                                                       !pip install git+https://github.com/mjkvaak/ImageDataAugmentor   \n",
       "2911504  from ImageDataAugmentor.image_data_augmentor import *ʶimport albumentations as Aʶʶ# augmentations referred from: https://www.kaggle.com/khyeh0719/pytorch-efficientnet-baseline-train-amp-augʶtrain_aug = albumentations.Compose([ʶ            albumentations.RandomResizedCrop(300, 300),ʶ            albumentations.Transpose(p=0.5),ʶ            albumentations.HorizontalFlip(p=0.5),ʶ            albumentations.VerticalFlip(p=0.5),ʶ            albumentations.ShiftScaleRotate(p=0.5),ʶ            albume...   \n",
       "2911505  def train_generator(train,valid,batch_size,image_size):ʶ    ʶ        datagen_train = ImageDataAugmentor(augment=train_aug)ʶ        datagen_val = ImageDataAugmentor(augment=valid_aug)ʶ        train_generator = datagen_train.flow_from_dataframe(dataframe=train,ʶ                                                    directory=train_image_path,ʶ                                                    x_col=\"image_id\",ʶ                                                    y_col=\"label\",ʶ                   ...   \n",
       "2911523                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               # **Define the model**   \n",
       "2911524                                                                                                                                                                                                                                                                                                                                                                                We will use the Xception architecture to train the model. To read more about this architecture refer https://arxiv.org/abs/1610.02357   \n",
       "2911506  def make_model(IMG_SIZE):ʶ    base_model = Xception(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False,ʶ                             weights = 'imagenet')ʶ    x = base_model.outputʶ    x = GlobalAveragePooling2D()(x)ʶ    x = Dropout(0.3)(x)ʶ    predictions = Dense(5, activation='softmax',name='Final', dtype='float32')(x)ʶʶ    model = Model(inputs=base_model.input, outputs=predictions)ʶʶ    model.compile(optimizer =tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=Tru...   \n",
       "2911519                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             # **Training the model**   \n",
       "2911507  def run_train(df,batch_size,image_size,fold):ʶ    ʶ    train=df[df.kfold!=fold].reset_index(drop=True)ʶ    valid=df[df.kfold==fold].reset_index(drop=True)ʶ    ʶ    train_gen,val_gen= train_generator(train,valid,batch_size,image_size)ʶ    ʶ    my_callbacks = [EarlyStopping(monitor = 'val_loss', min_delta = 0.001, ʶ                                  patience = 3, mode = 'min', verbose = 1,ʶ                                  restore_best_weights = True),ʶ                    ModelCheckpoint(filepa...   \n",
       "2911508                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           oof_acc=[]   \n",
       "2911509  for i in range(5):ʶ        print(25*\"-\")    ʶ        print(f'{i}-fold training')ʶ        print(25*\"-\")ʶ        ʶ        model,history,train_gen, val_gen = run_train(train_df,16,300,i)ʶʶ        train_acc = history.history['categorical_accuracy']ʶ        val_acc = history.history['val_categorical_accuracy']ʶ        loss = history.history['loss']ʶ        val_loss = history.history['val_loss']ʶ        ʶ        oof_acc.append(val_acc)ʶ        ʶ        epochs = range(1, len(train_acc) + 1)ʶ       ...   \n",
       "2911510                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             print(np.mean(oof_acc))ʶ   \n",
       "2911511  from sklearn.metrics import confusion_matrix, classification_reportʶ        ʶpred = model.predict_generator(val_gen) # Gives class probabilitiesʶpred = np.round(pred) # Gives one-hot encoded classesʶpred = np.argmax(pred, axis = 1) # Gives class labelsʶʶ# Obtain actual labelsʶactual = val_gen.classesʶ    ʶ# Now plot matrixʶsns.set(rc={'figure.figsize':(10,10)})ʶsns.set_style('whitegrid')ʶcm = confusion_matrix(actual, pred, labels = [0,1,2,3,4])ʶsns.heatmap(ʶ    cm, ʶ    cmap=\"Blues\",ʶ    ann...   \n",
       "2911512                                                                                                                                                                                                                                                                                                                                                                                                                                                                            print(classification_report(actual,pred))   \n",
       "2911518                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              **Work Under progress**   \n",
       "2911515                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   # **Improvements**   \n",
       "2911516                                                                                                                                               Some improvements that could possibly be made:ʶʶ1. Image augmentation (using cutmix etc.)ʶ2. Different learning rate and learning rate scheduleʶ3. Using TPU to decrease the training timeʶ4. Increased input sizeʶ5. Add more dense layers and regularizationʶ6. Using other architectures such as EfficientNetʶʶIf this notebook helped you, please leave an upvote!   \n",
       "\n",
       "                     id  \\\n",
       "2911522  43bd04946376da   \n",
       "2911521  43bd04946376da   \n",
       "2911491  43bd04946376da   \n",
       "2911513  43bd04946376da   \n",
       "2911520  43bd04946376da   \n",
       "2911492  43bd04946376da   \n",
       "2911493  43bd04946376da   \n",
       "2911494  43bd04946376da   \n",
       "2911495  43bd04946376da   \n",
       "2911496  43bd04946376da   \n",
       "2911497  43bd04946376da   \n",
       "2911498  43bd04946376da   \n",
       "2911499  43bd04946376da   \n",
       "2911525  43bd04946376da   \n",
       "2911500  43bd04946376da   \n",
       "2911501  43bd04946376da   \n",
       "2911502  43bd04946376da   \n",
       "2911517  43bd04946376da   \n",
       "2911514  43bd04946376da   \n",
       "2911503  43bd04946376da   \n",
       "2911504  43bd04946376da   \n",
       "2911505  43bd04946376da   \n",
       "2911523  43bd04946376da   \n",
       "2911524  43bd04946376da   \n",
       "2911506  43bd04946376da   \n",
       "2911519  43bd04946376da   \n",
       "2911507  43bd04946376da   \n",
       "2911508  43bd04946376da   \n",
       "2911509  43bd04946376da   \n",
       "2911510  43bd04946376da   \n",
       "2911511  43bd04946376da   \n",
       "2911512  43bd04946376da   \n",
       "2911518  43bd04946376da   \n",
       "2911515  43bd04946376da   \n",
       "2911516  43bd04946376da   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   input_ids  \\\n",
       "2911522  [1, 5388, 7478, 94989, 268, 261, 128001, 128001, 329, 269, 312, 362, 2027, 267, 4219, 89061, 261, 273, 338, 334, 264, 752, 312, 1218, 277, 262, 18961, 16925, 6712, 1682, 2027, 260, 128001, 573, 1218, 267, 90974, 415, 268, 294, 128001, 1124, 2891, 39170, 1628, 2634, 128001, 1124, 2891, 16265, 264, 2184, 262, 1040, 128001, 1124, 2891, 1898, 91547, 268, 264, 24906, 262, 12438, 264, 1843, 360, 25335, 128001, 1124, 2891, 262, 38251, 13329, 51708, 1371, 283, 262, 12438, 269, 32147, 260, 128001, 12...   \n",
       "2911521                                                                                                                                                                                                                                                                                                                                                                                                                                                                [1, 953, 1124, 1225, 60098, 510, 7296, 1225, 1225, 2]   \n",
       "2911491  [1, 6306, 67927, 283, 845, 407, 128001, 6306, 36221, 11751, 283, 76767, 128001, 6306, 8358, 33918, 14434, 260, 11751, 33918, 283, 28944, 297, 128001, 6306, 2673, 268, 128001, 292, 33566, 29274, 260, 19928, 616, 57907, 6306, 38251, 13329, 51708, 1371, 128001, 6306, 2164, 6107, 283, 41339, 268, 128001, 6306, 74883, 128001, 6306, 37821, 445, 128001, 128001, 6306, 55919, 14068, 283, 78191, 128001, 292, 55919, 14068, 260, 8285, 1628, 6306, 1836, 261, 4974, 261, 430, 87386, 46580, 261, 34020, 4322...   \n",
       "2911513  [1, 18961, 16925, 2423, 281, 266, 2241, 1271, 265, 2927, 261, 8525, 261, 263, 9571, 260, 672, 261, 262, 2192, 265, 1688, 64804, 268, 263, 45781, 26429, 77462, 54787, 281, 262, 852, 26810, 267, 66351, 2423, 319, 2642, 359, 857, 4003, 260, 606, 1688, 64804, 268, 263, 7290, 8312, 265, 66351, 2423, 1138, 847, 4253, 2719, 277, 262, 4003, 674, 260, 420, 8804, 4253, 281, 852, 2175, 265, 1970, 10474, 260, 559, 262, 408, 265, 514, 1693, 261, 278, 372, 282, 628, 264, 2313, 1019, 4253, 324, 306, 295, 2...   \n",
       "2911520                                                                                                                                                                                                                                                                                                                                                                                                                                                   [1, 953, 1124, 1225, 15006, 6207, 263, 1148, 10945, 1225, 1225, 2]   \n",
       "2911492                                                                                                                                                                                  [1, 2184, 616, 15428, 616, 14035, 1510, 309, 260, 260, 320, 42177, 320, 21783, 268, 16925, 271, 22334, 271, 58272, 271, 79642, 320, 23822, 616, 24227, 320, 309, 128001, 2184, 616, 32392, 616, 14035, 1510, 309, 260, 260, 320, 42177, 320, 21783, 268, 16925, 271, 22334, 271, 58272, 271, 79642, 320, 23822, 260, 76413, 309, 2]   \n",
       "2911493                                                                                                                                                                                                                                                                                                                                                                 [1, 2184, 616, 32392, 1510, 39871, 260, 8523, 616, 76413, 555, 23822, 616, 32392, 616, 14035, 285, 128001, 2184, 616, 32392, 260, 5563, 555, 285, 2]   \n",
       "2911494                                                             [1, 275, 615, 555, 309, 260, 260, 320, 42177, 320, 21783, 268, 16925, 271, 22334, 271, 58272, 271, 79642, 320, 25289, 616, 22062, 616, 725, 616, 58272, 616, 14727, 260, 50574, 309, 285, 283, 1092, 294, 128001, 2269, 616, 58348, 1842, 74883, 260, 61373, 555, 13093, 260, 8523, 555, 285, 285, 128001, 2269, 616, 58348, 1842, 13856, 17925, 555, 1165, 285, 877, 1942, 270, 4219, 261, 1942, 267, 2269, 616, 58348, 260, 55735, 555, 285, 14986, 2]   \n",
       "2911495                                                                                                                                                                                                                                                                                                                    [1, 2184, 616, 32392, 2550, 309, 16264, 309, 592, 1510, 23822, 616, 32392, 2550, 309, 25289, 309, 592, 260, 14727, 555, 14727, 616, 58348, 285, 128001, 2184, 616, 32392, 260, 5563, 555, 285, 2]   \n",
       "2911496  [1, 41339, 268, 260, 6207, 555, 19637, 1510, 19976, 280, 22971, 260, 30134, 7283, 280, 294, 555, 804, 261, 554, 285, 14986, 285, 128001, 41339, 268, 260, 6207, 616, 4602, 555, 280, 7551, 25549, 280, 285, 128001, 128001, 17632, 1510, 268, 7565, 260, 21036, 33918, 555, 608, 1510, 309, 16264, 309, 261, 9832, 1510, 23822, 616, 32392, 261, 15151, 8583, 1510, 280, 109289, 280, 285, 128001, 28944, 297, 260, 982, 25289, 555, 309, 16264, 1110, 265, 2423, 309, 261, 35557, 7283, 1510, 1435, 285, 128001...   \n",
       "2911497  [1, 23097, 18438, 555, 15428, 616, 26657, 261, 6768, 285, 294, 128001, 28944, 297, 260, 22971, 555, 30134, 7283, 1510, 555, 1984, 261, 621, 285, 285, 128001, 270, 267, 407, 261, 287, 15428, 616, 4765, 261, 3734, 285, 267, 71955, 555, 21550, 555, 15428, 616, 26657, 261, 6768, 285, 285, 294, 128001, 28944, 297, 260, 12109, 33918, 555, 554, 261, 453, 261, 267, 407, 1566, 376, 285, 128001, 1115, 1842, 37821, 445, 260, 6263, 8523, 555, 3603, 260, 14035, 260, 46901, 555, 309, 260, 260, 320, 42177,...   \n",
       "2911498                                                                                                                                                                                [1, 2184, 616, 32392, 435, 1510, 23822, 616, 32392, 260, 26154, 555, 804, 285, 128001, 1115, 616, 26657, 1842, 2184, 616, 32392, 435, 2550, 309, 15428, 616, 4765, 309, 592, 260, 41801, 128001, 6768, 1842, 2184, 616, 32392, 435, 2550, 309, 16264, 309, 592, 260, 41801, 128001, 18438, 555, 15428, 616, 26657, 261, 6768, 285, 2]   \n",
       "2911499                                                                                                                                                                                                                                                                                                                                                                                                                                          [1, 2184, 616, 32392, 260, 25289, 260, 11651, 616, 21036, 268, 555, 285, 2]   \n",
       "2911525  [1, 463, 274, 295, 6695, 261, 279, 514, 487, 269, 32147, 275, 262, 1705, 496, 265, 3894, 270, 3734, 404, 261, 18961, 16925, 94798, 6504, 9384, 287, 105211, 285, 261, 263, 262, 51156, 496, 265, 3894, 270, 3734, 767, 261, 18961, 16925, 66630, 86389, 287, 711, 15416, 285, 260, 502, 360, 488, 291, 301, 380, 38251, 13329, 1301, 10945, 264, 3671, 262, 12438, 270, 838, 263, 10872, 264, 807, 262, 876, 265, 262, 1040, 260, 128001, 128001, 279, 1042, 3017, 269, 283, 3832, 294, 128001, 376, 260, 60749,...   \n",
       "2911500  [1, 23097, 91597, 616, 673, 10945, 555, 23822, 616, 32392, 261, 673, 616, 43483, 285, 294, 128001, 2184, 616, 32392, 260, 28372, 2550, 294, 261, 309, 1165, 10945, 309, 592, 1510, 271, 435, 128001, 2184, 616, 32392, 1510, 23822, 616, 32392, 260, 26154, 555, 71074, 1510, 435, 285, 260, 68584, 616, 13915, 555, 17915, 1510, 35733, 285, 128001, 9937, 1510, 95232, 13329, 51708, 1371, 555, 673, 616, 43483, 268, 1510, 673, 616, 43483, 285, 128001, 2982, 1510, 23822, 616, 32392, 260, 25289, 260, 4180...   \n",
       "2911501                                                                                                                                                                                                                                                                 [1, 2184, 616, 32392, 260, 25289, 1510, 23822, 616, 32392, 260, 25289, 260, 1628, 5967, 555, 309, 22889, 309, 285, 128001, 953, 98936, 262, 3734, 264, 25275, 283, 301, 296, 282, 478, 48301, 1943, 33631, 283, 1265, 1571, 264, 2184, 262, 1040, 2]   \n",
       "2911502                                                                                                                                                                                                                                                                                                                                                       [1, 2184, 616, 32392, 1510, 66937, 297, 616, 673, 10945, 555, 23822, 616, 32392, 261, 524, 285, 128001, 2184, 616, 32392, 260, 5563, 555, 524, 285, 128001, 2]   \n",
       "2911517                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [1, 953, 1124, 1225, 32995, 78863, 1225, 1225, 2]   \n",
       "2911514                                                                                                                                                                                                                                             [1, 4439, 31306, 268, 269, 619, 275, 262, 408, 265, 262, 2634, 15821, 91547, 390, 462, 4439, 15006, 117384, 260, 345, 296, 380, 266, 1637, 650, 4439, 15006, 32995, 59423, 287, 20085, 264, 96509, 68738, 70935, 288, 55346, 285, 272, 1279, 381, 264, 333, 291, 260, 2]   \n",
       "2911503                                                                                                                                                                                                                                                                                                                                                                          [1, 1084, 70415, 2625, 25182, 1186, 13229, 294, 320, 320, 45552, 260, 549, 320, 358, 68151, 6586, 7654, 320, 23791, 15006, 32995, 59423, 2]   \n",
       "2911504  [1, 292, 4439, 15006, 32995, 59423, 260, 15428, 616, 9832, 616, 56244, 59423, 6306, 1124, 128001, 6306, 1898, 91547, 268, 283, 336, 128001, 128001, 953, 31306, 268, 3504, 292, 294, 3597, 294, 320, 320, 1965, 260, 1165, 89061, 260, 549, 320, 19491, 89675, 4649, 2573, 320, 11751, 96443, 271, 16454, 3163, 271, 113395, 271, 23822, 271, 10832, 271, 56244, 128001, 2184, 616, 56244, 1842, 1898, 91547, 268, 260, 30988, 17619, 555, 2550, 128001, 1898, 91547, 268, 260, 72388, 5396, 6545, 711, 52823, 5...   \n",
       "2911505  [1, 23097, 2184, 616, 68890, 555, 23822, 261, 70946, 261, 54847, 616, 7283, 261, 15428, 616, 7283, 285, 294, 128001, 128001, 514, 7073, 616, 23822, 1842, 4439, 15006, 32995, 59423, 555, 56244, 4572, 1510, 23822, 616, 56244, 285, 128001, 514, 7073, 616, 14206, 1842, 4439, 15006, 32995, 59423, 555, 56244, 4572, 1510, 70946, 616, 56244, 285, 128001, 2184, 616, 68890, 1842, 514, 7073, 616, 23822, 260, 14068, 616, 5117, 616, 9832, 16439, 555, 9832, 16439, 1510, 23822, 261, 128001, 5514, 1510, 238...   \n",
       "2911523                                                                                                                                                                                                                                                                                                                                                                                                                                                          [1, 953, 1124, 1225, 46301, 5152, 262, 1040, 1225, 1225, 2]   \n",
       "2911524                                                                                                                                                                                                                                                                                                             [1, 345, 296, 380, 262, 1477, 56237, 3781, 264, 2184, 262, 1040, 260, 502, 623, 310, 314, 291, 3781, 3886, 3597, 294, 320, 320, 3260, 70707, 260, 2083, 320, 58032, 320, 1984, 894, 260, 4159, 34805, 2]   \n",
       "2911506  [1, 23097, 365, 616, 19928, 555, 100417, 616, 92921, 285, 294, 128001, 1436, 616, 19928, 1842, 1477, 56237, 555, 42177, 616, 29753, 1842, 287, 100417, 616, 92921, 261, 55699, 616, 92921, 261, 404, 285, 261, 680, 616, 6500, 1842, 21333, 261, 128001, 12355, 1842, 382, 15428, 3163, 280, 285, 128001, 1204, 1842, 1436, 616, 19928, 260, 35055, 128001, 1204, 1842, 2974, 94222, 48910, 510, 445, 691, 555, 285, 555, 982, 285, 128001, 1204, 1842, 10577, 2355, 555, 693, 260, 508, 285, 555, 982, 285, 128...   \n",
       "2911519                                                                                                                                                                                                                                                                                                                                                                                                                                                                [1, 953, 1124, 1225, 59089, 262, 1040, 1225, 1225, 2]   \n",
       "2911507  [1, 23097, 684, 616, 23822, 555, 32392, 261, 54847, 616, 7283, 261, 15428, 616, 7283, 261, 10945, 285, 294, 128001, 128001, 2184, 1510, 32392, 2550, 32392, 260, 1165, 10945, 300, 1510, 10945, 592, 260, 68584, 616, 13915, 555, 17915, 1510, 35733, 285, 128001, 3816, 1510, 32392, 2550, 32392, 260, 1165, 10945, 1510, 1510, 10945, 592, 260, 68584, 616, 13915, 555, 17915, 1510, 35733, 285, 128001, 128001, 2184, 616, 7073, 261, 14206, 616, 7073, 1510, 2184, 616, 68890, 555, 23822, 261, 70946, 261, ...   \n",
       "2911508                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [1, 2673, 1580, 616, 46708, 1510, 2550, 592, 2]   \n",
       "2911509  [1, 270, 584, 267, 778, 555, 524, 285, 294, 128001, 2118, 555, 1883, 1225, 309, 271, 309, 285, 128001, 2118, 555, 1892, 280, 19976, 667, 14986, 271, 10945, 838, 280, 285, 128001, 2118, 555, 1883, 1225, 309, 271, 309, 285, 128001, 128001, 1040, 261, 27850, 261, 23822, 616, 7073, 261, 26520, 616, 7073, 1842, 684, 616, 23822, 555, 23822, 616, 32392, 261, 1984, 261, 4320, 261, 667, 285, 128001, 128001, 2184, 616, 46708, 1842, 820, 260, 27850, 2550, 280, 60336, 12292, 616, 111452, 280, 592, 12800...   \n",
       "2911510                                                                                                                                                                                                                                                                                                                                                                                                                                   [1, 2118, 555, 48221, 260, 28431, 555, 795, 1580, 616, 46708, 285, 285, 128001, 2]   \n",
       "2911511  [1, 292, 33566, 29274, 260, 56282, 6306, 6803, 616, 53195, 261, 9209, 616, 27551, 128001, 128001, 1348, 407, 1842, 1040, 260, 57796, 616, 68890, 555, 14206, 616, 7073, 285, 953, 36203, 938, 30717, 128001, 1348, 407, 1842, 76767, 260, 6494, 555, 9894, 407, 285, 953, 36203, 311, 271, 10069, 23717, 2141, 128001, 1348, 407, 1842, 76767, 260, 52183, 10537, 555, 9894, 407, 261, 10558, 1842, 376, 285, 953, 36203, 938, 6768, 128001, 128001, 953, 34485, 1854, 6768, 128001, 1854, 1842, 26520, 616, 707...   \n",
       "2911512                                                                                                                                                                                                                                                                                                                                                                                                                                           [1, 2118, 555, 79642, 616, 27551, 555, 41841, 261, 9894, 407, 285, 285, 2]   \n",
       "2911518                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [1, 1124, 1225, 22625, 2978, 2201, 1225, 1225, 2]   \n",
       "2911515                                                                                                                                                                                                                                                                                                                                                                                                                                                             [1, 953, 1124, 1225, 23553, 52397, 16850, 1225, 1225, 2]   \n",
       "2911516                            [1, 879, 4528, 272, 387, 2441, 282, 412, 294, 128001, 128001, 376, 260, 4439, 31306, 287, 13691, 1174, 20260, 965, 260, 285, 128001, 392, 260, 9339, 1101, 1039, 263, 1101, 1039, 2093, 128001, 404, 260, 2891, 71813, 264, 4843, 262, 838, 326, 128001, 453, 260, 21772, 3210, 884, 128001, 456, 260, 2373, 310, 9854, 4974, 263, 1481, 4820, 128001, 525, 260, 2891, 340, 30805, 405, 283, 29230, 9923, 128001, 128001, 369, 291, 12452, 1666, 274, 261, 811, 1021, 299, 85623, 300, 2]   \n",
       "\n",
       "         n_words  rank  \\\n",
       "2911522      208     0   \n",
       "2911521       10     1   \n",
       "2911491      242     2   \n",
       "2911513      242     3   \n",
       "2911520       12     4   \n",
       "2911492       56     5   \n",
       "2911493       26     6   \n",
       "2911494       77     7   \n",
       "2911495       34     8   \n",
       "2911496      110     9   \n",
       "2911497      186    10   \n",
       "2911498       56    11   \n",
       "2911499       14    12   \n",
       "2911525      278    13   \n",
       "2911500      139    14   \n",
       "2911501       43    15   \n",
       "2911502       28    16   \n",
       "2911517        9    17   \n",
       "2911514       47    18   \n",
       "2911503       24    19   \n",
       "2911504      480    20   \n",
       "2911505      271    21   \n",
       "2911523       11    22   \n",
       "2911524       37    23   \n",
       "2911506      232    24   \n",
       "2911519       10    25   \n",
       "2911507      372    26   \n",
       "2911508        9    27   \n",
       "2911509      447    28   \n",
       "2911510       15    29   \n",
       "2911511      213    30   \n",
       "2911512       14    31   \n",
       "2911518        9    32   \n",
       "2911515       10    33   \n",
       "2911516       82    34   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   inpu_ids2  \\\n",
       "2911522  [1, 5388, 7478, 94989, 268, 261, 128001, 128001, 329, 269, 312, 362, 2027, 267, 4219, 89061, 261, 273, 338, 334, 264, 752, 312, 1218, 277, 262, 18961, 16925, 6712, 1682, 2027, 260, 128001, 573, 1218, 267, 90974, 415, 268, 294, 128001, 1124, 2891, 39170, 1628, 2634, 128001, 1124, 2891, 16265, 264, 2184, 262, 1040, 128001, 1124, 2891, 1898, 91547, 268, 264, 24906, 262, 12438, 264, 1843, 360, 25335, 128001, 1124, 2891, 262, 38251, 13329, 51708, 1371, 283, 262, 12438, 269, 32147, 260, 128001, 12...   \n",
       "2911521                                                                                                                                                                                                                                                                                                                                                                                                                                                                [1, 953, 1124, 1225, 60098, 510, 7296, 1225, 1225, 2]   \n",
       "2911491  [1, 6306, 67927, 283, 845, 407, 128001, 6306, 36221, 11751, 283, 76767, 128001, 6306, 8358, 33918, 14434, 260, 11751, 33918, 283, 28944, 297, 128001, 6306, 2673, 268, 128001, 292, 33566, 29274, 260, 19928, 616, 57907, 6306, 38251, 13329, 51708, 1371, 128001, 6306, 2164, 6107, 283, 41339, 268, 128001, 6306, 74883, 128001, 6306, 37821, 445, 128001, 128001, 6306, 55919, 14068, 283, 78191, 128001, 292, 55919, 14068, 260, 8285, 1628, 6306, 1836, 261, 4974, 261, 430, 87386, 46580, 261, 34020, 4322...   \n",
       "2911513  [1, 18961, 16925, 2423, 281, 266, 2241, 1271, 265, 2927, 261, 8525, 261, 263, 9571, 260, 672, 261, 262, 2192, 265, 1688, 64804, 268, 263, 45781, 26429, 77462, 54787, 281, 262, 852, 26810, 267, 66351, 2423, 319, 2642, 359, 857, 4003, 260, 606, 1688, 64804, 268, 263, 7290, 8312, 265, 66351, 2423, 1138, 847, 4253, 2719, 277, 262, 4003, 674, 260, 420, 8804, 4253, 281, 852, 2175, 265, 1970, 10474, 260, 559, 262, 408, 265, 514, 1693, 261, 278, 372, 282, 628, 264, 2313, 1019, 4253, 324, 306, 295, 2...   \n",
       "2911520                                                                                                                                                                                                                                                                                                                                                                                                                                                   [1, 953, 1124, 1225, 15006, 6207, 263, 1148, 10945, 1225, 1225, 2]   \n",
       "2911492                                                                                                                                                                                  [1, 2184, 616, 15428, 616, 14035, 1510, 309, 260, 260, 320, 42177, 320, 21783, 268, 16925, 271, 22334, 271, 58272, 271, 79642, 320, 23822, 616, 24227, 320, 309, 128001, 2184, 616, 32392, 616, 14035, 1510, 309, 260, 260, 320, 42177, 320, 21783, 268, 16925, 271, 22334, 271, 58272, 271, 79642, 320, 23822, 260, 76413, 309, 2]   \n",
       "2911493                                                                                                                                                                                                                                                                                                                                                                 [1, 2184, 616, 32392, 1510, 39871, 260, 8523, 616, 76413, 555, 23822, 616, 32392, 616, 14035, 285, 128001, 2184, 616, 32392, 260, 5563, 555, 285, 2]   \n",
       "2911494                                                             [1, 275, 615, 555, 309, 260, 260, 320, 42177, 320, 21783, 268, 16925, 271, 22334, 271, 58272, 271, 79642, 320, 25289, 616, 22062, 616, 725, 616, 58272, 616, 14727, 260, 50574, 309, 285, 283, 1092, 294, 128001, 2269, 616, 58348, 1842, 74883, 260, 61373, 555, 13093, 260, 8523, 555, 285, 285, 128001, 2269, 616, 58348, 1842, 13856, 17925, 555, 1165, 285, 877, 1942, 270, 4219, 261, 1942, 267, 2269, 616, 58348, 260, 55735, 555, 285, 14986, 2]   \n",
       "2911495                                                                                                                                                                                                                                                                                                                    [1, 2184, 616, 32392, 2550, 309, 16264, 309, 592, 1510, 23822, 616, 32392, 2550, 309, 25289, 309, 592, 260, 14727, 555, 14727, 616, 58348, 285, 128001, 2184, 616, 32392, 260, 5563, 555, 285, 2]   \n",
       "2911496  [1, 41339, 268, 260, 6207, 555, 19637, 1510, 19976, 280, 22971, 260, 30134, 7283, 280, 294, 555, 804, 261, 554, 285, 14986, 285, 128001, 41339, 268, 260, 6207, 616, 4602, 555, 280, 7551, 25549, 280, 285, 128001, 128001, 17632, 1510, 268, 7565, 260, 21036, 33918, 555, 608, 1510, 309, 16264, 309, 261, 9832, 1510, 23822, 616, 32392, 261, 15151, 8583, 1510, 280, 109289, 280, 285, 128001, 28944, 297, 260, 982, 25289, 555, 309, 16264, 1110, 265, 2423, 309, 261, 35557, 7283, 1510, 1435, 285, 128001...   \n",
       "2911497  [1, 23097, 18438, 555, 15428, 616, 26657, 261, 6768, 285, 294, 128001, 28944, 297, 260, 22971, 555, 30134, 7283, 1510, 555, 1984, 261, 621, 285, 285, 128001, 270, 267, 407, 261, 287, 15428, 616, 4765, 261, 3734, 285, 267, 71955, 555, 21550, 555, 15428, 616, 26657, 261, 6768, 285, 285, 294, 128001, 28944, 297, 260, 12109, 33918, 555, 554, 261, 453, 261, 267, 407, 1566, 376, 285, 128001, 1115, 1842, 37821, 445, 260, 6263, 8523, 555, 3603, 260, 14035, 260, 46901, 555, 309, 260, 260, 320, 42177,...   \n",
       "2911498                                                                                                                                                                                [1, 2184, 616, 32392, 435, 1510, 23822, 616, 32392, 260, 26154, 555, 804, 285, 128001, 1115, 616, 26657, 1842, 2184, 616, 32392, 435, 2550, 309, 15428, 616, 4765, 309, 592, 260, 41801, 128001, 6768, 1842, 2184, 616, 32392, 435, 2550, 309, 16264, 309, 592, 260, 41801, 128001, 18438, 555, 15428, 616, 26657, 261, 6768, 285, 2]   \n",
       "2911499                                                                                                                                                                                                                                                                                                                                                                                                                                          [1, 2184, 616, 32392, 260, 25289, 260, 11651, 616, 21036, 268, 555, 285, 2]   \n",
       "2911525  [1, 463, 274, 295, 6695, 261, 279, 514, 487, 269, 32147, 275, 262, 1705, 496, 265, 3894, 270, 3734, 404, 261, 18961, 16925, 94798, 6504, 9384, 287, 105211, 285, 261, 263, 262, 51156, 496, 265, 3894, 270, 3734, 767, 261, 18961, 16925, 66630, 86389, 287, 711, 15416, 285, 260, 502, 360, 488, 291, 301, 380, 38251, 13329, 1301, 10945, 264, 3671, 262, 12438, 270, 838, 263, 10872, 264, 807, 262, 876, 265, 262, 1040, 260, 128001, 128001, 279, 1042, 3017, 269, 283, 3832, 294, 128001, 376, 260, 60749,...   \n",
       "2911500  [1, 23097, 91597, 616, 673, 10945, 555, 23822, 616, 32392, 261, 673, 616, 43483, 285, 294, 128001, 2184, 616, 32392, 260, 28372, 2550, 294, 261, 309, 1165, 10945, 309, 592, 1510, 271, 435, 128001, 2184, 616, 32392, 1510, 23822, 616, 32392, 260, 26154, 555, 71074, 1510, 435, 285, 260, 68584, 616, 13915, 555, 17915, 1510, 35733, 285, 128001, 9937, 1510, 95232, 13329, 51708, 1371, 555, 673, 616, 43483, 268, 1510, 673, 616, 43483, 285, 128001, 2982, 1510, 23822, 616, 32392, 260, 25289, 260, 4180...   \n",
       "2911501                                                                                                                                                                                                                                                                 [1, 2184, 616, 32392, 260, 25289, 1510, 23822, 616, 32392, 260, 25289, 260, 1628, 5967, 555, 309, 22889, 309, 285, 128001, 953, 98936, 262, 3734, 264, 25275, 283, 301, 296, 282, 478, 48301, 1943, 33631, 283, 1265, 1571, 264, 2184, 262, 1040, 2]   \n",
       "2911502                                                                                                                                                                                                                                                                                                                                                       [1, 2184, 616, 32392, 1510, 66937, 297, 616, 673, 10945, 555, 23822, 616, 32392, 261, 524, 285, 128001, 2184, 616, 32392, 260, 5563, 555, 524, 285, 128001, 2]   \n",
       "2911517                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [1, 953, 1124, 1225, 32995, 78863, 1225, 1225, 2]   \n",
       "2911514                                                                                                                                                                                                                                             [1, 4439, 31306, 268, 269, 619, 275, 262, 408, 265, 262, 2634, 15821, 91547, 390, 462, 4439, 15006, 117384, 260, 345, 296, 380, 266, 1637, 650, 4439, 15006, 32995, 59423, 287, 20085, 264, 96509, 68738, 70935, 288, 55346, 285, 272, 1279, 381, 264, 333, 291, 260, 2]   \n",
       "2911503                                                                                                                                                                                                                                                                                                                                                                          [1, 1084, 70415, 2625, 25182, 1186, 13229, 294, 320, 320, 45552, 260, 549, 320, 358, 68151, 6586, 7654, 320, 23791, 15006, 32995, 59423, 2]   \n",
       "2911504  [1, 292, 4439, 15006, 32995, 59423, 260, 15428, 616, 9832, 616, 56244, 59423, 6306, 1124, 128001, 6306, 1898, 91547, 268, 283, 336, 128001, 128001, 953, 31306, 268, 3504, 292, 294, 3597, 294, 320, 320, 1965, 260, 1165, 89061, 260, 549, 320, 19491, 89675, 4649, 2573, 320, 11751, 96443, 271, 16454, 3163, 271, 113395, 271, 23822, 271, 10832, 271, 56244, 128001, 2184, 616, 56244, 1842, 1898, 91547, 268, 260, 30988, 17619, 555, 2550, 128001, 1898, 91547, 268, 260, 72388, 5396, 6545, 711, 52823, 5...   \n",
       "2911505  [1, 23097, 2184, 616, 68890, 555, 23822, 261, 70946, 261, 54847, 616, 7283, 261, 15428, 616, 7283, 285, 294, 128001, 128001, 514, 7073, 616, 23822, 1842, 4439, 15006, 32995, 59423, 555, 56244, 4572, 1510, 23822, 616, 56244, 285, 128001, 514, 7073, 616, 14206, 1842, 4439, 15006, 32995, 59423, 555, 56244, 4572, 1510, 70946, 616, 56244, 285, 128001, 2184, 616, 68890, 1842, 514, 7073, 616, 23822, 260, 14068, 616, 5117, 616, 9832, 16439, 555, 9832, 16439, 1510, 23822, 261, 128001, 5514, 1510, 238...   \n",
       "2911523                                                                                                                                                                                                                                                                                                                                                                                                                                                          [1, 953, 1124, 1225, 46301, 5152, 262, 1040, 1225, 1225, 2]   \n",
       "2911524                                                                                                                                                                                                                                                                                                             [1, 345, 296, 380, 262, 1477, 56237, 3781, 264, 2184, 262, 1040, 260, 502, 623, 310, 314, 291, 3781, 3886, 3597, 294, 320, 320, 3260, 70707, 260, 2083, 320, 58032, 320, 1984, 894, 260, 4159, 34805, 2]   \n",
       "2911506  [1, 23097, 365, 616, 19928, 555, 100417, 616, 92921, 285, 294, 128001, 1436, 616, 19928, 1842, 1477, 56237, 555, 42177, 616, 29753, 1842, 287, 100417, 616, 92921, 261, 55699, 616, 92921, 261, 404, 285, 261, 680, 616, 6500, 1842, 21333, 261, 128001, 12355, 1842, 382, 15428, 3163, 280, 285, 128001, 1204, 1842, 1436, 616, 19928, 260, 35055, 128001, 1204, 1842, 2974, 94222, 48910, 510, 445, 691, 555, 285, 555, 982, 285, 128001, 1204, 1842, 10577, 2355, 555, 693, 260, 508, 285, 555, 982, 285, 128...   \n",
       "2911519                                                                                                                                                                                                                                                                                                                                                                                                                                                                [1, 953, 1124, 1225, 59089, 262, 1040, 1225, 1225, 2]   \n",
       "2911507  [1, 23097, 684, 616, 23822, 555, 32392, 261, 54847, 616, 7283, 261, 15428, 616, 7283, 261, 10945, 285, 294, 128001, 128001, 2184, 1510, 32392, 2550, 32392, 260, 1165, 10945, 300, 1510, 10945, 592, 260, 68584, 616, 13915, 555, 17915, 1510, 35733, 285, 128001, 3816, 1510, 32392, 2550, 32392, 260, 1165, 10945, 1510, 1510, 10945, 592, 260, 68584, 616, 13915, 555, 17915, 1510, 35733, 285, 128001, 128001, 2184, 616, 7073, 261, 14206, 616, 7073, 1510, 2184, 616, 68890, 555, 23822, 261, 70946, 261, ...   \n",
       "2911508                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [1, 2673, 1580, 616, 46708, 1510, 2550, 592, 2]   \n",
       "2911509  [1, 270, 584, 267, 778, 555, 524, 285, 294, 128001, 2118, 555, 1883, 1225, 309, 271, 309, 285, 128001, 2118, 555, 1892, 280, 19976, 667, 14986, 271, 10945, 838, 280, 285, 128001, 2118, 555, 1883, 1225, 309, 271, 309, 285, 128001, 128001, 1040, 261, 27850, 261, 23822, 616, 7073, 261, 26520, 616, 7073, 1842, 684, 616, 23822, 555, 23822, 616, 32392, 261, 1984, 261, 4320, 261, 667, 285, 128001, 128001, 2184, 616, 46708, 1842, 820, 260, 27850, 2550, 280, 60336, 12292, 616, 111452, 280, 592, 12800...   \n",
       "2911510                                                                                                                                                                                                                                                                                                                                                                                                                                   [1, 2118, 555, 48221, 260, 28431, 555, 795, 1580, 616, 46708, 285, 285, 128001, 2]   \n",
       "2911511  [1, 292, 33566, 29274, 260, 56282, 6306, 6803, 616, 53195, 261, 9209, 616, 27551, 128001, 128001, 1348, 407, 1842, 1040, 260, 57796, 616, 68890, 555, 14206, 616, 7073, 285, 953, 36203, 938, 30717, 128001, 1348, 407, 1842, 76767, 260, 6494, 555, 9894, 407, 285, 953, 36203, 311, 271, 10069, 23717, 2141, 128001, 1348, 407, 1842, 76767, 260, 52183, 10537, 555, 9894, 407, 261, 10558, 1842, 376, 285, 953, 36203, 938, 6768, 128001, 128001, 953, 34485, 1854, 6768, 128001, 1854, 1842, 26520, 616, 707...   \n",
       "2911512                                                                                                                                                                                                                                                                                                                                                                                                                                           [1, 2118, 555, 79642, 616, 27551, 555, 41841, 261, 9894, 407, 285, 285, 2]   \n",
       "2911518                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [1, 1124, 1225, 22625, 2978, 2201, 1225, 1225, 2]   \n",
       "2911515                                                                                                                                                                                                                                                                                                                                                                                                                                                             [1, 953, 1124, 1225, 23553, 52397, 16850, 1225, 1225, 2]   \n",
       "2911516                            [1, 879, 4528, 272, 387, 2441, 282, 412, 294, 128001, 128001, 376, 260, 4439, 31306, 287, 13691, 1174, 20260, 965, 260, 285, 128001, 392, 260, 9339, 1101, 1039, 263, 1101, 1039, 2093, 128001, 404, 260, 2891, 71813, 264, 4843, 262, 838, 326, 128001, 453, 260, 21772, 3210, 884, 128001, 456, 260, 2373, 310, 9854, 4974, 263, 1481, 4820, 128001, 525, 260, 2891, 340, 30805, 405, 283, 29230, 9923, 128001, 128001, 369, 291, 12452, 1666, 274, 261, 811, 1021, 299, 85623, 300, 2]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  input_ids2  \n",
       "2911522  [1, 5388, 7478, 94989, 268, 261, 128001, 128001, 329, 269, 312, 362, 2027, 267, 4219, 89061, 261, 273, 338, 334, 264, 752, 312, 1218, 277, 262, 18961, 16925, 6712, 1682, 2027, 260, 128001, 573, 1218, 267, 90974, 415, 268, 294, 128001, 1124, 2891, 39170, 1628, 2634, 128001, 1124, 2891, 16265, 264, 2184, 262, 1040, 128001, 1124, 2891, 1898, 91547, 268, 264, 24906, 262, 12438, 264, 1843, 360, 25335, 128001, 1124, 2891, 262, 38251, 13329, 51708, 1371, 283, 262, 12438, 269, 32147, 260, 128001, 12...  \n",
       "2911521                                                                                                                                                                                                                                                                                                                                                                                                                                                                [1, 953, 1124, 1225, 60098, 510, 7296, 1225, 1225, 2]  \n",
       "2911491  [1, 6306, 67927, 283, 845, 407, 128001, 6306, 36221, 11751, 283, 76767, 128001, 6306, 8358, 33918, 14434, 260, 11751, 33918, 283, 28944, 297, 128001, 6306, 2673, 268, 128001, 292, 33566, 29274, 260, 19928, 616, 57907, 6306, 38251, 13329, 51708, 1371, 128001, 6306, 2164, 6107, 283, 41339, 268, 128001, 6306, 74883, 128001, 6306, 37821, 445, 128001, 128001, 6306, 55919, 14068, 283, 78191, 128001, 292, 55919, 14068, 260, 8285, 1628, 6306, 1836, 261, 4974, 261, 430, 87386, 46580, 261, 34020, 4322...  \n",
       "2911513  [1, 18961, 16925, 2423, 281, 266, 2241, 1271, 265, 2927, 261, 8525, 261, 263, 9571, 260, 672, 261, 262, 2192, 265, 1688, 64804, 268, 263, 45781, 26429, 77462, 54787, 281, 262, 852, 26810, 267, 66351, 2423, 319, 2642, 359, 857, 4003, 260, 606, 1688, 64804, 268, 263, 7290, 8312, 265, 66351, 2423, 1138, 847, 4253, 2719, 277, 262, 4003, 674, 260, 420, 8804, 4253, 281, 852, 2175, 265, 1970, 10474, 260, 559, 262, 408, 265, 514, 1693, 261, 278, 372, 282, 628, 264, 2313, 1019, 4253, 324, 306, 295, 2...  \n",
       "2911520                                                                                                                                                                                                                                                                                                                                                                                                                                                   [1, 953, 1124, 1225, 15006, 6207, 263, 1148, 10945, 1225, 1225, 2]  \n",
       "2911492                                                                                                                                                                                  [1, 2184, 616, 15428, 616, 14035, 1510, 309, 260, 260, 320, 42177, 320, 21783, 268, 16925, 271, 22334, 271, 58272, 271, 79642, 320, 23822, 616, 24227, 320, 309, 128001, 2184, 616, 32392, 616, 14035, 1510, 309, 260, 260, 320, 42177, 320, 21783, 268, 16925, 271, 22334, 271, 58272, 271, 79642, 320, 23822, 260, 76413, 309, 2]  \n",
       "2911493                                                                                                                                                                                                                                                                                                                                                                 [1, 2184, 616, 32392, 1510, 39871, 260, 8523, 616, 76413, 555, 23822, 616, 32392, 616, 14035, 285, 128001, 2184, 616, 32392, 260, 5563, 555, 285, 2]  \n",
       "2911494                                                             [1, 275, 615, 555, 309, 260, 260, 320, 42177, 320, 21783, 268, 16925, 271, 22334, 271, 58272, 271, 79642, 320, 25289, 616, 22062, 616, 725, 616, 58272, 616, 14727, 260, 50574, 309, 285, 283, 1092, 294, 128001, 2269, 616, 58348, 1842, 74883, 260, 61373, 555, 13093, 260, 8523, 555, 285, 285, 128001, 2269, 616, 58348, 1842, 13856, 17925, 555, 1165, 285, 877, 1942, 270, 4219, 261, 1942, 267, 2269, 616, 58348, 260, 55735, 555, 285, 14986, 2]  \n",
       "2911495                                                                                                                                                                                                                                                                                                                    [1, 2184, 616, 32392, 2550, 309, 16264, 309, 592, 1510, 23822, 616, 32392, 2550, 309, 25289, 309, 592, 260, 14727, 555, 14727, 616, 58348, 285, 128001, 2184, 616, 32392, 260, 5563, 555, 285, 2]  \n",
       "2911496  [1, 41339, 268, 260, 6207, 555, 19637, 1510, 19976, 280, 22971, 260, 30134, 7283, 280, 294, 555, 804, 261, 554, 285, 14986, 285, 128001, 41339, 268, 260, 6207, 616, 4602, 555, 280, 7551, 25549, 280, 285, 128001, 128001, 17632, 1510, 268, 7565, 260, 21036, 33918, 555, 608, 1510, 309, 16264, 309, 261, 9832, 1510, 23822, 616, 32392, 261, 15151, 8583, 1510, 280, 109289, 280, 285, 128001, 28944, 297, 260, 982, 25289, 555, 309, 16264, 1110, 265, 2423, 309, 261, 35557, 7283, 1510, 1435, 285, 128001...  \n",
       "2911497  [1, 23097, 18438, 555, 15428, 616, 26657, 261, 6768, 285, 294, 128001, 28944, 297, 260, 22971, 555, 30134, 7283, 1510, 555, 1984, 261, 621, 285, 285, 128001, 270, 267, 407, 261, 287, 15428, 616, 4765, 261, 3734, 285, 267, 71955, 555, 21550, 555, 15428, 616, 26657, 261, 6768, 285, 285, 294, 128001, 28944, 297, 260, 12109, 33918, 555, 554, 261, 453, 261, 267, 407, 1566, 376, 285, 128001, 1115, 1842, 37821, 445, 260, 6263, 8523, 555, 3603, 260, 14035, 260, 46901, 555, 309, 260, 260, 320, 42177,...  \n",
       "2911498                                                                                                                                                                                [1, 2184, 616, 32392, 435, 1510, 23822, 616, 32392, 260, 26154, 555, 804, 285, 128001, 1115, 616, 26657, 1842, 2184, 616, 32392, 435, 2550, 309, 15428, 616, 4765, 309, 592, 260, 41801, 128001, 6768, 1842, 2184, 616, 32392, 435, 2550, 309, 16264, 309, 592, 260, 41801, 128001, 18438, 555, 15428, 616, 26657, 261, 6768, 285, 2]  \n",
       "2911499                                                                                                                                                                                                                                                                                                                                                                                                                                          [1, 2184, 616, 32392, 260, 25289, 260, 11651, 616, 21036, 268, 555, 285, 2]  \n",
       "2911525  [1, 463, 274, 295, 6695, 261, 279, 514, 487, 269, 32147, 275, 262, 1705, 496, 265, 3894, 270, 3734, 404, 261, 18961, 16925, 94798, 6504, 9384, 287, 105211, 285, 261, 263, 262, 51156, 496, 265, 3894, 270, 3734, 767, 261, 18961, 16925, 66630, 86389, 287, 711, 15416, 285, 260, 502, 360, 488, 291, 301, 380, 38251, 13329, 1301, 10945, 264, 3671, 262, 12438, 270, 838, 263, 10872, 264, 807, 262, 876, 265, 262, 1040, 260, 128001, 128001, 279, 1042, 3017, 269, 283, 3832, 294, 128001, 376, 260, 60749,...  \n",
       "2911500  [1, 23097, 91597, 616, 673, 10945, 555, 23822, 616, 32392, 261, 673, 616, 43483, 285, 294, 128001, 2184, 616, 32392, 260, 28372, 2550, 294, 261, 309, 1165, 10945, 309, 592, 1510, 271, 435, 128001, 2184, 616, 32392, 1510, 23822, 616, 32392, 260, 26154, 555, 71074, 1510, 435, 285, 260, 68584, 616, 13915, 555, 17915, 1510, 35733, 285, 128001, 9937, 1510, 95232, 13329, 51708, 1371, 555, 673, 616, 43483, 268, 1510, 673, 616, 43483, 285, 128001, 2982, 1510, 23822, 616, 32392, 260, 25289, 260, 4180...  \n",
       "2911501                                                                                                                                                                                                                                                                 [1, 2184, 616, 32392, 260, 25289, 1510, 23822, 616, 32392, 260, 25289, 260, 1628, 5967, 555, 309, 22889, 309, 285, 128001, 953, 98936, 262, 3734, 264, 25275, 283, 301, 296, 282, 478, 48301, 1943, 33631, 283, 1265, 1571, 264, 2184, 262, 1040, 2]  \n",
       "2911502                                                                                                                                                                                                                                                                                                                                                       [1, 2184, 616, 32392, 1510, 66937, 297, 616, 673, 10945, 555, 23822, 616, 32392, 261, 524, 285, 128001, 2184, 616, 32392, 260, 5563, 555, 524, 285, 128001, 2]  \n",
       "2911517                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [1, 953, 1124, 1225, 32995, 78863, 1225, 1225, 2]  \n",
       "2911514                                                                                                                                                                                                                                             [1, 4439, 31306, 268, 269, 619, 275, 262, 408, 265, 262, 2634, 15821, 91547, 390, 462, 4439, 15006, 117384, 260, 345, 296, 380, 266, 1637, 650, 4439, 15006, 32995, 59423, 287, 20085, 264, 96509, 68738, 70935, 288, 55346, 285, 272, 1279, 381, 264, 333, 291, 260, 2]  \n",
       "2911503                                                                                                                                                                                                                                                                                                                                                                          [1, 1084, 70415, 2625, 25182, 1186, 13229, 294, 320, 320, 45552, 260, 549, 320, 358, 68151, 6586, 7654, 320, 23791, 15006, 32995, 59423, 2]  \n",
       "2911504  [1, 292, 4439, 15006, 32995, 59423, 260, 15428, 616, 9832, 616, 56244, 59423, 6306, 1124, 128001, 6306, 1898, 91547, 268, 283, 336, 128001, 128001, 953, 31306, 268, 3504, 292, 294, 3597, 294, 320, 320, 1965, 260, 1165, 89061, 260, 549, 320, 19491, 89675, 4649, 2573, 320, 11751, 96443, 271, 16454, 3163, 271, 113395, 271, 23822, 271, 10832, 271, 56244, 128001, 2184, 616, 56244, 1842, 1898, 91547, 268, 260, 30988, 17619, 555, 2550, 128001, 1898, 91547, 268, 260, 72388, 5396, 6545, 711, 52823, 5...  \n",
       "2911505  [1, 23097, 2184, 616, 68890, 555, 23822, 261, 70946, 261, 54847, 616, 7283, 261, 15428, 616, 7283, 285, 294, 128001, 128001, 514, 7073, 616, 23822, 1842, 4439, 15006, 32995, 59423, 555, 56244, 4572, 1510, 23822, 616, 56244, 285, 128001, 514, 7073, 616, 14206, 1842, 4439, 15006, 32995, 59423, 555, 56244, 4572, 1510, 70946, 616, 56244, 285, 128001, 2184, 616, 68890, 1842, 514, 7073, 616, 23822, 260, 14068, 616, 5117, 616, 9832, 16439, 555, 9832, 16439, 1510, 23822, 261, 128001, 5514, 1510, 238...  \n",
       "2911523                                                                                                                                                                                                                                                                                                                                                                                                                                                          [1, 953, 1124, 1225, 46301, 5152, 262, 1040, 1225, 1225, 2]  \n",
       "2911524                                                                                                                                                                                                                                                                                                             [1, 345, 296, 380, 262, 1477, 56237, 3781, 264, 2184, 262, 1040, 260, 502, 623, 310, 314, 291, 3781, 3886, 3597, 294, 320, 320, 3260, 70707, 260, 2083, 320, 58032, 320, 1984, 894, 260, 4159, 34805, 2]  \n",
       "2911506  [1, 23097, 365, 616, 19928, 555, 100417, 616, 92921, 285, 294, 128001, 1436, 616, 19928, 1842, 1477, 56237, 555, 42177, 616, 29753, 1842, 287, 100417, 616, 92921, 261, 55699, 616, 92921, 261, 404, 285, 261, 680, 616, 6500, 1842, 21333, 261, 128001, 12355, 1842, 382, 15428, 3163, 280, 285, 128001, 1204, 1842, 1436, 616, 19928, 260, 35055, 128001, 1204, 1842, 2974, 94222, 48910, 510, 445, 691, 555, 285, 555, 982, 285, 128001, 1204, 1842, 10577, 2355, 555, 693, 260, 508, 285, 555, 982, 285, 128...  \n",
       "2911519                                                                                                                                                                                                                                                                                                                                                                                                                                                                [1, 953, 1124, 1225, 59089, 262, 1040, 1225, 1225, 2]  \n",
       "2911507  [1, 23097, 684, 616, 23822, 555, 32392, 261, 54847, 616, 7283, 261, 15428, 616, 7283, 261, 10945, 285, 294, 128001, 128001, 2184, 1510, 32392, 2550, 32392, 260, 1165, 10945, 300, 1510, 10945, 592, 260, 68584, 616, 13915, 555, 17915, 1510, 35733, 285, 128001, 3816, 1510, 32392, 2550, 32392, 260, 1165, 10945, 1510, 1510, 10945, 592, 260, 68584, 616, 13915, 555, 17915, 1510, 35733, 285, 128001, 128001, 2184, 616, 7073, 261, 14206, 616, 7073, 1510, 2184, 616, 68890, 555, 23822, 261, 70946, 261, ...  \n",
       "2911508                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [1, 2673, 1580, 616, 46708, 1510, 2550, 592, 2]  \n",
       "2911509  [1, 270, 584, 267, 778, 555, 524, 285, 294, 128001, 2118, 555, 1883, 1225, 309, 271, 309, 285, 128001, 2118, 555, 1892, 280, 19976, 667, 14986, 271, 10945, 838, 280, 285, 128001, 2118, 555, 1883, 1225, 309, 271, 309, 285, 128001, 128001, 1040, 261, 27850, 261, 23822, 616, 7073, 261, 26520, 616, 7073, 1842, 684, 616, 23822, 555, 23822, 616, 32392, 261, 1984, 261, 4320, 261, 667, 285, 128001, 128001, 2184, 616, 46708, 1842, 820, 260, 27850, 2550, 280, 60336, 12292, 616, 111452, 280, 592, 12800...  \n",
       "2911510                                                                                                                                                                                                                                                                                                                                                                                                                                   [1, 2118, 555, 48221, 260, 28431, 555, 795, 1580, 616, 46708, 285, 285, 128001, 2]  \n",
       "2911511  [1, 292, 33566, 29274, 260, 56282, 6306, 6803, 616, 53195, 261, 9209, 616, 27551, 128001, 128001, 1348, 407, 1842, 1040, 260, 57796, 616, 68890, 555, 14206, 616, 7073, 285, 953, 36203, 938, 30717, 128001, 1348, 407, 1842, 76767, 260, 6494, 555, 9894, 407, 285, 953, 36203, 311, 271, 10069, 23717, 2141, 128001, 1348, 407, 1842, 76767, 260, 52183, 10537, 555, 9894, 407, 261, 10558, 1842, 376, 285, 953, 36203, 938, 6768, 128001, 128001, 953, 34485, 1854, 6768, 128001, 1854, 1842, 26520, 616, 707...  \n",
       "2911512                                                                                                                                                                                                                                                                                                                                                                                                                                           [1, 2118, 555, 79642, 616, 27551, 555, 41841, 261, 9894, 407, 285, 285, 2]  \n",
       "2911518                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [1, 1124, 1225, 22625, 2978, 2201, 1225, 1225, 2]  \n",
       "2911515                                                                                                                                                                                                                                                                                                                                                                                                                                                             [1, 953, 1124, 1225, 23553, 52397, 16850, 1225, 1225, 2]  \n",
       "2911516                            [1, 879, 4528, 272, 387, 2441, 282, 412, 294, 128001, 128001, 376, 260, 4439, 31306, 287, 13691, 1174, 20260, 965, 260, 285, 128001, 392, 260, 9339, 1101, 1039, 263, 1101, 1039, 2093, 128001, 404, 260, 2891, 71813, 264, 4843, 262, 838, 326, 128001, 453, 260, 21772, 3210, 884, 128001, 456, 260, 2373, 310, 9854, 4974, 263, 1481, 4820, 128001, 525, 260, 2891, 340, 30805, 405, 283, 29230, 9923, 128001, 128001, 369, 291, 12452, 1666, 274, 261, 811, 1021, 299, 85623, 300, 2]  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.id==ids[102]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ddfd239c</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np # linear algebraʶimport pandas as pd # data processing,ʶimport matplotlib.pyplot as pltʶfrom sklearn.decomposition import PCAʶfrom sklearn.preprocessing import StandardScalerʶfrom sklearn.preprocessing import scaleʶfrom sklearn.impute import SimpleImputerʶʶʶimport osʶfor dirname, _, filenames in os.walk('/kaggle/input'):ʶ    for filename in filenames:ʶ        print(os.path.join(dirname, filename))</td>\n",
       "      <td>0009d135ece78d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c6cd22db</td>\n",
       "      <td>code</td>\n",
       "      <td>df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')ʶdf</td>\n",
       "      <td>0009d135ece78d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1372ae9b</td>\n",
       "      <td>code</td>\n",
       "      <td>numerical_data = df.loc[:, ~df.columns.isin(['id', \"diagnosis\"])]ʶʶlabels = df[\"diagnosis\"].factorize(['B','M'])[0]ʶʶheader_labels = pd.DataFrame(data=labels, columns=[\"diagnosis\"])</td>\n",
       "      <td>0009d135ece78d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90ed07ab</td>\n",
       "      <td>code</td>\n",
       "      <td>def comparison_plot_maker(data_1, data_2, name, column_name_1, column_name_2):ʶ    # Scaling Data for testingʶ    # data_1 = scale(data_1)ʶ    # data_2 = scale(data_2)ʶʶ    range =  np.random.randn(len(data_1))ʶ    plt.scatter(range, data_1, label=column_name_1, color='orange')ʶ    plt.scatter(range, data_2, label=column_name_2, color='green')ʶ    plt.title(name)ʶ    plt.xlabel('X-Axis')ʶ    plt.ylabel('Y-Axis')ʶ    plt.legend()ʶ    plt.show()ʶ</td>\n",
       "      <td>0009d135ece78d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7f388a41</td>\n",
       "      <td>code</td>\n",
       "      <td># Ploting data with different columnsʶ#####################################ʶcomparison_plot_maker(numerical_data[\"radius_mean\"], numerical_data[\"radius_worst\"], \"Mean Radius vs Worst Radius\", \"Mean Radius\", \"Worst Radius\")ʶcomparison_plot_maker(numerical_data[\"perimeter_se\"], numerical_data[\"perimeter_worst\"], \"S.D Perimeter vs Worst Perimeter\", \"S.D Perimeter\", \"Worst Perimeter\")ʶcomparison_plot_maker(numerical_data[\"compactness_mean\"], numerical_data[\"compactness_se\"], \"Mean Compactness vs...</td>\n",
       "      <td>0009d135ece78d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2843a25a</td>\n",
       "      <td>code</td>\n",
       "      <td># Scaling Dataʶscaler = StandardScaler()ʶscaler.fit(numerical_data)ʶ# print(scaled_data)ʶʶ# Assigning VariablesʶX = scaler.transform(numerical_data)ʶy = labelsʶʶmy_imputer = SimpleImputer()ʶpd.DataFrame(X).fillna(0)ʶX = my_imputer.fit_transform(X)ʶʶprint(\"Ignore the errors, they occurred because of NaN values\")ʶprint()ʶprint(\"But worry not human! The errors are fixed with Imputer &gt;o&gt;\")ʶprint()</td>\n",
       "      <td>0009d135ece78d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>06dbf8cf</td>\n",
       "      <td>code</td>\n",
       "      <td># 3. Implementing PCA on X (green for benign; red for malignant)ʶ################################################################ʶʶ# PCAʶPCA3=PCA(n_components=2)ʶ# print(X.shape)ʶPCA3.fit(X)ʶXPCA = PCA3.transform(X)ʶ# print(XPCA.shape)ʶʶ# Plottingʶplt.figure()ʶplt.title(\"PCA\")ʶplt.xlabel('X-Axis')ʶplt.ylabel('Y-Axis')ʶʶplt.plot(XPCA[y==0,0],XPCA[y==0,1],'g.')ʶplt.plot(XPCA[y==1,0],XPCA[y==1,1],'r.')ʶʶplt.show()</td>\n",
       "      <td>0009d135ece78d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>f9893819</td>\n",
       "      <td>markdown</td>\n",
       "      <td># Scaling Data ⚖ʶLet's scale the data so PCA can be applied</td>\n",
       "      <td>0009d135ece78d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ba55e576</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Testing Plots &gt;w&gt;ʶLet's these mystery soliving plots! :O</td>\n",
       "      <td>0009d135ece78d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39e937ec</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Plotting PCA 📊ʶThus, the sun boils down to this, the PCA is hence plotted 😮</td>\n",
       "      <td>0009d135ece78d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cell_id cell_type  \\\n",
       "0  ddfd239c      code   \n",
       "1  c6cd22db      code   \n",
       "2  1372ae9b      code   \n",
       "3  90ed07ab      code   \n",
       "4  7f388a41      code   \n",
       "5  2843a25a      code   \n",
       "6  06dbf8cf      code   \n",
       "7  f9893819  markdown   \n",
       "8  ba55e576  markdown   \n",
       "9  39e937ec  markdown   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                source  \\\n",
       "0                                                                                  import numpy as np # linear algebraʶimport pandas as pd # data processing,ʶimport matplotlib.pyplot as pltʶfrom sklearn.decomposition import PCAʶfrom sklearn.preprocessing import StandardScalerʶfrom sklearn.preprocessing import scaleʶfrom sklearn.impute import SimpleImputerʶʶʶimport osʶfor dirname, _, filenames in os.walk('/kaggle/input'):ʶ    for filename in filenames:ʶ        print(os.path.join(dirname, filename))   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                           df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')ʶdf   \n",
       "2                                                                                                                                                                                                                                                                                                                                numerical_data = df.loc[:, ~df.columns.isin(['id', \"diagnosis\"])]ʶʶlabels = df[\"diagnosis\"].factorize(['B','M'])[0]ʶʶheader_labels = pd.DataFrame(data=labels, columns=[\"diagnosis\"])   \n",
       "3                                                def comparison_plot_maker(data_1, data_2, name, column_name_1, column_name_2):ʶ    # Scaling Data for testingʶ    # data_1 = scale(data_1)ʶ    # data_2 = scale(data_2)ʶʶ    range =  np.random.randn(len(data_1))ʶ    plt.scatter(range, data_1, label=column_name_1, color='orange')ʶ    plt.scatter(range, data_2, label=column_name_2, color='green')ʶ    plt.title(name)ʶ    plt.xlabel('X-Axis')ʶ    plt.ylabel('Y-Axis')ʶ    plt.legend()ʶ    plt.show()ʶ        \n",
       "4  # Ploting data with different columnsʶ#####################################ʶcomparison_plot_maker(numerical_data[\"radius_mean\"], numerical_data[\"radius_worst\"], \"Mean Radius vs Worst Radius\", \"Mean Radius\", \"Worst Radius\")ʶcomparison_plot_maker(numerical_data[\"perimeter_se\"], numerical_data[\"perimeter_worst\"], \"S.D Perimeter vs Worst Perimeter\", \"S.D Perimeter\", \"Worst Perimeter\")ʶcomparison_plot_maker(numerical_data[\"compactness_mean\"], numerical_data[\"compactness_se\"], \"Mean Compactness vs...   \n",
       "5                                                                                                         # Scaling Dataʶscaler = StandardScaler()ʶscaler.fit(numerical_data)ʶ# print(scaled_data)ʶʶ# Assigning VariablesʶX = scaler.transform(numerical_data)ʶy = labelsʶʶmy_imputer = SimpleImputer()ʶpd.DataFrame(X).fillna(0)ʶX = my_imputer.fit_transform(X)ʶʶprint(\"Ignore the errors, they occurred because of NaN values\")ʶprint()ʶprint(\"But worry not human! The errors are fixed with Imputer >o>\")ʶprint()   \n",
       "6                                                                                       # 3. Implementing PCA on X (green for benign; red for malignant)ʶ################################################################ʶʶ# PCAʶPCA3=PCA(n_components=2)ʶ# print(X.shape)ʶPCA3.fit(X)ʶXPCA = PCA3.transform(X)ʶ# print(XPCA.shape)ʶʶ# Plottingʶplt.figure()ʶplt.title(\"PCA\")ʶplt.xlabel('X-Axis')ʶplt.ylabel('Y-Axis')ʶʶplt.plot(XPCA[y==0,0],XPCA[y==0,1],'g.')ʶplt.plot(XPCA[y==1,0],XPCA[y==1,1],'r.')ʶʶplt.show()   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                          # Scaling Data ⚖ʶLet's scale the data so PCA can be applied   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                          ## Testing Plots >w>ʶLet's these mystery soliving plots! :O   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                       ## Plotting PCA 📊ʶThus, the sun boils down to this, the PCA is hence plotted 😮   \n",
       "\n",
       "               id  \n",
       "0  0009d135ece78d  \n",
       "1  0009d135ece78d  \n",
       "2  0009d135ece78d  \n",
       "3  0009d135ece78d  \n",
       "4  0009d135ece78d  \n",
       "5  0009d135ece78d  \n",
       "6  0009d135ece78d  \n",
       "7  0009d135ece78d  \n",
       "8  0009d135ece78d  \n",
       "9  0009d135ece78d  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1925003cfa3979ae366740114cfe890bf8d7ad5b88e4afe0ec571fe261ed45e3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
