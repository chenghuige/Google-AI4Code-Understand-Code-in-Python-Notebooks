{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gezi.common import *\n",
    "from gensim.models import Word2Vec\n",
    "sys.path.append('..')\n",
    "gezi.set_pandas()\n",
    "# gezi.set_pandas_widder()\n",
    "from src.config import *\n",
    "gezi.init_flags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = FLAGS.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(folder, workers=80):\n",
    "  def _create_df(fpath):\n",
    "    df = pd.read_json(fpath, dtype={'cell_type': 'category', 'source': 'str'}).reset_index().rename({\"index\":\"cell_id\"}, axis=1)\n",
    "    df[\"id\"] = fpath.rsplit(\".\", 1)[0].rsplit(\"/\", 1)[-1]\n",
    "    return df\n",
    "  dfs = gezi.prun(_create_df, glob.glob(f'{folder}/*.json'), workers)\n",
    "  df = pd.concat(dfs)\n",
    "  df['source'] = df.source.apply(lambda x: x.replace('\\n', BR))\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = 80\n",
    "train_file = f'{FLAGS.root}/train2.fea'\n",
    "if os.path.exists(train_file):\n",
    "  df = pd.read_feather(train_file)\n",
    "else:\n",
    "  df = create_df(f'{FLAGS.root}/train', workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-small')\n",
    "if not 'input_ids' in df.columns:\n",
    "  if tokenizer.convert_tokens_to_ids(BR) == tokenizer.unk_token_id:\n",
    "    assert len(BR) == 1\n",
    "    tokenizer.add_tokens([BR], special_tokens=False)\n",
    "  input_ids_list = gezi.prun(lambda x: tokenizer(x).input_ids, df.source.values, 80, desc='tokenize')\n",
    "  df['input_ids'] = input_ids_list\n",
    "  df['tokens'] = gezi.prun(tokenizer.convert_ids_to_tokens, df.input_ids.values, 80, desc='convert_ids_to_tokens')\n",
    "  df.reset_index().to_feather(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1c7a5a71</td>\n",
       "      <td>code</td>\n",
       "      <td>import warningsʶwarnings.filterwarnings(\"ignore\")ʶʶimport sqlite3ʶimport pandas as pdʶimport numpy as npʶimport nltkʶimport stringʶimport matplotlib.pyplot as pltʶimport seaborn as snsʶfrom sklearn.feature_extraction.text import TfidfTransformerʶfrom sklearn.feature_extraction.text import TfidfVectorizerʶʶfrom sklearn.feature_extraction.text import CountVectorizerʶfrom sklearn.metrics import confusion_matrixʶfrom sklearn import metricsʶfrom sklearn.metrics import roc_curve, aucʶfrom nltk.ste...</td>\n",
       "      <td>a3baf6134c8506</td>\n",
       "      <td>[1, 6306, 11917, 128001, 11917, 260, 28865, 60656, 268, 555, 309, 66478, 309, 285, 128001, 128001, 6306, 120474, 508, 128001, 6306, 67927, 283, 845, 407, 128001, 6306, 36221, 11751, 283, 76767, 128001, 6306, 90668, 39501, 128001, 6306, 4022, 128001, 6306, 8358, 33918, 14434, 260, 11751, 33918, 283, 28944, 297, 128001, 6306, 2164, 6107, 283, 41339, 268, 128001, 292, 33566, 29274, 260, 51532, 616, 113492, 260, 12948, 6306, 897, 59426, 1892, 86911, 649, 128001, 292, 33566, 29274, 260, 51532, 61...</td>\n",
       "      <td>[[CLS], ▁import, ▁warnings, ʶ, ▁warnings, ., filter, warning, s, (, \", ignore, \", ), ʶ, ʶ, ▁import, ▁sqlite, 3, ʶ, ▁import, ▁pandas, ▁as, ▁p, d, ʶ, ▁import, ▁num, py, ▁as, ▁np, ʶ, ▁import, ▁nl, tk, ʶ, ▁import, ▁string, ʶ, ▁import, ▁mat, plot, lib, ., py, plot, ▁as, ▁pl, t, ʶ, ▁import, ▁sea, born, ▁as, ▁sn, s, ʶ, ▁from, ▁sk, learn, ., feature, _, extraction, ., text, ▁import, ▁T, fid, f, Transform, er, ʶ, ▁from, ▁sk, learn, ., feature, _, extraction, ., text, ▁import, ▁T, fid, f, Vector, izer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>68f71f96</td>\n",
       "      <td>code</td>\n",
       "      <td># using the SQLite Table to read data.ʶcon = sqlite3.connect('../input/database.sqlite')ʶ#con = sqlite3.connect('database.sqlite') ʶʶ#filtering only positive and negative reviews i.e. ʶ# not taking into consideration those reviews with Score=3ʶfiltered_data = pd.read_sql_query(\"\"\"SELECT * FROM Reviews WHERE Score != 3 LIMIT 100000\"\"\", con) ʶʶ# Give reviews with Score&gt;3 a positive rating, and reviews with a score&lt;3 a negative rating.ʶdef partition(x):ʶ    if x &lt; 3:ʶ        return 0ʶ    return...</td>\n",
       "      <td>a3baf6134c8506</td>\n",
       "      <td>[1, 953, 478, 262, 78550, 3751, 264, 623, 514, 260, 128001, 4636, 1842, 120474, 508, 260, 30407, 555, 280, 260, 260, 320, 42177, 320, 54698, 260, 51972, 5936, 280, 285, 128001, 953, 5699, 1842, 120474, 508, 260, 30407, 555, 280, 54698, 260, 51972, 5936, 280, 285, 128001, 128001, 953, 28865, 510, 364, 1453, 263, 2330, 1937, 584, 260, 473, 260, 128001, 953, 298, 787, 352, 3937, 421, 1937, 275, 13938, 1510, 508, 128001, 16334, 616, 9832, 1842, 845, 407, 260, 8523, 616, 51972, 616, 47975, 555, 3...</td>\n",
       "      <td>[[CLS], ▁#, ▁using, ▁the, ▁SQLite, ▁Table, ▁to, ▁read, ▁data, ., ʶ, ▁con, ▁=, ▁sqlite, 3, ., connect, (, ', ., ., /, input, /, database, ., sql, ite, ', ), ʶ, ▁#, con, ▁=, ▁sqlite, 3, ., connect, (, ', database, ., sql, ite, ', ), ʶ, ʶ, ▁#, filter, ing, ▁only, ▁positive, ▁and, ▁negative, ▁reviews, ▁i, ., e, ., ʶ, ▁#, ▁not, ▁taking, ▁into, ▁consideration, ▁those, ▁reviews, ▁with, ▁Score, =, 3, ʶ, ▁filtered, _, data, ▁=, ▁p, d, ., read, _, sql, _, query, (, \", \", \", SELECT, ▁*, ▁FROM, ▁Reviews...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>f0a7f5c4</td>\n",
       "      <td>code</td>\n",
       "      <td>display = pd.read_sql_query(\"\"\" SELECT UserId, ProductId, ProfileName, Time, Score, Text, COUNT(*) FROM Reviews GROUP BY UserId HAVING COUNT(*)&gt;1 \"\"\", con)ʶprint(display.shape)ʶdisplay.head()ʶ</td>\n",
       "      <td>a3baf6134c8506</td>\n",
       "      <td>[1, 1689, 1842, 845, 407, 260, 8523, 616, 51972, 616, 47975, 555, 309, 309, 309, 45786, 5675, 29935, 261, 4899, 29935, 261, 12028, 15303, 261, 2210, 261, 13938, 261, 7655, 261, 73857, 555, 1225, 285, 11371, 8939, 30686, 9506, 5675, 29935, 92773, 73857, 555, 1225, 285, 1504, 435, 307, 309, 309, 261, 4636, 285, 128001, 2118, 555, 35459, 260, 29753, 285, 128001, 1689, 260, 5563, 555, 285, 128001, 2]</td>\n",
       "      <td>[[CLS], ▁display, ▁=, ▁p, d, ., read, _, sql, _, query, (, \", \", \", ▁SELECT, ▁User, Id, ,, ▁Product, Id, ,, ▁Profile, Name, ,, ▁Time, ,, ▁Score, ,, ▁Text, ,, ▁COUNT, (, *, ), ▁FROM, ▁Reviews, ▁GROUP, ▁BY, ▁User, Id, ▁HAVING, ▁COUNT, (, *, ), &gt;, 1, ▁\", \", \", ,, ▁con, ), ʶ, ▁print, (, display, ., shape, ), ʶ, ▁display, ., head, (, ), ʶ, [SEP]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>548f02a6</td>\n",
       "      <td>code</td>\n",
       "      <td>display[display['UserId']=='AZY10LLTJ71NX']</td>\n",
       "      <td>a3baf6134c8506</td>\n",
       "      <td>[1, 1689, 2550, 35459, 2550, 280, 26359, 29935, 280, 592, 1510, 1510, 280, 558, 54368, 894, 17145, 1193, 2252, 9156, 34690, 280, 592, 2]</td>\n",
       "      <td>[[CLS], ▁display, [, display, [, ', User, Id, ', ], =, =, ', A, ZY, 10, LL, T, J, 71, NX, ', ], [SEP]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>627f1de4</td>\n",
       "      <td>code</td>\n",
       "      <td>display['COUNT(*)'].sum()</td>\n",
       "      <td>a3baf6134c8506</td>\n",
       "      <td>[1, 1689, 2550, 280, 98460, 555, 1225, 285, 280, 592, 260, 17608, 555, 285, 2]</td>\n",
       "      <td>[[CLS], ▁display, [, ', COUNT, (, *, ), ', ], ., sum, (, ), [SEP]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   cell_id cell_type  \\\n",
       "0      0  1c7a5a71      code   \n",
       "1      1  68f71f96      code   \n",
       "2      2  f0a7f5c4      code   \n",
       "3      3  548f02a6      code   \n",
       "4      4  627f1de4      code   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                source  \\\n",
       "0  import warningsʶwarnings.filterwarnings(\"ignore\")ʶʶimport sqlite3ʶimport pandas as pdʶimport numpy as npʶimport nltkʶimport stringʶimport matplotlib.pyplot as pltʶimport seaborn as snsʶfrom sklearn.feature_extraction.text import TfidfTransformerʶfrom sklearn.feature_extraction.text import TfidfVectorizerʶʶfrom sklearn.feature_extraction.text import CountVectorizerʶfrom sklearn.metrics import confusion_matrixʶfrom sklearn import metricsʶfrom sklearn.metrics import roc_curve, aucʶfrom nltk.ste...   \n",
       "1  # using the SQLite Table to read data.ʶcon = sqlite3.connect('../input/database.sqlite')ʶ#con = sqlite3.connect('database.sqlite') ʶʶ#filtering only positive and negative reviews i.e. ʶ# not taking into consideration those reviews with Score=3ʶfiltered_data = pd.read_sql_query(\"\"\"SELECT * FROM Reviews WHERE Score != 3 LIMIT 100000\"\"\", con) ʶʶ# Give reviews with Score>3 a positive rating, and reviews with a score<3 a negative rating.ʶdef partition(x):ʶ    if x < 3:ʶ        return 0ʶ    return...   \n",
       "2                                                                                                                                                                                                                                                                                                                     display = pd.read_sql_query(\"\"\" SELECT UserId, ProductId, ProfileName, Time, Score, Text, COUNT(*) FROM Reviews GROUP BY UserId HAVING COUNT(*)>1 \"\"\", con)ʶprint(display.shape)ʶdisplay.head()ʶ   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                          display[display['UserId']=='AZY10LLTJ71NX']   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            display['COUNT(*)'].sum()   \n",
       "\n",
       "               id  \\\n",
       "0  a3baf6134c8506   \n",
       "1  a3baf6134c8506   \n",
       "2  a3baf6134c8506   \n",
       "3  a3baf6134c8506   \n",
       "4  a3baf6134c8506   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             input_ids  \\\n",
       "0  [1, 6306, 11917, 128001, 11917, 260, 28865, 60656, 268, 555, 309, 66478, 309, 285, 128001, 128001, 6306, 120474, 508, 128001, 6306, 67927, 283, 845, 407, 128001, 6306, 36221, 11751, 283, 76767, 128001, 6306, 90668, 39501, 128001, 6306, 4022, 128001, 6306, 8358, 33918, 14434, 260, 11751, 33918, 283, 28944, 297, 128001, 6306, 2164, 6107, 283, 41339, 268, 128001, 292, 33566, 29274, 260, 51532, 616, 113492, 260, 12948, 6306, 897, 59426, 1892, 86911, 649, 128001, 292, 33566, 29274, 260, 51532, 61...   \n",
       "1  [1, 953, 478, 262, 78550, 3751, 264, 623, 514, 260, 128001, 4636, 1842, 120474, 508, 260, 30407, 555, 280, 260, 260, 320, 42177, 320, 54698, 260, 51972, 5936, 280, 285, 128001, 953, 5699, 1842, 120474, 508, 260, 30407, 555, 280, 54698, 260, 51972, 5936, 280, 285, 128001, 128001, 953, 28865, 510, 364, 1453, 263, 2330, 1937, 584, 260, 473, 260, 128001, 953, 298, 787, 352, 3937, 421, 1937, 275, 13938, 1510, 508, 128001, 16334, 616, 9832, 1842, 845, 407, 260, 8523, 616, 51972, 616, 47975, 555, 3...   \n",
       "2                                                                                                      [1, 1689, 1842, 845, 407, 260, 8523, 616, 51972, 616, 47975, 555, 309, 309, 309, 45786, 5675, 29935, 261, 4899, 29935, 261, 12028, 15303, 261, 2210, 261, 13938, 261, 7655, 261, 73857, 555, 1225, 285, 11371, 8939, 30686, 9506, 5675, 29935, 92773, 73857, 555, 1225, 285, 1504, 435, 307, 309, 309, 261, 4636, 285, 128001, 2118, 555, 35459, 260, 29753, 285, 128001, 1689, 260, 5563, 555, 285, 128001, 2]   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                             [1, 1689, 2550, 35459, 2550, 280, 26359, 29935, 280, 592, 1510, 1510, 280, 558, 54368, 894, 17145, 1193, 2252, 9156, 34690, 280, 592, 2]   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                       [1, 1689, 2550, 280, 98460, 555, 1225, 285, 280, 592, 260, 17608, 555, 285, 2]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                tokens  \n",
       "0  [[CLS], ▁import, ▁warnings, ʶ, ▁warnings, ., filter, warning, s, (, \", ignore, \", ), ʶ, ʶ, ▁import, ▁sqlite, 3, ʶ, ▁import, ▁pandas, ▁as, ▁p, d, ʶ, ▁import, ▁num, py, ▁as, ▁np, ʶ, ▁import, ▁nl, tk, ʶ, ▁import, ▁string, ʶ, ▁import, ▁mat, plot, lib, ., py, plot, ▁as, ▁pl, t, ʶ, ▁import, ▁sea, born, ▁as, ▁sn, s, ʶ, ▁from, ▁sk, learn, ., feature, _, extraction, ., text, ▁import, ▁T, fid, f, Transform, er, ʶ, ▁from, ▁sk, learn, ., feature, _, extraction, ., text, ▁import, ▁T, fid, f, Vector, izer...  \n",
       "1  [[CLS], ▁#, ▁using, ▁the, ▁SQLite, ▁Table, ▁to, ▁read, ▁data, ., ʶ, ▁con, ▁=, ▁sqlite, 3, ., connect, (, ', ., ., /, input, /, database, ., sql, ite, ', ), ʶ, ▁#, con, ▁=, ▁sqlite, 3, ., connect, (, ', database, ., sql, ite, ', ), ʶ, ʶ, ▁#, filter, ing, ▁only, ▁positive, ▁and, ▁negative, ▁reviews, ▁i, ., e, ., ʶ, ▁#, ▁not, ▁taking, ▁into, ▁consideration, ▁those, ▁reviews, ▁with, ▁Score, =, 3, ʶ, ▁filtered, _, data, ▁=, ▁p, d, ., read, _, sql, _, query, (, \", \", \", SELECT, ▁*, ▁FROM, ▁Reviews...  \n",
       "2                                                                                                                                                              [[CLS], ▁display, ▁=, ▁p, d, ., read, _, sql, _, query, (, \", \", \", ▁SELECT, ▁User, Id, ,, ▁Product, Id, ,, ▁Profile, Name, ,, ▁Time, ,, ▁Score, ,, ▁Text, ,, ▁COUNT, (, *, ), ▁FROM, ▁Reviews, ▁GROUP, ▁BY, ▁User, Id, ▁HAVING, ▁COUNT, (, *, ), >, 1, ▁\", \", \", ,, ▁con, ), ʶ, ▁print, (, display, ., shape, ), ʶ, ▁display, ., head, (, ), ʶ, [SEP]]  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                               [[CLS], ▁display, [, display, [, ', User, Id, ', ], =, =, ', A, ZY, 10, LL, T, J, 71, NX, ', ], [SEP]]  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                   [[CLS], ▁display, [, ', COUNT, (, *, ), ', ], ., sum, (, ), [SEP]]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10w using 3.14min 1 epoch for emb 256\n",
    "# for emb 128 only 0.3min\n",
    "def gen_w2v(df, tokenizer, name='tokens', window=16, min_count=5, emb_dim=256, limit=0):\n",
    "  sentences = [list(x) for x in df[name].values]\n",
    "  ic(len(sentences))\n",
    "\n",
    "  if limit:\n",
    "    sentences = sentences[:limit]\n",
    "    ic(len(sentences))\n",
    "    name = name + f'.limit{limit}'\n",
    "  monitor = gezi.MonitorCallback(name) \n",
    "  w2v = Word2Vec(sentences, vector_size=emb_dim, window=window, min_count=min_count, sg=1, workers=cpu_count(), epochs=10, callbacks=[monitor])\n",
    "  \n",
    "  root = f'{FLAGS.root}/w2v/{emb_dim}'\n",
    "  ofile = f'{root}/{name}.pkl'\n",
    "  gezi.try_mkdir(os.path.dirname(ofile))\n",
    "  gezi.save(w2v, ofile)\n",
    "  emb = np.random.uniform(-0.05, 0.05,(tokenizer.vocab_size, emb_dim))\n",
    "  for i in range(tokenizer.vocab_size):\n",
    "    token = tokenizer.convert_ids_to_tokens(i)\n",
    "    if token in w2v.wv:\n",
    "      emb[i] = w2v.wv[token]\n",
    "  ofile = f'{root}/{name}.npy'\n",
    "  np.save(ofile, emb)\n",
    "  return w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[06/23/22 20:54:06] 1419350845.py:5 in gen_w2v()\n",
      "                    len(sentences): 6370646\n",
      "[06/23/22 20:54:08] 1419350845.py:9 in gen_w2v()\n",
      "                    len(sentences): 100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: tokens.limit100000 epoch: 1 model loss: 0.0 elapsed minutes: 2.47\n",
      "name: tokens.limit100000 epoch: 2 model loss: 0.0 elapsed minutes: 2.49\n",
      "name: tokens.limit100000 epoch: 3 model loss: 0.0 elapsed minutes: 2.43\n",
      "name: tokens.limit100000 epoch: 4 model loss: 0.0 elapsed minutes: 2.21\n",
      "name: tokens.limit100000 epoch: 5 model loss: 0.0 elapsed minutes: 2.25\n",
      "name: tokens.limit100000 epoch: 6 model loss: 0.0 elapsed minutes: 2.49\n",
      "name: tokens.limit100000 epoch: 7 model loss: 0.0 elapsed minutes: 2.33\n",
      "name: tokens.limit100000 epoch: 8 model loss: 0.0 elapsed minutes: 2.30\n",
      "name: tokens.limit100000 epoch: 9 model loss: 0.0 elapsed minutes: 2.33\n",
      "name: tokens.limit100000 epoch: 10 model loss: 0.0 elapsed minutes: 2.22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x7f2afe660f90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_w2v(df, tokenizer, emb_dim=128, limit=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[06/23/22 21:18:20] 1419350845.py:5 in gen_w2v()\n",
      "                    len(sentences): 6370646\n",
      "[06/23/22 21:18:22] 1419350845.py:9 in gen_w2v()\n",
      "                    len(sentences): 1000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: tokens.limit1000000 epoch: 1 model loss: 0.0 elapsed minutes: 3.62\n",
      "name: tokens.limit1000000 epoch: 2 model loss: 0.0 elapsed minutes: 3.42\n",
      "name: tokens.limit1000000 epoch: 3 model loss: 0.0 elapsed minutes: 3.40\n",
      "name: tokens.limit1000000 epoch: 4 model loss: 0.0 elapsed minutes: 3.39\n",
      "name: tokens.limit1000000 epoch: 5 model loss: 0.0 elapsed minutes: 3.38\n",
      "name: tokens.limit1000000 epoch: 6 model loss: 0.0 elapsed minutes: 3.36\n",
      "name: tokens.limit1000000 epoch: 7 model loss: 0.0 elapsed minutes: 3.36\n",
      "name: tokens.limit1000000 epoch: 8 model loss: 0.0 elapsed minutes: 3.37\n",
      "name: tokens.limit1000000 epoch: 9 model loss: 0.0 elapsed minutes: 3.21\n",
      "name: tokens.limit1000000 epoch: 10 model loss: 0.0 elapsed minutes: 3.02\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x7f2aee1ddc50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_w2v(df, tokenizer, emb_dim=128, limit=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['n_tokens'] = df.tokens.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6370646.0000</td>\n",
       "      <td>6370646.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.9360</td>\n",
       "      <td>108.0791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>49.0379</td>\n",
       "      <td>1746.4885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.0000</td>\n",
       "      <td>16.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.0000</td>\n",
       "      <td>40.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.0000</td>\n",
       "      <td>97.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>89.0000</td>\n",
       "      <td>213.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>124.0000</td>\n",
       "      <td>326.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>231.0000</td>\n",
       "      <td>813.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.9%</th>\n",
       "      <td>495.0000</td>\n",
       "      <td>2965.3550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1004.0000</td>\n",
       "      <td>743881.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index     n_tokens\n",
       "count 6370646.0000 6370646.0000\n",
       "mean       39.9360     108.0791\n",
       "std        49.0379    1746.4885\n",
       "min         0.0000       3.0000\n",
       "25%        11.0000      16.0000\n",
       "50%        26.0000      40.0000\n",
       "75%        51.0000      97.0000\n",
       "90%        89.0000     213.0000\n",
       "95%       124.0000     326.0000\n",
       "99%       231.0000     813.0000\n",
       "99.9%     495.0000    2965.3550\n",
       "max      1004.0000  743881.0000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(PERCENTILES2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.0000</td>\n",
       "      <td>1000000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.2587</td>\n",
       "      <td>106.8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>48.9060</td>\n",
       "      <td>1616.4606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.0000</td>\n",
       "      <td>16.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.0000</td>\n",
       "      <td>40.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>52.0000</td>\n",
       "      <td>97.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>90.0000</td>\n",
       "      <td>212.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>125.0000</td>\n",
       "      <td>325.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>232.0000</td>\n",
       "      <td>816.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.9%</th>\n",
       "      <td>462.0000</td>\n",
       "      <td>3050.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>935.0000</td>\n",
       "      <td>611758.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index     n_tokens\n",
       "count 1000000.0000 1000000.0000\n",
       "mean       40.2587     106.8540\n",
       "std        48.9060    1616.4606\n",
       "min         0.0000       3.0000\n",
       "25%        11.0000      16.0000\n",
       "50%        26.0000      40.0000\n",
       "75%        52.0000      97.0000\n",
       "90%        90.0000     212.0000\n",
       "95%       125.0000     325.0000\n",
       "99%       232.0000     816.0000\n",
       "99.9%     462.0000    3050.0010\n",
       "max       935.0000  611758.0000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1000000).describe(PERCENTILES2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[06/23/22 22:18:16] 1419350845.py:5 in gen_w2v()\n",
      "                    len(sentences): 6370646\n",
      "[06/23/22 22:18:17] 1419350845.py:9 in gen_w2v()\n",
      "                    len(sentences): 3000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: tokens.limit3000000 epoch: 1 model loss: 0.0 elapsed minutes: 61.66\n",
      "name: tokens.limit3000000 epoch: 2 model loss: 0.0 elapsed minutes: 63.36\n",
      "name: tokens.limit3000000 epoch: 3 model loss: 0.0 elapsed minutes: 70.73\n",
      "name: tokens.limit3000000 epoch: 4 model loss: 0.0 elapsed minutes: 70.91\n",
      "name: tokens.limit3000000 epoch: 5 model loss: 0.0 elapsed minutes: 69.81\n",
      "name: tokens.limit3000000 epoch: 6 model loss: 0.0 elapsed minutes: 69.59\n",
      "name: tokens.limit3000000 epoch: 7 model loss: 0.0 elapsed minutes: 69.15\n",
      "name: tokens.limit3000000 epoch: 8 model loss: 0.0 elapsed minutes: 68.21\n",
      "name: tokens.limit3000000 epoch: 9 model loss: 0.0 elapsed minutes: 67.85\n",
      "name: tokens.limit3000000 epoch: 10 model loss: 0.0 elapsed minutes: 69.11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x7f2aca2c9610>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_w2v(df, tokenizer, emb_dim=128, limit=3000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1925003cfa3979ae366740114cfe890bf8d7ad5b88e4afe0ec571fe261ed45e3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
