{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gezi.common import *\n",
    "sys.path.append('..')\n",
    "from src.config import *\n",
    "from src.preprocess import *\n",
    "from src.eval import *\n",
    "gezi.init_flags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/goldenlock/ai4code-base?scriptVersionId=101148262\n",
    "# 9025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../working/offline/6/0'\n",
    "context_model_name = 'deberta-v3-small.flag-context2-aug.n_context-40.cls_loss_rate-0.1.eval.p13-4'\n",
    "pairwise_model_name = 'all-mpnet-base-v2.flag-pairwise13-4.pooling_mask-attention_mask.grad_acc-4'\n",
    "pmodel2_name = 'deberta-v3-small.flag-pairwise14-2-cat.eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc = gezi.load(f'{root}/{context_model_name}/valid.pkl')\n",
    "xp = gezi.load(f'{root}/{pairwise_model_name}/valid.pkl')\n",
    "xp2 = gezi.load(f'{root}/{pmodel2_name}/valid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gezi.sort_dict_byid_(xc, 'cid')\n",
    "gezi.sort_dict_byid_(xp, 'cid')\n",
    "gezi.sort_dict_byid_(xp2, 'cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = set(xc['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0002115f48f982</td>\n",
       "      <td>[9ec225f0, 18281c6c, e3b6b115, 4a044c54, 365fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00062ab8487156</td>\n",
       "      <td>[dcad687f, a2e1fc80, 7d977ee8, 45a82a59, cbbc3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>000efd285fb982</td>\n",
       "      <td>[74a30f80, ee2c8e08, 5523374e, ae8f8fe8, 2138e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0012865b766949</td>\n",
       "      <td>[f9cb50e9, 25f7db90, d804e819, 6593a545, fc5bb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>001308991e0c5e</td>\n",
       "      <td>[21147235, 6c01d0d2, 5bd28595, b8fd3a8c, a2501...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                         cell_order\n",
       "4   0002115f48f982  [9ec225f0, 18281c6c, e3b6b115, 4a044c54, 365fe...\n",
       "11  00062ab8487156  [dcad687f, a2e1fc80, 7d977ee8, 45a82a59, cbbc3...\n",
       "28  000efd285fb982  [74a30f80, ee2c8e08, 5523374e, ae8f8fe8, 2138e...\n",
       "39  0012865b766949  [f9cb50e9, 25f7db90, d804e819, 6593a545, fc5bb...\n",
       "42  001308991e0c5e  [21147235, 6c01d0d2, 5bd28595, b8fd3a8c, a2501..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gt = pd.read_csv(f'{FLAGS.root}/train_orders.csv')\n",
    "df_gt = df_gt[df_gt.id.isin(ids)]\n",
    "df_gt['cell_order'] = df_gt['cell_order'].apply(lambda x: x.split())\n",
    "df_gt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9006251692558017"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_metric(xc, 'reg_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8992880214723898"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_metric(xc, 'pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896173129530509"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_metric(xc, 'cls_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8966581181771137"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_metric(xp, 'cls_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9044248355992179"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = xc.copy()\n",
    "x['pred'] = xc['reg_pred'] * 0.5 + xp['cls_pred'] * 0.5\n",
    "calc_metric(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9018247872358709"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = xc.copy()\n",
    "x['pred'] = xc['cls_pred'] * 0.5 + xp['cls_pred'] * 0.5\n",
    "calc_metric(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9036697563235938"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = xc.copy()\n",
    "x['pred'] = xc['reg_pred'] * 0.5 + xp['pred'] * 0.5\n",
    "calc_metric(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(x, y, prob):\n",
    "  # return y\n",
    "  # return x\n",
    "  if prob > 0.9:\n",
    "    return x * (1 - 0.0001) + y * 0.0001\n",
    "  elif abs(y - x) < 0.1:\n",
    "    return x * (1 - 0.0001) + y * 0.0001\n",
    "  elif abs(y - x) < 0.2:\n",
    "    return x * 0.95 * prob + y * (1 - 0.95 * prob)\n",
    "  elif abs(y - x) < 0.3:\n",
    "    return x * 0.85 * prob + y * (1 - 0.85 * prob)\n",
    "  elif abs(y - x) < 0.4:\n",
    "    return x * 0.5 * prob + y * (1 - 0.5 * prob)\n",
    "  else:\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.908585923202479"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['pred'] = [merge(x, y, prob) for x, y, prob in zip(xp['pred'], xc['pred'], xp['max_prob'])]\n",
    "calc_metric(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = pd.DataFrame(xp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = pd.DataFrame(gezi.batch2list(xc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_c.merge(df_p[['cid', 'pred', 'cls_pred', 'max_prob', 'max_sim', 'probs', 'sims']], on='cid', suffixes=['_c', '_p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_feather('../working/train.fea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train.id.isin(ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_train[['cid', 'ancestor_id', 'n_words', 'source']], on='cid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gezi.set_fold(df, 5, 'ancestor_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8dfedefff4c4ad7ab191fb572fa01d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "top:   0%|          | 0/424943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5324284b6b4346c38556dd8c771cf0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ctop:   0%|          | 0/424943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79b967fad1e4ed89fc849ac7270b2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "p2:   0%|          | 0/424943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ecdde05d13e4b699a6d332352ccbe29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rule:   0%|          | 0/424943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['markdown_frac'] = df['n_markdown_cell'] / df['n_cell']\n",
    "df['span'] = 1 / (df['n_code_cell'] + 1)\n",
    "top2, top3, top4, top5 = [], [], [], []\n",
    "top2_prob, top3_prob, top4_prob, top5_prob = [], [], [], []\n",
    "top2_sim, top3_sim, top4_sim, top5_sim = [], [], [], []\n",
    "for i in tqdm(range(len(df)), desc='top'):\n",
    "  # cls_preds = df['cls_pred_ori'].values[i]\n",
    "  n_code = df['n_code_cell'].values[i]\n",
    "  probs = df['probs'].values[i]\n",
    "  sims = df['sims'].values[i]\n",
    "  idxes = (-probs).argsort()\n",
    "  if len(idxes) > 1:\n",
    "    top2.append((idxes[1] + 0.5) / (n_code + 1))\n",
    "    top2_prob.append(probs[idxes[1]])\n",
    "    top2_sim.append(sims[idxes[1]])\n",
    "  else:\n",
    "    top2.append(-1)\n",
    "    top2_prob.append(-1)\n",
    "    top2_sim.append(-1)\n",
    "  if len(idxes) > 2:\n",
    "    top3.append((idxes[2] + 0.5) / (n_code + 1))\n",
    "    top3_prob.append(probs[idxes[2]])\n",
    "    top3_sim.append(sims[idxes[2]])\n",
    "  else:\n",
    "    top3.append(-1)\n",
    "    top3_prob.append(-1)\n",
    "    top3_sim.append(-1)\n",
    "  if len(idxes) > 3:\n",
    "    top4.append((idxes[3] + 0.5) / (n_code + 1))\n",
    "    top4_prob.append(probs[idxes[3]])\n",
    "    top4_sim.append(sims[idxes[3]])\n",
    "  else:\n",
    "    top4.append(-1)\n",
    "    top4_prob.append(-1)\n",
    "    top4_sim.append(-1)\n",
    "  if len(idxes) > 4:\n",
    "    top5.append((idxes[4] + 0.5) / (n_code + 1))\n",
    "    top5_prob.append(probs[idxes[4]])\n",
    "    top5_sim.append(sims[idxes[4]])\n",
    "  else:\n",
    "    top5.append(-1)\n",
    "    top5_prob.append(-1)\n",
    "    top5_sim.append(-1)\n",
    "ctop_prob, ctop2, ctop3, ctop4, ctop2_prob, ctop3_prob, ctop4_prob = [], [], [], [], [], [], []\n",
    "for i in tqdm(range(len(df)), desc='ctop'):\n",
    "  preds = df['cls_pred_ori'].values[i]\n",
    "  probs = gezi.softmax(preds)\n",
    "  idxes = (-probs).argsort()\n",
    "  ctop_prob.append(probs[idxes[0]])\n",
    "  ctop2.append((idxes[1] + 0.5) / FLAGS.num_classes)\n",
    "  ctop2_prob.append(probs[idxes[1]])\n",
    "  ctop3.append((idxes[2] + 0.5) / FLAGS.num_classes)\n",
    "  ctop3_prob.append(probs[idxes[2]])\n",
    "  ctop4.append((idxes[3] + 0.5) / FLAGS.num_classes)\n",
    "  ctop4_prob.append(probs[idxes[3]])\n",
    "# for i in range(FLAGS.num_classes):\n",
    "#   df[f'cls_pred{i}'] = df['cls_pred_ori'].apply(lambda x: x[i])\n",
    "df['top2'] = top2\n",
    "df['top2_prob'] = top2_prob\n",
    "df['top2_sim'] = top2_sim\n",
    "df['top3'] = top3\n",
    "df['top3_prob'] = top3_prob\n",
    "df['top3_sim'] = top3_sim\n",
    "df['top4'] = top4\n",
    "df['top4_prob'] = top4_prob\n",
    "df['top4_sim'] = top4_sim\n",
    "df['top5'] = top5\n",
    "df['top5_prob'] = top5_prob\n",
    "df['top5_sim'] = top5_sim\n",
    "df['ctop_prob'] = ctop_prob\n",
    "df['ctop2'] = ctop2\n",
    "df['ctop2_prob'] = ctop2_prob\n",
    "df['ctop3'] = ctop3\n",
    "df['ctop3_prob'] = ctop3_prob\n",
    "df['ctop4'] = ctop4\n",
    "df['ctop4_prob'] = ctop4_prob\n",
    "df['pred_p2'] = xp2['pred']\n",
    "p2_max_prob = []\n",
    "p2_top2 = []\n",
    "p2_top2_prob = []\n",
    "for i in tqdm(range(len(df)), desc='p2'):\n",
    "  code_idxes = xp2['code_idxes'][i]\n",
    "  n_code = df['n_code_cell'].values[i]\n",
    "  probs = gezi.softmax(xp2['cls_pred_ori'][i])\n",
    "  idxes = (-probs).argsort()\n",
    "  p2_top2.append((code_idxes[idxes[1]] + 0.5) / (n_code + 1))\n",
    "  p2_max_prob.append(probs[idxes[0]])\n",
    "  p2_top2_prob.append(probs[idxes[1]])\n",
    "df['p2_max_prob'] = p2_max_prob\n",
    "df['p2_top2'] = p2_top2\n",
    "df['p2_top2_prob'] = p2_top2_prob\n",
    "  \n",
    "df['pred_diff0'] = abs(df['pred_c'] - df['pred_p'])\n",
    "df['pred_diff1'] = abs(df['reg_pred'] - df['pred_p'])\n",
    "df['pred_diff2'] = abs(df['cls_pred_c'] - df['pred_p'])\n",
    "df['pred_diff3'] = abs(df['cls2_pred'] - df['pred_p'])\n",
    "df['pred_diff4'] = abs(df['pred_c'] - df['top2'])\n",
    "df['pred_diff5'] = abs(df['reg_pred'] - df['top2'])\n",
    "df['pred_diff6'] = abs(df['cls_pred_c'] - df['top2'])\n",
    "df['pred_diff7'] = abs(df['cls2_pred'] - df['top2'])\n",
    "df['pred_diff8'] = abs(df['pred_p'] - df['top2'])\n",
    "df['pred_diff9'] = abs(df['cls_pred_c'] - df['top3'])\n",
    "df['pred_diff10'] = abs(df['pred_p'] - df['top3'])\n",
    "df['pred_diff11'] = abs(df['pred_c'] - df['pred_p2'])\n",
    "df['pred_diff12'] = abs(df['reg_pred'] - df['pred_p2'])\n",
    "df['pred_diff13'] = abs(df['cls_pred_c'] - df['pred_p2'])\n",
    "df['rule_pred'] = [merge(x, y, prob) for x, y, prob in tqdm(zip(df.pred_p.values, df.pred_c.values, df.max_prob.values), total=len(df), desc='rule')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_cols =  [\n",
    "          'n_code_cell',\n",
    "          'n_markdown_cell',\n",
    "          'n_cell',\n",
    "          'cls_pred_c',\n",
    "          'pred_c',\n",
    "          'reg_pred',\n",
    "          'cls2_pred',\n",
    "          'pred_p',\n",
    "          'cls_pred_p',\n",
    "          'rule_pred',\n",
    "          'pred_diff0',\n",
    "          'pred_diff1',\n",
    "          'pred_diff2',\n",
    "          'pred_diff3',\n",
    "          'pred_diff4',\n",
    "          'pred_diff5',\n",
    "          'pred_diff6',\n",
    "          'pred_diff7',\n",
    "          'pred_diff8',\n",
    "          'pred_diff9',\n",
    "          'pred_diff10',\n",
    "          'pred_diff11',\n",
    "          'pred_diff12',\n",
    "          'pred_diff13',\n",
    "          'max_sim',\n",
    "          'max_prob',\n",
    "          'markdown_frac',\n",
    "          'span',\n",
    "          'top2',\n",
    "          'top2_prob',\n",
    "          'top2_sim',\n",
    "          'top3',\n",
    "          'top3_prob',\n",
    "          'top3_sim',\n",
    "          'top4',\n",
    "          'top4_prob',\n",
    "          'top4_sim',\n",
    "          'top5',\n",
    "          'top5_prob',\n",
    "          'top5_sim',\n",
    "          'ctop_prob', \n",
    "          'ctop2', \n",
    "          'ctop3', \n",
    "          'ctop4', \n",
    "          'ctop2_prob', \n",
    "          'ctop3_prob', \n",
    "          'ctop4_prob',\n",
    "          'pred_p2',\n",
    "          'p2_max_prob',\n",
    "          'p2_top2',\n",
    "          'p2_top2_prob',\n",
    "        ]\n",
    "# for i in range(FLAGS.num_classes):\n",
    "#   reg_cols += [f'cls_pred{i}']\n",
    "cat_cols = [\n",
    "          \n",
    "            ]\n",
    "label_col = 'rel_rank'\n",
    "cols = reg_cols + cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "import lightgbm as lgb\n",
    "xgb_params = {'learning_rate': 0.02,\n",
    "              'reg_lambda': 7.960622217848342e-07, \n",
    "              'subsample': 0.7422597612762745,\n",
    "              'max_depth': 10, \n",
    "              'early_stopping_rounds': 500,\n",
    "              'n_estimators': 10000,\n",
    "              'cat_features': [],\n",
    "              'loss_function': 'MAE',\n",
    "              }\n",
    "\n",
    "xgb_params2 = {'learning_rate': 0.09827605967564293,'tree_method':'gpu_hist', 'gpu_id':0,\n",
    "               'early_stopping_rounds': 50,\n",
    "               'n_estimators': 10000, }\n",
    "\n",
    "params = {\n",
    "          'boosting': 'gbdt',\n",
    "          'objective': 'regression_l1',\n",
    "          'metric': {'l1'},\n",
    "          'num_leaves': 32,\n",
    "          'min_data_in_leaf': 300,\n",
    "          # 'max_depth': 10,\n",
    "          'learning_rate': 0.02,\n",
    "          \"feature_fraction\": 0.8,\n",
    "          \"bagging_fraction\": 0.75,\n",
    "          'min_data_in_bin':100,\n",
    "          \"lambda_l1\": 1e-7,\n",
    "          'lambda_l2': 1e-7,\n",
    "          \"random_state\": 1024,\n",
    "          \"num_threads\": 12,\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ea22fa492049dcb02d0c4ec5cc7522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2544626\ttest: 0.2544626\ttest1: 0.2543977\tbest: 0.2543977 (0)\ttotal: 67.1ms\tremaining: 11m 11s\n",
      "500:\tlearn: 0.0623257\ttest: 0.0623257\ttest1: 0.0650472\tbest: 0.0650472 (500)\ttotal: 30.4s\tremaining: 9m 35s\n",
      "1000:\tlearn: 0.0600127\ttest: 0.0600127\ttest1: 0.0639836\tbest: 0.0639836 (1000)\ttotal: 1m 11s\tremaining: 10m 44s\n",
      "1500:\tlearn: 0.0585698\ttest: 0.0585698\ttest1: 0.0636613\tbest: 0.0636613 (1500)\ttotal: 1m 58s\tremaining: 11m 11s\n",
      "2000:\tlearn: 0.0575620\ttest: 0.0575620\ttest1: 0.0636038\tbest: 0.0636032 (1991)\ttotal: 2m 39s\tremaining: 10m 36s\n",
      "2500:\tlearn: 0.0566180\ttest: 0.0566180\ttest1: 0.0636183\tbest: 0.0636008 (2026)\ttotal: 3m 22s\tremaining: 10m 8s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.06360083571\n",
      "bestIteration = 2026\n",
      "\n",
      "Shrink model to first 2027 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 17:56:25] 2749851879.py:22 in <module>\n",
      "                    abs(x['pred'] - dvalid['rel_rank']).mean(): 0.06579407253591144\n",
      "                    merge_score: 0.9070703368237418\n",
      "[07/19/22 17:56:27] 2749851879.py:24 in <module>\n",
      "                    cbt_score: 0.9110552050830005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12117\n",
      "[LightGBM] [Info] Number of data points in the train set: 342411, number of used features: 51\n",
      "[LightGBM] [Info] Start training from score 0.455056\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.0641013\tvalid_1's l1: 0.065489\n",
      "[1000]\ttraining's l1: 0.0627585\tvalid_1's l1: 0.0644039\n",
      "[1500]\ttraining's l1: 0.0621628\tvalid_1's l1: 0.0640303\n",
      "[2000]\ttraining's l1: 0.0617093\tvalid_1's l1: 0.0637891\n",
      "[2500]\ttraining's l1: 0.0613294\tvalid_1's l1: 0.0636073\n",
      "[3000]\ttraining's l1: 0.0610143\tvalid_1's l1: 0.0634572\n",
      "[3500]\ttraining's l1: 0.0607024\tvalid_1's l1: 0.0633355\n",
      "[4000]\ttraining's l1: 0.0604758\tvalid_1's l1: 0.0632593\n",
      "[4500]\ttraining's l1: 0.0603\tvalid_1's l1: 0.0632132\n",
      "[5000]\ttraining's l1: 0.0601138\tvalid_1's l1: 0.0631522\n",
      "[5500]\ttraining's l1: 0.0599398\tvalid_1's l1: 0.0631053\n",
      "[6000]\ttraining's l1: 0.0597749\tvalid_1's l1: 0.0630649\n",
      "[6500]\ttraining's l1: 0.0596412\tvalid_1's l1: 0.0630346\n",
      "[7000]\ttraining's l1: 0.0595164\tvalid_1's l1: 0.0630081\n",
      "[7500]\ttraining's l1: 0.059378\tvalid_1's l1: 0.0629786\n",
      "[8000]\ttraining's l1: 0.0592498\tvalid_1's l1: 0.0629581\n",
      "[8500]\ttraining's l1: 0.059158\tvalid_1's l1: 0.0629456\n",
      "[9000]\ttraining's l1: 0.059069\tvalid_1's l1: 0.0629308\n",
      "[9500]\ttraining's l1: 0.0589943\tvalid_1's l1: 0.0629223\n",
      "[10000]\ttraining's l1: 0.058902\tvalid_1's l1: 0.0629089\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.058902\tvalid_1's l1: 0.0629089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 17:59:40] 2749851879.py:38 in <module>\n",
      "                    lgb_score: 0.9114947248763512\n",
      "[07/19/22 17:59:41] 2749851879.py:40 in <module>\n",
      "                    score: 0.9117161527798324\n",
      "[07/19/22 17:59:41] 2749851879.py:46 in <module>\n",
      "                    fold: 0\n",
      "                    np.asarray(merge_scores).mean(): 0.9070703368237418\n",
      "                    np.asarray(cbt_scores).mean(): 0.9110552050830005\n",
      "                    np.asarray(lgb_scores).mean(): 0.9114947248763512\n",
      "                    np.asarray(scores).mean(): 0.9117161527798324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2544739\ttest: 0.2544739\ttest1: 0.2543809\tbest: 0.2543809 (0)\ttotal: 114ms\tremaining: 18m 58s\n",
      "500:\tlearn: 0.0625483\ttest: 0.0625483\ttest1: 0.0640227\tbest: 0.0640227 (500)\ttotal: 49.6s\tremaining: 15m 40s\n",
      "1000:\tlearn: 0.0601447\ttest: 0.0601447\ttest1: 0.0629770\tbest: 0.0629770 (1000)\ttotal: 1m 39s\tremaining: 14m 57s\n",
      "1500:\tlearn: 0.0585119\ttest: 0.0585119\ttest1: 0.0626606\tbest: 0.0626602 (1499)\ttotal: 2m 41s\tremaining: 15m 12s\n",
      "2000:\tlearn: 0.0571658\ttest: 0.0571658\ttest1: 0.0625091\tbest: 0.0625090 (1996)\ttotal: 3m 48s\tremaining: 15m 15s\n",
      "2500:\tlearn: 0.0559808\ttest: 0.0559808\ttest1: 0.0624683\tbest: 0.0624650 (2442)\ttotal: 4m 56s\tremaining: 14m 50s\n",
      "3000:\tlearn: 0.0549391\ttest: 0.0549391\ttest1: 0.0624778\tbest: 0.0624624 (2710)\ttotal: 6m 4s\tremaining: 14m 10s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.06246237343\n",
      "bestIteration = 2710\n",
      "\n",
      "Shrink model to first 2711 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 18:06:23] 2749851879.py:22 in <module>\n",
      "                    abs(x['pred'] - dvalid['rel_rank']).mean(): 0.06494859335498927\n",
      "                    merge_score: 0.9082661676659034\n",
      "[07/19/22 18:06:25] 2749851879.py:24 in <module>\n",
      "                    cbt_score: 0.9122639594101563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12117\n",
      "[LightGBM] [Info] Number of data points in the train set: 339696, number of used features: 51\n",
      "[LightGBM] [Info] Start training from score 0.455882\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.0644048\tvalid_1's l1: 0.0647484\n",
      "[1000]\ttraining's l1: 0.0629712\tvalid_1's l1: 0.0635642\n",
      "[1500]\ttraining's l1: 0.0624481\tvalid_1's l1: 0.0632164\n",
      "[2000]\ttraining's l1: 0.0619187\tvalid_1's l1: 0.0628975\n",
      "[2500]\ttraining's l1: 0.0615654\tvalid_1's l1: 0.0627249\n",
      "[3000]\ttraining's l1: 0.0613173\tvalid_1's l1: 0.0626146\n",
      "[3500]\ttraining's l1: 0.0610615\tvalid_1's l1: 0.0624926\n",
      "[4000]\ttraining's l1: 0.0609173\tvalid_1's l1: 0.0624455\n",
      "[4500]\ttraining's l1: 0.0606903\tvalid_1's l1: 0.0623534\n",
      "[5000]\ttraining's l1: 0.060492\tvalid_1's l1: 0.0622786\n",
      "[5500]\ttraining's l1: 0.0603187\tvalid_1's l1: 0.0622293\n",
      "[6000]\ttraining's l1: 0.0601467\tvalid_1's l1: 0.0621801\n",
      "[6500]\ttraining's l1: 0.0600027\tvalid_1's l1: 0.0621484\n",
      "[7000]\ttraining's l1: 0.0598678\tvalid_1's l1: 0.0621236\n",
      "[7500]\ttraining's l1: 0.0597053\tvalid_1's l1: 0.0620863\n",
      "[8000]\ttraining's l1: 0.0595898\tvalid_1's l1: 0.0620689\n",
      "[8500]\ttraining's l1: 0.0594846\tvalid_1's l1: 0.0620447\n",
      "[9000]\ttraining's l1: 0.0593855\tvalid_1's l1: 0.0620348\n",
      "[9500]\ttraining's l1: 0.0592847\tvalid_1's l1: 0.062019\n",
      "[10000]\ttraining's l1: 0.0591541\tvalid_1's l1: 0.0619945\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0591541\tvalid_1's l1: 0.0619945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 18:21:03] 2749851879.py:38 in <module>\n",
      "                    lgb_score: 0.9128915111485981\n",
      "[07/19/22 18:21:05] 2749851879.py:40 in <module>\n",
      "                    score: 0.91307099263503\n",
      "[07/19/22 18:21:05] 2749851879.py:46 in <module>\n",
      "                    fold: 1\n",
      "                    np.asarray(merge_scores).mean(): 0.9076682522448226\n",
      "                    np.asarray(cbt_scores).mean(): 0.9116595822465784\n",
      "                    np.asarray(lgb_scores).mean(): 0.9121931180124747\n",
      "                    np.asarray(scores).mean(): 0.9123935727074313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2543773\ttest: 0.2543773\ttest1: 0.2547489\tbest: 0.2547489 (0)\ttotal: 235ms\tremaining: 39m 12s\n",
      "500:\tlearn: 0.0626088\ttest: 0.0626088\ttest1: 0.0641495\tbest: 0.0641495 (500)\ttotal: 1m 41s\tremaining: 31m 57s\n",
      "1000:\tlearn: 0.0601181\ttest: 0.0601181\ttest1: 0.0630282\tbest: 0.0630282 (1000)\ttotal: 3m 28s\tremaining: 31m 13s\n",
      "1500:\tlearn: 0.0585940\ttest: 0.0585940\ttest1: 0.0626825\tbest: 0.0626824 (1498)\ttotal: 5m 2s\tremaining: 28m 34s\n",
      "2000:\tlearn: 0.0574286\ttest: 0.0574286\ttest1: 0.0625646\tbest: 0.0625646 (2000)\ttotal: 6m 42s\tremaining: 26m 47s\n",
      "2500:\tlearn: 0.0564626\ttest: 0.0564626\ttest1: 0.0625319\tbest: 0.0625319 (2497)\ttotal: 8m 24s\tremaining: 25m 13s\n",
      "3000:\tlearn: 0.0557332\ttest: 0.0557332\ttest1: 0.0625308\tbest: 0.0625161 (2692)\ttotal: 9m 56s\tremaining: 23m 10s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.06251605759\n",
      "bestIteration = 2692\n",
      "\n",
      "Shrink model to first 2693 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 18:31:49] 2749851879.py:22 in <module>\n",
      "                    abs(x['pred'] - dvalid['rel_rank']).mean(): 0.06479006687657934\n",
      "                    merge_score: 0.9108612410210817\n",
      "[07/19/22 18:31:52] 2749851879.py:24 in <module>\n",
      "                    cbt_score: 0.9142991201535796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12112\n",
      "[LightGBM] [Info] Number of data points in the train set: 337766, number of used features: 51\n",
      "[LightGBM] [Info] Start training from score 0.456522\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.0644238\tvalid_1's l1: 0.0648453\n",
      "[1000]\ttraining's l1: 0.0629415\tvalid_1's l1: 0.0635452\n",
      "[1500]\ttraining's l1: 0.0624081\tvalid_1's l1: 0.0631897\n",
      "[2000]\ttraining's l1: 0.061945\tvalid_1's l1: 0.062917\n",
      "[2500]\ttraining's l1: 0.0615052\tvalid_1's l1: 0.0626671\n",
      "[3000]\ttraining's l1: 0.0612318\tvalid_1's l1: 0.0625384\n",
      "[3500]\ttraining's l1: 0.060976\tvalid_1's l1: 0.0624289\n",
      "[4000]\ttraining's l1: 0.060774\tvalid_1's l1: 0.062345\n",
      "[4500]\ttraining's l1: 0.0605943\tvalid_1's l1: 0.0622858\n",
      "[5000]\ttraining's l1: 0.0603925\tvalid_1's l1: 0.062213\n",
      "[5500]\ttraining's l1: 0.060229\tvalid_1's l1: 0.0621648\n",
      "[6000]\ttraining's l1: 0.0600876\tvalid_1's l1: 0.0621157\n",
      "[6500]\ttraining's l1: 0.0599764\tvalid_1's l1: 0.0620902\n",
      "[7000]\ttraining's l1: 0.0598366\tvalid_1's l1: 0.0620618\n",
      "[7500]\ttraining's l1: 0.0596999\tvalid_1's l1: 0.0620379\n",
      "[8000]\ttraining's l1: 0.0595769\tvalid_1's l1: 0.0620064\n",
      "[8500]\ttraining's l1: 0.0594557\tvalid_1's l1: 0.0619824\n",
      "[9000]\ttraining's l1: 0.0593101\tvalid_1's l1: 0.0619402\n",
      "[9500]\ttraining's l1: 0.0592057\tvalid_1's l1: 0.0619211\n",
      "[10000]\ttraining's l1: 0.0590917\tvalid_1's l1: 0.0619057\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0590917\tvalid_1's l1: 0.0619057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 19:02:34] 2749851879.py:38 in <module>\n",
      "                    lgb_score: 0.9150470858201794\n",
      "[07/19/22 19:02:37] 2749851879.py:40 in <module>\n",
      "                    score: 0.9151520773068894\n",
      "[07/19/22 19:02:37] 2749851879.py:46 in <module>\n",
      "                    fold: 2\n",
      "                    np.asarray(merge_scores).mean(): 0.908732581836909\n",
      "                    np.asarray(cbt_scores).mean(): 0.9125394282155788\n",
      "                    np.asarray(lgb_scores).mean(): 0.913144440615043\n",
      "                    np.asarray(scores).mean(): 0.9133130742405839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2545072\ttest: 0.2545072\ttest1: 0.2542524\tbest: 0.2542524 (0)\ttotal: 256ms\tremaining: 42m 41s\n",
      "500:\tlearn: 0.0629028\ttest: 0.0629028\ttest1: 0.0624033\tbest: 0.0624033 (500)\ttotal: 1m 42s\tremaining: 32m 25s\n",
      "1000:\tlearn: 0.0605367\ttest: 0.0605367\ttest1: 0.0613851\tbest: 0.0613851 (1000)\ttotal: 3m 5s\tremaining: 27m 44s\n",
      "1500:\tlearn: 0.0590771\ttest: 0.0590771\ttest1: 0.0610488\tbest: 0.0610488 (1500)\ttotal: 4m 33s\tremaining: 25m 50s\n",
      "2000:\tlearn: 0.0577704\ttest: 0.0577704\ttest1: 0.0609245\tbest: 0.0609243 (1998)\ttotal: 6m 32s\tremaining: 26m 7s\n",
      "2500:\tlearn: 0.0567356\ttest: 0.0567356\ttest1: 0.0608969\tbest: 0.0608969 (2500)\ttotal: 8m 31s\tremaining: 25m 34s\n",
      "3000:\tlearn: 0.0557374\ttest: 0.0557374\ttest1: 0.0608976\tbest: 0.0608762 (2679)\ttotal: 10m 15s\tremaining: 23m 55s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.06087624559\n",
      "bestIteration = 2679\n",
      "\n",
      "Shrink model to first 2680 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 19:13:36] 2749851879.py:22 in <module>\n",
      "                    abs(x['pred'] - dvalid['rel_rank']).mean(): 0.06352573785829235\n",
      "                    merge_score: 0.912103082718156\n",
      "[07/19/22 19:13:39] 2749851879.py:24 in <module>\n",
      "                    cbt_score: 0.9164747205270958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.112077 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12115\n",
      "[LightGBM] [Info] Number of data points in the train set: 337964, number of used features: 51\n",
      "[LightGBM] [Info] Start training from score 0.455939\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.0647732\tvalid_1's l1: 0.0629515\n",
      "[1000]\ttraining's l1: 0.0634609\tvalid_1's l1: 0.0619424\n",
      "[1500]\ttraining's l1: 0.062835\tvalid_1's l1: 0.0615486\n",
      "[2000]\ttraining's l1: 0.0623649\tvalid_1's l1: 0.0612971\n",
      "[2500]\ttraining's l1: 0.061993\tvalid_1's l1: 0.0611183\n",
      "[3000]\ttraining's l1: 0.0616619\tvalid_1's l1: 0.0609516\n",
      "[3500]\ttraining's l1: 0.0614048\tvalid_1's l1: 0.0608366\n",
      "[4000]\ttraining's l1: 0.0611815\tvalid_1's l1: 0.0607604\n",
      "[4500]\ttraining's l1: 0.0609802\tvalid_1's l1: 0.0606949\n",
      "[5000]\ttraining's l1: 0.0608171\tvalid_1's l1: 0.0606418\n",
      "[5500]\ttraining's l1: 0.060576\tvalid_1's l1: 0.0605673\n",
      "[6000]\ttraining's l1: 0.0603776\tvalid_1's l1: 0.0605254\n",
      "[6500]\ttraining's l1: 0.0602477\tvalid_1's l1: 0.0604945\n",
      "[7000]\ttraining's l1: 0.0601226\tvalid_1's l1: 0.0604732\n",
      "[7500]\ttraining's l1: 0.0599719\tvalid_1's l1: 0.060441\n",
      "[8000]\ttraining's l1: 0.0598464\tvalid_1's l1: 0.0604144\n",
      "[8500]\ttraining's l1: 0.0596691\tvalid_1's l1: 0.0603901\n",
      "[9000]\ttraining's l1: 0.0595585\tvalid_1's l1: 0.0603739\n",
      "[9500]\ttraining's l1: 0.0594602\tvalid_1's l1: 0.0603639\n",
      "[10000]\ttraining's l1: 0.0593742\tvalid_1's l1: 0.060354\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0593742\tvalid_1's l1: 0.060354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 19:28:40] 2749851879.py:38 in <module>\n",
      "                    lgb_score: 0.9170191022445477\n",
      "[07/19/22 19:28:43] 2749851879.py:40 in <module>\n",
      "                    score: 0.91725629300348\n",
      "[07/19/22 19:28:43] 2749851879.py:46 in <module>\n",
      "                    fold: 3\n",
      "                    np.asarray(merge_scores).mean(): 0.9095752070572207\n",
      "                    np.asarray(cbt_scores).mean(): 0.913523251293458\n",
      "                    np.asarray(lgb_scores).mean(): 0.9141131060224191\n",
      "                    np.asarray(scores).mean(): 0.914298878931308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2544319\ttest: 0.2544319\ttest1: 0.2545198\tbest: 0.2545198 (0)\ttotal: 383ms\tremaining: 1h 3m 51s\n",
      "500:\tlearn: 0.0622288\ttest: 0.0622288\ttest1: 0.0650961\tbest: 0.0650961 (500)\ttotal: 1m 39s\tremaining: 31m 30s\n",
      "1000:\tlearn: 0.0597644\ttest: 0.0597644\ttest1: 0.0640164\tbest: 0.0640164 (1000)\ttotal: 2m 48s\tremaining: 25m 10s\n",
      "1500:\tlearn: 0.0583114\ttest: 0.0583114\ttest1: 0.0637223\tbest: 0.0637220 (1498)\ttotal: 3m 45s\tremaining: 21m 16s\n",
      "2000:\tlearn: 0.0570179\ttest: 0.0570179\ttest1: 0.0635879\tbest: 0.0635874 (1999)\ttotal: 4m 44s\tremaining: 18m 57s\n",
      "2500:\tlearn: 0.0558048\ttest: 0.0558048\ttest1: 0.0635335\tbest: 0.0635329 (2488)\ttotal: 5m 57s\tremaining: 17m 51s\n",
      "3000:\tlearn: 0.0548574\ttest: 0.0548574\ttest1: 0.0635302\tbest: 0.0635249 (2856)\ttotal: 7m 42s\tremaining: 17m 59s\n",
      "3500:\tlearn: 0.0540844\ttest: 0.0540844\ttest1: 0.0635533\tbest: 0.0635235 (3152)\ttotal: 9m 24s\tremaining: 17m 27s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 0.06352346061\n",
      "bestIteration = 3152\n",
      "\n",
      "Shrink model to first 3153 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 19:38:51] 2749851879.py:22 in <module>\n",
      "                    abs(x['pred'] - dvalid['rel_rank']).mean(): 0.06573988537486983\n",
      "                    merge_score: 0.9039693073200067\n",
      "[07/19/22 19:38:54] 2749851879.py:24 in <module>\n",
      "                    cbt_score: 0.9072678199781201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030733 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12115\n",
      "[LightGBM] [Info] Number of data points in the train set: 341935, number of used features: 51\n",
      "[LightGBM] [Info] Start training from score 0.456522\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's l1: 0.0640428\tvalid_1's l1: 0.0656852\n",
      "[1000]\ttraining's l1: 0.062795\tvalid_1's l1: 0.0646732\n",
      "[1500]\ttraining's l1: 0.0621823\tvalid_1's l1: 0.0642807\n",
      "[2000]\ttraining's l1: 0.0617099\tvalid_1's l1: 0.0639999\n",
      "[2500]\ttraining's l1: 0.0613732\tvalid_1's l1: 0.063815\n",
      "[3000]\ttraining's l1: 0.061076\tvalid_1's l1: 0.0636712\n",
      "[3500]\ttraining's l1: 0.060834\tvalid_1's l1: 0.063567\n",
      "[4000]\ttraining's l1: 0.0606172\tvalid_1's l1: 0.0634763\n",
      "[4500]\ttraining's l1: 0.0604379\tvalid_1's l1: 0.0634081\n",
      "[5000]\ttraining's l1: 0.0602769\tvalid_1's l1: 0.0633451\n",
      "[5500]\ttraining's l1: 0.0600795\tvalid_1's l1: 0.0632882\n",
      "[6000]\ttraining's l1: 0.0599436\tvalid_1's l1: 0.0632515\n",
      "[6500]\ttraining's l1: 0.0597974\tvalid_1's l1: 0.0632149\n",
      "[7000]\ttraining's l1: 0.0596604\tvalid_1's l1: 0.0631869\n",
      "[7500]\ttraining's l1: 0.0595136\tvalid_1's l1: 0.0631515\n",
      "[8000]\ttraining's l1: 0.0593857\tvalid_1's l1: 0.0631239\n",
      "[8500]\ttraining's l1: 0.0592249\tvalid_1's l1: 0.063088\n",
      "[9000]\ttraining's l1: 0.0590845\tvalid_1's l1: 0.0630655\n",
      "[9500]\ttraining's l1: 0.0589771\tvalid_1's l1: 0.0630388\n",
      "[10000]\ttraining's l1: 0.0589059\tvalid_1's l1: 0.0630243\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0589059\tvalid_1's l1: 0.0630243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[07/19/22 19:58:03] 2749851879.py:38 in <module>\n",
      "                    lgb_score: 0.9077804888224067\n",
      "[07/19/22 19:58:05] 2749851879.py:40 in <module>\n",
      "                    score: 0.9079099152585337\n",
      "[07/19/22 19:58:05] 2749851879.py:46 in <module>\n",
      "                    fold: 4\n",
      "                    np.asarray(merge_scores).mean(): 0.908454027109778\n",
      "                    np.asarray(cbt_scores).mean(): 0.9122721650303905\n",
      "                    np.asarray(lgb_scores).mean(): 0.9128465825824167\n",
      "                    np.asarray(scores).mean(): 0.9130210861967532\n"
     ]
    }
   ],
   "source": [
    "merge_scores = []\n",
    "cbt_scores, lgb_scores = [], []\n",
    "scores = []\n",
    "for fold in tqdm(range(FOLDS)):\n",
    "  dvalid = df[df.fold==fold]\n",
    "  dtrain = df[df.fold!=fold]\n",
    "  X_train = dtrain[cols]\n",
    "  y_train = dtrain[label_col]\n",
    "  X_valid = dvalid[cols]\n",
    "  y_valid = dvalid[label_col]\n",
    "  cbt_model = CatBoostRegressor(**xgb_params)\n",
    "  cbt_model.fit(X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                verbose=500,\n",
    "                )  \n",
    "  cbt_model.save_model(f'../working/trees/{fold}.cbt')\n",
    "  dvalid['cb_pred'] = cbt_model.predict(dvalid[cols])\n",
    "  \n",
    "  x = {'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values}\n",
    "  x['pred'] = [merge(x, y, prob) for x, y, prob in zip(dvalid.pred_p.values, dvalid.pred_c.values, dvalid.max_prob.values)]\n",
    "  merge_score = calc_metric(x, 'pred', df_gt)\n",
    "  ic(abs(x['pred'] - dvalid['rel_rank']).mean(), merge_score)\n",
    "  cbt_score = calc_metric({'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values, 'pred': dvalid.cb_pred.values})\n",
    "  ic(cbt_score)\n",
    "  \n",
    "  d_train = lgb.Dataset(X_train, y_train)\n",
    "  d_valid = lgb.Dataset(X_valid, y_valid, reference=d_train)\n",
    "  lgb_model = lgb.train(params,\n",
    "                  d_train,\n",
    "                  10000,\n",
    "                  valid_sets=[d_train, d_valid],\n",
    "                  verbose_eval=500,\n",
    "                  early_stopping_rounds=500)\n",
    "  lgb_model.save_model(f'../working/trees/{fold}.lgb')\n",
    "  dvalid['lgb_pred'] = lgb_model.predict(dvalid[cols])\n",
    "  \n",
    "  lgb_score = calc_metric({'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values, 'pred': dvalid.lgb_pred.values})\n",
    "  ic(lgb_score)\n",
    "  score = calc_metric({'id': dvalid.id.values, 'cell_id': dvalid.cell_id.values, 'pred': (dvalid.cb_pred.values * 0.3 + dvalid.lgb_pred.values * 0.7)})\n",
    "  ic(score)\n",
    "  \n",
    "  merge_scores.append(merge_score)\n",
    "  cbt_scores.append(cbt_score)\n",
    "  lgb_scores.append(lgb_score)\n",
    "  scores.append(score)\n",
    "  ic(fold, \n",
    "     np.asarray(merge_scores).mean(), \n",
    "     np.asarray(cbt_scores).mean(), \n",
    "     np.asarray(lgb_scores).mean(),\n",
    "     np.asarray(scores).mean(),\n",
    "     )\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'feat_importances' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_41040/4086542548.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgezi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbt_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/work/pikachu/utils/gezi/plot.py\u001b[0m in \u001b[0;36mfeature_importance\u001b[0;34m(model, topn)\u001b[0m\n\u001b[1;32m    823\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lightgbm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0mfeat_importances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m   \u001b[0msorted_idxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_importances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtopn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0msorted_idxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_idxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtopn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'feat_importances' referenced before assignment"
     ]
    }
   ],
   "source": [
    "gezi.plot.feature_importance(cbt_model, topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gezi.plot.feature_importance(lgb_model, topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1925003cfa3979ae366740114cfe890bf8d7ad5b88e4afe0ec571fe261ed45e3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
