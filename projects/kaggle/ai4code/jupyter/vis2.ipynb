{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../../../../utils')\n",
    "sys.path.append('../../../../third')\n",
    "from gezi.common import *\n",
    "from src.config import *\n",
    "from src.preprocess import *\n",
    "from src.eval import *\n",
    "gezi.init_flags()\n",
    "gezi.set_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 7\n",
    "root = f'../working/offline/{V}/0'\n",
    "# pairwise two tower, recall model\n",
    "# p2t_model = 'all-mpnet-base-v2.flag-pairwise14-2-pre_ext_emlm_mlm.ep1.eval'\n",
    "# p2t_model = 'all-mpnet-base-v2.flag-pairwise14-2'\n",
    "p2t_model = 'all-mpnet-base-v2.flag-pairwise14-2-pre_mlm3'\n",
    "p2t_model2 = 'pmminilm.flag-pairwise14-2-pre_emlm_mlm-mmnilm'\n",
    "p2t_model2 = 'pmminilm.flag-pairwise14-2'\n",
    "# pairwise concat, rank model\n",
    "pc_model = 'deberta-v3-small.flag-pairwise14-4-cat-insert-extpred-ft.neg_rand_prob-0.neg_strategy-rand-sample.eval'\n",
    "# context model\n",
    "context_model = 'deberta-v3-small.flag-context4-2-d'\n",
    "context_model2 = 'lsg-mminilm.flag-context4-3-d-s-mminilm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('../working/train.fea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cell_id', 'cell_type', 'source', 'id', 'n_words', 'cid', 'ancestor_id',\n",
       "       'parent_id', 'n_cell', 'n_code_cell', 'n_markdown_cell',\n",
       "       'markdown_frac', 'rank', 'code_rank', 'markdown_rank', 'rel_rank',\n",
       "       'global_rank', 'local_rank', 'pct_rank', 'fold', 'worker'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>rank</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>rel_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>1862f0a6</td>\n",
       "      <td>0</td>\n",
       "      <td>code</td>\n",
       "      <td>0.0323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>448eb224</td>\n",
       "      <td>1</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.0484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>2a9e43d6</td>\n",
       "      <td>2</td>\n",
       "      <td>code</td>\n",
       "      <td>0.0645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>7e2f170a</td>\n",
       "      <td>3</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.0806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00001756c60be8</td>\n",
       "      <td>038b763d</td>\n",
       "      <td>4</td>\n",
       "      <td>code</td>\n",
       "      <td>0.0968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370641</th>\n",
       "      <td>fffe1d764579d5</td>\n",
       "      <td>5369934b</td>\n",
       "      <td>67</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.9597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370642</th>\n",
       "      <td>fffe1d764579d5</td>\n",
       "      <td>ac9db030</td>\n",
       "      <td>68</td>\n",
       "      <td>code</td>\n",
       "      <td>0.9677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370643</th>\n",
       "      <td>fffe1d764579d5</td>\n",
       "      <td>a8ffc8b4</td>\n",
       "      <td>69</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.9758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370644</th>\n",
       "      <td>fffe1d764579d5</td>\n",
       "      <td>70455170</td>\n",
       "      <td>70</td>\n",
       "      <td>code</td>\n",
       "      <td>0.9839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370645</th>\n",
       "      <td>fffe1d764579d5</td>\n",
       "      <td>380852e6</td>\n",
       "      <td>71</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.9919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6370646 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id   cell_id  rank cell_type  rel_rank\n",
       "0        00001756c60be8  1862f0a6     0      code    0.0323\n",
       "1        00001756c60be8  448eb224     1  markdown    0.0484\n",
       "2        00001756c60be8  2a9e43d6     2      code    0.0645\n",
       "3        00001756c60be8  7e2f170a     3  markdown    0.0806\n",
       "4        00001756c60be8  038b763d     4      code    0.0968\n",
       "...                 ...       ...   ...       ...       ...\n",
       "6370641  fffe1d764579d5  5369934b    67  markdown    0.9597\n",
       "6370642  fffe1d764579d5  ac9db030    68      code    0.9677\n",
       "6370643  fffe1d764579d5  a8ffc8b4    69  markdown    0.9758\n",
       "6370644  fffe1d764579d5  70455170    70      code    0.9839\n",
       "6370645  fffe1d764579d5  380852e6    71  markdown    0.9919\n",
       "\n",
       "[6370646 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = df[['id', 'cell_id', 'rank', 'cell_type', 'rel_rank']]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = gezi.load(f'{root}/{p2t_model}/valid.pkl')\n",
    "dxp = pd.DataFrame(xp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dxp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8906600693426994"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_metric(xp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8940493638363678"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_metric(xp, 'cls_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5fc040f4f340b5b530cf85687053b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calc_metrics:   0%|          | 0/27590 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = calc_metrics(xp, 'pred')\n",
    "# scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxp = to_df(xp, groupby=False, key='pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dxp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxp = dxp[['id', 'cell_id', 'rank', 'cell_type', 'rel_rank', 'pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = scores.sort_values('score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxp.loc[dxp[\"cell_type\"] == 'code',\n",
    "        'pred'] = dxp.loc[dxp[\"cell_type\"] == 'code', 'rel_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis(idx):\n",
    "  # print(scores.score.values[idx])\n",
    "  id = scores.id.values[idx]\n",
    "  id = '4562d150cadf6a'\n",
    "  id = '1a7d96060f8e36'\n",
    "  id = '674983f1fb6a94'\n",
    "  id = '2d93ad6380413d'\n",
    "  id = 'a6073f4fdf1845'\n",
    "  d2 = dxp[dxp.id==id]\n",
    "  ic(scores[scores.id==id])\n",
    "  gezi.plot.display_side_by_side((d[d.id==id], 'gt'), (d2.sort_values('pred'), 'pred'))\n",
    "  d_ = df[['id', 'cell_id', 'rank', 'cell_type', 'rel_rank', 'source']]\n",
    "  d_ = d_[d_.id==id]\n",
    "  display(d_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08/08/22 21:32:10] 1115278365.py:10 in vis()\n",
      "                    scores[scores.id==id]:                    id  score\n",
      "                                           19754  a6073f4fdf1845 0.8794\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style='border: 1px solid black;'><td style=\"text-align:left; border-left: 1px solid #000;border-right: 1px solid #000;min-width: 50%;width: 50%;\"><b>gt</b><br><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>rank</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>rel_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4144473</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>58c2cc54</td>\n",
       "      <td>0</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.0172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144474</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>3c8ef895</td>\n",
       "      <td>1</td>\n",
       "      <td>code</td>\n",
       "      <td>0.0345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144475</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>1e525ebb</td>\n",
       "      <td>2</td>\n",
       "      <td>code</td>\n",
       "      <td>0.0690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144476</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>5681077e</td>\n",
       "      <td>3</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.0862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144477</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>290ae46d</td>\n",
       "      <td>4</td>\n",
       "      <td>code</td>\n",
       "      <td>0.1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144478</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>ab7ab2ad</td>\n",
       "      <td>5</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.1207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144479</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>e708def2</td>\n",
       "      <td>6</td>\n",
       "      <td>code</td>\n",
       "      <td>0.1379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144480</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>635c05d1</td>\n",
       "      <td>7</td>\n",
       "      <td>code</td>\n",
       "      <td>0.1724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144481</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>11b29874</td>\n",
       "      <td>8</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.1897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144482</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>65c3c0f0</td>\n",
       "      <td>9</td>\n",
       "      <td>code</td>\n",
       "      <td>0.2069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144483</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>1a5c5090</td>\n",
       "      <td>10</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.2184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144484</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>ec2213c7</td>\n",
       "      <td>11</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.2299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144485</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>41111796</td>\n",
       "      <td>12</td>\n",
       "      <td>code</td>\n",
       "      <td>0.2414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144486</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>7b7f132f</td>\n",
       "      <td>13</td>\n",
       "      <td>code</td>\n",
       "      <td>0.2759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144487</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>a5a7469c</td>\n",
       "      <td>14</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.2874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144488</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>9c9fae82</td>\n",
       "      <td>15</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.2989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144489</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>48a8c96e</td>\n",
       "      <td>16</td>\n",
       "      <td>code</td>\n",
       "      <td>0.3103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144490</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>bfab3857</td>\n",
       "      <td>17</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.3276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144491</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>5fb275e7</td>\n",
       "      <td>18</td>\n",
       "      <td>code</td>\n",
       "      <td>0.3448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144492</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>af445b8a</td>\n",
       "      <td>19</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.3621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144493</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>97cfdf6a</td>\n",
       "      <td>20</td>\n",
       "      <td>code</td>\n",
       "      <td>0.3793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144494</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>cf38a788</td>\n",
       "      <td>21</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.3966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144495</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>0613c5df</td>\n",
       "      <td>22</td>\n",
       "      <td>code</td>\n",
       "      <td>0.4138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144496</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>fbc0e41b</td>\n",
       "      <td>23</td>\n",
       "      <td>code</td>\n",
       "      <td>0.4483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144497</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>d699a100</td>\n",
       "      <td>24</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.4655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144498</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>5dbc7ad8</td>\n",
       "      <td>25</td>\n",
       "      <td>code</td>\n",
       "      <td>0.4828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144499</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>ddd49d26</td>\n",
       "      <td>26</td>\n",
       "      <td>code</td>\n",
       "      <td>0.5172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144500</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>520354c2</td>\n",
       "      <td>27</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.5345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144501</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>d2905539</td>\n",
       "      <td>28</td>\n",
       "      <td>code</td>\n",
       "      <td>0.5517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144502</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>2446880b</td>\n",
       "      <td>29</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.5690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144503</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>d31c0f20</td>\n",
       "      <td>30</td>\n",
       "      <td>code</td>\n",
       "      <td>0.5862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144504</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>3c2f688c</td>\n",
       "      <td>31</td>\n",
       "      <td>code</td>\n",
       "      <td>0.6207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144505</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>e93dd66b</td>\n",
       "      <td>32</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.6276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144506</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>9e45ffa9</td>\n",
       "      <td>33</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.6345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144507</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>7b814f1e</td>\n",
       "      <td>34</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.6414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144508</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>d508aa83</td>\n",
       "      <td>35</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.6483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144509</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>365be679</td>\n",
       "      <td>36</td>\n",
       "      <td>code</td>\n",
       "      <td>0.6552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144510</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>b8fa388a</td>\n",
       "      <td>37</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.6724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144511</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>b2738a40</td>\n",
       "      <td>38</td>\n",
       "      <td>code</td>\n",
       "      <td>0.6897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144512</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>2e037a59</td>\n",
       "      <td>39</td>\n",
       "      <td>code</td>\n",
       "      <td>0.7241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144513</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>375cc5b5</td>\n",
       "      <td>40</td>\n",
       "      <td>code</td>\n",
       "      <td>0.7586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144514</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>5348a538</td>\n",
       "      <td>41</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.7759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144515</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>af635b97</td>\n",
       "      <td>42</td>\n",
       "      <td>code</td>\n",
       "      <td>0.7931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144516</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>2050745b</td>\n",
       "      <td>43</td>\n",
       "      <td>code</td>\n",
       "      <td>0.8276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144517</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>ba4f96a8</td>\n",
       "      <td>44</td>\n",
       "      <td>code</td>\n",
       "      <td>0.8621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144518</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>ea75e4e6</td>\n",
       "      <td>45</td>\n",
       "      <td>code</td>\n",
       "      <td>0.8966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144519</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>c748ab74</td>\n",
       "      <td>46</td>\n",
       "      <td>code</td>\n",
       "      <td>0.9310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144520</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>f2e1079a</td>\n",
       "      <td>47</td>\n",
       "      <td>code</td>\n",
       "      <td>0.9655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></td><td style=\"text-align:left; border-left: 1px solid #000;border-right: 1px solid #000;min-width: 50%;width: 50%;\"><b>pred</b><br><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>rank</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>rel_rank</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>810496</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>58c2cc54</td>\n",
       "      <td>0</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810499</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>5681077e</td>\n",
       "      <td>3</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.0862</td>\n",
       "      <td>0.0172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810511</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>9c9fae82</td>\n",
       "      <td>15</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.2988</td>\n",
       "      <td>0.0172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810497</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>3c8ef895</td>\n",
       "      <td>1</td>\n",
       "      <td>code</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810498</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>1e525ebb</td>\n",
       "      <td>2</td>\n",
       "      <td>code</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.0690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810500</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>290ae46d</td>\n",
       "      <td>4</td>\n",
       "      <td>code</td>\n",
       "      <td>0.1035</td>\n",
       "      <td>0.1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810501</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>ab7ab2ad</td>\n",
       "      <td>5</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.1207</td>\n",
       "      <td>0.1207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810502</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>e708def2</td>\n",
       "      <td>6</td>\n",
       "      <td>code</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.1379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810503</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>635c05d1</td>\n",
       "      <td>7</td>\n",
       "      <td>code</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>0.1724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810504</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>11b29874</td>\n",
       "      <td>8</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.1897</td>\n",
       "      <td>0.1897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810505</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>65c3c0f0</td>\n",
       "      <td>9</td>\n",
       "      <td>code</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.2069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810508</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>41111796</td>\n",
       "      <td>12</td>\n",
       "      <td>code</td>\n",
       "      <td>0.2413</td>\n",
       "      <td>0.2413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810509</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>7b7f132f</td>\n",
       "      <td>13</td>\n",
       "      <td>code</td>\n",
       "      <td>0.2759</td>\n",
       "      <td>0.2759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810507</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>ec2213c7</td>\n",
       "      <td>11</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.2299</td>\n",
       "      <td>0.2931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810510</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>a5a7469c</td>\n",
       "      <td>14</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.2874</td>\n",
       "      <td>0.2931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810512</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>48a8c96e</td>\n",
       "      <td>16</td>\n",
       "      <td>code</td>\n",
       "      <td>0.3103</td>\n",
       "      <td>0.3103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810514</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>5fb275e7</td>\n",
       "      <td>18</td>\n",
       "      <td>code</td>\n",
       "      <td>0.3447</td>\n",
       "      <td>0.3447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810515</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>af445b8a</td>\n",
       "      <td>19</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.3621</td>\n",
       "      <td>0.3621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810506</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>1a5c5090</td>\n",
       "      <td>10</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.2184</td>\n",
       "      <td>0.3621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810516</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>97cfdf6a</td>\n",
       "      <td>20</td>\n",
       "      <td>code</td>\n",
       "      <td>0.3794</td>\n",
       "      <td>0.3794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810517</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>cf38a788</td>\n",
       "      <td>21</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.3965</td>\n",
       "      <td>0.3966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810518</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>0613c5df</td>\n",
       "      <td>22</td>\n",
       "      <td>code</td>\n",
       "      <td>0.4138</td>\n",
       "      <td>0.4138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810519</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>fbc0e41b</td>\n",
       "      <td>23</td>\n",
       "      <td>code</td>\n",
       "      <td>0.4482</td>\n",
       "      <td>0.4482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810521</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>5dbc7ad8</td>\n",
       "      <td>25</td>\n",
       "      <td>code</td>\n",
       "      <td>0.4827</td>\n",
       "      <td>0.4827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810520</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>d699a100</td>\n",
       "      <td>24</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.4656</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810522</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>ddd49d26</td>\n",
       "      <td>26</td>\n",
       "      <td>code</td>\n",
       "      <td>0.5171</td>\n",
       "      <td>0.5171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810523</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>520354c2</td>\n",
       "      <td>27</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>0.5345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810513</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>bfab3857</td>\n",
       "      <td>17</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.3276</td>\n",
       "      <td>0.5345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810524</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>d2905539</td>\n",
       "      <td>28</td>\n",
       "      <td>code</td>\n",
       "      <td>0.5518</td>\n",
       "      <td>0.5518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810526</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>d31c0f20</td>\n",
       "      <td>30</td>\n",
       "      <td>code</td>\n",
       "      <td>0.5864</td>\n",
       "      <td>0.5864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810525</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>2446880b</td>\n",
       "      <td>29</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.5688</td>\n",
       "      <td>0.6034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810527</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>3c2f688c</td>\n",
       "      <td>31</td>\n",
       "      <td>code</td>\n",
       "      <td>0.6206</td>\n",
       "      <td>0.6206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810531</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>d508aa83</td>\n",
       "      <td>35</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.6484</td>\n",
       "      <td>0.6379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810532</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>365be679</td>\n",
       "      <td>36</td>\n",
       "      <td>code</td>\n",
       "      <td>0.6553</td>\n",
       "      <td>0.6553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810528</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>e93dd66b</td>\n",
       "      <td>32</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.6274</td>\n",
       "      <td>0.6724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810534</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>b2738a40</td>\n",
       "      <td>38</td>\n",
       "      <td>code</td>\n",
       "      <td>0.6895</td>\n",
       "      <td>0.6895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810537</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>5348a538</td>\n",
       "      <td>41</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.7759</td>\n",
       "      <td>0.7069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810535</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>2e037a59</td>\n",
       "      <td>39</td>\n",
       "      <td>code</td>\n",
       "      <td>0.7241</td>\n",
       "      <td>0.7241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810533</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>b8fa388a</td>\n",
       "      <td>37</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.6724</td>\n",
       "      <td>0.7414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810536</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>375cc5b5</td>\n",
       "      <td>40</td>\n",
       "      <td>code</td>\n",
       "      <td>0.7588</td>\n",
       "      <td>0.7588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810538</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>af635b97</td>\n",
       "      <td>42</td>\n",
       "      <td>code</td>\n",
       "      <td>0.7930</td>\n",
       "      <td>0.7930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810539</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>2050745b</td>\n",
       "      <td>43</td>\n",
       "      <td>code</td>\n",
       "      <td>0.8276</td>\n",
       "      <td>0.8276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810540</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>ba4f96a8</td>\n",
       "      <td>44</td>\n",
       "      <td>code</td>\n",
       "      <td>0.8623</td>\n",
       "      <td>0.8623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810541</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>ea75e4e6</td>\n",
       "      <td>45</td>\n",
       "      <td>code</td>\n",
       "      <td>0.8965</td>\n",
       "      <td>0.8965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810542</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>c748ab74</td>\n",
       "      <td>46</td>\n",
       "      <td>code</td>\n",
       "      <td>0.9312</td>\n",
       "      <td>0.9312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810543</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>f2e1079a</td>\n",
       "      <td>47</td>\n",
       "      <td>code</td>\n",
       "      <td>0.9653</td>\n",
       "      <td>0.9653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810529</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>9e45ffa9</td>\n",
       "      <td>33</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.6343</td>\n",
       "      <td>0.9828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810530</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>7b814f1e</td>\n",
       "      <td>34</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.6416</td>\n",
       "      <td>0.9828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></td></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>rank</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>rel_rank</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4144473</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>58c2cc54</td>\n",
       "      <td>0</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.0172</td>\n",
       "      <td># Playing Surface Analysis\\n![](https://i.imgur.com/ZsERLAT.png)\\n## Lateral movement and increased injury risk.\\n\\nThis report contains my analysis for the 2019 NFL 1st and Future competition. The competition tasked data scientists to investigate the relationship between the playing surface and the injury and performance of National Football League (NFL) athletes and to examine factors that may contribute to lower extremity injuries.\\n\\nI propose a metric for measuring the angle between ath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144474</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>3c8ef895</td>\n",
       "      <td>1</td>\n",
       "      <td>code</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>import pandas as pd\\nimport numpy as np\\nimport seaborn as sns\\nimport matplotlib.pylab as plt\\nimport os\\nimport psutil\\n\\nimport lightgbm as lgb\\nfrom sklearn.model_selection import train_test_split\\nimport random\\nimport sklearn\\nfrom itertools import cycle, islice\\n\\nimport warnings\\nwarnings.filterwarnings(\"ignore\")\\n\\nfrom tqdm.notebook import tqdm\\npd.set_option('max_columns', 500)\\nplt.style.use('fivethirtyeight')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144475</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>1e525ebb</td>\n",
       "      <td>2</td>\n",
       "      <td>code</td>\n",
       "      <td>0.0690</td>\n",
       "      <td># Read in data\\ntracks = pd.read_csv('../input/nfl-playing-surface-analytics/PlayerTrackData.csv',\\n                        dtype={'time':'float64',\\n                                'x':'float16',\\n                                'y':'float16',\\n                                'dir': 'float16',\\n                                'dis': 'float16',\\n                                'o':'float16',\\n                                's':'float16'})\\n\\nplays = pd.read_csv('../input/nfl-playing-surface...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144476</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>5681077e</td>\n",
       "      <td>3</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.0862</td>\n",
       "      <td># Background\\nThere has long been professional and academic interest in the differences regarding athletic performance measures and injury occurrence on various surface types (Meyers and Barnhill, 2004; Powell and Schootman, 1992). Recent studies have specifically examined synthetic turf (Mack et al., 2018; Loughran et al., 2019). These observational studies only show a correlation in injury rate-- they don’t make assertions about the specific mechanisms associated with lower body injury. My...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144477</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>290ae46d</td>\n",
       "      <td>4</td>\n",
       "      <td>code</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>plt.style.use('fivethirtyeight')\\n# Find Injury Rate by Surface\\ninjury_playkeys = injury['PlayKey'].unique()\\nplays['counter'] = 1 # Column used when grouping to count\\nplays['isInjuryPlay'] = False\\nplays.loc[plays['PlayKey'].isin(injury_playkeys), 'isInjuryPlay'] = True\\n\\n# Plot Results\\nfig, ax = plt.subplots(1, 1, figsize=(8, 6))\\n(plays.groupby('FieldType')[['isInjuryPlay']].mean() * 100000).plot(kind='bar', ax=ax)\\nax.get_legend().remove()\\nax.set_xlabel('')\\nax.set_title('Lower Body...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144478</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>ab7ab2ad</td>\n",
       "      <td>5</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.1207</td>\n",
       "      <td># Focusing on the players and plays at high risk\\n\\nIt’s intuitive, and quickly reveals itself in the data that certain players are at higher risk than others when it comes to NC lower body injuries. Among  the 100+ injuries from  the 2 seasons of game play, 70% (74/105) were sustained by just three positions (Defensive Backs, Linebackers and Wide Receivers). When thinking about why these positions might be at higher risk, I envisioned the movements commonly made by these players. I was stru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144479</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>e708def2</td>\n",
       "      <td>6</td>\n",
       "      <td>code</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>#### USED FOR SLIDES\\n\\n# ax = injury_detailed.groupby('RosterPosition_notplay')['PlayerKey'].count().sort_values() \\\\n#     .plot(kind='barh', title='Non-Contact Injuries', figsize=(8, 5))\\n# count = 0\\n# for x in ax.patches:\\n#     if count &gt; 3:\\n#         x.set_color('orange')\\n#     count += 1\\n# # plt.annotate('Three positions account for 2/3 of injuries', xy=(15, 1.5), fontsize=15, color='brown')\\n# # plt.arrow(15, 2, -0.3, 1, color='brown', head_width=0.2, head_length=0.2, lw=3)\\n# ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144480</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>635c05d1</td>\n",
       "      <td>7</td>\n",
       "      <td>code</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>fig, axes = plt.subplots(1, 2, figsize=(15, 5))\\nax = axes[0]\\ninjury_detailed.groupby('RosterPosition_notplay')['PlayerKey'].count().sort_values() \\\\n    .plot(kind='barh', title='Non-Contact Injuries', figsize=(10, 5), ax=ax)\\ncount = 0\\nfor x in ax.patches:\\n    if count &gt; 3:\\n        x.set_color('orange')\\n    count += 1\\n# plt.annotate('Three positions account for 2/3 of injuries', xy=(15, 1.5), fontsize=15, color='brown')\\n# plt.arrow(15, 2, -0.3, 1, color='brown', head_width=0.2, head...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144481</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>11b29874</td>\n",
       "      <td>8</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.1897</td>\n",
       "      <td>Special teams plays are inherently different from a normal play. As one would expect, most of the injuries (roughly 2/3) in the data were for non-special team plays.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144482</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>65c3c0f0</td>\n",
       "      <td>9</td>\n",
       "      <td>code</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>injury_detailed['PlayType_simple'] = injury_detailed['PlayType'] \\\\n    .replace({'Kickoff Not Returned' : 'Kickoff',\\n              'Kickoff Returned' : 'Kickoff',\\n              'Punt Not Returned' : 'Punt',\\n              'Punt Returned' : 'Punt'})\\n\\n\\nax = injury_detailed.groupby('PlayType_simple') \\\\n    .count()['PlayKey'] \\\\n    .sort_values().plot(kind='barh',\\n                        figsize=(8, 4),\\n                       title='Non-Contact Injury count by Play Type')\\ncount = 0\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144483</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>1a5c5090</td>\n",
       "      <td>10</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.2184</td>\n",
       "      <td>With these findings in mind, I decided to focus my analysis on **Defensive Backs, Linebackers, and Wide Receivers during rushing and passing plays**. Narrowing the scope of my analysis allows me to clearly identify player movements that involve high risk of injury for these positions and play types while removing the \"noise\" of plays and positions that have very different movement patterns.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144484</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>ec2213c7</td>\n",
       "      <td>11</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.2299</td>\n",
       "      <td># Data Cleaning and Standardizing the Orientation Feature\\n\\nIt was noted in the data description that the orientation feature may not be completely reliable when considering \"geography\". I have some experience working with the NGS data in the 2019 Big Data Bowl. During that competition, it was found that the orientation was shifted 90 degrees for one of the seasons' data. To correct for this orientation difference, I determined the plays which appeared to be shifted and standardized them as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144485</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>41111796</td>\n",
       "      <td>12</td>\n",
       "      <td>code</td>\n",
       "      <td>0.2414</td>\n",
       "      <td># Remove any data for a play 0.1 second before snap\\n# print(tracks.shape)\\ntracks_snap = tracks[['PlayKey','x','y','time','event']].query('event == \"ball_snap\"')\\ntracks_snap = tracks_snap[['PlayKey','x','y','time']] \\\\n    .rename(columns={'x':'x_snap',\\n                     'y':'y_snap',\\n                     'time':'time_snap'}).copy()\\ntracks = tracks.merge(tracks_snap, on='PlayKey', how='left')\\ntracks = tracks.query('time &gt;= (time_snap - 0.1)')\\n# print(tracks.shape)\\n\\n# Remove any d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144486</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>7b7f132f</td>\n",
       "      <td>13</td>\n",
       "      <td>code</td>\n",
       "      <td>0.2759</td>\n",
       "      <td>tracks.query('event == \"ball_snap\"')['o'] \\\\n    .plot(kind='hist',\\n          bins=50,\\n          figsize=(15, 5),\\n          title='Distribution of Orientation during Snap after Data Cleaning')\\nplt.show()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144487</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>a5a7469c</td>\n",
       "      <td>14</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.2874</td>\n",
       "      <td># Computing the Orientation-Movement Angle\\n\\nDefensive backs and Linebackers have responsibilities to track offensive players- they’re mirroring quick directional movements. As compared to their offensive opponents, they aren’t putting a lot of forethought into their path. Could this be placing statistically more strain on their knees and ankles? Wide receivers make quick movements down field and then make cuts in their routes to create space between themselves and defenders. Could lateral ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144488</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>9c9fae82</td>\n",
       "      <td>15</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.2989</td>\n",
       "      <td>To quantify these types of lateral movements, I can calculate the angle between the direction a player is moving and the orientation he is facing.\\n\\n![](https://i.imgur.com/OmtVL37.png)\\n\\nI created three specific movement groups based on the calculated angle: **Forward Movement** is when a player’s orientation is generally in line with the direction he’s moving; **Lateral Movement** is when a player is moving from side to side; and **Backpedaling** is when a player is moving in the opposit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144489</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>48a8c96e</td>\n",
       "      <td>16</td>\n",
       "      <td>code</td>\n",
       "      <td>0.3103</td>\n",
       "      <td># O vs Dir feature\\ntracks['o_dir_diff1'] = np.abs(tracks['o'] - tracks['dir'])\\ntracks['o_dir_diff2'] = np.abs(tracks['o'] - (tracks['dir'] - 360))\\ntracks['o_dir_diff3'] = np.abs(tracks['o'] - (tracks['dir'] + 360))\\ntracks['o_dir_diff'] = tracks[['o_dir_diff1','o_dir_diff2','o_dir_diff3']].min(axis=1)\\ntracks = tracks.drop(['o_dir_diff1','o_dir_diff2','o_dir_diff3'], axis=1)\\n\\n# Create movement groups\\ntracks['OffsetAngleGroup'] = 'Forward'\\ntracks.loc[tracks['o_dir_diff'] &gt;= 75, 'Offset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144490</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>bfab3857</td>\n",
       "      <td>17</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.3276</td>\n",
       "      <td># Analysis of movement category over duration of play\\n\\nI found it useful to visualize the percentage of time a given position spends using each of these three movement categories during a play. Wide Receivers in our dataset tend to move forward right after the snap use lateral movement and backpedaling 2 to 3 seconds after the play. Defensive Backs spend much of the beginning of a play backpedaling and then quickly change to lateral or forward movement. Linebackers appear to have a mix of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144491</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>5fb275e7</td>\n",
       "      <td>18</td>\n",
       "      <td>code</td>\n",
       "      <td>0.3448</td>\n",
       "      <td>fig, axes = plt.subplots(1, 3, figsize=(15, 4))\\n# Linebacker\\nax=axes[0]\\nt_group = tracks.query('isRushPass and Position_inj == \"Linebacker\" and time_since_snap &lt; 5 and s &gt; 0') \\\\n    .groupby(['time_since_snap','OffsetAngleGroup'])['OffsetAngleGroup'] \\\\n    .count() \\\\n    .unstack('OffsetAngleGroup')\\nt_group.apply(lambda x: 100 * x / float(x.sum()), axis=1) \\\\n    .plot(kind='area', stacked=True, alpha=0.5, ax=ax, title='Linebacker')\\nfor tick in ax.get_xticklabels():\\n    tick.set_rot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144492</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>af445b8a</td>\n",
       "      <td>19</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.3621</td>\n",
       "      <td># Lateral Movement During Plays is Linked to Injury\\nAfter looking at the data, it was clear to me that one factor closely linked to player injury was the amount of time during a play that he spent in lateral movement.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144493</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>97cfdf6a</td>\n",
       "      <td>20</td>\n",
       "      <td>code</td>\n",
       "      <td>0.3793</td>\n",
       "      <td>t_group = tracks[['s','isRushPass','isInjuryPronePos',\\n                  'PlayKey','OffsetAngleGroup','isInjuryPlay']] \\\\n    .loc[tracks['isRushPass'] &amp; tracks['isInjuryPronePos']] \\\\n    .groupby(['OffsetAngleGroup','isInjuryPlay'])['PlayKey'] \\\\n    .count() \\\\n    .unstack(['OffsetAngleGroup'])\\n\\nfig, ax = plt.subplots(1,1, figsize=(8, 8))\\nt_group.apply(lambda x: 100 * x / float(x.sum()), axis=1)['Lateral'] \\\\n    .plot(kind='bar',\\n          title='Time spent in Lateral Movement',\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144494</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>cf38a788</td>\n",
       "      <td>21</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.3966</td>\n",
       "      <td>When we look closer at the lateral movement by position, I found this relationship between lateral movement and injury is found across all three of my focus positions (Wide Receivers, Linebackers and Defensive Backs).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144495</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>0613c5df</td>\n",
       "      <td>22</td>\n",
       "      <td>code</td>\n",
       "      <td>0.4138</td>\n",
       "      <td># Numbers used in powerpoint presentation.\\n# (tracks.query('isRushPass') \\\\n#     .groupby(['Position_inj','isInjuryPlay'])['isLateralMovement'].mean() * 100) \\\\n#     .unstack('isInjuryPlay')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144496</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>fbc0e41b</td>\n",
       "      <td>23</td>\n",
       "      <td>code</td>\n",
       "      <td>0.4483</td>\n",
       "      <td>injury_prone_pos = ['Wide Receiver', 'Linebacker', 'Defensive Back']\\nax = (tracks.query('Position_inj in @injury_prone_pos and isRushPass') \\\\n    .groupby(['Position_inj','isInjuryPlay'])['isLateralMovement'].mean() * 100) \\\\n    .unstack('isInjuryPlay').plot(kind='barh', figsize=(10, 5),\\n                                  title='Time Spent in Lateral Movement')\\n\\n# set individual bar lables using above list\\nfor i in ax.patches:\\n    # get_width pulls left or right; get_y pushes up or do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144497</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>d699a100</td>\n",
       "      <td>24</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.4655</td>\n",
       "      <td># No evidence to support a link between playing surface and lateral movement\\n\\nPrevious observational studies have shown a link between injury and playing surface. My analysis for this report identifies an association between NC injuries and lateral movement during game play. Now I wonder: is there a measurable difference between time spent in lateral movement based  on playing surface? My hypothesis would be that, if players gain more traction when interacting with a type of turf, then I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144498</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>5dbc7ad8</td>\n",
       "      <td>25</td>\n",
       "      <td>code</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>fig, ax= plt.subplots(1,1, figsize=(15, 5))\\nsns.distplot(tracks.query('FieldType == \"Natural\"')['o_dir_diff'].dropna(),\\n             hist=False, label='Natural', color='darkgreen')\\nsns.distplot(tracks.query('FieldType == \"Synthetic\"')['o_dir_diff'].dropna(),\\n             hist=False, label='Synthetic', color='mediumseagreen')\\nax.set_ylabel('% of play time')\\nax.set_xlabel('Orientation-Movement Angle')\\nax.set_title('Player movement angle by Turf Type')\\nax.legend(['Natural Turf', 'Synthe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144499</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>ddd49d26</td>\n",
       "      <td>26</td>\n",
       "      <td>code</td>\n",
       "      <td>0.5172</td>\n",
       "      <td>from scipy.stats import ks_2samp\\n\\nks_stat = ks_2samp(tracks.query('FieldType == \"Natural\"')['o_dir_diff'].dropna(),\\n        tracks.query('FieldType == \"Synthetic\"')['o_dir_diff'].dropna())[0]\\nprint(f'The Kolmogorov-Smirnov statistic on 2 samples is {ks_stat:0.4f}')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144500</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>520354c2</td>\n",
       "      <td>27</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.5345</td>\n",
       "      <td>I also compared the differences of time spent in lateral movement by field type. I broke down the percentages by positions in a similar manner to how I compared injury plays to non-injury plays. I found more commonalities than differences. The difference for each position  were all less than 1%.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144501</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>d2905539</td>\n",
       "      <td>28</td>\n",
       "      <td>code</td>\n",
       "      <td>0.5517</td>\n",
       "      <td>injury_prone_pos = ['Wide Receiver', 'Linebacker', 'Defensive Back']\\nmy_colors = list(islice(cycle(['darkgreen','mediumseagreen']), None, 3))\\nax = (tracks.query('Position_inj in @injury_prone_pos and isRushPass') \\\\n    .groupby(['Position_inj','FieldType'])['isLateralMovement'].mean() * 100) \\\\n    .unstack('FieldType').plot(kind='barh', figsize=(10, 5),\\n                               title='Time Spent in Lateral Movement',\\n                               color=my_colors)\\n\\n# set indivi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144502</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>2446880b</td>\n",
       "      <td>29</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.5690</td>\n",
       "      <td>I  created a regression model to capture any difference in the percent of lateral movement by player, based on features about the play. The regression included:\\n- Position (one-hot-encoded)\\n- PlayerDay (integer sequence reflecting timeline of a players participation in games)\\n- PlayerGame (Uniquely identifies player’s games)\\n- PlayerGamePlay (Ordered interger denoting the running count of plays the player has participated in during the game)\\n- Synthetic (binary indicator if field type i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144503</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>d31c0f20</td>\n",
       "      <td>30</td>\n",
       "      <td>code</td>\n",
       "      <td>0.5862</td>\n",
       "      <td># Data Prep for linear model\\n\\nplay_movement_dir = tracks.loc[tracks['Position_inj'].isin(injury_prone_pos) &amp;\\n                               tracks['isRushPass']] \\\\n    .groupby(['PlayKey','PlayerKey','OffsetAngleGroup','Position_inj','FieldType',\\n              'isInjuredPlayer','isInjuryPlay']) \\\\n    .count()['counter'] \\\\n    .unstack('OffsetAngleGroup') \\\\n    .fillna(0)\\nplay_mov_pct = play_movement_dir.apply(lambda x: 100 * x / float(x.sum()), axis=1)\\nplay_mov_pct = play_mov_pct.r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144504</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>3c2f688c</td>\n",
       "      <td>31</td>\n",
       "      <td>code</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>from sklearn.linear_model import LinearRegression\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\n\\nimport statsmodels.api as sm\\nfrom scipy import stats\\n\\n\\nFEATURES = ['PlayerDay','PlayerGame','PlayerGamePlay','Rush','Temperature','Defensive Back',\\n            'Linebacker', # , DB and WR as 0 is equalt\\n            'Wide Receiver',\\n            'Synthetic','isInjuryPlay']\\nX = play_mov_pct_w_feats[FEATURES]\\nX['isInjuryPlay'] = X['i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144505</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>e93dd66b</td>\n",
       "      <td>32</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.6276</td>\n",
       "      <td>This model wasn’t created for its predictive power, but rather as  an attempt to quantify the impact of each feature and its statistical significance. The R-squared value is quite low, however we can still gain insights from the model. The main insights are as follows:\\n1. The position type (Defensive Back, Linebacker, or Wide Receiver) has the strongest relationship with lateral movement.\\n2. Injury Play is also a strong indicator, this supports our analysis above.\\n3. Synthetic playing sur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144506</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>9e45ffa9</td>\n",
       "      <td>33</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.6345</td>\n",
       "      <td>## Conclusion and Recommendations\\n\\nSo there you have it. I've shown that high lateral movements have a strong relationship with injury plays. I've also shown that there isn't a relationship between playing surface and lateral movement. Because of that we can't conclude that turf type plays a role in increasing this specific type of high risk movement.\\n\\nGiven my findings I have the following suggestions for the NFL:\\n1. Monitor the percentage of lateral movement of players during game pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144507</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>7b814f1e</td>\n",
       "      <td>34</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.6414</td>\n",
       "      <td># References\\n- Murphy, D F. “Risk Factors for Lower Extremity Injury: a Review of the Literature.” British Journal of Sports Medicine, vol. 37, no. 1, Jan. 2003, pp. 13–29., doi:10.1136/bjsm.37.1.13.\\n- Stockman, J.a. “Incidence, Causes, and Severity of High School Football Injuries On FieldTurf Versus Natural Grass: A 5-Year Prospective Study.” Yearbook of Pediatrics, vol. 2006, 2006, pp. 333–335., doi:10.1016/s0084-3954(07)70202-6.\\n- Powell, John W., and Mario Schootman. “A Multivariate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144508</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>d508aa83</td>\n",
       "      <td>35</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.6483</td>\n",
       "      <td># Appendix\\n\\n## Details of Regression analysis\\n\\nExpand the cell below to see the full details of the regression model.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144509</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>365be679</td>\n",
       "      <td>36</td>\n",
       "      <td>code</td>\n",
       "      <td>0.6552</td>\n",
       "      <td>print(est2.summary())</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144510</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>b8fa388a</td>\n",
       "      <td>37</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.6724</td>\n",
       "      <td>## Machine Learning Model\\nBelow is an approach I worked on that did not provide conclusive results. I created three machine learning model based on players movement patterns. These models tried to predict using only player movement:\\n- What surface type was the player on\\n- If it was raining\\n- If it was snowing\\n\\nI chose these three models because I assumed that players movements would be impacted by rain and snow. If I was able to show similar accuracy when trying to predict playing surf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144511</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>b2738a40</td>\n",
       "      <td>38</td>\n",
       "      <td>code</td>\n",
       "      <td>0.6897</td>\n",
       "      <td># Preparing model training data\\ntracks_model = tracks.loc[(tracks['time_since_snap'] &lt; 5) &amp;\\n                           tracks['isRushPass'] &amp;\\n                           tracks['isInjuryPronePos']]\\n\\ntracks_model['a'] = tracks_model['a'].astype('float32')\\ntracks_model['s'] = tracks_model['s'].astype('float32')\\n\\n# Every Play is a row, - create features for every 10th of a second up until 5 seconds after snap\\npp_piv = tracks_model[['PlayKey',\\n                       'time_since_snap',\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144512</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>2e037a59</td>\n",
       "      <td>39</td>\n",
       "      <td>code</td>\n",
       "      <td>0.7241</td>\n",
       "      <td>plt.style.use('default')\\nax = pp_piv[o_dir_diff_cols].head(50).T \\\\n    .plot(title='Orientation-Movement Angle over first 5 seconds of play',\\n          figsize=(15, 4), color='grey')\\nax.get_legend().remove()\\nplt.show()\\nax = pp_piv[a_cols].head(50).T \\\\n    .plot(title='Acceleration over first 5 seconds of play',\\n         figsize=(15, 4), color='brown')\\nax.get_legend().remove()\\nplt.show()\\nax = pp_piv[s_cols].sample(50).T \\\\n    .plot(title='Speed over first 5 seconds of play',\\n    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144513</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>375cc5b5</td>\n",
       "      <td>40</td>\n",
       "      <td>code</td>\n",
       "      <td>0.7586</td>\n",
       "      <td># Add features for percipitation and snow based on weather feature\\nweather_percip_mapping = {\\n    'Controlled Climate' : False,\\n    'Sunny' : False,\\n    0 : False,\\n    'Cloudy' : False,\\n    'Clear' : False,\\n    'N/A Indoor' : False,\\n    'Partly sunny' : False,\\n    'N/A (Indoors)' : False,\\n    'Sunny and clear' : False,\\n    'Partly Cloudy' : False,\\n    'Snow' : True,\\n    'Indoor' : False,\\n    'Indoors' : False,\\n    'Showers' : True,\\n    'Rain' : True,\\n    'Clear and warm' : F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144514</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>5348a538</td>\n",
       "      <td>41</td>\n",
       "      <td>markdown</td>\n",
       "      <td>0.7759</td>\n",
       "      <td>## Show the first few rows of features used in the model\\n- s -&gt; speed features\\n- a -&gt; acceleration features\\n- o_dir_diff -&gt; angle difference between orientation and direction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144515</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>af635b97</td>\n",
       "      <td>42</td>\n",
       "      <td>code</td>\n",
       "      <td>0.7931</td>\n",
       "      <td># Add position\\npp_piv = pp_piv.merge(tracks_model[['Position_inj','PlayKey']].drop_duplicates(), on='PlayKey', how='left')\\npp_piv = pd.concat([pp_piv, pd.get_dummies(pp_piv['Position_inj'])], axis=1)\\npp_piv['Position_inj'] = pp_piv['Position_inj'].astype('category')\\n# Perform a train / test split\\nX = pp_piv.drop(['FieldType','PlayKey','isSynthetic','PlayType','Temperature',\\n                 'PlayerGame','PlayerDay','Weather','PlayerKey',\\n                 'Precipitation', 'Snow'], axis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144516</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>2050745b</td>\n",
       "      <td>43</td>\n",
       "      <td>code</td>\n",
       "      <td>0.8276</td>\n",
       "      <td>params = {}\\nparams['max_bin'] = 50\\nparams['learning_rate'] = 0.01\\nparams['boosting_type'] = 'gbdt'\\nparams['objective'] = 'binary'\\nparams['metric'] = 'auc'\\n\\n##################################################\\n# TRAIN MODEL TO PREDICT FIELD TYPE (isSynthetic)\\n##################################################\\n\\nX = pp_piv.drop(['FieldType','PlayKey','isSynthetic','PlayType','Temperature',\\n                 'PlayerGame','PlayerDay','Weather','PlayerKey',\\n                 'Precipitatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144517</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>ba4f96a8</td>\n",
       "      <td>44</td>\n",
       "      <td>code</td>\n",
       "      <td>0.8621</td>\n",
       "      <td>##################################################\\n# TRAIN MODEL TO PREDICT PRECIPITATION\\n##################################################\\n\\nX = pp_piv.drop(['FieldType','PlayKey','isSynthetic','PlayType','Temperature',\\n                 'PlayerGame','PlayerDay','Weather','PlayerKey',\\n                 'Precipitation', 'Snow'], axis=1)\\ny = pp_piv['Precipitation']\\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=529)\\n\\nd_train = lgb.Dataset(X_train, label=y_train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144518</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>ea75e4e6</td>\n",
       "      <td>45</td>\n",
       "      <td>code</td>\n",
       "      <td>0.8966</td>\n",
       "      <td>#####################################\\n# TRAIN MODEL TO PREDICT IF SNOWING\\n#####################################\\n\\nX = pp_piv.drop(['FieldType','PlayKey','isSynthetic','PlayType','Temperature',\\n                 'PlayerGame','PlayerDay','Weather','PlayerKey',\\n                 'Precipitation', 'Snow'], axis=1)\\ny = pp_piv['Snow']\\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=529)\\n\\nd_train = lgb.Dataset(X_train, label=y_train)#, categorical_feature=['PlayerKey'])...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144519</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>c748ab74</td>\n",
       "      <td>46</td>\n",
       "      <td>code</td>\n",
       "      <td>0.9310</td>\n",
       "      <td># Concat results\\nfi_df = pd.concat([fi_df_lgbm_model_SNOW, fi_df_lgbm_model_FieldType, fi_df_lgbm_model_PRECIP], axis=1)\\nfi_df.columns = ['snow_importance','fieldtype_importance','precipitation_importance']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144520</th>\n",
       "      <td>a6073f4fdf1845</td>\n",
       "      <td>f2e1079a</td>\n",
       "      <td>47</td>\n",
       "      <td>code</td>\n",
       "      <td>0.9655</td>\n",
       "      <td>fig, axes = plt.subplots(1,3,figsize=(15, 5))\\nfi_df.sort_values('fieldtype_importance', ascending=True).tail(10)[['fieldtype_importance']] \\\\n    .plot(kind='barh', ax=axes[0], title='Top 10 Features to predict FieldType')\\nfi_df.sort_values('precipitation_importance', ascending=True).tail(10)[['precipitation_importance']] \\\\n    .plot(kind='barh', ax=axes[1], title='Top 10 Features to predict precipitation')\\nfi_df.sort_values('snow_importance', ascending=True).tail(10)[['snow_importance']...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id   cell_id  rank cell_type  rel_rank  \\\n",
       "4144473  a6073f4fdf1845  58c2cc54     0  markdown    0.0172   \n",
       "4144474  a6073f4fdf1845  3c8ef895     1      code    0.0345   \n",
       "4144475  a6073f4fdf1845  1e525ebb     2      code    0.0690   \n",
       "4144476  a6073f4fdf1845  5681077e     3  markdown    0.0862   \n",
       "4144477  a6073f4fdf1845  290ae46d     4      code    0.1034   \n",
       "4144478  a6073f4fdf1845  ab7ab2ad     5  markdown    0.1207   \n",
       "4144479  a6073f4fdf1845  e708def2     6      code    0.1379   \n",
       "4144480  a6073f4fdf1845  635c05d1     7      code    0.1724   \n",
       "4144481  a6073f4fdf1845  11b29874     8  markdown    0.1897   \n",
       "4144482  a6073f4fdf1845  65c3c0f0     9      code    0.2069   \n",
       "4144483  a6073f4fdf1845  1a5c5090    10  markdown    0.2184   \n",
       "4144484  a6073f4fdf1845  ec2213c7    11  markdown    0.2299   \n",
       "4144485  a6073f4fdf1845  41111796    12      code    0.2414   \n",
       "4144486  a6073f4fdf1845  7b7f132f    13      code    0.2759   \n",
       "4144487  a6073f4fdf1845  a5a7469c    14  markdown    0.2874   \n",
       "4144488  a6073f4fdf1845  9c9fae82    15  markdown    0.2989   \n",
       "4144489  a6073f4fdf1845  48a8c96e    16      code    0.3103   \n",
       "4144490  a6073f4fdf1845  bfab3857    17  markdown    0.3276   \n",
       "4144491  a6073f4fdf1845  5fb275e7    18      code    0.3448   \n",
       "4144492  a6073f4fdf1845  af445b8a    19  markdown    0.3621   \n",
       "4144493  a6073f4fdf1845  97cfdf6a    20      code    0.3793   \n",
       "4144494  a6073f4fdf1845  cf38a788    21  markdown    0.3966   \n",
       "4144495  a6073f4fdf1845  0613c5df    22      code    0.4138   \n",
       "4144496  a6073f4fdf1845  fbc0e41b    23      code    0.4483   \n",
       "4144497  a6073f4fdf1845  d699a100    24  markdown    0.4655   \n",
       "4144498  a6073f4fdf1845  5dbc7ad8    25      code    0.4828   \n",
       "4144499  a6073f4fdf1845  ddd49d26    26      code    0.5172   \n",
       "4144500  a6073f4fdf1845  520354c2    27  markdown    0.5345   \n",
       "4144501  a6073f4fdf1845  d2905539    28      code    0.5517   \n",
       "4144502  a6073f4fdf1845  2446880b    29  markdown    0.5690   \n",
       "4144503  a6073f4fdf1845  d31c0f20    30      code    0.5862   \n",
       "4144504  a6073f4fdf1845  3c2f688c    31      code    0.6207   \n",
       "4144505  a6073f4fdf1845  e93dd66b    32  markdown    0.6276   \n",
       "4144506  a6073f4fdf1845  9e45ffa9    33  markdown    0.6345   \n",
       "4144507  a6073f4fdf1845  7b814f1e    34  markdown    0.6414   \n",
       "4144508  a6073f4fdf1845  d508aa83    35  markdown    0.6483   \n",
       "4144509  a6073f4fdf1845  365be679    36      code    0.6552   \n",
       "4144510  a6073f4fdf1845  b8fa388a    37  markdown    0.6724   \n",
       "4144511  a6073f4fdf1845  b2738a40    38      code    0.6897   \n",
       "4144512  a6073f4fdf1845  2e037a59    39      code    0.7241   \n",
       "4144513  a6073f4fdf1845  375cc5b5    40      code    0.7586   \n",
       "4144514  a6073f4fdf1845  5348a538    41  markdown    0.7759   \n",
       "4144515  a6073f4fdf1845  af635b97    42      code    0.7931   \n",
       "4144516  a6073f4fdf1845  2050745b    43      code    0.8276   \n",
       "4144517  a6073f4fdf1845  ba4f96a8    44      code    0.8621   \n",
       "4144518  a6073f4fdf1845  ea75e4e6    45      code    0.8966   \n",
       "4144519  a6073f4fdf1845  c748ab74    46      code    0.9310   \n",
       "4144520  a6073f4fdf1845  f2e1079a    47      code    0.9655   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      source  \n",
       "4144473  # Playing Surface Analysis\\n![](https://i.imgur.com/ZsERLAT.png)\\n## Lateral movement and increased injury risk.\\n\\nThis report contains my analysis for the 2019 NFL 1st and Future competition. The competition tasked data scientists to investigate the relationship between the playing surface and the injury and performance of National Football League (NFL) athletes and to examine factors that may contribute to lower extremity injuries.\\n\\nI propose a metric for measuring the angle between ath...  \n",
       "4144474                                                                            import pandas as pd\\nimport numpy as np\\nimport seaborn as sns\\nimport matplotlib.pylab as plt\\nimport os\\nimport psutil\\n\\nimport lightgbm as lgb\\nfrom sklearn.model_selection import train_test_split\\nimport random\\nimport sklearn\\nfrom itertools import cycle, islice\\n\\nimport warnings\\nwarnings.filterwarnings(\"ignore\")\\n\\nfrom tqdm.notebook import tqdm\\npd.set_option('max_columns', 500)\\nplt.style.use('fivethirtyeight')  \n",
       "4144475  # Read in data\\ntracks = pd.read_csv('../input/nfl-playing-surface-analytics/PlayerTrackData.csv',\\n                        dtype={'time':'float64',\\n                                'x':'float16',\\n                                'y':'float16',\\n                                'dir': 'float16',\\n                                'dis': 'float16',\\n                                'o':'float16',\\n                                's':'float16'})\\n\\nplays = pd.read_csv('../input/nfl-playing-surface...  \n",
       "4144476  # Background\\nThere has long been professional and academic interest in the differences regarding athletic performance measures and injury occurrence on various surface types (Meyers and Barnhill, 2004; Powell and Schootman, 1992). Recent studies have specifically examined synthetic turf (Mack et al., 2018; Loughran et al., 2019). These observational studies only show a correlation in injury rate-- they don’t make assertions about the specific mechanisms associated with lower body injury. My...  \n",
       "4144477  plt.style.use('fivethirtyeight')\\n# Find Injury Rate by Surface\\ninjury_playkeys = injury['PlayKey'].unique()\\nplays['counter'] = 1 # Column used when grouping to count\\nplays['isInjuryPlay'] = False\\nplays.loc[plays['PlayKey'].isin(injury_playkeys), 'isInjuryPlay'] = True\\n\\n# Plot Results\\nfig, ax = plt.subplots(1, 1, figsize=(8, 6))\\n(plays.groupby('FieldType')[['isInjuryPlay']].mean() * 100000).plot(kind='bar', ax=ax)\\nax.get_legend().remove()\\nax.set_xlabel('')\\nax.set_title('Lower Body...  \n",
       "4144478  # Focusing on the players and plays at high risk\\n\\nIt’s intuitive, and quickly reveals itself in the data that certain players are at higher risk than others when it comes to NC lower body injuries. Among  the 100+ injuries from  the 2 seasons of game play, 70% (74/105) were sustained by just three positions (Defensive Backs, Linebackers and Wide Receivers). When thinking about why these positions might be at higher risk, I envisioned the movements commonly made by these players. I was stru...  \n",
       "4144479  #### USED FOR SLIDES\\n\\n# ax = injury_detailed.groupby('RosterPosition_notplay')['PlayerKey'].count().sort_values() \\\\n#     .plot(kind='barh', title='Non-Contact Injuries', figsize=(8, 5))\\n# count = 0\\n# for x in ax.patches:\\n#     if count > 3:\\n#         x.set_color('orange')\\n#     count += 1\\n# # plt.annotate('Three positions account for 2/3 of injuries', xy=(15, 1.5), fontsize=15, color='brown')\\n# # plt.arrow(15, 2, -0.3, 1, color='brown', head_width=0.2, head_length=0.2, lw=3)\\n# ax...  \n",
       "4144480  fig, axes = plt.subplots(1, 2, figsize=(15, 5))\\nax = axes[0]\\ninjury_detailed.groupby('RosterPosition_notplay')['PlayerKey'].count().sort_values() \\\\n    .plot(kind='barh', title='Non-Contact Injuries', figsize=(10, 5), ax=ax)\\ncount = 0\\nfor x in ax.patches:\\n    if count > 3:\\n        x.set_color('orange')\\n    count += 1\\n# plt.annotate('Three positions account for 2/3 of injuries', xy=(15, 1.5), fontsize=15, color='brown')\\n# plt.arrow(15, 2, -0.3, 1, color='brown', head_width=0.2, head...  \n",
       "4144481                                                                                                                                                                                                                                                                                                                                                Special teams plays are inherently different from a normal play. As one would expect, most of the injuries (roughly 2/3) in the data were for non-special team plays.  \n",
       "4144482  injury_detailed['PlayType_simple'] = injury_detailed['PlayType'] \\\\n    .replace({'Kickoff Not Returned' : 'Kickoff',\\n              'Kickoff Returned' : 'Kickoff',\\n              'Punt Not Returned' : 'Punt',\\n              'Punt Returned' : 'Punt'})\\n\\n\\nax = injury_detailed.groupby('PlayType_simple') \\\\n    .count()['PlayKey'] \\\\n    .sort_values().plot(kind='barh',\\n                        figsize=(8, 4),\\n                       title='Non-Contact Injury count by Play Type')\\ncount = 0\\n...  \n",
       "4144483                                                                                                           With these findings in mind, I decided to focus my analysis on **Defensive Backs, Linebackers, and Wide Receivers during rushing and passing plays**. Narrowing the scope of my analysis allows me to clearly identify player movements that involve high risk of injury for these positions and play types while removing the \"noise\" of plays and positions that have very different movement patterns.   \n",
       "4144484  # Data Cleaning and Standardizing the Orientation Feature\\n\\nIt was noted in the data description that the orientation feature may not be completely reliable when considering \"geography\". I have some experience working with the NGS data in the 2019 Big Data Bowl. During that competition, it was found that the orientation was shifted 90 degrees for one of the seasons' data. To correct for this orientation difference, I determined the plays which appeared to be shifted and standardized them as...  \n",
       "4144485  # Remove any data for a play 0.1 second before snap\\n# print(tracks.shape)\\ntracks_snap = tracks[['PlayKey','x','y','time','event']].query('event == \"ball_snap\"')\\ntracks_snap = tracks_snap[['PlayKey','x','y','time']] \\\\n    .rename(columns={'x':'x_snap',\\n                     'y':'y_snap',\\n                     'time':'time_snap'}).copy()\\ntracks = tracks.merge(tracks_snap, on='PlayKey', how='left')\\ntracks = tracks.query('time >= (time_snap - 0.1)')\\n# print(tracks.shape)\\n\\n# Remove any d...  \n",
       "4144486                                                                                                                                                                                                                                                                                                      tracks.query('event == \"ball_snap\"')['o'] \\\\n    .plot(kind='hist',\\n          bins=50,\\n          figsize=(15, 5),\\n          title='Distribution of Orientation during Snap after Data Cleaning')\\nplt.show()  \n",
       "4144487  # Computing the Orientation-Movement Angle\\n\\nDefensive backs and Linebackers have responsibilities to track offensive players- they’re mirroring quick directional movements. As compared to their offensive opponents, they aren’t putting a lot of forethought into their path. Could this be placing statistically more strain on their knees and ankles? Wide receivers make quick movements down field and then make cuts in their routes to create space between themselves and defenders. Could lateral ...  \n",
       "4144488  To quantify these types of lateral movements, I can calculate the angle between the direction a player is moving and the orientation he is facing.\\n\\n![](https://i.imgur.com/OmtVL37.png)\\n\\nI created three specific movement groups based on the calculated angle: **Forward Movement** is when a player’s orientation is generally in line with the direction he’s moving; **Lateral Movement** is when a player is moving from side to side; and **Backpedaling** is when a player is moving in the opposit...  \n",
       "4144489  # O vs Dir feature\\ntracks['o_dir_diff1'] = np.abs(tracks['o'] - tracks['dir'])\\ntracks['o_dir_diff2'] = np.abs(tracks['o'] - (tracks['dir'] - 360))\\ntracks['o_dir_diff3'] = np.abs(tracks['o'] - (tracks['dir'] + 360))\\ntracks['o_dir_diff'] = tracks[['o_dir_diff1','o_dir_diff2','o_dir_diff3']].min(axis=1)\\ntracks = tracks.drop(['o_dir_diff1','o_dir_diff2','o_dir_diff3'], axis=1)\\n\\n# Create movement groups\\ntracks['OffsetAngleGroup'] = 'Forward'\\ntracks.loc[tracks['o_dir_diff'] >= 75, 'Offset...  \n",
       "4144490  # Analysis of movement category over duration of play\\n\\nI found it useful to visualize the percentage of time a given position spends using each of these three movement categories during a play. Wide Receivers in our dataset tend to move forward right after the snap use lateral movement and backpedaling 2 to 3 seconds after the play. Defensive Backs spend much of the beginning of a play backpedaling and then quickly change to lateral or forward movement. Linebackers appear to have a mix of ...  \n",
       "4144491  fig, axes = plt.subplots(1, 3, figsize=(15, 4))\\n# Linebacker\\nax=axes[0]\\nt_group = tracks.query('isRushPass and Position_inj == \"Linebacker\" and time_since_snap < 5 and s > 0') \\\\n    .groupby(['time_since_snap','OffsetAngleGroup'])['OffsetAngleGroup'] \\\\n    .count() \\\\n    .unstack('OffsetAngleGroup')\\nt_group.apply(lambda x: 100 * x / float(x.sum()), axis=1) \\\\n    .plot(kind='area', stacked=True, alpha=0.5, ax=ax, title='Linebacker')\\nfor tick in ax.get_xticklabels():\\n    tick.set_rot...  \n",
       "4144492                                                                                                                                                                                                                                                                                           # Lateral Movement During Plays is Linked to Injury\\nAfter looking at the data, it was clear to me that one factor closely linked to player injury was the amount of time during a play that he spent in lateral movement.  \n",
       "4144493  t_group = tracks[['s','isRushPass','isInjuryPronePos',\\n                  'PlayKey','OffsetAngleGroup','isInjuryPlay']] \\\\n    .loc[tracks['isRushPass'] & tracks['isInjuryPronePos']] \\\\n    .groupby(['OffsetAngleGroup','isInjuryPlay'])['PlayKey'] \\\\n    .count() \\\\n    .unstack(['OffsetAngleGroup'])\\n\\nfig, ax = plt.subplots(1,1, figsize=(8, 8))\\nt_group.apply(lambda x: 100 * x / float(x.sum()), axis=1)['Lateral'] \\\\n    .plot(kind='bar',\\n          title='Time spent in Lateral Movement',\\n ...  \n",
       "4144494                                                                                                                                                                                                                                                                                            When we look closer at the lateral movement by position, I found this relationship between lateral movement and injury is found across all three of my focus positions (Wide Receivers, Linebackers and Defensive Backs).  \n",
       "4144495                                                                                                                                                                                                                                                                                                                    # Numbers used in powerpoint presentation.\\n# (tracks.query('isRushPass') \\\\n#     .groupby(['Position_inj','isInjuryPlay'])['isLateralMovement'].mean() * 100) \\\\n#     .unstack('isInjuryPlay')  \n",
       "4144496  injury_prone_pos = ['Wide Receiver', 'Linebacker', 'Defensive Back']\\nax = (tracks.query('Position_inj in @injury_prone_pos and isRushPass') \\\\n    .groupby(['Position_inj','isInjuryPlay'])['isLateralMovement'].mean() * 100) \\\\n    .unstack('isInjuryPlay').plot(kind='barh', figsize=(10, 5),\\n                                  title='Time Spent in Lateral Movement')\\n\\n# set individual bar lables using above list\\nfor i in ax.patches:\\n    # get_width pulls left or right; get_y pushes up or do...  \n",
       "4144497  # No evidence to support a link between playing surface and lateral movement\\n\\nPrevious observational studies have shown a link between injury and playing surface. My analysis for this report identifies an association between NC injuries and lateral movement during game play. Now I wonder: is there a measurable difference between time spent in lateral movement based  on playing surface? My hypothesis would be that, if players gain more traction when interacting with a type of turf, then I w...  \n",
       "4144498  fig, ax= plt.subplots(1,1, figsize=(15, 5))\\nsns.distplot(tracks.query('FieldType == \"Natural\"')['o_dir_diff'].dropna(),\\n             hist=False, label='Natural', color='darkgreen')\\nsns.distplot(tracks.query('FieldType == \"Synthetic\"')['o_dir_diff'].dropna(),\\n             hist=False, label='Synthetic', color='mediumseagreen')\\nax.set_ylabel('% of play time')\\nax.set_xlabel('Orientation-Movement Angle')\\nax.set_title('Player movement angle by Turf Type')\\nax.legend(['Natural Turf', 'Synthe...  \n",
       "4144499                                                                                                                                                                                                                                        from scipy.stats import ks_2samp\\n\\nks_stat = ks_2samp(tracks.query('FieldType == \"Natural\"')['o_dir_diff'].dropna(),\\n        tracks.query('FieldType == \"Synthetic\"')['o_dir_diff'].dropna())[0]\\nprint(f'The Kolmogorov-Smirnov statistic on 2 samples is {ks_stat:0.4f}')  \n",
       "4144500                                                                                                                                                                                                             I also compared the differences of time spent in lateral movement by field type. I broke down the percentages by positions in a similar manner to how I compared injury plays to non-injury plays. I found more commonalities than differences. The difference for each position  were all less than 1%.  \n",
       "4144501  injury_prone_pos = ['Wide Receiver', 'Linebacker', 'Defensive Back']\\nmy_colors = list(islice(cycle(['darkgreen','mediumseagreen']), None, 3))\\nax = (tracks.query('Position_inj in @injury_prone_pos and isRushPass') \\\\n    .groupby(['Position_inj','FieldType'])['isLateralMovement'].mean() * 100) \\\\n    .unstack('FieldType').plot(kind='barh', figsize=(10, 5),\\n                               title='Time Spent in Lateral Movement',\\n                               color=my_colors)\\n\\n# set indivi...  \n",
       "4144502  I  created a regression model to capture any difference in the percent of lateral movement by player, based on features about the play. The regression included:\\n- Position (one-hot-encoded)\\n- PlayerDay (integer sequence reflecting timeline of a players participation in games)\\n- PlayerGame (Uniquely identifies player’s games)\\n- PlayerGamePlay (Ordered interger denoting the running count of plays the player has participated in during the game)\\n- Synthetic (binary indicator if field type i...  \n",
       "4144503  # Data Prep for linear model\\n\\nplay_movement_dir = tracks.loc[tracks['Position_inj'].isin(injury_prone_pos) &\\n                               tracks['isRushPass']] \\\\n    .groupby(['PlayKey','PlayerKey','OffsetAngleGroup','Position_inj','FieldType',\\n              'isInjuredPlayer','isInjuryPlay']) \\\\n    .count()['counter'] \\\\n    .unstack('OffsetAngleGroup') \\\\n    .fillna(0)\\nplay_mov_pct = play_movement_dir.apply(lambda x: 100 * x / float(x.sum()), axis=1)\\nplay_mov_pct = play_mov_pct.r...  \n",
       "4144504  from sklearn.linear_model import LinearRegression\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import mean_absolute_error\\n\\nimport statsmodels.api as sm\\nfrom scipy import stats\\n\\n\\nFEATURES = ['PlayerDay','PlayerGame','PlayerGamePlay','Rush','Temperature','Defensive Back',\\n            'Linebacker', # , DB and WR as 0 is equalt\\n            'Wide Receiver',\\n            'Synthetic','isInjuryPlay']\\nX = play_mov_pct_w_feats[FEATURES]\\nX['isInjuryPlay'] = X['i...  \n",
       "4144505  This model wasn’t created for its predictive power, but rather as  an attempt to quantify the impact of each feature and its statistical significance. The R-squared value is quite low, however we can still gain insights from the model. The main insights are as follows:\\n1. The position type (Defensive Back, Linebacker, or Wide Receiver) has the strongest relationship with lateral movement.\\n2. Injury Play is also a strong indicator, this supports our analysis above.\\n3. Synthetic playing sur...  \n",
       "4144506  ## Conclusion and Recommendations\\n\\nSo there you have it. I've shown that high lateral movements have a strong relationship with injury plays. I've also shown that there isn't a relationship between playing surface and lateral movement. Because of that we can't conclude that turf type plays a role in increasing this specific type of high risk movement.\\n\\nGiven my findings I have the following suggestions for the NFL:\\n1. Monitor the percentage of lateral movement of players during game pla...  \n",
       "4144507  # References\\n- Murphy, D F. “Risk Factors for Lower Extremity Injury: a Review of the Literature.” British Journal of Sports Medicine, vol. 37, no. 1, Jan. 2003, pp. 13–29., doi:10.1136/bjsm.37.1.13.\\n- Stockman, J.a. “Incidence, Causes, and Severity of High School Football Injuries On FieldTurf Versus Natural Grass: A 5-Year Prospective Study.” Yearbook of Pediatrics, vol. 2006, 2006, pp. 333–335., doi:10.1016/s0084-3954(07)70202-6.\\n- Powell, John W., and Mario Schootman. “A Multivariate ...  \n",
       "4144508                                                                                                                                                                                                                                                                                                                                                                                            # Appendix\\n\\n## Details of Regression analysis\\n\\nExpand the cell below to see the full details of the regression model.  \n",
       "4144509                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                print(est2.summary())  \n",
       "4144510  ## Machine Learning Model\\nBelow is an approach I worked on that did not provide conclusive results. I created three machine learning model based on players movement patterns. These models tried to predict using only player movement:\\n- What surface type was the player on\\n- If it was raining\\n- If it was snowing\\n\\nI chose these three models because I assumed that players movements would be impacted by rain and snow. If I was able to show similar accuracy when trying to predict playing surf...  \n",
       "4144511  # Preparing model training data\\ntracks_model = tracks.loc[(tracks['time_since_snap'] < 5) &\\n                           tracks['isRushPass'] &\\n                           tracks['isInjuryPronePos']]\\n\\ntracks_model['a'] = tracks_model['a'].astype('float32')\\ntracks_model['s'] = tracks_model['s'].astype('float32')\\n\\n# Every Play is a row, - create features for every 10th of a second up until 5 seconds after snap\\npp_piv = tracks_model[['PlayKey',\\n                       'time_since_snap',\\n...  \n",
       "4144512  plt.style.use('default')\\nax = pp_piv[o_dir_diff_cols].head(50).T \\\\n    .plot(title='Orientation-Movement Angle over first 5 seconds of play',\\n          figsize=(15, 4), color='grey')\\nax.get_legend().remove()\\nplt.show()\\nax = pp_piv[a_cols].head(50).T \\\\n    .plot(title='Acceleration over first 5 seconds of play',\\n         figsize=(15, 4), color='brown')\\nax.get_legend().remove()\\nplt.show()\\nax = pp_piv[s_cols].sample(50).T \\\\n    .plot(title='Speed over first 5 seconds of play',\\n    ...  \n",
       "4144513  # Add features for percipitation and snow based on weather feature\\nweather_percip_mapping = {\\n    'Controlled Climate' : False,\\n    'Sunny' : False,\\n    0 : False,\\n    'Cloudy' : False,\\n    'Clear' : False,\\n    'N/A Indoor' : False,\\n    'Partly sunny' : False,\\n    'N/A (Indoors)' : False,\\n    'Sunny and clear' : False,\\n    'Partly Cloudy' : False,\\n    'Snow' : True,\\n    'Indoor' : False,\\n    'Indoors' : False,\\n    'Showers' : True,\\n    'Rain' : True,\\n    'Clear and warm' : F...  \n",
       "4144514                                                                                                                                                                                                                                                                                                                                    ## Show the first few rows of features used in the model\\n- s -> speed features\\n- a -> acceleration features\\n- o_dir_diff -> angle difference between orientation and direction  \n",
       "4144515  # Add position\\npp_piv = pp_piv.merge(tracks_model[['Position_inj','PlayKey']].drop_duplicates(), on='PlayKey', how='left')\\npp_piv = pd.concat([pp_piv, pd.get_dummies(pp_piv['Position_inj'])], axis=1)\\npp_piv['Position_inj'] = pp_piv['Position_inj'].astype('category')\\n# Perform a train / test split\\nX = pp_piv.drop(['FieldType','PlayKey','isSynthetic','PlayType','Temperature',\\n                 'PlayerGame','PlayerDay','Weather','PlayerKey',\\n                 'Precipitation', 'Snow'], axis...  \n",
       "4144516  params = {}\\nparams['max_bin'] = 50\\nparams['learning_rate'] = 0.01\\nparams['boosting_type'] = 'gbdt'\\nparams['objective'] = 'binary'\\nparams['metric'] = 'auc'\\n\\n##################################################\\n# TRAIN MODEL TO PREDICT FIELD TYPE (isSynthetic)\\n##################################################\\n\\nX = pp_piv.drop(['FieldType','PlayKey','isSynthetic','PlayType','Temperature',\\n                 'PlayerGame','PlayerDay','Weather','PlayerKey',\\n                 'Precipitatio...  \n",
       "4144517  ##################################################\\n# TRAIN MODEL TO PREDICT PRECIPITATION\\n##################################################\\n\\nX = pp_piv.drop(['FieldType','PlayKey','isSynthetic','PlayType','Temperature',\\n                 'PlayerGame','PlayerDay','Weather','PlayerKey',\\n                 'Precipitation', 'Snow'], axis=1)\\ny = pp_piv['Precipitation']\\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=529)\\n\\nd_train = lgb.Dataset(X_train, label=y_train...  \n",
       "4144518  #####################################\\n# TRAIN MODEL TO PREDICT IF SNOWING\\n#####################################\\n\\nX = pp_piv.drop(['FieldType','PlayKey','isSynthetic','PlayType','Temperature',\\n                 'PlayerGame','PlayerDay','Weather','PlayerKey',\\n                 'Precipitation', 'Snow'], axis=1)\\ny = pp_piv['Snow']\\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=529)\\n\\nd_train = lgb.Dataset(X_train, label=y_train)#, categorical_feature=['PlayerKey'])...  \n",
       "4144519                                                                                                                                                                                                                                                                                                     # Concat results\\nfi_df = pd.concat([fi_df_lgbm_model_SNOW, fi_df_lgbm_model_FieldType, fi_df_lgbm_model_PRECIP], axis=1)\\nfi_df.columns = ['snow_importance','fieldtype_importance','precipitation_importance']  \n",
       "4144520  fig, axes = plt.subplots(1,3,figsize=(15, 5))\\nfi_df.sort_values('fieldtype_importance', ascending=True).tail(10)[['fieldtype_importance']] \\\\n    .plot(kind='barh', ax=axes[0], title='Top 10 Features to predict FieldType')\\nfi_df.sort_values('precipitation_importance', ascending=True).tail(10)[['precipitation_importance']] \\\\n    .plot(kind='barh', ax=axes[1], title='Top 10 Features to predict precipitation')\\nfi_df.sort_values('snow_importance', ascending=True).tail(10)[['snow_importance']...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xp = gezi.load(f'{root}/{p2t_model}/valid.pkl')\n",
    "# d = pd.DataFrame(xp)\n",
    "# d[d.id=='1a7d96060f8e36']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "828c32aa8796f4caf0c9fde9f523bba8dbc7385abbb3ec2757d19a79cb47766b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
